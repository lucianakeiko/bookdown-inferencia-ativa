\cleardoublepage 

\renewcommand{\[}{\begin{equation}}
\renewcommand{\]}{\end{equation}}

# (APPENDIX) Apêndice{-} 

# Bases Matemáticas

## Introdução

Este apêndice oferece uma introdução (ou uma atualização) às técnicas matemáticas básicas empregadas ao longo deste livro. Fornecemos uma visão geral introdutória (mas não exaustiva) de quatro tópicos: álgebra linear, aproximação de séries de Taylor, cálculo variacional e dinâmica estocástica. Para cada uma dessas técnicas, nos referimos a onde ela entra em jogo no livro. Nosso objetivo aqui é fornecer uma introdução focada - com ênfase na construção da intuição em oposição a provas formais e rigorosas. A matemática necessária para entender e usar a Inferência Ativa não é complicada, mas sua base multidisciplinar significa que muitas vezes é difícil encontrar recursos que reúnam os pré-requisitos necessários. Esperamos que este apêndice ajude de alguma forma a remediar isso.

## Álgebra Linear

### O básico

Álgebra linear refere-se a uma notação usada para expressar de forma simples e concisa combinações de multiplicações e somatórias. Ele se baseia em matrizes e vetores que compreendem matrizes de números em estruturas com várias linhas e colunas (ou várias linhas e uma única coluna, para um vetor). O elemento de uma matriz $A$ na linha $i$ e na coluna $j$ é referido como $A_{ij}$. O produto $A$ de duas matrizes $B$ e $C$ (ou uma matriz e um vetor) é definido da seguinte forma:


$$ A = BC $$
$$\Longrightarrow \qquad (A.1)$$
$$ A_{ij} = \sum_k B_{ik} C_{kj} $$
Para que essa definição seja válida, precisamos que o número de colunas de B corresponda ao número de linhas de C. No entanto, digamos que o número de colunas de B corresponda às colunas de C e queremos expressar a seguinte soma:

$$ A_{ij} = \sum_k B_{ki} C_{kj} \qquad (A.2) $$

Como faríamos isso usando a notação algébrica linear? Precisamos apelar para outra operação que troque os índices subscritos de B (ou seja, reflita a matriz de modo que as colunas se tornem linhas e vice-versa). Esta é a operação de transposição, normalmente expressa usando um T sobrescrito:

$$B_{ik}^T \triangleq B_{ki}$$

$$A=B^TC \triangleq B \cdot C$$

$$ \Longrightarrow \qquad (A.3)$$
$$A_{ij} = \sum_k B_{ki}C_{kj}$$

A Equação A.3 mostra como podemos usar o operador de transposição para expressar a soma da equação A.2. A segunda linha destaca uma notação alternativa usando um operador de ponto. Essa notação é inspirada no fato de que, quando B e C têm apenas uma coluna cada, a equação A.3 se reduz a um produto vetorial vetorial.
Outra operação útil é o operador de rastreamento. Isso pega os elementos ao longo da diagonal de uma matriz quadrada e os soma:

$$ tr[A] \triangleq \sum_i A_{ij} \qquad (A.4)$$

Parte da utilidade de um operador de traço é proporcionada pela maneira como podemos permutar elementos no traço de um produto de matriz:

$$ tr[ABC] = \sum_i \sum_j \sum_k A_{ij} B_{jk} C_{ki}$$
$$ = \sum_k \sum_i \sum_j C_{ki} A_{ij} B_{jk} = tr[CAB] $$
$$ = \sum_j \sum_k \sum_i B_{jk} C_{ki} A_{ij} = tr[BCA] \qquad (A.5) $$
O principal uso que encontraremos para essa identidade neste livro é quando aplicada a grandezas escalares. Um escalar pode ser visto como uma matriz com apenas uma linha e uma coluna. Como tal, podemos aplicar um operador de rastreamento a ele, mas isso não fará nada - obtemos o mesmo escalar. Isso significa que, se um produto de matriz der origem a uma quantidade escalar, podemos permutar os termos como acima.


Por exemplo, se tivermos uma matriz quadrada $B$ com $N$ colunas e linhas e um vetor $c$ com $N$ linhas, podemos usar a equação A.5 para mostrar o seguinte:


$$ a = c \cdot Bc$$

$$ tr[c^T Bc] $$
$$ tr[Bcc^T] \qquad (A.6)$$
$$ tr[BC]$$
$$ C = c \otimes c \triangleq cc^T  $$
Isso reexpressa uma expressão quadrática (primeira linha) com o traço do produto de duas matrizes (penúltima linha). A linha final define o produto externo(em contraste com o produto escalar interno)

A Equação A.6 torna-se particularmente útil no contexto de distribuições normais multivariadas, como veremos na seção A.2.3. 

Os conceitos finais de álgebra linear a serem observados são o inverso e o determinante de uma matriz. Uma inversa é definida da seguinte forma:

$$ A^{-1}A = AA^{-1} = I \qquad (A.7)$$

A Equação A.7 diz que o produto de uma matriz e sua inversa é a matriz identidade — uma matriz quadrada com uns ao longo de sua principal e zeros em outros lugares. Multiplicar qualquer matriz pela matriz identidade retorna a matriz original, inalterada. É o equivalente algébrico linear da multiplicação escalar por 1 (que pode ser interpretado como uma matriz identidade unidimensional). Isso significa que se multiplicarmos algo por uma matriz e depois pela inversa dessa matriz, acabamos com a quantidade original.

O determinante é uma quantidade útil, mas para a qual é mais difícil desenvolver uma intuição clara. O único ponto em que aparece neste livro é como parte da constante normalizadora de uma distribuição normal multivariada. Como tal, vale a pena saber como é calculado, mas não nos deteremos neste conceito. O determinante é definido recursivamente da seguinte forma:

$$ |A| \triangleq \sum_i(-1)^{i-1}A_{}1i | A_{\setminus(1,i)} |  $$


Aqui, a notação ted. Por exemplo:
$A_{\setminus(1, i)}$ significa a matriz A com linha 1 e coluna i omitidas. Por exemplo:

$$ A = 
\begin{bmatrix} 
  A_{11} A_{12} \\ 
  A_{21} A_{22} 
  \end{bmatrix}
  $$


$$ A_{\setminus(1,1)} = A_{22}$$
$$ A_{\setminus(1,2)} = A_{21} \qquad (A.9)$$
$$ |A| = A_{11} \; |A_{22}| -  A_{12} \;| A_{21}|$$
$$  A_{11}A_{22} - A_{12}A_{21} $$
Isso conclui nosso esboço das operações básicas da álgebra linear.



### Derivadas

A diferenciação de grandezas matriciais e vetoriais segue diretamente da aplicação do cálculo padrão a cada elemento de uma matriz. Por exemplo, se temos uma matriz B cujos elementos são funções de um escalar x, a derivada de B em relação a x é a seguinte:

$$ A(x) = \partial_x B(x)  $$
$$ A(x)_{ij} = \partial_x B(x)_{ij} \qquad (A.10)$$
$$ \partial x \triangleq  \frac {\partial} {\partial x} $$
No entanto, algumas definições e identidades importantes serão úteis para entender os detalhes técnicos deste livro. A primeira é como obter derivadas em relação a quantidades não escalares. Se tivermos uma quantidade vetorial b que é função de outro vetor c, a derivada de b em relação a c é uma matriz:


$$ A = \partial_c b(c) \Longrightarrow A{ij} = \partial_{c_j}b(c)_i  \qquad (A.11)$$
Também faremos uso do operador gradiente, que trata de derivadas em relação a um vetor. Isso é definido da seguinte forma:

$$ \nabla_b = \begin{bmatrix} 
\partial_{b_1} &  \partial_{b_1} & \partial_{b_1} & \cdots 
\end{bmatrix}^T  $$

$$ a = \nabla_bx(b) \qquad (A.12)$$

$$ \Longrightarrow $$

$$ a_i = \partial_{b_i}x(b)$$
A definição do operador gradiente como um vetor de operadores derivativos também fornece uma definição concisa de uma quantidade relacionada - a divergência de uma função vetorial:


$$ \nabla_a \cdot b(a) = \sum_i \partial_{a_i}b(a)_i \qquad (A.13)$$

Existem muitas identidades derivadas úteis para grandezas algébricas lineares, mas não tentaremos fornecer uma visão geral abrangente; para os leitores que desejam se aprofundar mais, recomendamos The Matrix Cookbook (Petersen e Pedersen 2012). Aqui, nos limitamos a duas identidades que serão particularmente úteis. O primeiro é o gradiente de uma quantidade quadrática:


$$ d(a) = \nabla_a(b(a) \cdot Cb(a))$$
$$ \Longrightarrow$$
$$d(a)_i$$







# As equações da inferência ativa

## Introdução

Neste apêndice, fornecemos um resumo matemático da Inferência Ativa. Isso complementa as equações nos capítulos principais com detalhes sobre de onde elas vêm e visa preencher algumas das etapas intermediárias omitidas. Isso baseia-se diretamente no fundo matemático do apêndice A e lida com inferência em processos de decisão Markov parcialmente observados (POMDP) e arquiteturas de codificação preditivas, e aborda questões de aprendizagem de estrutura e redução de modelo aludidas no texto principal. Nosso objetivo é que isso seja relativamente autocontido, com foco particular em tópicos que frequentemente causam confusão. Os leitores devem ter certeza de que não é necessário entender tudo neste apêndice para poder aplicar utilmente a Inferência Ativa; isso é mais para quem quer maior
detalhe técnico.

## Processos de decisão de Markov

### Inferência do Estado

Ao resolver um problema de POMDP, nosso objetivo é selecionar o curso de ação ou política apropriado. Sob Inferência Ativa, isso é enquadrado como um problema de inferência, no qual devemos encontrar uma distribuição de probabilidade posterior sobre políticas alternativas. Para calcular uma probabilidade posterior, precisamos de duas coisas: a probabilidade anterior de políticas (abordadas na seção B.2.2) e a probabilidade de observações de uma política. Esta seção se concentra neste último.

A probabilidade de observações dada uma política não é simples de calcular. Isso ocorre porque um problema POMDP é estruturado de forma que as políticas (π) influenciem as trajetórias (indicadas por ~) dos estados (s) que influenciam os resultados (o) sem uma influência direta das políticas nos resultados. O problema então envolve uma soma sobre trajetórias de estados para marginalizá-los e encontrar
uma probabilidade marginal de observações dadas políticas:

$$P(\tilde o | \pi ) = \sum_\tilde S P(\tilde o | \tilde s)P(\tilde s | \tilde \pi ) \qquad\qquad\qquad (B.1) $$
Para qualquer espaço de estado não trivial, essa soma pode ser muito desafiadora para calcular, de uma perspectiva computacional. No entanto, como veremos no capítulo 2, podemos aproximar probabilidades marginais desse tipo usando um funcional de energia livre. Os capítulos 2-4 descrevem a energia livre como funcional de duas coisas: crenças posteriores aproximadas (
Q ) e um modelo generativo (P). Isso nos permite expressar a energia livre para uma determinada política da seguinte forma:

$$ F(\pi)=\mathbb E_{Q(\tilde S|\pi)}[\ln Q(\tilde S|\pi)-\ln P(\tilde O, \tilde S|\pi)]\ge ln P(\tilde o|\pi)  \qquad (B.2)$$
$$Q(\tilde S|\pi) = \begin{matrix}arg\; min\;\\Q \end{matrix} F(\pi) \Rightarrow F(\pi) \approx - \ln P(\tilde O|\pi)  $$

A Equação B.2 nos diz algo simples, mas importante. Para poder inferir o que fazer, precisamos aproximar uma probabilidade marginal de uma política. Para encontrar uma boa aproximação dessa probabilidade marginal, precisamos otimizar nossas crenças sobre os estados sob essa política. Em suma, a inferência perceptual é obrigatória para que o planejamento prossiga. Então, como vamos resolver esse problema na prática? A resposta é apelar para os métodos descritos na seção A.4.2. Ao escolher formas explícitas para as distribuições de probabilidade na equação B.1, podemos encontrar uma expressão simples para a energia livre:

$$Q(\tilde s|\pi) = \prod_\tau Q(S_\tau|\pi):Q(S_\tau|\pi)=Cat(\mathbf s_{\pi\tau})$$
$$P(\tilde o | \tilde S) = \prod_\tau P(o_\tau|s_\tau):P(o_\tau|s_\tau)=Cat(A) \qquad (B.3)$$
$$P(\tilde S|\pi) = P(S_1)\prod_\tau P(s_{\tau+1}|s_\tau,\pi):P(s_{\tau+1}|s_\tau,\pi)=Cat(\mathbf B_{\pi\tau}) \\P(S_1) = Cat(\mathbf D)$$

Resumidamente, a primeira linha da equação B.3 define crenças sobre estados em termos de uma aproximação de campo médio (ver equação A.41), fatorada ao longo do tempo. Cada ponto no tempo está associado a uma crença sobre o que seria o estado ao perseguir uma política, dado pelo vetor sπτ, cujos elementos são as probabilidades de cada estado alternativo. A trajetória de observações na segunda linha depende de uma trajetória de estados ocultos, com a matriz (ou tensor, se os estados forem ainda fatorados) A indicando a distribuição sobre as observações para cada estado. Da mesma forma, a trajetória anterior dos estados sob um modelo compreende as probabilidades de transição sob aquela política (Bπτ) e as probabilidades iniciais dos estados (D). Substituindo-os na expressão de energia livre na Equação B.2, chegamos à seguinte expressão para a energia livre sob uma política:

$$\bf F_\pi = \mathbf s_{\pi1}(\ln \mathbf s_{\pi1} - \ln \mathbf A\cdot o_1-\ln \mathbf D)+ \sum S_{\pi\tau} \cdot (\ln \mathbf s_{\pi\tau} - \ln \mathbf A \cdot o_{\tau} - \ln \mathbf B_{\pi\tau}\mathbf s_{\pi\tau-1} )\qquad\qquad\qquad(B.4)  $$
Observe que o produto escalar de um vetor de probabilidade com outra quantidade é equivalente à operação de expectativa. Consulte a seção A.2.1 se isso não estiver claro. A Equação B.4 trata os resultados como se fossem vetores de probabilidade, mas com um no elemento correspondente ao resultado observado e zeros em outro lugar (às vezes chamado de codificação one-hot ou vetor 1-in-k). O desafio agora é minimizar a energia livre em relação às nossas crenças sobre estados (sπτ) para garantir que a energia livre se torne uma boa aproximação de uma probabilidade marginal. Poderíamos fazer isso como na seção A.4.2 e minimizar em relação a cada fator de nossas crenças, um de cada vez, iterando até convergir. No entanto, como estamos interessados em esquemas biologicamente mais plausíveis, podemos construir um sistema dinâmico que converge na mesma solução. Essa abordagem é conhecida como gradiente descendente, pois seguimos os gradientes de energia livre para baixo até chegarmos ao mínimo.

Para atualizar crenças sobre estados, tomamos o gradiente disso em relação às crenças atuais sobre estados. Em seguida, definimos uma variável auxiliar (v) que desempenha o papel de logaritmo e a configuramos para realizar um gradiente descendente na energia livre. Este log posterior é então passado por uma função softmax[^1101] (σ ) para convertê-lo em uma distribuição de probabilidade normalizada. Esse processo garante que as crenças sobre os estados mudem de tal forma que diminuam a energia livre.


[^1101]: Uma função exponencial normalizada

$$ S_{\pi\tau} = \sigma(\mathbf V_{\pi\tau}) \mathbf V_{\pi\tau} \\
 \dot V_{\pi\tau} = - \nabla_{S_{_\pi\tau}}\mathbf F_\pi \qquad\qquad\qquad  (B.5) \\ 
 \nabla_{S{\pi\tau}}\mathbf F_\pi = \ln S_{\pi\tau} - ln A \cdot o_\tau - \ln \mathbf B_{\pi\tau}\mathbf s_{\pi\tau-1}- \ln \mathbf B_{\pi\tau+1}\mathbf \cdot s_{\pi\tau+1}$$

A Equação B.5 tem a mesma solução para o esquema variacional de passagem de mensagens descrito na equação A.42. Ele permite a computação eficiente de crenças posteriores usando apenas informações derivadas localmente (neste caso, de dados sensoriais, crenças sobre o passado imediato e crenças sobre o futuro imediato). No entanto, vale a pena notar que a aproximação de campo médio usada aqui (fatoração ao longo do tempo) muitas vezes leva a posteriores superconfiantes. Na prática, isso pode ser combatido usando um esquema modificado chamado passagem de mensagens marginal (Friston, FitzGerald et al. 2017; Parr, Markovic et al. 2019):


$$ \bf \dot V_{\pi\tau} = \pmb\epsilon_{\pi\tau} \\ 
\pmb \epsilon_{\pi\tau} = \ln \pmb A \cdot o_\tau + \frac{1}{2}(\ln (B_{\pi\tau+1}\pmb s_{\pi\tau-1} )) + \ln (B^\dagger_{\pi\tau+1}\pmb s_{\pi\tau+1} )) - \ln \pmb s_{\pi\tau} \qquad (B.6)\\ 
B^\dagger_{\pi\tau} \propto B^T_{\pi\tau} 
$$

Isso leva a inferências mais conservadoras, com maior incerteza atribuída a crenças posteriores. Outras alternativas foram exploradas, incluindo a aproximação de Bethe (Schwöbel et al. 2018). No entanto, no momento da redação deste artigo, a implementação mais amplamente utilizada do Active Inference emprega a passagem de mensagens marginal.

### Planejamento como Inferência

A seção acima trata da inferência sobre estados condicionados a alguma política para minimizar uma energia livre condicionada à política. Essa energia livre desempenha o papel de uma probabilidade marginal logarítmica negativa (evidência do modelo), em que cada política é tratada como um modelo. Equipando isso com crenças anteriores e posteriores sobre a política mais provável, podemos expressar a energia livre como um funcional de crenças sobre políticas.


$$F = \mathbb E_{Q(\pi)}[lnQ(\pi)-\ln P(\pi,\tilde o)] \\ 
\approx \mathbb E_{Q(\pi)}[lnQ(\pi) +F(\pi) -\ln P(\pi)]  \qquad (B.7)\\
P(\pi) = Cat(\pmb \pi_0) \\
Q(\pi) = Cat(\pmb \pi) \\
\pi_0 = \sigma(\ln \pmb E - \pmb G)
$$


A igualdade aproximada na segunda linha vem da equação B.2. Aqui, E é um vetor de crenças fixas sobre políticas (isso pode ser pensado como um termo de viés, ou hábito), enquanto G é a energia livre esperada para cada política. Como antes, agora podemos escrever a energia livre em termos de estatísticas suficientes:

$$F = \pmb \pi \cdot (\ln \pmb\pi - \ln \pmb E + \pmb F + \pmb G )$$

Aqui, $F$ é um vetor cujos elementos são $F_π$ conforme definido na equação B.4. Tomando os gradientes, encontramos a atualização ideal para crenças sobre políticas (ou seja, planejamento):

$$ \nabla_\pi F = 0 \Longleftrightarrow \\ \pi=\sigma(\ln \pmb E-\pmb F - \pmb G )$$



### Aprendendo


Para possibilitar o aprendizado, precisamos incorporar crenças prévias sobre os parâmetros das distribuições de probabilidade que compõem o modelo generativo. Como estes são expressos como distribuições categóricas, a escolha apropriada (conjugada) de prior é uma distribuição de Dirichlet. Tomando a priori sobre os estados iniciais como exemplo, os termos da energia livre que dependem da priori esperada (log) incluem o seguinte:

$$F = ... + D_{KL}[Q(D) ||P(D)]- \mathbb E_{Q(S_1)Q(D)}[\ln P(S_1 | D)] \\
= ... +(\pmb d - d ) \cdot \mathbb E_{Q(D)}[ln D]- \pmb s_1 \cdot \mathbb E_Q(D) [ln D]\\
E_{Q(D)}[\ln \pmb D] = \psi(\pmb d) - \psi(\pmb d_0) \qquad\qquad\qquad (B.10)\\
d_o = \sum_i\pmb d_i\\
Q(D) \triangleq Dir(\pmb d)\\
P(D) \triangleq Dir (d) 
$$

A equação B.10 destaca na terceira igualdade uma identidade útil. A expectativa do logaritmo de uma variável distribuída de Dirichlet é a diferença entre duas funções digamma $(ψ)$ —onde a função digamma é a derivada de uma função gama. Podemos usar a equação **B.10** para encontrar o mínimo de energia livre:

$$\nabla_{\mathbb E{[\ln \pmb D]}}F = \pmb d - d -s_1 = 0 \Longleftrightarrow \pmb d = d +s_1 \qquad (B.11) $$

Isso fornece um esquema simples que pode ser usado para atualizar os parâmetros Dirichlet anteriores para seus valores posteriores. Regras de atualização muito semelhantes se aplicam às outras distribuições de probabilidade que compõem o modelo generativo:


$$
\pmb a = a + \sum_\tau o_\tau \otimes \pmb s_\tau \\
\pmb b_{\pi\tau} = b_{\pi\tau} + \sum_\tau s_{\pi\tau} \otimes s_{\pi\tau-1} \\
\pmb c = c + \sum_\tau o_\tau \\
\pmb d = d + s_1 \\
\pmb e = e + \pi
$$

Estes simplesmente dizem que quando a coisa prevista pelo termo relevante na distribuição de probabilidade acontece (que pode ser uma combinação de duas coisas para probabilidades condicionais), nós simplesmente aumentamos esse elemento da matriz de probabilidade para sinalizar que é mais provável volte a acontecer no futuro. 


### Precisão

Em algumas configurações, pode ser conveniente parametrizar o modelo generativo de uma maneira ligeiramente diferente. Uma opção aqui é usar uma medida de Gibbs, onde as distribuições de probabilidade são equipadas com um parâmetro de temperatura inverso que desempenha o papel de uma precisão. Mais comumente, isso é feito para a precisão $(γ)$ sobre as políticas:

$$P(\pi | \gamma) = Cat(\pmb \pi_0) \\ 
\pmb \pi_o = \sigma(-\gamma \pmb G) \qquad (B.13)
$$

Por simplicidade, omitimos o vetor E para esta seção. No que segue, também consideraremos uma precisão para a verossimilhança (ζ) e para transições (ω). A distribuição a priori sobre os parâmetros de precisão é considerada uma distribuição gama:

$$
P(\zeta) \propto \beta_\zeta \;exp(\beta_\zeta \zeta) \\ 
P(\omega) \propto \beta_\omega \;exp(\beta_\omega \omega)  \qquad (B.14)\\
P(\gamma) \propto \beta_\gamma \;exp(\beta_\gamma \gamma) \\
$$


As distribuições posteriores aproximadas têm a mesma forma (distribuição gama), e usaremos um hiperparâmetro beta em negrito para distinguir entre as estatísticas suficientes da posterior e da anterior acima. Uma propriedade útil da distribuição gama, quando parametrizada desta forma, é a seguinte:

$$
\begin{equation}
\zeta = \mathbb E_{Q(\zeta)}[\zeta] = \pmb \beta^{-1}_{\zeta} \qquad\qquad  \\
\omega = \mathbb E_{Q(\omega)}[\omega] = \pmb \beta^{-1}_{\omega}  \qquad (B.15)\\ 
\gamma = \mathbb E_{Q(\gamma)}[\gamma] = \pmb \beta^{-1}_{\gamma} \qquad\qquad 
\end{equation}
$$

Tendo definido essas distribuições, podemos escrever a energia livre variacional:
$$
\begin{equation}
F = \mathbb E_Q[F(\pi, \zeta, \omega) + D_{KL}[Q(\pi) || P(\pi | \gamma)]] \qquad (B.16) \\ 
+ D_{KL}[Q(\gamma) || P(\gamma)] + D_{KL}[Q(\omega)||P(\omega)]+D_{KL}[Q(\zeta) || P(\zeta)] 
\end{equation}
$$

Isso pode ser expresso em termos de suas estatísticas suficientes (omitindo constantes):



$$\begin{equation}

F = \pmb \pi \cdot (F+ \ln \pmb \pi + \gamma \cdot \pmb G + \ln \pmb Z(\pmb \gamma)) + \ln \pmb \beta_\gamma + \ln \pmb \beta_\omega + \ln \pmb \beta_\zeta \\
- \ln \pmb \beta_\gamma - \ln \pmb \beta_\omega - \ln \pmb \beta_\zeta + \pmb \gamma \beta_\gamma + \pmb \omega \beta_\omega + \pmb \zeta \beta_\zeta \qquad (B.17) \\
\pmb F_\pi \approx - \sum_\tau \pmb s_{\pi\tau} \cdot(\zeta \ln \pmb A \cdot o_\tau + \pmb \omega \ln \pmb B_{\pi\tau}\pmb s_{\pi\tau -1} - \ln \pmb Z(\zeta) \cdot o_\tau - \ln Z(\pmb \omega)\pmb s_{\pi\tau-1})

\end{equation}$$


Na equação B.17, $\pmb Z$representa funções de partição (ou seja, constantes de normalização) dadas pelo seguinte:

$$ \pmb Z(\zeta)_j = \sum_i(A_{ij})^\zeta \\
\pmb Z(\omega)_j = \sum_i(B_{\pi\tau ij})^\omega \\
\pmb Z(\gamma_j = \sum_\pi exp(-\gamma \cdot \pmb G_\pi) \\
\Rightarrow \qquad\qquad\qquad\qquad (B18) \\
\partial_\zeta \ln \pmb Z(\zeta)\pmb s_\tau = o^\zeta_\tau \cdot \ln \pmb A \\
\partial_\zeta \ln \pmb Z(\omega)\pmb s_{\pi\tau-1} = s^\omega_{\pi\tau} \cdot \ln \pmb B_\pi \\
\partial_\gamma \ln \pmb Z(\gamma) = -\pi_o \cdot  \pmb G \\
\pmb o_\tau^\zeta \triangleq \sigma(\zeta \ln \pmb A)\pmb s_\tau \\
\pmb s_{\pi\tau}^\omega \triangleq \sigma( \omega \ln \pmb B_{\pi\tau}) \pmb s_{\pi\tau-1} \\
\pmb \pi_o \triangleq \sigma(-\gamma \pmb G)$$


Tomando a derivada parcial[^B172] em relação às precisões esperadas, obtém-se:


$$\begin{Bmatrix} \partial_\zeta F\\ \partial_\omega F \\ \partial_\gamma F \end{Bmatrix} = 0 
\Leftrightarrow \begin{Bmatrix} \beta_\zeta \\ \beta_\omega \\ \beta_\gamma \end{Bmatrix}
=\begin{Bmatrix} \sum_\tau(o^\zeta_\tau - o_\tau) \cdot ln \pmb A + \beta_\zeta \\ \sum_\tau \pi \cdot(s^\omega_{\pi\tau}-s_{\pi\tau}) \cdot \ln \pmb B_\pi \pmb s_{\pi\tau-1} + \beta_\omega \\ (\pi - \pi_0)\cdot G + \beta_\gamma  \end{Bmatrix} \qquad (B.19)$$


[^B172]: Para concisão, omitimos alguns termos nas derivadas das funções de partição de log. Estamos autorizados a fazê-lo pela escolha da distribuição variacional, pois quaisquer termos polinomiais de ordem superior violariam a forma dessa distribuição.

Expressar essas atualizações como descidas de gradiente biologicamente plausíveis fornece as equações resultantes:


$$\begin{Bmatrix} \pmb {\dot \beta}_\zeta \\ \pmb {\dot \beta}_\omega \\  \pmb {\dot \beta}_\gamma \end{Bmatrix}
=\begin{Bmatrix} \sum_\tau(o^\zeta_\tau - o_\tau) \cdot ln \pmb A + \beta_\zeta - \pmb \beta_\zeta \\ \sum_\tau \pi \cdot(s^\omega_{\pi\tau}-s_{\pi\tau}) \cdot \ln \pmb B_\pi \pmb s_{\pi\tau-1} + \beta_\omega - \pmb \beta_\omega \\ (\pi - \pi_0)\cdot G + \beta_\gamma - \pmb \beta_\gamma  \end{Bmatrix} \qquad (B.19)$$

Observe que a dimensionalidade implica em um vetor (linha) de precisões para A, onde cada estado (coluna de A) está associado ao seu próprio parâmetro de precisão.

### Energia Livre Esperada

A energia livre esperada é discutida extensivamente no texto principal do livro. Nesta seção, complementamos essa discussão com duas coisas. Primeiro, oferecemos um breve esboço do pensamento atual sobre por que essa é a quantidade apropriada para definir crenças anteriores sobre políticas. Em segundo lugar, abordamos os detalhes de implementação para calcular essa quantidade.

Embora simulações numéricas (do tipo ilustrado no capítulo 7) tenham estabelecido que a energia livre esperada é útil, a questão de por que ela é útil ainda é uma área de pesquisa ativa. Antecipando que esta discussão continuará a evoluir, aqui apresentamos um breve resumo da explicação mais parcimoniosa no momento da escrita (Da Costa et al. 2020; Friston, Da Costa et al. 2020). O ponto de partida é estipular que um sistema atinge algum estado estacionário (ver seção A.5.2) ou, equivalentemente, cumpre suas preferências (definidas aqui em relação aos estados latentes) em algum momento futuro (τ ):



$$ Q(S_\tau)=\mathbb E_Q(\pi)[Q(S_\tau|\pi)]=P(S_\tau|C) \qquad\qquad (B.21) $$



Nosso desafio é encontrar o $Q(\pi)$ que satisfaça a equação B.21. Para isso, notamos que a equação B.21 implica o seguinte:

$$D_KL[Q(\pi|S_\tau)Q(S_\tau) || Q(\pi|S_\tau)P(S_\tau|C)]=0 \\ 
\Longrightarrow 
\\ \mathbb E_{Q(\pi,S_\tau)}[\ln Q(\pi,S_\tau)] = \mathbb E_{Q(\pi,S_\tau)}[\ln Q(\pi|S_\tau) + \ln P(S_\tau|C)] \qquad (B.22)$$

Em seguida, fatoramos o lado esquerdo para isolar o termo Q(π) em que estamos interessados:


$$\\ \mathbb E_{Q(\pi)}[\ln Q(\pi)] = \mathbb E_{Q(\pi,S_\tau)}[\ln Q(\pi|S_\tau) + \ln P(S_\tau|C) - \ln P(S_\tau|\pi)] \qquad (B.23)$$

Definimos uma variável $\alpha$ que representa a razão de duas entropias:

$$ \alpha = \frac{\mathbb E_{Q(s_\tau)}[H[Q(\pi| S_\tau)]]}{\mathbb E_{Q(S_\tau,\pi)}[H[P(O_\tau| S_\tau)]]} \qquad (B.24)$$

Heuristicamente, $\alpha$ expressa a gama relativa de resultados comportamentais (ou seja, políticas) que são plausíveis em um determinado estado, em comparação com a gama de resultados esperados nesse mesmo estado. Se muito grande, isso pode descrever uma criatura cujo comportamento tem pouca relação com o estado de seu mundo, apesar de observações sensoriais altamente precisas sendo geradas por esse mundo. Quando muito pequeno, isso pode descrever uma criatura que sempre se comporta da mesma maneira quando conhece o estado do mundo, mas raramente recebe dados precisos sobre esse mundo. Aqui, estipularemos que estamos interessados ​​em sistemas cujo $α = 1$ – implicando uma troca relativamente equilibrada e simétrica com seu mundo. Isso torna as duas entropias na equação B.24 iguais. Voltando à equação B.23:

$$\mathbb E_{Q(\pi)}[\ln Q(\pi)] = - \mathbb E_{Q(s_\tau)}[] \\
+ \mathbb E_{Q(\pi,s_\tau)}[\ln P(S_\tau | C) - \ln Q(S_\tau |\pi)] \\
=- \mathbb E_{Q(s_\tau,\pi)}[H[P(O_\tau, S_\tau)]] \\
- \mathbb E_{Q(\pi)}[D_{KL}[Q(S_\tau|\pi)||P(S_\tau|C)]] \\$$

A segunda linha segue da primeira e da equação B.24 com $\alpha=1$. Vemos agora que a equação B.25 e, portanto, a equação B.21, é satisfeita escolhendo o seguinte:


$$\ln Q(\pi) = \underbrace{- \mathbb E_{Q(S_\tau|\pi)}[H[P(O_\tau |S_\tau]] }_{ambiguidade \; esperada} - \underbrace{D_{KL}[Q(S_\tau|\pi) || P(S\tau |C)]}_{Risco}  \qquad (B.26)\\

$$

Nosso passo final é observar a relação entre a quantidade do lado direito e a energia livre esperada – com preferências definidas em termos de observações no lugar de estados:

$$
\mathbb E_{Q(S_\tau\pi)} \\
= \mathbb E_{Q(S_\tau\pi)} \\
+ \underbrace {\mathbb E_{Q(S_\tau\pi)P(O_\tau|S_\tau)}}_{=0} \\
=\mathbb E_{Q} \qquad (B.27) \\
=\mathbb E_{Q} \\
+ \mathbb E_{Q} \\
\ge  \mathbb E_{Q} \\
$$







































