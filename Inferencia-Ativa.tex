% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  12pt,
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Inferencia Ativa},
  pdfauthor={Thomas Parr, Giovanni Pezzulo, and Karl J. Friston},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Inferencia Ativa}
\author{Thomas Parr, Giovanni Pezzulo, and Karl J. Friston}
\date{2022-07-30}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}
\listoffigures
\listoftables
O Princípio da Energia Livre na Mente, Cérebro e Comportamento.

\hypertarget{conteuxfado}{%
\chapter*{Conteúdo}\label{conteuxfado}}
\addcontentsline{toc}{chapter}{Conteúdo}

\begin{enumerate}
\def\labelenumi{(\Roman{enumi})}
\tightlist
\item
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Visão geral\\
\item
  O caminho mais curto para a inferência ativa\\
\item
  O caminho mais árduo para a inferência ativa\\
\item
  Os Modelos Geradores de Inferência Ativa\\
\item
  Passagem de mensagens e neurobiologia
\end{enumerate}

\begin{enumerate}
\def\labelenumi{(\Roman{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Uma receita para projetar modelos de inferência ativos
\item
  Inferência ativa em tempo discreto
\item
  Inferência Ativa em Tempo Contínuo
\item
  Análise de dados baseada em modelo
\item
  Inferência Ativa como uma Teoria Unificada do Comportamento Sentiente
\end{enumerate}

Apêndice A: Fundamentos Matemáticos\\
Apêndice B: As Equações da Inferência Ativa\\
Apêndice C: Um Exemplo comentado do Código Matlab\\
Notas\\
Referências\\
Índice

\hypertarget{prefuxe1cio}{%
\chapter*{Prefácio}\label{prefuxe1cio}}
\addcontentsline{toc}{chapter}{Prefácio}

\textbf{Karl Friston}

A Inferência Ativa é uma maneira de entender o comportamento sentiente. O próprio fato de você estar lendo estas linhas significa que você está se engajando na Inferência Ativa - ou seja, criando amostras do mundo - de uma forma particular - porque você acredita que vai aprender alguma coisa. Você está apalpando esta página com os olhos simplesmente porque esse é o tipo de ação que resolverá a incerteza sobre o que você verá a seguir e -- de fato -- o que essas palavras transmitem. Em suma, a Inferência Ativa coloca a ação na percepção, em que a percepção é tratada como inferência perceptiva ou teste de hipóteses. A Inferência Ativa vai ainda mais longe e considera o planejamento como uma inferência -- isto é, inferir o que você faria a seguir para resolver a incerteza sobre o seu mundo vivido.

Para ilustrar a simplicidade da Inferência Ativa - e o que estamos tentando explicar - coloque a ponta dos dedos suavemente na perna. Mantenha-os lá imóveis por um segundo ou dois. Agora, sua perna está áspera ou lisa? Se você tivesse que mover os dedos para evidenciar uma sensação de aspereza ou suavidade, descobriu um fundamento da Inferência Ativa. Sentir é palpar. Ver é olhar. Ouvir é ouvir. Essa palpação não precisa necessariamente ser aberta -- podemos agir disfarçadamente, direcionando nossa atenção para isso ou aquilo. Em suma, não estamos simplesmente tentando dar sentido às nossas sensações; temos que criar ativamente nosso sensório. No que se segue, veremos por que isso tem que ser o caso e por que tudo o que percebemos, fazemos ou planejamos está na bússola de um imperativo existencial -- auto-evidente.

A Inferência Ativa não é apenas sobre leitura ou busca epistêmica. É, em um ponto de vista, algo que todas as criaturas e partículas fazem, em virtude de sua existência. Isso pode soar como uma afirmação forte; no entanto, fala do fato de que a Inferência Ativa herda de um princípio de energia livre que iguala existência com autoevidência e autoevidência com um tipo enativo de inferência. No entanto, este livro não está preocupado com a física dos sistemas sencientes. Seu foco está nas implicações dessa física para entender como o cérebro funciona.

Essa compreensão não é um negócio fácil, como testemunham milênios de filosofia natural e séculos de neurociência. Embora se possa encontrar as raízes da Inferência Ativa em relatos de primeiros princípios do comportamento auto-organizado (ou seja, princípios variacionais semelhantes ao princípio de ação estacionária de Hamilton), os primeiros princípios não ajudam muito quando se pergunta como um cérebro específico funciona e como ele difere de outro cérebro. Por exemplo, comprometer-se com a teoria da evolução por seleção natural não ajuda em nada quando se trata de entender por que tenho dois olhos ou falo francês. Este livro trata do uso de princípios para fundamentar questões-chave em neurociência e inteligência artificial. Para fazer isso, temos que ir além dos princípios e entender a mecânica à qual os princípios se aplicam.

Como tal, a Inferência Ativa -- e sua mecânica Bayesiana que a acompanha -- existe para formular questões sobre como percebemos, planejamos e agimos. Fundamentalmente, ele não visa substituir outras estruturas, como psicologia comportamental, teoria da decisão e aprendizado por reforço. Em vez disso, espera abraçar todas as abordagens que se mostraram tão bem-sucedidas dentro de uma estrutura unificada. A seguir, daremos atenção especial à ligação de construtos-chave da psicologia, neurociência cognitiva, enativismo, etologia e assim por diante ao cálculo da atualização de crenças na Inferência Ativa -- e suas teorias de processo associadas.

Por teorias de processo, nos referimos a teorias sobre como a atualização de crenças é realizada por processos neuronais (e outros biofísicos) no cérebro incorporado e além. O trabalho até agora em Active Inference oferece um conjunto bastante simples de arquiteturas computacionais e ferramentas de simulação para modelar vários aspectos de um cérebro em funcionamento e permitir que as pessoas testem hipóteses sobre diferentes arquiteturas computacionais. No entanto, essas ferramentas resolvem apenas metade do problema. No coração da Inferência Ativa está um modelo generativo --- ou seja, uma representação probabilística de como as causas não observáveis no mundo lá fora geram as consequências observáveis --- nossas sensações. Acertar o modelo generativo -- como uma explicação adequada para o comportamento senciente de qualquer sujeito ou criatura experimental -- é o grande desafio.

Este livro tenta explicar como enfrentar esse desafio. A primeira parte estabelece as ideias e formalismos básicos que são invocados na segunda parte -- para ilustrar como eles podem ser aplicados na prática. Resumindo, este livro é para pessoas que desejam usar a Inferência Ativa para simular e modelar o comportamento senciente, a serviço da investigação científica ou, possivelmente, da inteligência artificial. Assim, ele se concentra nas ideias e procedimentos que são necessários para entender e implementar um esquema de Inferência Ativa sem se distrair com a física dos sistemas sencientes, por um lado ou filosofia do outro.

\textbf{Uma nota de Karl Friston}

Eu tenho uma confissão a fazer. Eu não escrevi muito neste livro. Ou, mais precisamente, não me foi permitido. A agenda deste livro exige um estilo de escrita nítido e claro que está além de mim. Embora me tenham permitido colocar algumas de minhas palavras favoritas, o que se segue é uma prova de Thomas e Giovanni, sua profunda compreensão das questões em questão e, mais importante, sua teoria da mente -- em todos os sentidos.

\textbf{Agradecimentos}

Agradecemos a contribuição inestimável de nossos amigos e colegas - em particular, membros anteriores e atuais do grupo de Neurobiologia Teórica do Wellcome Center for Human Neuroimaging, University College London; o Laboratório Cognição em Ação (CONAN) do Instituto de Ciências e Tecnologias Cognitivas, Conselho Nacional de Pesquisa da Itália; e numerosos colaboradores internacionais que foram essenciais para o desenvolvimento das ideias apresentadas neste livro. Esta comunidade jovem, mas em crescimento, tem sido mais do que generosa em fornecer apoio intelectual e motivação. Além disso, agradecemos a Robert Prior e Anne-Marie Bono, do MIT Press, por nos acompanharem e aconselharem durante a preparação deste livro e a Jakob Hohwy e outros revisores atenciosos por sua orientação. Finalmente, agradecemos às agências de financiamento que forneceram apoio financeiro para nossa pesquisa: KJF foi financiada por uma bolsa de pesquisa principal do Wellcome Trust (Ref: 088130/Z/09/Z); O GP foi financiado pelo Conselho Europeu de Pesquisa sob o Contrato de Subvenção Nº 820213 (ThinkAhead) e o Programa-Quadro Horizonte 2020 da União Europeia para Pesquisa e Inovação sob o Contrato de Subvenção Específico Nº 945539 (Projeto Cérebro Humano SGA3).

\hypertarget{visuxe3o-geral}{%
\chapter{Visão Geral}\label{visuxe3o-geral}}

O acaso favorece a mente preparada.
---Louis Pasteur

\hypertarget{introduuxe7uxe3o}{%
\section{Introdução}\label{introduuxe7uxe3o}}

Este capítulo apresenta a principal questão que a Inferência Ativa procura abordar: Como os organismos vivos persistem enquanto se envolvem em trocas adaptativas com seu ambiente? Discutimos a motivação para abordar essa questão a partir de uma perspectiva normativa, que parte dos primeiros princípios e depois descompacta suas implicações cognitivas e biológicas. Além disso, este capítulo apresenta brevemente a estrutura do livro, incluindo sua subdivisão em duas partes: a primeira visa ajudar os leitores a entender a Inferência Ativa e a segunda visa ajudá-los a usá-la em suas próprias pesquisas.

\hypertarget{como-os-organismos-vivos-persistem-e-agem-adaptativamente}{%
\section{Como os Organismos Vivos Persistem e Agem Adaptativamente?}\label{como-os-organismos-vivos-persistem-e-agem-adaptativamente}}

Os organismos vivos constantemente se envolvem em interações recíprocas com seu ambiente (incluindo outros organismos). Eles emitem ações que alteram o ambiente e recebem dele observações sensoriais, conforme ilustrado esquematicamente na \textbf{figura 1.1}

\begin{figure}
\centering
\includegraphics{images/Figura_1_1.png}
\caption{\textbf{Figura 1.1} Um ciclo de percepção de ação conectando reciprocamente uma criatura e seu ambiente. O termo ambiente é intencionalmente genérico. Nos exemplos que discutimos, pode incluir o mundo físico, o corpo, o ambiente social e assim por diante.}
\end{figure}

Os organismos vivos só podem manter sua integridade corporal exercendo controle adaptativo sobre o ciclo ação-percepção. Isso significa agir para solicitar observações sensoriais que correspondam a resultados ou objetivos desejados (por exemplo, as sensações que acompanham nutrientes seguros e abrigo para organismos simples, ou amigos e empregos para organismos mais complexos) ou que ajudem a entender o mundo (por exemplo, informando o organismo sobre seus arredores).

Engajar-se em loops de percepção de ação adaptativa com o ambiente apresenta desafios formidáveis \hspace{0pt}\hspace{0pt}para os organismos vivos. Isso se deve em grande parte à natureza recursiva do ciclo, onde cada observação, solicitada pela ação anterior, muda a forma como decidimos sobre a próxima ação, para solicitar a próxima observação. As possibilidades de controle e adaptação são muitas, mas muito poucas são úteis. No entanto, durante a evolução, os organismos vivos conseguiram desenvolver estratégias adaptativas para enfrentar os desafios fundamentais da existência. Essas estratégias variam em seu nível de sofisticação cognitiva, com soluções mais simples e rígidas em organismos mais simples (por exemplo, seguindo gradientes de nutrientes em bactérias) e soluções mais cognitivamente exigentes e flexíveis em organismos mais avançados (por exemplo, planejando atingir objetivos distais em humanos). . Essas estratégias também variam de acordo com as escalas de tempo em que são selecionadas e operam - desde simples respostas a ameaças ambientais ou adaptações morfológicas que surgem em uma escala de tempo evolutiva, até padrões comportamentais estabelecidos durante o aprendizado cultural ou de desenvolvimento, até aqueles que exigem processos cognitivos que operam em escalas de tempo comparáveis à ação e percepção (por exemplo, atenção e memória).

\hypertarget{inferuxeancia-ativa-comportamento-a-partir-dos-primeiros-princuxedpios}{%
\section{Inferência Ativa: Comportamento a partir dos Primeiros Princípios}\label{inferuxeancia-ativa-comportamento-a-partir-dos-primeiros-princuxedpios}}

Essa diversidade é uma bênção para a biologia, mas desafiadora para as teorias formais do cérebro e da mente. Em termos gerais, há duas perspectivas que poderíamos assumir sobre isso. Uma perspectiva é que diferentes adaptações biológicas, processos neurais (por exemplo, trocas sinápticas e redes cerebrais) e mecanismos cognitivos (por exemplo, percepção, atenção, interação social) são altamente idiossincráticos e requerem explicações dedicadas. Isso levaria à proliferação de teorias em campos como filosofia, psicologia, neurociência, etologia, biologia, inteligência artificial e robótica, com pouca esperança de unificação. Outra perspectiva é que, apesar de suas diversas manifestações, os aspectos centrais do comportamento, cognição e adaptação nos organismos vivos são passíveis de uma explicação coerente desde os primeiros princípios.

Essas duas possibilidades mapeiam dois programas de pesquisa diferentes e, até certo ponto, diferentes atitudes em relação à ciência: ``puro'' versus ``desleixado'' (termos devidos a Roger Shank). Os puros sempre buscam a unificação além da (aparente) heterogeneidade dos fenômenos do cérebro e da mente. Isso geralmente corresponde a projetar modelos normativos\footnote{Aqui e ao longo do capítulo, o condicionamento ao modelo é deixado
  implícito; portanto, a evidência do modelo é escrita como \(P(y)\) e
  não \(P(y|m)\).} de cima para baixo que partem dos primeiros princípios e tentam derivar o máximo possível sobre cérebros e mentes. Os desleixados, em vez disso, abraçam a heterogeneidade, concentrando-se em detalhes que exigem explicações dedicadas. Isso geralmente corresponde a projetar modelos de baixo para cima que começam com dados e usam o que funciona para explicar fenômenos complexos, incluindo diferentes explicações para diferentes fenômenos.

É possível explicar fenômenos biológicos e cognitivos heterogêneos a partir de primeiros princípios, como supõem os puros? É possível uma estrutura unificada para entender o cérebro e a mente?

Este livro responde a essas perguntas afirmativamente e avança a Inferência Ativa como uma abordagem normativa para entender o cérebro e a mente. Nosso tratamento da Inferência Ativa parte dos primeiros princípios e desvenda suas implicações cognitivas e biológicas.

\hypertarget{estrutura-do-livro}{%
\section{Estrutura do Livro}\label{estrutura-do-livro}}

O livro compreende duas partes. Estes são voltados para leitores que desejam entender a Inferência Ativa (primeira parte) e aqueles que buscam usá-la para suas próprias pesquisas (segunda parte). A primeira parte do livro apresenta a Inferência Ativa tanto conceitualmente quanto formalmente, contextualizando-a dentro das atuais teorias da cognição. O objetivo desta primeira parte é fornecer uma introdução abrangente, formal e independente à Inferência Ativa: seus principais construtos e implicações para o estudo do cérebro e da cognição.

A segunda parte do livro ilustra exemplos específicos de modelos computacionais que usam a Inferência Ativa para explicar fenômenos cognitivos, como percepção, atenção, memória e planejamento. O objetivo desta segunda parte é ajudar os leitores a entender os modelos computacionais existentes usando a Inferência Ativa e criar novos modelos. Em suma, este livro se divide em teoria (parte 1) e prática (parte 2).

\hypertarget{parte-1-inferuxeancia-ativa-na-teoria}{%
\subsection{Parte 1: Inferência Ativa na Teoria}\label{parte-1-inferuxeancia-ativa-na-teoria}}

A Inferência Ativa é uma estrutura normativa para caracterizar o comportamento e a cognição de Bayes-ótimo\footnote{Tecnicamente, isso é verdade para qualquer função côncava, mas
  estamos preocupados apenas com logaritmos aqui.} em organismos vivos. Seu caráter normativo é evidenciado na ideia de que todas as facetas do comportamento e da cognição nos organismos vivos seguem um imperativo único: minimizar a surpresa de suas observações sensoriais. A surpresa deve ser interpretada em um sentido técnico: ela mede o quanto as observações sensoriais atuais de um agente diferem de suas observações sensoriais preferidas -- ou seja, aquelas que preservam sua integridade (por exemplo, para um peixe, estar na água). É importante ressaltar que minimizar a surpresa não é algo que pode ser feito observando passivamente o ambiente: em vez disso, os agentes devem controlar adaptativamente seus ciclos de percepção de ação para solicitar observações sensoriais desejadas. Este é o bit ativo da Inferência Ativa.

Minimizar a surpresa acaba sendo um problema desafiador por razões técnicas que se tornarão aparentes mais tarde. A Inferência Ativa oferece uma solução para esse problema. Ele assume que, mesmo que os organismos vivos não possam minimizar diretamente sua surpresa, eles podem minimizar um proxy -- chamado energia livre (variacional). Essa quantidade pode ser minimizada por meio de computação neural em resposta (e em antecipação) a observações sensoriais. Essa ênfase na minimização da energia livre revela a relação entre a Inferência Ativa e o (primeiro) princípio que a motiva: o princípio da energia livre (Friston 2009).

A minimização da energia livre parece um ponto de partida muito abstrato para explicar fenômenos biológicos. No entanto, é possível derivar uma série de implicações formais e empíricas a partir dele e abordar uma série de questões centrais na teoria cognitiva e neural. Estes incluem como as variáveis envolvidas na minimização da energia livre podem ser codificadas em populações neuronais; como os cálculos de energia livre minimizada mapeiam processos cognitivos específicos, como percepção, seleção de ações e aprendizado; e que tipo de comportamentos surgem quando um agente de Inferência Ativa minimiza sua energia livre.

Como a lista de tópicos acima exemplifica, neste livro estamos preocupados principalmente com a Inferência Ativa e a minimização da energia livre no nível dos organismos vivos -- mais simples (por exemplo, bacterianos) ou mais complexos (por exemplo, humanos) -- e seus aspectos comportamentais, cognitivos, processos sociais e neurais. Esse esclarecimento é necessário para contextualizar nosso tratamento da Inferência Ativa dentro do princípio de energia livre mais geral (FEP), que discute a minimização de energia livre em uma gama muito mais ampla de fenômenos biológicos e escalas de tempo além do processamento de informações neurais - variando de evolutivo a celular e cultural ( Friston, Levin et al.~2015; Isomura e Friston 2018; Palacios, Razi et al.~2020; Veissière et al.~2020)---que estão além do escopo deste livro.

É possível motivar a Inferência Ativa tomando um dos dois caminhos: um caminho alto e um caminho baixo; veja a figura 1.2. Esses dois caminhos fornecem duas perspectivas distintas, mas altamente complementares sobre a Inferência Ativa:

O caminho para a Inferência Ativa parte da questão de como os organismos vivos persistem e agem de forma adaptativa no mundo e motivam a Inferência Ativa como solução normativa para esses problemas. Essa perspectiva da estrada é útil para entender a natureza normativa da Inferência Ativa: o que os organismos vivos devem fazer para enfrentar seus desafios existenciais fundamentais (minimizar sua energia livre) e por quê (minimizar vicariamente a surpresa de suas observações sensoriais).

\begin{figure}
\centering
\includegraphics{images/Figura_1_2.png}
\caption{Figura 1.2 - duas estradas para a Inferência Ativa: a estrada principal (começando do canto superior direito) e a estrada inferior (começando do canto inferior esquerdo).}
\end{figure}

O caminho inferior para a Inferência Ativa começa com a noção do cérebro Bayesiano, que lança o cérebro como um motor de inferência tentando otimizar representações probabilísticas das causas de sua entrada sensorial. Em seguida, motiva a Inferência Ativa como uma aproximação variacional específica do problema inferencial (de outra forma intratável), que tem um grau de plausibilidade biológica. Essa perspectiva de baixo caminho é útil para ilustrar como os agentes de Inferência Ativa minimizam sua energia livre - ilustrando, portanto, a Inferência Ativa não apenas como um princípio, mas também como uma explicação mecanicista (também conhecida como teoria do processo) das funções cognitivas e seus fundamentos neuronais.

No capítulo 2, apresentamos a perspectiva do caminho mais baixo sobre a Inferência Ativa. Partimos de teorias fundamentais que lançam a percepção como um problema de inferência estatística (Bayesiana) (Helmholtz 1866) e sua encarnação moderna na hipótese do cérebro Bayesiano (Doya 2007). Veremos que para realizar tal inferência (perceptiva), os organismos vivos devem estar equipados com -- ou incorporar -- um modelo generativo probabilístico de como suas observações sensoriais são geradas, que codifica crenças (distribuições de probabilidade) sobre variáveis observáveis (observações sensoriais) e variáveis não observáveis (ocultas). Vamos estender essa visão inferencial além da percepção para cobrir problemas de seleção de ações, planejamento e aprendizado.

No capítulo 3, ilustramos a perspectiva complementar do caminho superior sobre a Inferência Ativa. Este capítulo apresenta o FEP e o imperativo para os organismos biológicos minimizarem a surpresa. Além disso, desvenda como esse princípio engloba a dinâmica da auto-organização e a preservação de uma fronteira estatística ou envoltório de Markov que mantém a separação do ambiente. Isso é vital para manter a integridade das criaturas biológicas e é central para sua autopoiese.

No capítulo 4, descompactamos a Inferência Ativa mais formalmente. Este capítulo se baseia na discussão do cérebro bayesiano no capítulo 2 e estabelece a relação matemática entre a dinâmica autoevidente do capítulo 3 e a inferência variacional. Além disso, este capítulo apresenta dois tipos de modelos generativos usados para formular problemas de Inferência Ativa. Estes incluem os processos de decisão Markov parcialmente observados usados para tomada de decisão e planejamento e os modelos dinâmicos de tempo contínuo que fazem interface com receptores sensoriais e músculos. Finalmente, vemos como a minimização de energia livre para cada um desses modelos se manifesta como uma atualização dinâmica de crenças.

No capítulo 5, passaremos dos tratamentos formais às implicações biológicas da Inferência Ativa. Partindo da premissa de que ``tudo o que muda no cérebro deve minimizar a energia livre'' (Friston 2009), discutiremos como as quantidades específicas envolvidas na minimização da energia livre (por exemplo, previsão, erro de previsão e sinais de precisão) se manifestam em dinâmica neuronal. Isso ajuda a mapear os princípios computacionais abstratos da Inferência Ativa para computações neurais específicas que podem ser executadas por substratos fisiológicos. Isso é importante na formação de hipóteses sob essa estrutura e garante que elas respondam aos dados medidos. Em outras palavras, o capítulo 5 apresenta a teoria do processo associada à Inferência Ativa.

Ao longo da primeira parte do livro, discutiremos vários aspectos característicos da Inferência Ativa. Eles destacam as maneiras pelas quais ela é diferente das estruturas alternativas que procuram explicar a regulação biológica e a cognição -- algumas das quais visualizamos aqui.

\begin{itemize}
\item
  Sob a Inferência Ativa, percepção e ação são duas formas complementares de cumprir o mesmo imperativo: a minimização da energia livre. A percepção minimiza a energia livre (e a surpresa) pela crença (bayesiana) atualizando ou mudando sua mente, tornando assim suas crenças compatíveis com as observações sensoriais. Em vez disso, a ação minimiza a energia livre (e a surpresa) mudando o mundo para torná-lo mais compatível com suas crenças e objetivos. Essa unificação das funções cognitivas marca uma diferença fundamental entre a Inferência Ativa e outras abordagens que tratam a ação e a percepção isoladamente uma da outra. Aprender é mais uma maneira de minimizar a energia livre. No entanto, não é fundamentalmente diferente da percepção; ele simplesmente opera em uma escala de tempo mais lenta. A complementaridade entre percepção e ação será desvendada no capítulo 2.
\item
  Além de direcionar a seleção de ações no presente para alterar os dados sensoriais atualmente disponíveis, a estrutura de Inferência Ativa acomoda o planejamento -- ou a seleção do curso de ação ideal (ou política) no futuro. A otimalidade aqui é medida em relação a uma energia livre esperada e é distinta da noção de energia livre variacional considerada acima no contexto de ação e percepção. De fato, enquanto o cálculo da energia livre variacional depende de observações presentes e passadas, o cálculo da energia livre esperada também requer observações futuras previstas (daí o termo esperado). Curiosamente, a energia livre esperada de uma política compreende duas partes. O primeiro quantifica até que ponto se espera que a política resolva a incerteza (exploração/prospecção) e o segundo quão consistentes os resultados previstos são com os objetivos de um agente (exploração/aproveitamento). Em contraste com outras estruturas, a seleção de políticas na Inferência Ativa equilibra automaticamente a prospecção e o aproveitamento. As relações entre a energia livre variacional e a esperada serão desvendadas no capítulo 2.
\item
  Sob a Inferência Ativa, todas as operações cognitivas são conceituadas como inferência sobre modelos generativos -- de acordo com a ideia de que o cérebro realiza cálculos probabilísticos -- também conhecido como a hipótese do cérebro Bayesiano. No entanto, o apelo a uma forma aproximada específica de inferência Bayesiana -- isto é, um esquema variacional que é motivado por primeiros princípios -- acrescenta especificidade à teoria do processo. Além disso, a Inferência Ativa estende a abordagem inferencial a domínios da cognição raramente considerados e adiciona alguma especificidade ao tipo de modelos e processos inferenciais que podem ser implementados por cérebros biológicos. Sob algumas suposições, a dinâmica que emerge dos modelos generativos usados na Inferência Ativa corresponde de perto a modelos difundidos na neurociência computacional, como a codificação preditiva (Rao e Ballard 1999) e a máquina de Helmholtz (Dayan et al.~1995). As especificidades do esquema variacional serão desvendadas no capítulo 4.
\item
  Sob a Inferência Ativa, tanto a percepção quanto a aprendizagem são processos ativos, por duas razões. Primeiro, o cérebro é essencialmente uma máquina preditiva, que prevê constantemente os estímulos recebidos, em vez de esperar passivamente por eles. Isso é importante, pois os processos perceptivos e de aprendizado são sempre contextualizados por previsões anteriores (por exemplo, estímulos esperados e inesperados afetam a percepção e o aprendizado de maneiras diferentes). Em segundo lugar, as criaturas envolvidas na Inferência Ativa buscam ativamente observações sensoriais salientes que resolvam sua incerteza (por exemplo, orientando seus sensores ou selecionando episódios de aprendizagem que sejam informativos). O caráter ativo da percepção e do aprendizado contrasta com a maioria das teorias atuais que os tratam como processos amplamente passivos; isso será descompactado no capítulo 2.
\item
  A ação é essencialmente direcionada a um objetivo e proposital. Ele começa a partir de um resultado ou objetivo desejado (análogo ao conceito de set-point na cibernética), que é codificado como uma previsão prévia. O planejamento prossegue inferindo uma sequência de ação que atende a essa previsão (ou equivalentemente, reduz qualquer erro de previsão entre a previsão anterior e o estado atual). O caráter da ação direcionada a objetivos na Inferência Ativa está de acordo com as primeiras formulações cibernéticas, mas é distinto da maioria das teorias atuais que explicam o comportamento em termos de mapeamentos estímulo-resposta ou políticas de ação do estado. A resposta ao estímulo ou comportamento habitual torna-se então um caso especial de uma família mais ampla de políticas em Inferência Ativa. A natureza direcionada a objetivos da Inferência Ativa será desvendada nos capítulos 2 e 3.
\item
  Várias construções de Inferência Ativa têm análogos biológicos plausíveis no cérebro. Isso implica que -- uma vez que se tenha definido um modelo generativo específico para um problema em mãos -- pode-se passar da Inferência Ativa como uma teoria normativa para a Inferência Ativa como uma teoria de processo, que faz previsões empíricas específicas. Por exemplo, a inferência perceptiva e a aprendizagem correspondem à alteração da atividade sináptica e à alteração da eficácia sináptica, respectivamente. A precisão das predições (na codificação preditiva) corresponde ao ganho sináptico das unidades de erro de predição. A precisão das políticas corresponde à atividade dopaminérgica. Algumas das consequências biológicas da Inferência Ativa serão desvendadas no capítulo 5.
\end{itemize}

\hypertarget{parte-2-inferuxeancia-ativa-na-pruxe1tica}{%
\subsection{Parte 2: Inferência Ativa na Prática}\label{parte-2-inferuxeancia-ativa-na-pruxe1tica}}

Enquanto a primeira parte do livro fornece aos leitores as ferramentas conceituais e formais para entender a Inferência Ativa, a segunda parte se concentra em questões práticas. Especificamente, esperamos fornecer aos leitores as ferramentas para entender os modelos existentes de Inferência Ativa de funções cognitivas (e disfunções) e projetar novos modelos. Para isso, discutimos exemplos específicos de modelos usando Inferência Ativa. É importante ressaltar que os modelos de Inferência Ativa podem variar em diferentes dimensões (por exemplo, com formulações de tempo discreto ou contínuo, inferência plana ou hierárquica). A segunda parte está estruturada da seguinte forma:

No capítulo 6, apresentamos uma receita para construir modelos de Inferência Ativa. A receita cobre as etapas essenciais para projetar um modelo eficaz, que incluem a identificação do sistema de interesse, a forma mais apropriada do modelo generativo (por exemplo, para caracterizar fenômenos de tempo discreto ou contínuo) e as variáveis específicas a serem incluídas no modelo. Este capítulo, portanto, oferece uma introdução aos princípios de design que sustentam os modelos discutidos nos capítulos seguintes.

No capítulo 7, discutimos modelos de Inferência Ativa que tratam de problemas formulados em tempo discreto; por exemplo, como modelos ocultos de Markov (HMMs) ou processos de decisão de Markov parcialmente observáveis (POMDPs). Nossos exemplos incluem um modelo de processamento perceptual e um modelo discreto de busca por escolhas - isto é, virar à esquerda ou à direita em um ponto de decisão para garantir uma recompensa. Também introduzimos tópicos como busca de informações, aprendizado e busca de novidades, que podem ser tratados em termos de Inferência Ativa em tempo discreto.

No capítulo 8, discutimos modelos de Inferência Ativa que tratam de problemas formulados em tempo contínuo, usando equações diferenciais estocásticas. Estes incluem modelos de percepção (como codificação preditiva), controle de movimento e dinâmica sequencial. Curiosamente, é na formulação de tempo contínuo que aparecem algumas das previsões mais distintivas da Inferência Ativa, como a ideia de que a geração de movimento decorre do cumprimento de previsões e que os fenômenos atencionais podem ser entendidos em termos de controle de precisão. Também introduzimos modelos híbridos de Inferência Ativa que incluem variáveis de tempo discreto e contínuo. Estes permitem a avaliação simultânea da escolha entre opções discretas (por exemplo, alvos para sacadas) e os movimentos contínuos resultantes da escolha (por exemplo, movimentos oculomotores).

No capítulo 9, ilustramos como usar modelos de Inferência Ativa para analisar dados de experimentos comportamentais. Discutimos as etapas específicas necessárias para a análise de dados baseada em modelos, desde a coleta de dados até a formulação de um modelo e sua inversão para apoiar a análise de dados de participantes individuais ou em nível de grupo.

No capítulo 10, discutimos as relações entre a Inferência Ativa e outras teorias em psicologia, neurociência, IA e filosofia. Destacamos também os aspectos mais importantes da Inferência Ativa que a distinguem das demais teorias.

Nos apêndices, discutimos brevemente a base matemática necessária para entender as partes mais técnicas do livro, incluindo as noções de aproximação de séries de Taylor, Laplace variacional, cálculo variacional e muito mais. Para referência, também apresentamos de forma concisa as equações mais importantes usadas na Inferência Ativa.

Em suma, a segunda parte do livro ilustra uma ampla variedade de modelos de fenômenos biológicos e cognitivos que podem ser construídos usando a Inferência Ativa e uma metodologia para projetar novos. Além do interesse dos modelos específicos, esperamos que nosso tratamento esclareça o valor de usar uma estrutura normativa unificada para abordar fenômenos biológicos e cognitivos de uma perspectiva coerente. No final das contas, este é o verdadeiro apelo das estruturas normativas: fornecer uma perspectiva unificada e um princípio orientador para reconciliar fenômenos aparentemente desconexos -- neste caso, fenômenos como percepção, tomada de decisão, atenção, aprendizado e controle de movimento, cada um tendo seu capítulo separado em qualquer psicologia ou manual de neurociência.

Os modelos destacados na segunda parte foram selecionados para ilustrar pontos específicos da forma mais simples possível. Embora cubramos vários modelos e domínios, desde decisões em tempo discreto até percepção de tempo contínuo e controle de movimento, estamos claramente desconsiderando muitos outros que são igualmente interessantes. Muitos outros modelos de Inferência Ativa existem na literatura que cobrem domínios tão diversos quanto a auto-organização biológica e as origens da vida (Friston 2013), morfogênese (Friston, Levin et al.~2015), robótica cognitiva (Pio-Lopez et al.~2016, Sancaktar et al.~2020), dinâmica social e construção de nicho (Bruineberg, Rietveld et al.~2018), a dinâmica das redes sinápticas (Palacios, Isomura et al.~2019), aprendizagem em redes biológicas (Friston e Herreros 2016), e condições psicopatológicas, como transtorno de estresse pós-traumático (Linson et al.~2020) e transtorno do pânico (Maisto, Barca et al.~2021). Esses modelos variam em muitas dimensões: alguns estão mais diretamente relacionados à biologia, enquanto outros menos; alguns são modelos de agente único, enquanto outros são modelos de múltiplos agentes; algumas inferências adaptativas alvo, enquanto outras inferências mal-adaptativas alvo (por exemplo, em grupos de pacientes), e assim por diante.

Essa literatura crescente exemplifica a crescente popularidade da Inferência Ativa e a possibilidade de usá-la em uma grande variedade de domínios. O objetivo deste livro é fornecer aos nossos leitores a capacidade de entender e usar a inferência ativa em sua própria pesquisa -- possivelmente, para explorar suas potencialidades imprevistas.

\hypertarget{resumo}{%
\section{Resumo}\label{resumo}}

Este capítulo apresenta brevemente a abordagem de Inferência Ativa para explicar problemas biológicos de uma perspectiva normativa - e prevê algumas implicações dessa perspectiva que serão desvendadas em capítulos posteriores. Além disso, este capítulo destaca a divisão do livro em duas partes, que visam auxiliar os leitores a compreender a Inferência Ativa e utilizá-la em suas próprias pesquisas, respectivamente. Nos próximos capítulos, desenvolveremos as perspectivas de baixo e alto caminho aqui descritas, antes de nos aprofundarmos na estrutura dos modelos generativos e na transmissão de mensagens resultante. Juntos, eles compreendem a Inferência Ativa em princípio e fornecem as preliminares para a Inferência Ativa na prática. Esperamos que esses capítulos convençam os leitores de que a Inferência Ativa oferece não apenas um princípio unificador sob o qual entender o comportamento, mas também uma abordagem tratável para estudar a ação e a percepção em sistemas autônomos.

\hypertarget{o-caminho-de-baixo-para-a-inferuxeancia-ativa}{%
\chapter{O Caminho de baixo para a Inferência Ativa}\label{o-caminho-de-baixo-para-a-inferuxeancia-ativa}}

My thinking is first and last and always for the sake of my ­doing. ---­William James

\hypertarget{introduuxe7uxe3o-1}{%
\section{Introdução}\label{introduuxe7uxe3o-1}}

Este capítulo introduz a Inferência Ativa partindo da visão helmholtziana --- ou talvez kantiana --- da ``percepção como inferência inconsciente'' (Helmholtz 1867) e ideias relacionadas que surgiram mais recentemente sob a hipótese do cérebro bayesiano. Ele explica como a Inferência Ativa engloba e estende essas ideias tratando não apenas a percepção, mas também a ação, o planejamento e o aprendizado como problemas de inferência (Bayesiana) e derivando uma aproximação baseada em princípios (variacional) para esses problemas de outra forma intratáveis.

\hypertarget{percepuxe7uxe3o-como-inferuxeancia}{%
\section{Percepção como Inferência}\label{percepuxe7uxe3o-como-inferuxeancia}}

Há uma longa tradição de ver o cérebro como uma ``máquina preditiva'', ou um órgão estatístico que infere e prevê estados externos do mundo. Essa ideia remonta à noção de ``percepção como inferência inconsciente'' (Helmholtz 1866). Mais recentemente, isso foi reformulado como a hipótese do ``cérebro bayesiano'' (Doya 2007). A partir dessa perspectiva, a percepção não é uma transdução puramente de baixo para cima de estados sensoriais (por exemplo, da retina) em representações internas do que está lá fora (por exemplo, como padrões de atividade neuronal). Em vez disso, é um processo inferencial que combina informações anteriores (de cima para baixo) sobre as causas mais prováveis \hspace{0pt}\hspace{0pt}das sensações com estímulos sensoriais (de baixo para cima). Os processos inferenciais operam em representações probabilísticas de estados do mundo e seguem a regra de Bayes, que prescreve a atualização (ótima) à luz da evidência sensorial. A percepção não é um processo passivo de fora para dentro -- no qual a informação é extraída de impressões em nosso epitélio sensorial de ``lá fora''. É um processo construtivo de dentro para fora -- no qual as sensações são usadas para confirmar ou refutar hipóteses sobre como elas foram geradas (MacKay 1956, Gregory 1980, Yuille e Kersten 2006, Neisser 2014, A. Clark 2015).

Por sua vez, realizar a inferência Bayesiana requer um modelo generativo -- às vezes chamado de modelo direto. Um modelo generativo é uma construção da teoria estatística que gera previsões sobre as observações. Pode ser formulado como a probabilidade conjunta \(P({\color{Red}x,\color{Orange}y)}\) das observações \(\color{Orange}y\) e os estados ocultos do mundo \(\color{Red}x\) que geram essas observações. Estes últimos são referidos como estados ocultos ou latentes, pois não podem ser observados diretamente. Esta probabilidade conjunta pode ser decomposta em duas partes. O primeiro é um \(P({\color{Red}x)}\) prévio, que denota o conhecimento do organismo sobre os estados ocultos do mundo antes de ver os dados sensoriais.

A segunda é a probabilidade \(P( y | x)\), que denota o conhecimento do organismo de como as observações são geradas a partir de estados. A regra de Bayes nos diz como combinar esses dois elementos, essencialmente atualizando uma probabilidade anterior \(P(x)\) em uma probabilidade posterior de estados ocultos após receber observações \(P(x | y)\). Para os leitores que precisam de uma breve atualização sobre a teoria básica da probabilidade, o \textbf{quadro 2.1} fornece um resumo.

A inferência bayesiana é um tópico amplo que surge em disciplinas como estatística, aprendizado de máquina e neurociência computacional. Um tratamento completo dos tópicos associados está além do escopo deste livro, mas há excelentes recursos disponíveis para aqueles que desejam entendê-lo em profundidade (Murphy 2012). No entanto, tudo isso é baseado em uma regra simples. Para ilustrar essa regra, consideramos um exemplo de inferência perceptiva Bayesiana (figura 2.1). Imagine uma pessoa que acredita fortemente que está diante de uma maçã. Essa crença corresponde a uma probabilidade anterior, ou abreviada. Essa priori compreende a probabilidade atribuída à hipótese da maçã e a probabilidade atribuída às hipóteses alternativas. Neste exemplo, nossa hipótese alternativa é que não é uma maçã, mas um sapo. Numericamente, a distribuição de probabilidade anterior atribui 0,9 à maçã e 0,1 à rã. Observe que, como assumimos que existem apenas duas hipóteses plausíveis (mutuamente exclusivas), elas devem somar um. A pessoa também está equipada com um modelo de probabilidade, que atribui uma alta probabilidade ao fato de que os sapos pulam, enquanto as maçãs não. Essa probabilidade especifica o mapeamento (probabilístico) dos dois estados ocultos (sapo ou maçã) para as duas observações (pula ou não pula). Juntos, o anterior e a probabilidade formam o modelo generativo da pessoa.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Quadro 2.1 As regras de soma e produto de probabilidade
\end{minipage} \\
\midrule
\endhead
O raciocínio probabilístico é sustentado por duas regras principais: as regras de soma e produto de probabilidade, que são as seguintes (respectivamente):\(\sum_{x} P(x)=1\) \(P(x)P(y|x)=P(x,y)\) A regra da soma diz que a probabilidade de todos os eventos possíveis \((x)\) deve somar (ou integrar) a um. A regra do produto diz que a probabilidade conjunta de duas variáveis aleatórias (\(x\) e \(y\)) pode ser decomposta no produto da probabilidade de uma variável (\(P(x)\)) e a probabilidade condicional da segunda variável dada a primeira (\(P(y|x)\)). Uma probabilidade condicional é a probabilidade de uma variável (aqui, \(y\)) se soubermos o valor que a outra variável (aqui, \(x\)) assume. Podemos desenvolver dois resultados importantes a partir dessas regras simples. A primeira é a operação de marginalização. A segunda é a regra de Bayes. A marginalização nos permite obter uma distribuição de apenas uma das duas variáveis de uma distribuição conjunta:\(\begin{matrix} \underbrace{\sum_{x}{P(x,y)}=\sum_{x}{P(y)P(x|y)}} \\ Regra\; do\; Produto \end{matrix}=\begin{matrix} \underbrace{P(x)\sum_{x}{P(x|y)}=P(y)} \\ Regra\; da\; Soma \end{matrix}\) A probabilidade de y é chamada de probabilidade marginal, e nos referimos a essa operação como marginalização de x. A regra de Bayes pode ser obtida diretamente da regra do produto: \(\begin{matrix} \underbrace{P(x)P(y|x)}=P(x,y)=\underbrace{P(y)P(x|y)}\\regra\;do\;produto\qquad \qquad regra\;do\;produto\end{matrix}\) Isso nos permite traduzir entre uma distribuição prévia e condicional (verossimilhança) e a marginal associada e a outra distribuição condicional (posterior). Simplificando, a regra de Bayes apenas diz que a probabilidade de duas coisas é a probabilidade da primeira, dada a segunda, vezes a probabilidade da segunda, que é o mesmo que a probabilidade da segunda, dada a primeira, vezes a probabilidade do primeiro. \\
\bottomrule
\end{longtable}

Agora imagine que a pessoa observa que seu sapo-maçã pula. A regra de Bayes nos diz como formar uma crença posterior a partir da anterior, levando em conta a probabilidade de pular. Essa regra é expressa da seguinte forma:

\[P(x|y)=\frac{P(x)P(y|x)}{P(y)}\]

\begin{figure}
\centering
\includegraphics{images/Figura2_1.png}
\caption{\textbf{Figura 2.1} Um exemplo simples de inferência Bayesiana. Superior esquerdo: A crença prévia P(x) do organismo sobre o objeto que ele verá, antes de ter feito qualquer observação, ou seja, uma distribuição categórica sobre duas possibilidades, maçã (com probabilidade 0,9) e sapo (com probabilidade 0,1). Superior direito: A crença posterior do organismo P(x \textbar{} y ) após observar que o objeto salta. Crenças posteriores podem ser calculadas usando a regra de Bayes sob uma função de verossimilhança P( y \textbar{} x). Isso é mostrado abaixo do anterior e do posterior e específica que, se o objeto for uma maçã, há uma probabilidade muito pequena (0,01) de que ele pule, enquanto se for um sapo, a probabilidade de pular é muito maior ( 0,81). (As barras de probabilidade nesta figura não estão exatamente em escala.) Neste caso específico, a atualização de anterior para posterior é grande.}
\end{figure}

Sob o modelo de verossimilhança da figura 2.1, a probabilidade posterior atribuída ao sapo é 0,9 e a probabilidade atribuída à maçã é 0,1. Conforme destacado no quadro 2.1, o denominador da equação 2.1 pode ser calculado marginalizando o numerador. Usando nosso exemplo do sapo-maçã, aproveitamos a oportunidade para descompactar duas noções diferentes de surpresa --- ambas importantes na Inferência Ativa. A primeira, a que nos referimos simplesmente como surpresa, é a evidência logarítmica negativa, onde a evidência é a probabilidade marginal das observações. Em nosso exemplo, esta é a probabilidade logarítmica negativa de observar qualquer coisa saltando sob o modelo generativo. A surpresa é uma quantidade muito importante do ponto de vista bayesiano. É uma medida de quão mal um modelo se ajusta aos dados que tenta explicar. Para colocar isso intuitivamente, podemos calcular a probabilidade do comportamento observado (pulo) sob nosso modelo. Lembre-se de que isso atribui uma probabilidade a priori muito alta às maçãs e uma probabilidade a priori baixa às rãs. Assim, nossa probabilidade marginal de pular é a seguinte:

\includegraphics{images/Prob Sapos Maças.png}

Isso significa que, sob esse modelo, esperaríamos observar o comportamento de pulor cerca de 9 vezes em 100 observações. Como tal, deveríamos nos surpreender ao observar isso se subscrevermos o modelo da figura 2.1. Podemos quantificar isso em termos de surpresa \((ℑ)\). Isso é dado por \(ℑ(y=pular) = −lnP(y=pular) = −ln(0,09) = 2,4 nats\) \footnote{Aqui e ao longo do capítulo, o condicionamento ao modelo é deixado
  implícito; portanto, a evidência do modelo é escrita como \(P(y)\) e
  não \(P(y|m)\).} . Quanto maior esse número, pior o modelo como explicação adequada para as observações em questão. Isso nos permite comparar modelos em relação aos dados. Por exemplo, considere um modelo alternativo, onde temos uma crença prévia de que os sapos são vistos 100\% do tempo. Seguindo os mesmos passos da equação 2.2, calculamos uma surpresa de cerca de 0,2 nats. Este é um modelo melhor desses dados, pois a observação é muito menos surpreendente. O procedimento de pontuação de modelos com base em suas evidências (ou surpresa) é frequentemente chamado de comparação de modelos bayesianos. Para modelos mais complicados, a forma da surpresa pode não ser tão simples.

A \textbf{Tabela 2.1} fornece a forma da surpresa (omitindo constantes) para uma série de distribuições de probabilidade -- além da probabilidade categórica em nosso exemplo. Crucialmente, isso nos permite falar sobre surpresa para distribuições de probabilidade cujo suporte\footnote{Tecnicamente, isso é verdade para qualquer função côncava, mas
  estamos preocupados apenas com logaritmos aqui.} difere do exemplo simples usado aqui. Isso é importante porque a maneira pela qual os dados sensoriais são gerados pelo mundo varia com o tipo de dados. Podemos nos surpreender ao encontrar o rosto de alguém que não esperávamos ver (distribuição categórica), ou podemos nos surpreender por estar mais frio do lado de fora do que prevíamos (distribuição contínua). A Tabela 2.1 pode ser vista como um portfólio das distribuições de probabilidade à nossa disposição quando passamos a construir modelos generativos em capítulos subsequentes. De maneira mais geral, ele afirma que a surpresa é um conceito que pode ser avaliado para qualquer família de distribuições de probabilidade.

\textbf{Tabela 2.1 Distribuições de probabilidade e surpresa\footnote{As estimativas MAP são os estados mais prováveis considerando as
  crenças anteriores e os dados disponíveis; contraste isso com
  abordagens de máxima verossimilhança que não levam crenças em conta.}}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2727}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4545}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2727}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\centering
Distribuição
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Suporte
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Surpresa\((ℑ)\)
\end{minipage} \\
\midrule
\endhead
Gaussiana\footnote{Casos especiais incluem distribuições categóricas \((K  > 2, N  =  1)\), binomial \((K  = 2, N  >  1)\) e Bernoulli \((K = 2, N  =  1)\)} & \(x\in\mathbb{R}\) & \(\frac{1}{2}(x-\mu)\prod(x-\mu)\) \\
Multinomial & \(x_{i}\in\left ( 0,\cdots, N \right )\) \({i}\in\left \{ 1 , \cdots , K \right \}\) \(\sum_i{x_i}=N\) & \(-\sum_i{x_i}\ln d_i\) \\
Dirichlet\footnote{Um caso especial é a distribuição beta \((K=2)\)} & \(x_{i}\in\left ( 0,1 \right )\) \({i}\in\left \{ 1 , \cdots , K \right \}\) \(\sum_i{x_i}=1\) & \(\sum(1 - \alpha_i)\ln(x_i)\) \\
Gamma & \(x\in(0,\infty)\) & \((bx+(1-a)\ln x)\) \\
\bottomrule
\end{longtable}

A segunda noção de surpresa é (um pouco confusa) referida como surpresa bayesiana. Esta é uma medida de quanto temos que atualizar nossas crenças após uma observação. Em outras palavras, a surpresa Bayesiana quantifica a diferença entre uma probabilidade anterior e uma posterior. Isso levanta a questão de como quantificamos a dissimilaridade de duas distribuições de probabilidade.

Uma resposta, da teoria da informação, é usar uma divergência de Kullback-Leibler (KL). Isso é definido como a diferença média entre duas probabilidades logarítmicas

\(D_{KL}[Q(x)||P(x)] \overset{\Delta}{=} \mathbb{E_{Q(x)}}[\ln{Q(x)} - \ln{P(x)}] \quad\quad\quad\quad\quad\quad\quad\quad\quad\quad \text{(2.3)}\)

O símbolo \(\mathbb{E}\) aqui indica uma média (ou expectativa) conforme descrito no \textbf{quadro 2.2}. Usando o KL-Divergence, podemos quantificar a surpresa Bayesiana do nosso exemplo:

\includegraphics{images/Surpresa Sapos Maças.png}

Isso pontua a quantidade de atualização de crenças, em oposição a simplesmente quão improvável era a observação. Para destacar a distinção entre surpresa e surpresa bayesiana, considere o que acontece se nos comprometermos com uma crença prévia de que sempre veremos maçãs. A surpresa bayesiana será zero, já que o prior está tão confiante que não o atualizamos seguindo nossas observações. No entanto, a surpresa é muito grande (4,6 nats), pois é altamente improvável que uma maçã salte.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Quadro 2.2 Expectativas}
\end{minipage} \\
\midrule
\endhead
É útil referir-se à expectativa de uma variável aleatória \(x\), geralmente denotada por \(\mathbb{E[x]}\). Esta é a média ponderada de todos os valores que a variável pode assumir, ponderada pela sua probabilidade. Para variáveis aleatórias discretas (que só podem receber um número contável de valores possíveis), isso é dado por uma soma ponderada: \(\mathbb{E(x)}=\sum_x{xP(x)}\) Por exemplo, para uma variável discreta (numérica) que só pode assumir dois valores (1 e 2) com igual probabilidade de \(\frac{1}{2}\), isto é \(\mathbb{E(x)}=1*\frac{1}{2}+2*\frac{1}{2}=\frac{3}{2}\). Para variáveis aleatórias contínuas (que podem ter infinitos valores), as somas são substituídas por integrais. As expectativas também podem ser aplicadas a funções de variáveis aleatórias, em oposição às variáveis diretamente. Por exemplo, se tivermos uma função f (x), onde x tem alguma distribuição contínua, a expectativa é definida como segue: \(\mathbb{E[f(x)]}=\int_{}^{} f(x)p(x)\, dx\)Usaremos essa notação ao longo deste livro, onde a função \(f (x)\) será frequentemente uma probabilidade logarítmica ou razão de probabilidade logarítmica. \\
 \\
\bottomrule
\end{longtable}

Observe que, embora tenhamos ilustrado a inferência bayesiana com base em um modelo generativo muito simples, ela se aplica a modelos generativos de qualquer complexidade. No capítulo 4, destacaremos duas formas de modelo generativo que subscrevem a maioria das aplicações em Inferência Ativa.

\hypertarget{inferuxeancia-bioluxf3gica-e-otimizauxe7uxe3o}{%
\section{Inferência Biológica e Otimização}\label{inferuxeancia-bioluxf3gica-e-otimizauxe7uxe3o}}

Há dois pontos importantes que conectam o esquema inferencial acima às teorias biológicas e psicológicas da percepção. Primeiro, o procedimento inferencial discutido requer a interação de processos de cima para baixo que codificam previsões (a partir do anterior) e processos de baixo para cima que codificam observações sensoriais (mediadas pela probabilidade). Essa interação de processos de cima para baixo e de baixo para cima distingue a visão inferencial de abordagens alternativas que consideram apenas processos de baixo para cima. Além disso, é central nos tratamentos biológicos modernos da percepção, como a codificação preditiva (discutida no capítulo 4), que é uma implementação algorítmica específica (ou em nível de processo) do esquema de inferência mais geral (bayesiano) discutido aqui.

Em segundo lugar, a inferência Bayesiana é ótima. A otimalidade é definida em relação a uma função de custo que é otimizada (ou seja, minimizada), que, por inferência Bayesiana, é conhecida como energia livre variacional -- intimamente relacionada à surpresa. Voltamos a isso na seção 2.5. Ao considerar explicitamente a distribuição completa sobre os estados ocultos, ele lida naturalmente com a incerteza, evitando as limitações de abordagens alternativas que consideram apenas estimativas pontuais de estados ocultos (por exemplo, o valor médio de x). Uma dessas alternativas seria a estimativa de máxima verossimilhança, que simplesmente seleciona o estado oculto mais provável de ter gerado os dados disponíveis. O problema com isso é que tais estimativas ignoram tanto a plausibilidade prévia do estado oculto quanto a incerteza em torno da estimativa. A inferência bayesiana não sofre essas limitações. No entanto, apesar do uso da surpresa para avaliar objetivamente se o modelo é adequado ao propósito, é importante apreciar que a inferência em si é subjetiva. Os resultados da inferência não são necessariamente precisos em nenhum sentido objetivo (ou seja, a crença do organismo pode não corresponder à realidade) por pelo menos duas razões importantes. Primeiro, as criaturas biológicas operam com base em recursos computacionais e energéticos limitados, que tornam a inferência Bayesiana exata intratável\footnote{Curiosamente, as limitações de recursos não são a única barreira para a inferência Bayesiana exata. Na presença de modelos complexos, a inferência exata pode ser analiticamente intratável, de modo que nenhum recurso adicional poderia ajudar a resolver o problema exato.} . Isso requer aproximações que excluem garantias de otimalidade Bayesiana exata. Essas aproximações incluem a noção de uma posterior variacional - baseada em algo chamado aproximação de campo médio - que é central para o capítulo 4.

A segunda razão pela qual a otimalidade pode ser pensada como subjetiva é que os organismos operam com base no modelo generativo de um sujeito de como suas observações são geradas, o que pode ou não corresponder ao processo generativo real que gera suas observações. Isso não quer dizer que o modelo generativo deva corresponder ao processo generativo. De fato, pode haver modelos que forneçam explicações melhores (por exemplo, mais simples) dos dados disponíveis do que os processos que realmente os geraram -- conforme quantificado por sua relativa surpresa. Um bom exemplo disso são as ilusões, para as quais alguém encontra uma explicação mais simples para sua entrada visual em relação a como os estímulos visuais foram cuidadosamente projetados por um psicofísico malicioso.

O próprio modelo generativo pode ser otimizado à medida que novas experiências são adquiridas. Isso pode ou não convergir para o processo generativo.

A \textbf{Figura 2.2} ilustra esse ponto e a diferença entre as verdadeiras contingências ambientais, ou o processo generativo, que é inacessível ao organismo e o modelo generativo do organismo do mundo. Neste exemplo em particular, o processo generativo está em um verdadeiro estado \(x*\) que é inacessível ao organismo. No entanto, o organismo e o mundo estão mutuamente acoplados, e \(x*\) gera uma observação \(y\), que o organismo sente. O organismo pode usar esta observação \(y\) e a regra de Bayes para inferir a (probabilidade posterior de) alguma variável explicativa ou estado oculto no modelo generativo. Na figura, nos referimos a \(x*\) e \(x\) como estados ocultos, enfatizando que nenhum deles é observável. No entanto, eles são sutilmente diferentes: o primeiro faz parte do modelo generativo do organismo, enquanto o último faz parte do processo generativo e inacessível ao organismo. Além disso, \(x*\) e \(x\) não vivem necessariamente no mesmo espaço. Pode ser que os estados ocultos no mundo externo assumam valores que estão fora do espaço de explicações disponíveis ao cérebro. Por outro lado, pode ser que as explicações do cérebro incluam variáveis que não existem no mundo exterior. Por exemplo, o primeiro pode ser de 5 dimensões e o último de 2 dimensões, ou um pode ser contínuo e o outro categórico.

\includegraphics{images/Figura2_2.png}
A distinção entre o modelo generativo e o processo é importante para contextualizar as afirmações psicológicas sobre a otimalidade da inferência -- na medida em que essas afirmações são válidas -- que, em uma visão bayesiana, é sempre contingente aos recursos do organismo. Por recursos, queremos dizer seu modelo generativo específico e recursos computacionais e mnemônicos limitados.

\hypertarget{auxe7uxe3o-como-inferuxeancia}{%
\section{Ação como Inferência}\label{auxe7uxe3o-como-inferuxeancia}}

A discussão até este ponto é comum a todas as teorias do cérebro Bayesianas. No entanto, agora apresentamos o avanço simples, mas fundamental, oferecido pela Inferência Ativa. Isso parte da mesma perspectiva inferencial discutida acima, mas a estende para considerar a ação como inferência. Essa ideia decorre do conceito de que a inferência bayesiana minimiza a surpresa (ou, equivalentemente, maximiza a evidência do modelo bayesiano). Até agora, consideramos o que acontece quando computamos a surpresa realizando inferências -- e selecionamos entre os modelos com base em sua capacidade de minimizar a surpresa. No entanto, a surpresa não depende apenas do modelo. Também depende dos dados. Ao agir no mundo para mudar a maneira como os dados são gerados, podemos garantir que um modelo seja adequado ao propósito, escolhendo os dados que são menos surpreendentes em nosso modelo.

Equipado com um mecanismo para produzir ações, um organismo pode se engajar em trocas recíprocas com seu ambiente; veja a figura 2.2. Nos animais, esse mecanismo assume a forma de um loop reflexo motor. Essencialmente, para cada ciclo de ação-percepção, o ambiente envia uma observação ao organismo. O organismo usa (uma aproximação da) inferência Bayesiana para inferir seus estados ocultos mais prováveis. Em seguida, gera uma ação e a envia para o ambiente na tentativa de tornar o ambiente menos surpreendente. O ambiente executa a ação, gera uma nova observação e a envia ao organismo. Em seguida, inicia-se um novo ciclo. A descrição sequencial aqui é escrita para fins didáticos; é importante perceber que estes não são realmente passos discretos, mas são processos dinâmicos contínuos.

A Inferência Ativa vai além do reconhecimento de que percepção e ação têm a mesma natureza (inferencial). Também pressupõe que tanto a percepção quanto a ação cooperam para realizar um único objetivo -- ou otimizar apenas uma função -- em vez de ter dois objetivos distintos, como mais comumente se supõe. Na literatura de Inferência Ativa, esse objetivo comum foi descrito de várias maneiras (informais e formais), incluindo a minimização de surpresa, entropia, incerteza, erro de previsão ou energia livre (variacional). Esses termos estão relacionados entre si, mas às vezes suas relações não são imediatamente claras, causando alguma confusão. Além disso, esses termos são usados em diferentes contextos; por exemplo, a minimização de erros de previsão é usada em contextos biológicos onde o objetivo é explicar os sinais cerebrais, enquanto a minimização de energia livre variacional é usada em aprendizado de máquina.

Nas próximas duas seções, esclareceremos que a única quantidade que os agentes de Inferência Ativa minimizam por meio da percepção e da ação é a energia livre variacional. No entanto, sob algumas condições, pode-se reduzir a energia livre variacional a outras noções, como a discrepância entre o modelo generativo e o mundo, ou a diferença entre o que se espera e o que se observa (ou seja, um erro de previsão). Introduziremos formalmente a energia livre variacional na seção 2.5. Para simplificar, a seção 2.4 concentra-se nas maneiras pelas quais a percepção e a ação minimizam a discrepância entre o modelo generativo e o mundo.

\hypertarget{minimizando-a-discrepuxe2ncia-entre-o-modelo-e-o-mundo}{%
\section{Minimizando a discrepância entre o modelo e o mundo}\label{minimizando-a-discrepuxe2ncia-entre-o-modelo-e-o-mundo}}

Tendo estabelecido percepção e ação em termos de inferência bayesiana, agora nos voltamos para a questão de qual é o objetivo da inferência. Em outras palavras, o que está sendo otimizado por inferência? Na ciência cognitiva, é comum supor que diferentes funções cognitivas, como percepção e ação, otimizam objetivos diferentes. Por exemplo, poderíamos supor que a percepção maximiza a precisão da reconstrução enquanto a seleção de ação maximiza a utilidade. Em vez disso, um insight fundamental da Inferência Ativa é que tanto a percepção quanto a ação servem ao mesmo objetivo. Como primeira aproximação, esse objetivo comum de percepção e ação pode ser formulado como uma minimização da discrepância entre o modelo e o mundo. Às vezes, isso é operacionalizado em termos de erro de previsão.

Para entender como a percepção e a ação reduzem a discrepância entre o modelo e o mundo, considere novamente o exemplo de uma pessoa que espera ver uma maçã (figura 2.3). Ela gera uma previsão visual de cima para baixo (por exemplo, sobre ver algo vermelho e não pular). Essa previsão visual é comparada com uma sensação (por exemplo, algo pulando) -- e essa comparação resulta em uma discrepância.

\begin{figure}
\centering
\includegraphics{images/Figura2_3.png}
\caption{\textbf{Figura 2.3} Tanto a percepção quanto a ação minimizam a discrepância entre modelo e mundo.}
\end{figure}

A pessoa pode resolver essa discrepância de duas maneiras. Primeiro, ela pode mudar de ideia sobre o que está vendo (ou seja, um sapo) para se adequar ao mundo, resolvendo assim a discrepância. Isso corresponde à percepção. Segundo, ela poderia fovear a macieira mais próxima e ver algo que se parece muito com uma maçã. Isso também resolve a discrepância inicial, mas de uma maneira diferente. Isso implica mudar o mundo -- incluindo a direção do olhar -- e as sensações subsequentes para se adequar ao que está em sua mente, não mudar sua mente para se adequar ao mundo. Esta é a outra direção de ajuste. Isso é ação.

Embora mudar a direção do olhar pareça menos atraente do que mudar de ideia no mundo das maçãs e sapos, vamos considerar outro caso: uma pessoa que espera que sua temperatura corporal esteja em uma certa faixa que sente uma temperatura alta por meio de termorreceptores centrais. Isso é surpreendente e apresenta uma discrepância significativa para resolver. Como no exemplo anterior, ele tem duas formas de minimizar essa discrepância, correspondendo à percepção (mudança de mente) e ação (mudança do mundo), respectivamente. Nesse caso, simplesmente mudar de ideia não parece muito adaptativo, mas agir para diminuir a temperatura do corpo (por exemplo, abrindo a janela) é.

Isso fala do fato de que, na Inferência Ativa, a noção de probabilidades marginais ou surpresa (por exemplo, sobre a temperatura corporal) tem um significado que vai além dos tratamentos Bayesianos padrão para absorver noções como pontos de ajuste homeostáticos e alostáticos. Tecnicamente, os agentes de Inferência Ativa vêm equipados com modelos que atribuem altas probabilidades marginais aos estados que preferem visitar ou às observações que preferem obter. Para um peixe, isso significa uma alta probabilidade marginal de estar na água. Isso implica que os organismos esperam implicitamente que as observações que eles amostram estejam dentro de sua zona de conforto (por exemplo, limites fisiológicos).

Em suma, discutimos como, a qualquer momento, podemos minimizar a discrepância entre nosso modelo e nosso mundo por meio da percepção e da ação. Se ajustamos nossas crenças ou nossos dados depende da confiança com que mantemos essas crenças. Em nosso exemplo da maçã, a crença é mantida com incerteza suficiente de que isso será atualizado em vez de posto em prática. Em contraste, no exemplo da temperatura, estamos consideravelmente mais confiantes sobre nossa temperatura central porque ela garante nossa existência. Essa confiança significa que atualizamos nosso mundo para cumprir nossas crenças. Ainda, na Inferência Ativa, percepção e ação agem de forma mais cooperativa do que o sugerido por este tratamento. Para entender por que esse é o caso, a próxima seção passa da noção restrita de discrepância (ou erro de previsão) para a noção mais geral de energia livre variacional - que é a quantidade que a Inferência Ativa realmente minimiza e que inclui o erro de previsão como um caso especial.

\hypertarget{minimizando-a-energia-livre-variacional}{%
\section{Minimizando a Energia Livre Variacional}\label{minimizando-a-energia-livre-variacional}}

Até agora, discutimos percepção e ação dentro de um esquema bayesiano que visa minimizar a surpresa. No entanto, a inferência Bayesiana exata que suporta a percepção e a ação é computacionalmente intratável na maioria dos casos, porque duas quantidades -- a evidência do modelo (\(P( y)\)) e a probabilidade posterior (\(P(x | y)\)) -- não podem ser computadas por duas razões possíveis. A primeira é que, para modelos complexos, pode haver muitos tipos de estados ocultos que precisam ser marginalizados, tornando o problema computacionalmente intratável. A segunda é que a operação de marginalização pode exigir integrais analiticamente intratáveis. A Inferência Ativa apela a uma aproximação variacional da inferência Bayesiana que é tratável.

O formalismo da inferência variacional será desvendado no capítulo 4. Aqui, basta dizer que realizar inferência Bayesiana variacional implica substituir as duas quantidades intratáveis - probabilidade posterior e evidência do modelo (log) - por duas quantidades que as aproximam, mas podem ser calculadas eficientemente - a saber, um Q posterior aproximado e uma energia livre variacional F, respectivamente. A posterior aproximada às vezes é chamada de distribuição variacional ou de reconhecimento. A energia livre variacional negativa também é conhecida como um limite inferior de evidência (ELBO), especialmente em aprendizado de máquina.

Mais importante ainda, o problema da inferência bayesiana agora se torna um problema de otimização: a minimização da energia livre variacional F. A energia livre variacional é uma quantidade com raízes na física estatística que desempenha um papel fundamental na Inferência Ativa. Na equação 2.5, é denotado como F {[}Q, y{]}, pois é um funcional (função de uma função) do Q posterior aproximado e uma função dos dados y:

\[F[Q,y]=
\begin{matrix}  \underbrace{  -\mathbb{E_{Q(x)}}[\ln P(x,y) }[\\ Energia \end{matrix}
\begin{matrix}  \underbrace{  -\mathbb{H_{Q(x)}}) } \\ Entropia \end{matrix}\]
\[=
\begin{matrix}  \underbrace{  D_{KL}{[Q(x)||P(x)]}}\\ Complexidade \end{matrix}
\begin{matrix}  \underbrace{  -\mathbb{E_{Q(x)}}[\ln P(y|x)]}\\ Acurácia \end{matrix}\]
\[=\begin{matrix} \underbrace{ D_{KL}{[Q(x) || P(x|y)]} } \\ Divergência \end{matrix}
\begin{matrix} \underbrace{-\ln P(x)} \\ Evidência \end{matrix} \qquad\qquad (2.5)
\]

A energia livre variacional pode parecer, a primeira vista, um conceito abstrato, mas sua natureza e o papel que desempenha na Inferência Ativa tornam-se aparentes quando decompostas em quantidades que são mais intuitivas e familiares na ciência cognitiva. Cada uma dessas perspectivas sobre energia livre variacional oferece intuições úteis sobre o que significa minimização de energia livre. Esboçamos brevemente essas intuições aqui, pois elas se tornarão importantes quando discutirmos exemplos na segunda parte do livro.

A primeira linha da equação 2.5 mostra que a minimização em relação a \(Q\) requer consistência com o modelo generativo (energia), mantendo também uma alta entropia posterior.\footnote{Como o KL-Divergence, a entropia é uma quantidade da teoria da informação. É uma medida da dispersão (ou incerteza) de uma distribuição de probabilidade. Tecnicamente, é a média da probabilidade logarítmica negativa ou surpresa média.} A última significa que, na ausência de dados ou crenças prévias precisas (que apenas influenciam o termo de energia), devemos adotar crenças maximamente incertas sobre os estados ocultos do mundo, de acordo com o princípio de entropia máxima de Jaynes ( Jaynes 1957). Simplificando, devemos ser incertos (adotar uma crença de alta entropia ) quando não temos informações. O termo energia herda da física estatística. Especificamente, sob uma distribuição de Boltzmann, a probabilidade logarítmica média de um sistema adotar alguma configuração é inversamente proporcional à energia associada a essa configuração - ou seja, a energia necessária para mover o sistema para essa configuração a partir de uma configuração de linha de base.

A segunda linha enfatiza a interpretação da minimização da energia livre como encontrar a melhor explicação para os dados sensoriais, que deve ser a explicação mais simples (minimamente complexa \footnote{A complexidade, conforme usada aqui, pontua o grau em que devemos nos afastar de nossas crenças anteriores sobre o mundo para explicar os dados.}) capaz de explicar com precisão \footnote{Isso é chamado de precisão porque a precisão de uma explicação aumenta quando uma alta probabilidade logarítmica de resultados, esperada sob os estados ocultos inferidos, é atribuída a dados observados - ou seja, quando a distribuição prevista de resultados captura com precisão a distribuição medida.} os dados (cf.~navalha de Occam) . O trade-off complexidade-precisão ocorre em vários domínios, normalmente no contexto de comparação de modelos para análise de dados. Em estatística, às vezes são usadas outras aproximações para a evidência do modelo, como o critério de informação Bayesiano ou o critério de informação de Akaike. A compensação complexidade-precisão se tornará importante quando descrevermos como usar a energia livre para comparação de modelos durante a análise de dados baseada em modelo - e no contexto de aprendizado de estrutura e redução de modelo. Inferir explicações que tenham complexidade mínima também é importante do ponto de vista cognitivo. Isso porque pode-se supor que atualizar o que se sabe (o anterior) para acomodar os dados acarreta um custo cognitivo (Ortega e Braun 2013, Zénon et al.~2019); portanto, uma explicação que diverge minimamente da anterior é preferível.

Nesta visão, o custo da complexidade é apenas uma surpresa bayesiana. Em outras palavras, o grau em que ``mudo de ideia'' é quantificado pela divergência entre o anterior e o posterior. Isso significa que toda explicação precisa para minhas sensações incorre em um custo de complexidade, e esse custo pontua o grau de atualização da crença bayesiana. A energia livre variacional, então, marca a diferença entre precisão e complexidade.

A linha final expressa a energia livre como um limite na evidência logarítmica negativa (veja a figura 2.4). Como a parte esquerda da figura ilustra, a energia livre é um limite superior na evidência logarítmica negativa, onde o limite é a divergência entre \(Q\) e a probabilidade posterior que teria sido obtida se fosse possível realizar exatamente (em oposição a variacional) inferência. A parte direita da figura mostra que, à medida que a divergência diminui, a energia livre se aproxima da evidência logarítmica negativa (surpresa) - e se torna igual a surpresa, se o Q posterior aproximado corresponder ao posterior exato \(P(x | y)\). Isso oferece uma motivação formal para a inferência perceptiva como uma maneira de diminuir a energia livre otimizando nosso Q posterior aproximado o máximo possível.

\begin{figure}
\centering
\includegraphics{images/Figura2_4.png}
\caption{\textbf{Figura 2.4} Energia livre variacional como um limite superior na evidência logarítmica negativa.}
\end{figure}

A linha final da equação 2.5 mostra que a inferência perceptual não é a única maneira de minimizar a energia livre. Também poderíamos alterar o termo de evidência de log agindo para alterar os dados sensoriais. Essa decomposição é interessante do ponto de vista cognitivo, pois minimizar a divergência e maximizar a evidência mapeiam os dois subobjetivos complementares de percepção e ação, respectivamente; veja a figura 2.5. Observe que todas as expressões acima se tornam formas de caracterizar a evidência logarítmica negativa se substituirmos \(Q\) por \(P( x| y)\), generalizando para o caso de inferência exata.

Em suma, a Inferência Ativa equivale a minimizar a energia livre variacional por percepção e ação. Essa minimização permite que um organismo ajuste seu modelo generativo às observações que amostra. Esse ajuste é uma medida tanto da adequação perceptual (como expressa pelo termo de divergência) quanto do controle ativo sobre os estados externos -- no sentido de que permite que o organismo se mantenha em um conjunto adequado de estados preferidos, conforme definido pelo modelo generativo. Outra maneira de expressar isso é apelar para a divergência versus decomposição de evidências da energia livre. Igualando a evidência logarítmica negativa com surpresa e notando que a menor divergência possível é zero, vemos que a energia livre é um limite superior da surpresa. Isso significa que só pode ser maior ou igual a surpresa. Quando o organismo minimiza sua divergência (através da percepção), então a energia livre torna-se uma aproximação da surpresa. Quando um organismo altera adicionalmente as observações que reúne (atuando) para torná-las mais semelhantes às previsões anteriores, minimiza a surpresa.

\begin{figure}
\centering
\includegraphics{images/Figura_2_5.png}
\caption{\textbf{Figura 2.5} Papéis complementares de percepção e ação na minimização da energia livre variacional.}
\end{figure}

A energia livre variacional tem um aspecto retrospectivo, pois é uma função de observações passadas e presentes, mas não futuras. Embora facilite inferências sobre o futuro com base em dados passados, não facilita diretamente formas prospectivas de inferência com base em dados futuros previstos. Isso é importante no planejamento e na tomada de decisões. Aqui, inferimos as melhores ações ou sequências de ações (políticas) com base nas observações futuras que se espera que elas tragam. Fazer isso requer que complementemos nossos modelos generativos com a noção de energia livre esperada.

\hypertarget{energia-livre-esperada-e-planejamento-como-inferuxeancia}{%
\section{Energia Livre Esperada e Planejamento como Inferência}\label{energia-livre-esperada-e-planejamento-como-inferuxeancia}}

A energia livre esperada estende a Inferência Ativa para incluir uma forma de cognição essencialmente prospectiva: planejamento. Planejar uma sequência de ações, como a série de movimentos necessários para escapar de um labirinto, requer considerar as observações futuras que se espera reunir. Por exemplo, as consequências de possíveis cursos de ação incluem ver um beco sem saída depois de virar à direita ou ver a saída após uma sequência de três curvas à esquerda. Cada sequência possível de ações é chamada de política. Isso destaca uma importante distinção feita na Inferência Ativa entre uma ação e uma política. O primeiro é algo que influencia diretamente o mundo exterior, enquanto o segundo é uma hipótese sobre um modo de se comportar. A implicação é que a Inferência Ativa trata o planejamento e a tomada de decisão como um processo de inferir o que fazer. Isso traz o planejamento firmemente para o domínio da inferência bayesiana e significa que devemos especificar prioritários e probabilidades como antes (seção 2.1). No entanto, no lugar de rãs e maçãs, as alternativas são políticas comportamentais (é mais provável que eu olhe para o lago ou para a árvore?). Nesta seção, primeiro lidamos brevemente com a probabilidade - isto é, as consequências de seguir uma política - e depois nos voltamos para o anterior. É aqui que entra a energia livre esperada.

Os resultados dependentes de políticas não estão imediatamente disponíveis (eles estão no futuro), mas podem ser previstos encadeando dois componentes do modelo generativo. A primeira são nossas crenças sobre como os estados ocultos mudam em função das políticas. Entraremos em detalhes disso no capítulo 4. Por enquanto, usamos a notação \(x\sim\) para denotar uma sequência ou trajetória de estados ocultos ao longo do tempo, e condicionamos as trajetórias às políticas \((π)\) que uma criatura segue. Isso significa que a parte dinâmica do nosso modelo é dada por \(P(x\sim{}|π)\). Com base em nosso exemplo anterior da maçã-rã, a política pode ser a decisão de ir a um lago ou a um pomar, o que altera a probabilidade de encontrar rãs versus maçãs.

O segundo componente do modelo é a distribuição de verossimilhança usual. Isso descreve quais observações esperar em todos os estados possíveis (por exemplo, pulando ou não, condicionado ao sapo ou à maçã). Ao combinar esses dois componentes, um organismo pode engajar seu modelo generativo indiretamente para executar ``e se'' ou simulações contrafactuais das consequências de suas possíveis ações ou políticas -- por exemplo, ``O que aconteceria se eu fosse ao lago?'' Marginalizando sobre os estados, isso nos dá a probabilidade marginal ou evidência para uma política \((P(y\sim|π))\), ou uma aproximação de energia livre para essa quantidade. Em outras palavras, saber como as políticas influenciam as transições de estado nos permite calcular a probabilidade de uma sequência de observações sob essa política. Como vimos na equação 2.1, precisamos combinar essa probabilidade com uma probabilidade anterior para calcular a probabilidade posterior de seguir uma política.

A Inferência Ativa decompõe esse problema de planejamento em duas operações sucessivas. A primeira é calcular uma pontuação para cada política. A segunda é formar crenças posteriores sobre as quais perseguir. A primeira define a crença prévia sobre as políticas a serem seguidas, onde as melhores políticas têm alta probabilidade e as piores políticas têm baixa probabilidade. Sob a Inferência Ativa, a qualidade de uma política é pontuada pela energia livre esperada negativa associada -- assim como a qualidade de um ajuste de modelo é pontuada pela energia livre negativa desse modelo. A energia livre esperada \((G)\) da política é diferente da energia livre variacional \((F)\), uma vez que o cálculo da primeira requer a consideração de observações futuras dependentes da política. Em contraste, este último considera apenas observações presentes e passadas. O cálculo da energia livre esperada, portanto, envolve o modelo generativo para prever observações futuras que resultariam de cada política -- se ela fosse executada -- até algum horizonte de planejamento. Além disso, como uma política se desdobra em várias etapas de tempo, a medida final da energia livre esperada para cada política deve ser integrada em todas as etapas de tempo futuras dessa política.

A energia livre esperada de cada política pode ser convertida em um índice de qualidade (tomando seu negativo) e é disponibilizada diretamente como a priori pelos agentes envolvidos na Inferência Ativa. Isso ocorre porque - consistente com a noção de energia potencial na física - a energia livre esperada é expressa no espaço de probabilidades logarítmicas. Convertê-lo em uma crença (ou distribuição de probabilidade) sobre políticas é então uma questão de exponenciar (para desfazer o log) e normalizar (para garantir consistência com a regra da soma no quadro 2.1). As políticas que estão associadas a uma menor energia livre esperada recebem maior probabilidade e se tornam as políticas que o organismo espera seguir.

Em última análise, inferir que estamos seguindo uma política específica tem consequências para os dados sensoriais que prevemos. Por exemplo, uma política que inclui flexionar o cotovelo implica em previsões sobre a entrada proprioceptiva dos músculos bíceps e tríceps. Isso fornece a ligação entre planejamento e ação, pois as previsões associadas a um plano se traduzem em ação que resolve discrepâncias com dados proprioceptivos medidos (consulte a seção 2.3).

\hypertarget{o-que-uxe9-energia-livre-esperada}{%
\section{O que é energia livre esperada?}\label{o-que-uxe9-energia-livre-esperada}}

Até agora, assumimos que durante o planejamento, o organismo pontua suas políticas de acordo com sua energia livre esperada. No entanto, evitamos o que a energia livre esperada realmente é. Como a energia livre variacional, a energia livre esperada pode ser decomposta de várias maneiras matematicamente equivalentes. Cada um deles fornece uma perspectiva alternativa sobre essa quantidade.

\[G(x)=\begin{matrix} \underbrace{-\mathbb{E_{Q(\tilde x,\tilde y|\pi)}}[ D_{KL}[Q(\tilde x|\tilde y,\pi)||Q(\tilde x|\pi)] }\\ ganho\; de\; informação  \end{matrix} -  \begin{matrix} \underbrace{\mathbb{E_{Q(\tilde y|\pi)}} \ln P(\tilde y|C)])} \\ valor\;pragmático \end{matrix} \]
\[ =  \begin{matrix} \underbrace{\mathbb{E_{Q(\tilde x,\tilde y | \pi)}}[H[P(\tilde y, \tilde x)]]} \\ ambiguidade\; esperada \end{matrix} + \begin{matrix} \underbrace{D_{KL}[Q(\tilde y | \pi) \;||\; P(\tilde y | C)]} \\ risco(resultados) \end{matrix} \]
\[ \le  \begin{matrix} \underbrace{\mathbb{E_{Q(\tilde x,\tilde y | \pi)}}[ H[P(\tilde y, \tilde x)]]} \\ ambiguidade\; esperada \end{matrix} + \begin{matrix} \underbrace{D_{KL}[Q(\tilde x | \pi) \;||\; P(\tilde x | C)]} \\ risco(estados) \end{matrix} \]
\[ =  \begin{matrix} \underbrace{-\mathbb{E_{Q(\tilde x,\tilde y | \pi)}}[\ln P(\tilde y, \tilde x|C)]} \\ energia\; esperada \end{matrix} - \begin{matrix} \underbrace{H[Q(\tilde x | \pi)]} \\ entropia \end{matrix} \;\;\;\;\;\; (2.6)\]

\[ Q(\tilde x,\tilde y | \pi) \overset{\Delta}{=}  Q(\tilde x | \pi)P(\tilde y | \tilde x) \]

O primeiro deles é talvez o mais útil, intuitivamente, pois expressa o valor de buscar novas informações (ou seja, exploração(``/ prospecção'') exatamente nas mesmas unidades (nats) que o valor de buscar observações preferidas (ou seja, exploração(``/aproveitamento''), dissolvendo o clássico Dilema explorar-explorar em psicologia comportamental. Ao minimizar a energia livre esperada, o equilíbrio relativo entre esses termos determina se o comportamento é predominantemente exploratório ou explorador. Observe que o valor pragmático surge como uma crença prévia sobre observações, onde o parâmetro C inclui preferências.
A ligação (potencialmente não intuitiva) entre crenças anteriores e preferências é descompactada no capítulo 7; por enquanto, notamos que esse termo pode ser tratado como uma utilidade ou valor esperado, sob a suposição de que resultados valiosos são os tipos de resultados que caracterizam cada agente (por exemplo, uma temperatura corporal de 37°C).

O termo ganho de informação herda da divergência que consideramos na seção 2.5, que garante que a energia livre seja um limite superior da surpresa. No entanto, há uma reviravolta: em vez de minimizar a divergência, queremos selecionar políticas que maximizem a divergência esperada -- portanto, ganho de informação. Essa mudança se deve ao fato de que agora estamos obtendo uma média das probabilidades logarítmicas sobre os resultados que ainda não foram observados. Este é um ponto sutil que pode ser entendido em termos de resultados mudando seus papéis. Ao avaliar a energia livre dos resultados, os resultados são as consequências. No entanto, ao avaliar a energia livre esperada, os resultados desempenham o papel de causas no sentido de que são variáveis que estão ocultas no futuro, mas explicam as decisões no presente.

O ganho de informação resultante penaliza as observações para as quais há um mapeamento de muitos para um de observações para estados - no sentido de que se pode obter as mesmas observações em diferentes estados - pois isso impede a atualização precisa da crença. Em inteligência artificial e robótica, os estados que trazem a mesma observação (por exemplo, duas junções em T de um labirinto que parecem idênticos) às vezes são chamados de alias e geralmente são difíceis de lidar usando métodos simples (ou seja, estímulo-resposta, sem inferência ou memória).
O problema é que não podemos saber qual estado ocupamos apenas a partir de observações atuais. A Inferência Ativa evita entrar em tais situações em primeiro lugar, dado seu baixo potencial de ganho de informação.

Um exemplo simples pode ajudar a desfazer a distinção entre ganho de informação (ou valor epistêmico) e valor pragmático e destacar por que, na maioria das situações realistas, os valores pragmáticos e epistêmicos precisam ser perseguidos em conjunto. Imagine uma pessoa que quer um expresso e sabe que existem dois bons cafés na cidade: um que abre apenas de segunda a sexta e outro que abre apenas durante o fim de semana. Se ele não sabe que dia da semana é, ele deve primeiro selecionar uma ação que tenha valor epistêmico e resolva sua incerteza (ou seja, uma ação epistêmica para olhar o calendário) -- e somente depois disso selecione uma ação que carrega valor pragmático e traz a recompensa (ou seja, uma ação pragmática para ir ao café correto). Esse cenário ilustra o fato de que, na maioria das situações incertas, deve-se primeiro realizar ações epistêmicas para resolver a incerteza antes de selecionar com confiança uma ação pragmática. Os métodos de seleção de políticas que não consideram a possibilidade epistêmica das escolhas só podem selecionar políticas usando geradores de números aleatórios -- e muitas vezes perderão seu café expresso. Portanto, esquemas que consideram apenas valor pragmático são geralmente restritos a situações sem incerteza epistêmica, como no caso de uma pessoa que já sabe o dia da semana e, portanto, pode dirigir-se diretamente ao café correto.

A segunda decomposição na equação 2.6 é em termos de risco e ambiguidade esperada. Esses termos são análogos de complexidade e imprecisão: risco é a complexidade esperada e ambiguidade é a imprecisão esperada. Risco, uma noção comum em economia, corresponde ao fato de que pode haver um mapeamento um-para-muitos entre políticas e suas consequências -- no sentido de que se pode obter vários resultados diferentes (por acaso) sob a mesma política. Um exemplo é um cenário de jogo com recompensas estocásticas (por exemplo, um bandido de um braço só, também conhecido como caça-níqueis), em que se pode conhecer a distribuição de recompensas - digamos, que obteremos recompensa 10\% das vezes. Isso é chamado de situação de risco em economia porque, após o mesmo movimento (puxar uma alavanca), pode-se obter duas observações diferentes (recompensa ou nenhuma recompensa). Isso significa que é preciso escolher políticas ou planos que acomodem a incerteza. Em esquemas sensíveis ao risco -- como inferência ativa -- o jogo é escolher políticas cujos resultados probabilísticos correspondam, no sentido de uma KL-Divergência, às preferências anteriores. Em suma, minimizar o custo da complexidade torna-se minimizar o risco quando ambos são medidas de afastamento de crenças anteriores.

Da mesma forma, a ambiguidade corresponde à imprecisão esperada devido a um mapeamento ambíguo entre estados e resultados. Um mapeamento é ambíguo se a distribuição dos resultados previstos for altamente dispersa (ou entrópica), mesmo que conheçamos os estados que os geram com total confiança. Por exemplo, a probabilidade de cara ou coroa no lançamento de uma moeda, condicionada pelo sol ou pela chuva, será extremamente ambígua, pois não há relação entre o clima e a chance de 50\% de cara ou coroa. Como tal, não seria possível obter informações sobre o clima observando as caudas. Observe que a maioria das situações é dotada de risco e ambiguidade -- o que implica um mapeamento de muitos para um entre estados e resultados e entre políticas e resultados. Lembre-se de que os resultados (observações) são o único tipo de variável que pode ser observada. A Inferência Ativa lida automaticamente com essas situações, porque a energia livre esperada compreende termos de risco e ambiguidade.

A terceira linha da equação 2.6 destaca uma formulação alternativa da energia livre esperada ao reexpressar o risco como uma divergência entre crenças sobre estados e preferências definidas em termos de estados. Uma característica atraente dessa forma é que ela pode ser rearranjada em uma energia e entropia esperadas em analogia com a energia livre variacional (equação 2.5). Embora essa relação seja atraente, uma desvantagem dessa formulação é que ela assume que o espaço de estados é conhecido a priori, de modo que as preferências anteriores podem ser associadas aos estados. Na maioria dos cenários, isso não é um problema, e a escolha entre definir preferências em termos de estados ou resultados tem pouca relevância prática. No entanto, a prática comum é especificar preferências em termos de resultados -- permitindo que o próprio espaço de estados seja aprendido enquanto preserva a motivação extrínseca.

Em resumo, a energia livre esperada pode ser decomposta em termos de risco e ambiguidade e em termos de valores pragmáticos e epistêmicos. Essas decomposições são interessantes, pois permitem uma compreensão formal da ampla variedade de situações com as quais a Inferência Ativa lida. Além disso, eles facilitam uma apreciação de como a Inferência Ativa inclui vários esquemas de decisão -- que podem ser obtidos ignorando um ou mais componentes da energia livre esperada (figura 2.6). Se removermos as preferências anteriores, o valor pragmático torna-se irrelevante e toda ação é motivada por affordances epistêmicas -- portanto, tais esquemas só podem lidar com a resolução da incerteza. Uma vez que as preferências anteriores são removidas, a energia livre esperada (negativa) é conhecida como surpresa Bayesiana esperada (no contexto da exploração atencional) ou motivação intrínseca (no contexto da aprendizagem autônoma). Se a ambiguidade for removida, o esquema resultante corresponde ao controle sensível ao risco ou KL na teoria do controle. Finalmente, se removermos tanto a ambiguidade quanto às preferências anteriores, o único imperativo restante é maximizar a entropia das observações (ou estados, se estiver usando a formulação da terceira linha da equação 2.6). Isso pode ser interpretado como amostragem de incerteza (ou manter as opções em aberto). A Inferência Ativa evidencia as relações formais entre esses esquemas e as situações (limitadas) em que eles se aplicam.

\begin{figure}
\centering
\includegraphics{images/Figura_2_6.png}
\caption{\textbf{Figura 2.6} Vários esquemas que podem ser derivados removendo termos da equação da energia livre. O painel superior mostra os termos que contribuem para a energia livre esperada. Os painéis inferiores mostram os esquemas resultantes da remoção de preferências anteriores (1), ambiguidade (2) ou tudo, exceto as preferências anteriores. Cada uma dessas quantidades aparece em vários campos diferentes sob uma variedade de nomes, mas todas podem ser vistas como componentes de a mesma energia livre esperada.}
\end{figure}

Embora tenhamos decomposto cuidadosamente a energia livre esperada de forma que pessoas diferentes possam ler esse funcional, não há maneira certa ou errada de dividi-la. Veremos na segunda metade deste livro por que sistemas autônomos de um certo tipo devem, em virtude de existir, escolher ações que pareçam minimizar a energia livre esperada. Essa perspectiva significa que não há papel privilegiado para imperativos epistêmicos (explorativos) versus pragmáticos (exploradores) -- ou para risco versus ambiguidade. Essas (possivelmente falsas) dicotomias são apenas dois lados da mesma moeda existencial.

\hypertarget{no-final-da-estrada-baixa}{%
\section{No final da estrada baixa}\label{no-final-da-estrada-baixa}}

Tendo introduzido as duas noções distintas de energia livre variacional e energia livre esperada, estamos agora em condições de considerar o que elas alcançam juntas. Isso representa um ponto final para o caminho inferior da Inferência Ativa, a partir da noção de inferência inconsciente, via cérebro Bayesiano, a dualidade de percepção e ação e, finalmente, planejamento como inferência.

A energia livre variacional está no centro da Inferência Ativa. Ele mede o ajuste entre o modelo generativo interno e as observações (atuais e passadas). Ao minimizar a energia livre variacional, as criaturas maximizam sua evidência de modelo. Isso garante que o modelo generativo se torne um bom modelo do ambiente e que o ambiente esteja em conformidade com o modelo.

A energia livre esperada é uma forma de pontuar políticas alternativas para o planejamento. Isso é fundamentalmente prospectivo -- considera possíveis observações futuras -- e contrafactual -- as possíveis observações futuras estão condicionadas às políticas que se podem adotar. A energia livre esperada mede a plausibilidade das políticas de ação em relação aos estados e observações preferidos (futuros). Ao pontuar as políticas em termos de sua energia livre negativa esperada, as criaturas envolvidas na Inferência Ativa efetivamente acreditam que seguem o curso de ação para o qual essa quantidade é mais baixa. Em termos psicológicos, isso implica que a crença de uma criatura sobre as políticas corresponde diretamente à sua intenção -- que ela cumpre agindo.

Do ponto de vista conceitual, podemos associar a minimização da energia livre variacional e da energia livre esperada com dois laços inferenciais, um aninhado no outro. A minimização variacional de energia livre é o ciclo chave (externo) da Inferência Ativa, que é suficiente para otimizar a percepção e as crenças sobre as políticas. Um agente de Inferência Ativa também pode ser dotado de um modelo generativo das consequências de sua ação que envolve uma avaliação da energia livre esperada (o loop interno). Essa capacidade de planejar o futuro suporta formas prospectivas de seleção de ações, fornecendo valores de probabilidade para políticas (Friston, Samothrakis e Montague 2012; Pezzulo 2012).

\hypertarget{resumo-1}{%
\section{Resumo}\label{resumo-1}}

A Inferência Ativa é uma teoria de como os artefatos vivos sustentam sua existência minimizando a surpresa -- ou um proxy tratável para surpreender, energia livre variacional -- via percepção e ação. Neste capítulo, buscamos motivar essa ideia partindo de um tratamento bayesiano da percepção como inferência e estendendo-o ao domínio da ação. A inferência bayesiana baseia-se em um modelo generativo de como as observações sensoriais são geradas, que codifica (probabilisticamente) o conhecimento implícito do organismo do mundo -- formalizado como crenças anteriores e os resultados esperados sob estados e políticas alternativas.

A tomada específica da Inferência Ativa nos força a revisitar a semântica usual de um prior na inferência Bayesiana. Os estados esperados são preferidos e incluem as condições do organismo para a sobrevivência (por exemplo, estados objetivos específicos de nicho), enquanto seus opostos -- estados surpreendentes -- são despreferidos. Dessa forma, ao atender suas expectativas, os agentes de Inferência Ativa garantem sua própria sobrevivência. Dadas as importantes ligações entre a noção de a priori e as condições que sustentam a existência de um organismo, também podemos dizer que, na Inferência Ativa, a identidade de um agente é isomórfica com suas a priori. Essa terminologia se tornará mais familiar mais adiante no livro.

Observe que, nessa visão, surpresa (ou às vezes surpresa ) é uma construção formal da teoria da informação e não necessariamente equivalente a uma construção psicológica (popular). Grosso modo, quanto mais o estado do organismo difere do estado anterior (que codifica os estados preferidos), mais surpreendente é -- portanto, a Inferência Ativa equivale à ideia de que um organismo (ou seu cérebro) tem que minimizar ativamente sua surpresa para permanecer vivo. Sob certas condições, a minimização da surpresa pode ser interpretada como a redução da discrepância entre o modelo e o mundo. Mais geralmente, a quantidade que é realmente minimizada na Inferência Ativa é a energia livre variacional. A energia livre variacional é uma aproximação (limite superior) da surpresa e pode ser minimizada de forma eficiente usando a passagem de mensagens químicas ou neuronais e informações que estão disponíveis para o modelo generativo do organismo.

É importante ressaltar que tanto a percepção quanto a ação minimizam a energia livre variacional de maneiras complementares: refinando sua estimativa (crença posterior ) e realizando ações que amostram seletivamente o que é esperado. Além disso, o Active Inference também minimiza a energia livre esperada seguindo políticas associadas a ambiguidade e risco mínimos. A energia livre esperada então estende a Inferência Ativa para formas de inferência prospectivas e contrafactuais. Isso completa nossa jornada ao longo da estrada secundária para a Inferência Ativa. No capítulo 3, percorreremos a estrada principal, que chega à mesma conclusão com base nos primeiros princípios e na auto-organização.

\hypertarget{o-caminho-para-a-inferuxeancia-ativa}{%
\chapter{O caminho para a inferência ativa}\label{o-caminho-para-a-inferuxeancia-ativa}}

Máquinas de sobrevivência que podem simular o futuro estão um salto à frente das máquinas de sobrevivência que só podem aprender com base em tentativa e erro evidentes. O problema com o julgamento aberto é que leva tempo e energia. O problema com o erro evidente é que muitas vezes é fatal. A simulação é mais segura e mais rápida.
---Richard Dawkins

\hypertarget{introduuxe7uxe3o-2}{%
\section{Introdução}\label{introduuxe7uxe3o-2}}

No capítulo 2, motivamos a introdução da energia livre como meio de realizar inferência Bayesiana aproximada (ou seja, o caminho inferior para a Inferência Ativa). Aqui, introduzimos a energia livre de outra perspectiva, a da estrada principal, que inverte esse raciocínio: ela parte dos primeiros princípios da física estatística e do imperativo central de que os organismos devem manter sua existência - ou seja, evitar estados surpreendentes - e então introduz a minimização da energia livre como uma solução computacionalmente tratável para este problema. O capítulo revela a equivalência formal entre a minimização da energia livre variacional e a maximização da evidência do modelo (ou auto-evidência) em inferência Bayesiana aproximada, revelando uma conexão entre energia livre e perspectivas Bayesianas em sistemas adaptativos. Finalmente, discute como a Inferência Ativa fornece uma nova perspectiva de primeiro princípio para entender o comportamento (ótimo).

A Inferência Ativa é uma teoria de como os organismos vivos mantêm sua existência minimizando a surpresa -- ou um substituto tratável para surpreender, energia livre variacional -- via percepção e ação. Partindo dos primeiros princípios, avança um novo esquema baseado em crenças para entender o comportamento e a cognição, que tem inúmeras implicações empíricas.

O caminho para a Inferência Ativa parte da premissa de que, para sobreviver, qualquer organismo vivo precisa se manter em um conjunto adequado de estados preferidos, evitando outros estados não preferidos do ambiente. Esses estados preferidos são definidos em primeiro lugar por adaptações evolutivas específicas de nicho. No entanto, como veremos mais tarde, em organismos avançados, isso também pode se estender a objetivos cognitivos aprendidos. Por exemplo, para sobreviver, um peixe tem que ficar em uma zona de conforto que corresponde a um pequeno subconjunto de todos os estados possíveis do universo: tem que ficar na água. Da mesma forma, um ser humano precisa garantir que seus estados internos (por exemplo, variáveis \hspace{0pt}\hspace{0pt}fisiológicas como temperatura corporal e frequência cardíaca) permaneçam sempre dentro de faixas aceitáveis \hspace{0pt}\hspace{0pt}- caso contrário, eles morrerão (ou, mais precisamente, se tornarão outra coisa, como um cadáver). Essa faixa aceitável ou zona de conforto define estipulativamente os estados característicos em que algo deve estar para ser essa coisa.

Os organismos vivos resolvem esse problema biológico fundamental exercendo controle ativo sobre seus estados (por exemplo, da temperatura corporal) em muitos níveis, que variam de mecanismos reguladores automáticos, como sudorese (fisiologia), a mecanismos cognitivos, como comprar e consumir uma bebida (psicologia). ) a práticas culturais como a distribuição de sistemas de ar condicionado (ciências sociais).

De uma perspectiva mais formal, a Inferência Ativa apresenta o problema biológico da -- ou explicação para -- a sobrevivência como minimização de surpresas. Essa formulação se baseia em uma definição técnica de estados surpreendentes da teoria da informação -- essencialmente, estados surpreendentes indexam aqueles fora da zona de conforto dos organismos vivos. Em seguida, propõe a minimização da energia livre como uma maneira prática e biologicamente fundamentada para que organismos ou sistemas adaptativos minimizem a surpresa dos encontros sensoriais.

\hypertarget{envoltuxf3rios-de-markov}{%
\section{Envoltórios de Markov}\label{envoltuxf3rios-de-markov}}

Uma pré-condição importante para qualquer sistema adaptativo é que ele deve desfrutar de alguma separação e autonomia do ambiente -- sem o qual ele simplesmente se dissiparia, dissolveria e, assim, sucumbiria à dinâmica ambiental. Na ausência dessa separação, não haveria surpresa a minimizar; deve haver algo para se surpreender e algo para se surpreender. Em outras palavras, há pelo menos duas coisas -- sistema e ambiente -- e elas podem ser desambiguações uma da outra. Uma maneira formal de expressar uma separação entre um sistema e o resto do ambiente é a construção estatística de um envoltório de Markov (Pearl 1988); ver quadro 3.1

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
quadro 3.1 Envoltórios de Markov
\end{minipage} \\
\midrule
\endhead
Um envoltório de Markov é um importante conceito recorrente neste livro (Friston 2019a, Kirchhoff et al.~2018, Palacios et al.~2020). Tecnicamente, um envoltório (b) é definido da seguinte forma: \( \mu \perp x|b \Longleftrightarrow p(\mu, x|b) = p(\mu|b)p(x|b)\) Isso diz (de duas maneiras diferentes, mas equivalentes) que uma variável μ é condicionalmente independente de uma variável x se b for conhecido. Em outras palavras, se conhecemos b, conhecer x não nos daria informações adicionais sobre μ. Um exemplo comum disso é uma cadeia de Markov, onde o passado causa o presente causa o futuro. Nesse cenário, o passado só pode influenciar o futuro por meio do presente. Isso significa que nenhuma informação adicional sobre o futuro é obtida descobrindo sobre o passado (assumindo que conhecemos o presente). Para identificar um envoltório de Markov em um sistema em que conhecemos as dependências condicionais, podemos seguir uma regra simples. O envoltório para uma determinada variável inclui seus pais (as variáveis das quais ela depende), seus filhos (as variáveis que dependem dela) e, em algumas configurações, os outros pais de seus filhos. \\
\bottomrule
\end{longtable}

Em resumo, um envoltório de Markov é o conjunto de variáveis que medeiam todas as interações (estatísticas) entre um sistema e seu ambiente. A Figura 3.1 ilustra uma interpretação de um envoltório de Markov em um cenário dinâmico. Aqui as independências condicionais foram complementadas com restrições dinâmicas, de modo que os fluxos não dependam de estados no lado oposto do envoltório.

O envoltório de Markov na figura 3.1 distingue estados internos ao sistema adaptativo (ou seja, atividade cerebral) de estados externos do ambiente. Além disso, identifica dois estados adicionais, estados sensoriais rotulados e estados ativos, que formam o envoltório que (estatisticamente) separa os estados internos e externos. A separação estatística significa que, se soubéssemos sobre os estados ativo e sensorial, os estados externos não ofereceriam informações adicionais sobre os estados internos (e vice-versa). Em uma configuração dinâmica, isso é frequentemente interpretado como dizendo que os estados internos não podem alterar diretamente os estados externos, mas podem fazê-lo vicariamente alterando os estados ativos. Da mesma forma, os estados externos não podem alterar diretamente os estados internos, mas podem fazê-lo indiretamente, alterando os estados sensoriais.

Esta é uma reafirmação do ciclo clássico de percepção de ação, em que um sistema adaptativo e seu ambiente podem interagir (apenas) por meio de ações e observações, respectivamente. Esta reformulação tem dois benefícios principais.

\begin{figure}
\centering
\includegraphics{images/Figura_3_1.png}
\caption{\textbf{Figura 3.1} Um envoltório de Markov dinâmico, que separa um sistema adaptativo (aqui, o cérebro) do ambiente. A dinâmica de cada conjunto de estados é determinada por um fluxo determinístico especificado como uma função \((f)\) fornecendo a taxa média de variação e flutuações estocásticas adicionais (aleatórias) \((ω)\). As setas indicam a direção da influência de cada variável sobre as taxas de variação de outras variáveis (tecnicamente, os elementos não nulos dos jacobianos associados). Isso é apenas um exemplo; pode-se usar um envoltório de Markov para separar um organismo inteiro do ambiente ou aninhar vários envoltórios de Markov um dentro do outro. Por exemplo, cérebros, organismos, díades e comunidades podem ser concebidos em termos de diferentes envoltórios de Markov que estão aninhadas umas nas outras (veja Friston 2019a; Parr, Da Costa e Friston 2020 para um tratamento formal). Confusamente, campos diferentes usam notações diferentes para as variáveis; às vezes, os estados sensoriais são denotados por \(s\), estados externos \(η\) e estados ativos \(a\). Aqui escolhemos variáveis para consistência com os outros capítulos deste livro.}
\end{figure}

Primeiro, formaliza o fato de que os estados internos de um sistema adaptativo são autônomos da dinâmica ambiental e, portanto, podem resistir às suas influências. Em segundo lugar, ela estrutura a maneira pela qual os sistemas adaptativos minimizam sua surpresa: destaca os estados internos, sensoriais e ativos aos quais eles têm acesso. Especificamente, a surpresa é definida em relação aos estados sensoriais, enquanto a dinâmica dos estados internos e ativos são os meios pelos quais a surpresa dos estados sensoriais pode ser minimizada.

O ponto-chave a ser observado aqui é que os estados internos de um sistema adaptativo têm uma relação formal com os estados externos. Isso se deve a um tipo de simetria em toda o envoltório de Markov, pois tanto influenciam quanto são influenciadas por estados do envoltório. Uma consequência disso é que podemos construir distribuições de probabilidade condicional para os estados internos e externos, dados os estados gerais. Como eles estão condicionados aos mesmos estados gerais, podemos associar pares de estados internos e externos esperados entre si. Em outras palavras, em média, os estados interno e externo adquirem uma espécie de sincronia (generalizada) -- exatamente como poderíamos antecipar ao prender um pêndulo a cada extremidade de uma viga de madeira. Com o tempo, à medida que se sincronizam, cada pêndulo torna-se preditivo do outro através da influência vicária do feixe (Huygens 1673).

A Figura 3.2 oferece uma intuição gráfica para essa relação. Isso significa que, se pudermos escrever distribuições independentes sobre estados externos e internos, dado seu envoltório de Markov, os dois estados se tornarão informativos um sobre o outro por meio desse envoltório.

\begin{figure}
\centering
\includegraphics{images/Figura_3_2.png}
\caption{Figura 3.2 Associação entre estados internos médios de um envoltório de Markov e distribuições de estados externos. Topo: Assumindo uma forma gaussiana linear para as probabilidades condicionais, esses gráficos mostram amostras da distribuição condicional sobre estados externos e internos, respectivamente, dados estados gerais. As linhas pretas grossas indicam a média dessas variáveis, dado o estado do envoltório associado. Inferior esquerdo: Os mesmos dados são plotados para ilustrar a sincronização de estados internos e externos proporcionada pelo compartilhamento de um envoltório de Markov -- aqui, uma sincronização inversa. As linhas tracejadas e a cruz preta ilustram que se conhecêssemos o estado médio interno (linha vertical), poderíamos identificar o estado médio externo (linha horizontal) e a dispersão em torno deste ponto. Inferior direito: Podemos associar o estado interno médio com uma distribuição sobre o estado externo.}
\end{figure}

Essa sincronia dá aos estados internos a aparência de representar (ou modelar) estados externos --- o que remete à ideia de minimização da surpresa apresentada no capítulo 2. Isso porque a surpresa depende de um modelo interno de como os dados sensoriais são gerados. Para recapitular, minimizar a surpresa (probabilidade logarítmica negativa) de observações sensoriais torna-se idêntica a maximizar a evidência (probabilidade marginal) para o modelo, que é apenas a probabilidade de observações sensoriais sob esse modelo. Essa noção de minimização de surpresas pode ser entendida a partir de duas perspectivas equivalentes -- bayesiana e de energia livre --, que discutiremos a seguir.

\hypertarget{minimizauxe7uxe3o-de-surpresa-e-auto-eviduxeancia}{%
\section{Minimização de surpresa e auto-evidência}\label{minimizauxe7uxe3o-de-surpresa-e-auto-eviduxeancia}}

Sob uma perspectiva bayesiana, um agente com um envoltório de Markov parece modelar o ambiente externo no sentido de que estados internos correspondem (em média) a uma representação probabilística -- uma crença posterior aproximada -- de estados externos do sistema (figura 3.2). A dinâmica dos estados internos corresponde a uma forma de inferência bayesiana (aproximada) de estados externos, pois seu movimento altera a distribuição de probabilidade associada, que é proporcionada por um modelo generativo implícito de como as sensações (ou estados sensoriais no jargão do envoltório de Markov) são gerados. Se restabelecermos a noção de um agente como constituído por estados internos e gerais, podemos falar sobre o modelo generativo de um agente.

É importante ressaltar que o modelo generativo do agente não pode simplesmente imitar a dinâmica externa (caso contrário, o agente simplesmente seguiria a dinâmica dissipativa externa). Em vez disso, o modelo também deve especificar as condições preferenciais para a existência do agente, ou as regiões de estados que o agente deve visitar para manter sua existência, ou satisfazer os critérios de sua existência em termos de ocupação de estados característicos. Esses estados preferidos (ou observações) podem ser especificados como os anteriores do modelo - o que implica que o modelo assume implicitamente que suas sensações preferidas (anteriores) são mais prováveis de ocorrer (ou seja, são menos surpreendentes) se satisfizer os critérios de existência . Isso significa que tem um viés de otimismo implícito. Esse viés de otimismo é necessário para que o agente vá além da mera duplicação de dinâmicas externas para prescrever estados ativos que subscrevem seus estados preferenciais ou característicos.

Sob essa formulação, pode-se definir o comportamento ótimo (com relação às preferências anteriores) como a maximização da evidência do modelo por percepção e ação. De fato, a evidência do modelo resume quão bem o modelo generativo se ajusta ou explica as sensações. Um bom ajuste indica que o modelo explica com sucesso suas sensações (este é o lado descritivo da inferência); ao mesmo tempo, realiza suas sensações preferidas, já que são menos surpreendentes (este é o lado prescritivo da inferência). Esse bom ajuste é uma garantia de minimização da surpresa, pois maximizar a evidência do modelo \(P( y)\) é matematicamente equivalente a minimizar a surpresa: \(ℑ( y)  =  −ln P( y).\)

Uma forma de reformular os argumentos acima de forma mais sucinta consiste em dizer que qualquer sistema adaptativo se engaja em ``auto-evidência'' (Hohwy 2016). Autoevidenciar aqui significa agir para reunir dados sensoriais consistentes com (ou seja, que fornece evidência para) um modelo interno, maximizando assim a evidência do modelo.

\hypertarget{minimizauxe7uxe3o-de-surpresa-como-um-princuxedpio-hamiltoniano-de-menor-auxe7uxe3o}{%
\subsection{Minimização de surpresa como um princípio hamiltoniano de menor ação}\label{minimizauxe7uxe3o-de-surpresa-como-um-princuxedpio-hamiltoniano-de-menor-auxe7uxe3o}}

Nas seções anteriores, afirmamos que a surpresa deve ser minimizada, mas não detalhamos por que isso acontece. Embora os detalhes da física subjacente da autoevidência estejam fora do escopo deste livro (consulte Friston 2019b para obter detalhes), fornecemos aqui uma breve visão geral dos princípios. Estes são sustentados pela ideia de que criaturas biológicas -- com envoltórios de Markov -- persistem ao longo do tempo, resistindo aos efeitos dispersivos das flutuações ambientais. A persistência de uma envoltório de Markov implica que a distribuição de estados do envoltório permanece constante ao longo do tempo. Simplificando, isso significa que qualquer desvio de estados sensoriais (ou ativos) de regiões que são altamente prováveis \hspace{0pt}\hspace{0pt}sob essa distribuição deve ser corrigido pelo fluxo médio de estados (que é apenas a parte determinística do fluxo na figura 3.1). Expressando isso como um físico poderia, sistemas estocásticos (aleatórios) em estado estacionário se envolvem em dinâmicas que (em média) descem uma função de energia (ou Hamiltoniana) que é interpretável como uma evidência de log negativo ou surpresa. Isso é como uma bola rolando morro abaixo de alta energia potencial gravitacional no topo da colina para baixa energia em uma bacia. Veja a figura 3.3.

Para o sistema mostrado à esquerda da figura 3.3, toda vez que uma flutuação causa um movimento para um estado menos provável, isso é corrigido por um movimento para cima no gradiente de probabilidade, de modo que o sistema ocupe regiões com densidade de probabilidade maior parte do tempo . O principal insight aqui é que esse sistema mantém os estados sensoriais dentro de uma faixa estreita, minimizando a surpresa (em média) -- em contraste com o sistema da direita, para o qual a surpresa cresce indefinidamente.

\begin{figure}
\centering
\includegraphics{images/Figura_3_3.png}
\caption[\textbf{Figura 3.3} Esquerda: Caminho tomado por um sistema dinâmico aleatório bidimensional com um estado estacionário (não-equilíbrio ). Isso pode ser interpretado como minimizando sua surpresa, que é mostrada no gráfico de contorno à direita. Direita: O centro é a região menos surpreendente; os círculos que se afastam do centro representam regiões progressivamente mais surpreendentes. Meio: Em contraste, este gráfico mostra a trajetória de um sistema começando no mesmo lugar (5, 5), com flutuações aleatórias de mesma amplitude, cuja dinâmica não guarda relação com surpresa. Não só entra em regiões mais surpreendentes do espaço; também não consegue atingir qualquer tipo de estado estacionário, dissipando-se de forma irrestrita ao longo do tempo. O escopo da Inferência Ativa é restrito a sistemas como o da esquerda -- que contrariam flutuações aleatórias com seu fluxo médio e, assim, mantêm sua forma ao longo do tempo.]{\textbf{Figura 3.3} Esquerda: Caminho tomado por um sistema dinâmico aleatório bidimensional com um estado estacionário (não-equilíbrio \footnotemark{}). Isso pode ser interpretado como minimizando sua surpresa, que é mostrada no gráfico de contorno à direita. Direita: O centro é a região menos surpreendente; os círculos que se afastam do centro representam regiões progressivamente mais surpreendentes. Meio: Em contraste, este gráfico mostra a trajetória de um sistema começando no mesmo lugar (5, 5), com flutuações aleatórias de mesma amplitude, cuja dinâmica não guarda relação com surpresa. Não só entra em regiões mais surpreendentes do espaço; também não consegue atingir qualquer tipo de estado estacionário, dissipando-se de forma irrestrita ao longo do tempo. O escopo da Inferência Ativa é restrito a sistemas como o da esquerda -- que contrariam flutuações aleatórias com seu fluxo médio e, assim, mantêm sua forma ao longo do tempo.}
\end{figure}
\footnotetext{Desequilíbrio aqui se refere à ausência de equilíbrio detalhado. O equilíbrio detalhado é a invariância de um sistema sob reversão no tempo, uma vez que atingiu o estado estacionário. Podemos ver que o sistema da esquerda da figura 3.3 não possui equilíbrio detalhado, pois a trajetória tende a se curvar no sentido anti-horário em torno dos contornos de surpresa. Se fôssemos reproduzir isso ao contrário, o sistema pareceria girar no sentido horário.}

A minimização da surpresa permite que os organismos vivos resistam (temporariamente) à segunda lei da termodinâmica, que afirma que a entropia -- ou a dispersão de estados sistêmicos -- sempre cresce. Isso porque, em média, a entropia é a média de longo prazo da surpresa e, em média, a maximização de uma probabilidade logarítmica de observações é equivalente à minimização da entropia (Shannon) \footnote{Isso não é o mesmo que dizer que sistemas que minimizam surpresas devem minimizar sua entropia. Como vemos na figura 3.3, o sistema não tende a uma distribuição (ponto) infinitamente precisa que minimizaria a entropia, mas mantém uma dispersão consistente ao longo do tempo -- limitando a entropia de cima e de baixo.}

\(H[P(y)]=\mathbb{E_{P(y)}[ℑ(y)]}=-\mathbb{E_{P(y)}[\ln P(y)]}\qquad\qquad\qquad (3.1)\)

Garantir que uma pequena proporção de estados sensoriais seja ocupada com alta probabilidade é equivalente a manter uma entropia particular. Essa é uma característica definidora dos sistemas auto-organizados, há muito reconhecida pelas teorias cibernéticas.

Do ponto de vista de um fisiologista, a minimização de surpresas formaliza a ideia de homeostase. À medida que um valor de sensor sai de sua faixa ideal, mecanismos de feedback negativo entram em ação que revertem esses desvios. De uma perspectiva de controle, podemos interpretar o comportamento ótimo em relação a alguma densidade de probabilidade de estado estacionário desejada. Em outras palavras, se definirmos uma distribuição de resultados preferidos, o comportamento ótimo envolverá a evolução do sistema em direção a essa distribuição e sua manutenção.

Como vimos no capítulo 2, a energia livre é um limite superior para a surpresa, sugerindo que o comportamento ótimo pode ser obtido minimizando a energia livre em face de flutuações aleatórias. Lembre-se de que a diferença entre energia livre e surpresa é a divergência entre uma probabilidade posterior exata (isto é, a distribuição de estados externos dados estados envoltórios) e uma probabilidade posterior aproximada (isto é, a distribuição sobre estados externos dados estados internos médios). Como tal, o movimento dos estados internos pode ser pensado como minimizando a divergência, o que permite que os estados ativos, em média, minimizem a surpresa que acompanha os estados sensoriais. Em outras palavras, o comportamento ótimo resultante da minimização da energia livre é aquele que é menos surpreendente e segue um caminho de menor Ação \footnote{O A maiúsculo é usado para distinguir Ação como uma integral de caminho de uma Lagrangiana da ação como a dinâmica dos estados ativos de um envoltório de Markov.} do estado atual para o estado desejado -- ou seja, o princípio hamiltoniano de menor Ação aplicado ao comportamento .

A Figura 3.3 mostra um exemplo muito simples de um sistema equipado com um atrator aleatório. Isso é análogo a um termostato, que (no jargão cibernético) tem um único ponto de ajuste e não pode aprender ou planejar. A Inferência Ativa visa usar o mesmo aparato explicativo para cobrir sistemas muito mais complexos e adaptativos. Aqui, a diferença entre sistemas mais simples e mais complexos pode ser reduzida às diferentes formas de seus atratores -- de pontos fixos a dinâmicas cada vez mais complexas e itinerantes. A partir dessa perspectiva, pode-se entender os organismos vivos como buscando constantemente um compromisso entre estabilidade excessiva e dispersão excessiva -- e a Inferência Ativa visa explicar como esse compromisso é alcançado.

\hypertarget{relauxe7uxf5es-entre-inferuxeancia-cogniuxe7uxe3o-e-dinuxe2mica-estocuxe1stica}{%
\section{Relações entre Inferência, Cognição e Dinâmica Estocástica}\label{relauxe7uxf5es-entre-inferuxeancia-cogniuxe7uxe3o-e-dinuxe2mica-estocuxe1stica}}

O físico E. T. Jaynes ficou famoso por argumentar que a inferência, a teoria da informação e a física estatística são perspectivas diferentes sobre a mesma coisa ( Jaynes 1957). Nas seções anteriores, discutimos como as perspectivas Bayesiana e da física estatística oferecem duas maneiras equivalentes de entender a minimização de surpresas e o comportamento ideal -- adicionando efetivamente uma forma de cognição à tríade de Jaynes. Essa equivalência entre várias escolas de pensamento é atraente, mas pode ser confusa para quem não está familiarizado com os respectivos formalismos, onde muitas palavras diferentes são usadas para se referir às mesmas quantidades. Para ajudar a desmistificar isso, nesta seção elaboramos as principais equivalências entre as perspectivas Bayesiana e Física Estatística e suas interpretações cognitivas; veja a tabela 3.1 para um resumo e o quadro 3.2.

\textbf{Tabela 3.1} Física estatística, inferência bayesiana e teoria da informação - e suas interpretações cognitivas

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\centering
Física estatística
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Inferência Bayesiana e Teoria da Informação
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Interpretação cognitiva
\end{minipage} \\
\midrule
\endhead
Minimize a energia livre variacional & Maximize a evidência do modelo (ou probabilidade marginal); minimizar a surpresa (ou auto-informação) & Percepção e ação \\
Minimize a energia livre esperada; Hamiltoniano princípio da menor ação & Inferir o curso de ação mais provável (ou menos surpreendente) & Planejamento como inferência \\
Atingir o estado estacionário de não equilíbrio & Realizar inferência Bayesiana aproximada & Auto-evidência \\
Fluxos de gradiente em funções de energia; gradiente descendente em energia livre & Ascensão do gradiente na evidência do modelo; descida gradiente na surpresa & Dinâmica neuronal \\
\bottomrule
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Quadro 3.2 Energia livre em física estatística e inferência ativa
\end{minipage} \\
\midrule
\endhead
A noção de energia livre é amplamente utilizada em física estatística para caracterizar (por exemplo) sistemas termodinâmicos. Embora a Inferência Ativa use exatamente as mesmas equações, ela as aplica para caracterizar o estado de crença de um agente (em relação a um modelo generativo). Assim, quando falamos de um agente de Inferência Ativa minimizando sua energia livre (variacional), estamos nos referindo a processos que mudam seu estado de crença, não (por exemplo) as partículas de seu corpo. Para evitar mal-entendidos, usamos o termo energia livre variacional, adotando uma terminologia mais comum em aprendizado de máquina. Outro ponto mais sutil é que o conceito de energia livre é frequentemente usado no contexto da termodinâmica estatística de equilíbrio. A Inferência Ativa tem como alvo organismos vivos -- ou sistemas de estado estacionário de não equilíbrio que são abertos -- que apresentam trocas contínuas e recíprocas com o meio ambiente. Este é um campo de romance emocionante (Friston 2019a). \\
\bottomrule
\end{longtable}

\hypertarget{energia-livre-variacional-eviduxeancia-modelo-e-surpresa}{%
\subsection{Energia Livre Variacional, Evidência Modelo e Surpresa}\label{energia-livre-variacional-eviduxeancia-modelo-e-surpresa}}

Uma primeira equivalência importante é entre a maximização da evidência do modelo (ou probabilidade marginal) na inferência Bayesiana e a minimização da energia livre variacional -- ambas minimizam a surpresa. Essa equivalência torna-se evidente quando se apela para uma solução aproximada específica para problemas intratáveis de inferência -- inferência variacional. A inferência variacional reformula o problema de inferência como um problema de otimização minimizando a energia livre. O mínimo da energia livre é o ponto em que a aproximação da solução exata está no seu melhor. Expressar isso formalmente esclarece as relações entre as três quantidades:

\[\begin{matrix} \underbrace {ℑ(y|m)} \\ Surpresa \end{matrix} = \begin{matrix}\underbrace{-ln\;P(y|m)} \\ Evidência\; do \; modelo\end{matrix} \le \begin{matrix} \underbrace{D_{KL}[Q(x)||P(x|y,m)]- \ln P(y|m)} \\ Energia \; Livre\; Variacional \end{matrix} \qquad (3.2)\]
Na equação 3.2, diferentemente do capítulo 2, condicionamos explicitamente todas as quantidades em um modelo, m, para enfatizar que elas dependem do modelo que temos (ou somos) sobre como y são gerados, e as quantidades irão variar se modelos diferentes são usados. A equivalência dessas quantidades levanta a questão de por que é útil distingui-las. A principal razão é que, ao contrário da evidência do modelo, a energia livre variacional pode ser minimizada de forma eficiente.

Lembre-se do capítulo 2 que a energia livre variacional só é exatamente equivalente à evidência negativa do modelo ou surpresa quando o termo KL-Divergência se torna zero. Isso nem sempre é possível, mas pode ser feito próximo de zero. Assim, no processo de encontrar valores cada vez melhores para \(Q(x)\), a energia livre variacional também se aproxima mais da surpresa. Já dissemos isso algumas vezes porque é importante enfatizar a relação central entre energia livre e surpresa que é a base deste livro. Especificamente, a energia livre é um limite superior para a surpresa. Pode ser o mesmo ou maior que a surpresa -- onde o que é maior do que é quantificado pela KL-Divergence.

Um aspecto interessante disso é que qualquer sistema que minimize sua surpresa, incluindo o sistema muito simples da figura 3.2, também está minimizando uma energia livre, onde \(Q(x)\) é sempre igual à probabilidade a posteriori exata - isto é, definindo o KL-Divergence como zero. Uma perspectiva sobre a diferença entre sistemas cognitivos e não cognitivos é que os últimos sempre têm uma divergência KL zero, enquanto os sistemas cognitivos devem passar pelo processo (perceptual) de minimizar esse termo antes que suas ações sejam garantidas para minimizar a surpresa. Observe que minimizar a divergência é a única coisa que a percepção pode fazer.

Isso dá muita ênfase ao movimento dos estados internos, de modo que a distribuição que eles parametrizam (figura 3.2) é o mais próximo possível da posterior exata. No entanto, a percepção não pode minimizar o segundo componente (evidência) da energia livre variacional que corresponde à surpresa real, porque não pode alterar as sensações que foram coletadas. Somente agindo de maneira que mude as sensações, um agente pode minimizar o segundo componente (evidência) da energia livre variacional e resolver sua surpresa -- ou, equivalentemente, maximizar sua evidência de modelo. Isso coloca ênfase no movimento de estados ativos, dados estados internos, em auto-evidência.

Um exemplo ajuda a ilustrar este ponto. Imagine que seu modelo generativo preveja uma distribuição dos níveis de glicose em seu sangue, de acordo com os níveis de fome, com níveis de glicose relativamente altos versus baixos relacionados à saciedade e à fome, respectivamente. Além disso, imagine que esse modelo atribua uma probabilidade anterior mais alta à saciedade e, portanto, a níveis relativamente altos de glicose -- tornando os níveis baixos de glicose surpreendentes. Imagine que você está inicialmente incerto sobre seus níveis de fome e sente a glicemia baixa. A percepção leva à inferência de que você está com fome e à experiência da fome -- fechando a KL-Divergence. No entanto, a percepção não pode ir além disso para reduzir sua surpresa -- e a discrepância entre o alto nível de glicose que você espera a priori e o baixo nível de glicose que você sente -- porque ela não pode agir em suas sensações (baixa glicose) ou em suas sensações. causas (fisiologia). Você só pode minimizar sua surpresa agindo para mudar (a fonte oculta de) as sensações que você reúne -- por exemplo, comendo uma sobremesa.

Em suma, a percepção pode minimizar a energia livre variacional ao reduzir a discrepância entre o posterior aproximado e o verdadeiro, mas não pode ir além na minimização da surpresa. O próximo passo da minimização da surpresa envolve a mudança das sensações que se obtém ao agir, que é onde a inferência vai além da percepção e se torna ativa.

\hypertarget{energia-livre-esperada-e-inferuxeancia-da-trajetuxf3ria-mais-provuxe1vel}{%
\subsection{Energia Livre Esperada e Inferência da Trajetória Mais Provável}\label{energia-livre-esperada-e-inferuxeancia-da-trajetuxf3ria-mais-provuxe1vel}}

Outra equivalência importante é entre a minimização da energia livre esperada e a inferência do curso de ação ou política mais provável. Isso vai além de especificar a parte menos surpreendente do espaço de estados e trata de quão surpreendentes podem ser as rotas alternativas para essa parte ou local. Esses caminhos alternativos são expressos em termos de políticas, que são essencialmente trajetórias entre estados. É importante ressaltar que na Inferência Ativa a probabilidade de log

Outra equivalência importante é entre a minimização da energia gratuita esperada e a inferência do curso de ação ou política mais provável. Isso vai além de especificar a parte menos surpreendente do espaço de estados e lida com o quão surpreendentes podem ser as rotas alternativas para essa parte ou local. Esses caminhos alternativos são expressos em termos de políticas, que são essencialmente trajetórias entre estados. É importante ressaltar que na Inferência Ativa a probabilidade logarítmica de uma política é definida proporcionalmente à energia livre esperada se essa política for seguida. Isso implica que o caminho mais provável ou menos surpreendente é (definido para ser) aquele que minimiza a energia livre esperada. Esta formulação é equivalente à forma como Ação é definida na física, onde pontua a probabilidade de um caminho por uma integral (ou soma) de uma energia. Enquanto um sistema físico pode perseguir um espaço de trajetórias hipotéticas, o caminho que ele realmente segue é aquele para o qual Ação é minimizada -- ou seja, o princípio da menor Ação de Hamilton. Essa analogia entre a Inferência Ativa e o princípio da menor Ação de Hamilton é descompactada na próxima seção.

\hypertarget{inferuxeancia-ativa-uma-nova-base-para-entender-o-comportamento-e-a-cogniuxe7uxe3o}{%
\section{Inferência ativa: uma nova base para entender o comportamento e a cognição}\label{inferuxeancia-ativa-uma-nova-base-para-entender-o-comportamento-e-a-cogniuxe7uxe3o}}

Em campos como controle ótimo, aprendizado por reforço e economia, a otimização do comportamento resulta de uma função de valor de estados, seguindo a equação de Bellman (Sutton e Barto 1998). Essencialmente, a cada estado (ou par estado-ação) é atribuído um valor, que representa quão bom é um estado para um agente estar. O valor dos estados (ou pares estado-ação) é geralmente aprendido por tentativa e erro, por contando quantas vezes - e depois de quanto tempo - se obtém recompensa partindo desses estados. O comportamento consiste em otimizar a aquisição de recompensas alcançando estados de alto valor, portanto, capitalizando o histórico de aprendizado.

Em contraste, na Inferência Ativa, o comportamento é resultado da inferência e sua otimização é uma função das crenças. Essa formulação une noções de crença (prévia) e preferência. Como discutido acima, usar a noção de energia livre esperada equivale a dotar o agente de uma crença prévia implícita de que ele realizará suas preferências. Assim, a preferência do agente por um curso de ação torna-se simplesmente uma crença sobre o que ele espera fazer e encontrar no futuro -- ou uma crença sobre futuras trajetórias de estados que ele visitará. Isso substitui a noção de valor pela noção de crença (prévia). Este é um movimento aparentemente estranho, se alguém tem experiência em aprendizado por reforço (onde valor e crença são separados) ou estatística Bayesiana (onde crença não implica nenhum valor). No entanto, é um movimento poderoso, por pelo menos três razões.

Primeiro, implica automaticamente um modelo de processo autoconsistente de comportamento intencional (ou teleológico), que é semelhante a formulações cibernéticas. Se dotarmos um agente de Inferência Ativa com alguma preferência prévia, ele agirá para realizar tais preferências - porque esse é o único curso de ação consistente com sua crença anterior de que ele agirá para cumprir suas expectativas. Observe que o curso de ação ou política resultante (preferido) é diretamente mensurável em ambientes experimentais, enquanto uma função de valor ou crença anterior precisa ser inferida e, portanto, é uma medida mais indireta, se não tautológica.

Em segundo lugar, colocar o comportamento como um funcional de crenças (distribuições de probabilidade) automaticamente implica noções como grau de crença e incerteza. Essas noções sustentam facetas importantes da ação adaptativa, mas não estão diretamente disponíveis na formulação de Bellman. Da mesma forma, essa formulação dá mais flexibilidade na modelagem de dinâmicas sequenciais e comportamentos itinerantes, que são mais difíceis de modelar em termos de uma função de valor de estados (Friston, Daunizeau e Kiebel 2009).

Terceiro, nesta formulação, o comportamento ótimo vem a seguir um princípio hamiltoniano de menor ação em física estatística. De fato, a Inferência Ativa vai um passo adiante em direção à ideia de que o comportamento é uma função de crenças: ela também assume que se torna uma função de energia -- e o curso de ação mais provável de um agente de Inferência Ativa é aquele que minimiza a energia livre. Uma consequência profunda é que os organismos vivos se comportam de acordo com o princípio de Hamilton da menor ação: eles seguem um caminho de menor resistência até atingirem um estado estacionário (ou uma trajetória y de estados), como exemplificado pelo comportamento de um sistema dinâmico aleatório (mostrado na figura 3.3). Esta é uma suposição fundamental que distingue a Inferência Ativa de teorias alternativas de comportamento e cognição baseadas na formulação de Bellman.

Vale a pena esboçar brevemente o que queremos dizer ao traçar analogias entre a física hamiltoniana e a Inferência Ativa. Isto destina-se a três níveis. A primeira é que o avanço oferecido pela Inferência Ativa às ciências do comportamento e da vida é comparável ao avanço das formulações lagrangeanas \footnote{Uma Lagrangiana é uma função de uma posição e velocidade que dá a diferença entre as energias cinética e potencial. Um hamiltoniano está relacionado (através de uma transformada de Legendre) e expressa a energia total do sistema em termos de posição e momento.} e hamiltonianas oferecidas aos relatos da mecânica de Newton. Enquanto a mecânica newtoniana foi originalmente formulada em termos de equações diferenciais -- incluindo a famosa terceira lei de Newton que expressa a proporcionalidade entre aceleração e força -- uma perspectiva complementar sobre a mecânica foi oferecida considerando o que é conservado pelos sistemas dinâmicos. A dinâmica newtoniana pode então ser derivada dessas leis de conservação.

O segundo ponto de conexão entre a física Hamiltoniana e a Inferência Ativa surge de uma associação mais direta entre um Hamiltoniano e medidas de probabilidade. A ideia aqui é associar o Hamiltoniano conservado com a energia do sistema. Lembre-se de que as quantidades às quais nos referimos como energias até agora (aqui e no capítulo 2) tiveram todas a forma de um logaritmo de probabilidade negativo. Isso reflete uma interpretação de energia como simplesmente uma medida da improbabilidade de qualquer configuração de um sistema. Nesta visão, conservação de energia e de probabilidade são leis equivalentes. À medida que os sistemas dissipativos -- acoplados a estados externos por meio de um envoltório de Markov -- se movem para estados de baixa energia ou alta probabilidade, podemos associar diretamente a energia ou o Hamiltoniano à surpresa. Como tal, a Inferência Ativa é a física Hamiltoniana aplicada a um certo tipo de sistema (sistemas que apresentam um envoltório de Markov).

A terceira associação entre essas formulações é o cálculo variacional que subscreve a associação entre energias e dinâmicas. Isso é mais aparente quando a física hamiltoniana é expressa como um princípio de menor Ação, onde Ação se refere à integral de uma Lagrangiana ao longo de um caminho. Crucialmente, esta Ação é um funcional de um caminho. Aqui, um caminho é uma função do tempo cuja saída é a posição e a velocidade de uma partícula naquele caminho naquele momento. O caminho seguido por uma partícula (determinística) minimiza esta Ação. Da mesma forma, a Inferência Ativa baseia-se na ideia de que as crenças (funções de estados ocultos) devem minimizar um funcional de energia livre. O ponto chave de contato aqui é que em ambos os casos, as funções (caminhos ou crenças) devem ser otimizadas em relação aos funcionais (Ação ou energia livre, respectivamente). Isso coloca ambos no contexto do cálculo variacional, que é um ramo da matemática dedicado a encontrar extremos de funcionais. Na física, isso leva às equações de Euler-Lagrange. Na Inferência Ativa, chegamos a procedimentos de inferência variacional.

\hypertarget{modelos-poluxedticas-e-trajetuxf3rias}{%
\section{Modelos, Políticas e Trajetórias}\label{modelos-poluxedticas-e-trajetuxf3rias}}

Na seção 3.2, destacamos que o escopo da Inferência Ativa pertence àqueles sistemas que desfrutam de alguma separação de seu ambiente e vimos que isso se traduz na presença de um envoltório de Markov. Na seção 3.3, destacamos que a persistência desse envoltório requer dinâmicas que (em média) minimizem a surpresa dos estados (sensoriais). Como isso pode ser interpretado como autoevidente, chegamos à conclusão de que o comportamento é determinado por uma distribuição de estado estacionário que pode ser interpretada como um modelo generativo de como os dados (sensoriais) são gerados.

Isso nos diz algo muito importante. Cada modelo generativo deve estar associado a diferentes tipos de comportamento. Como tal, diferentes tipos de comportamento podem ser explicados especificando diferentes modelos generativos -- e implicitamente o que esse sistema acharia surpreendente. Além disso, diferentes tipos de modelo generativo podem corresponder a criaturas adaptativas ou cognitivas com vários níveis de complexidade (Corcoran et al.~2020). Modelos generativos muito simples do tipo que conduzem a dinâmica na Figura 3.3 oferecem um tipo mínimo de cognição, pois não podem considerar a possibilidade de trajetórias alternativas (ou contrafactuais). Além disso, esses modelos são superficiais, no sentido de que permitem inferência em apenas uma escala de tempo. Em contraste, os modelos generativos hierárquicos permitem inferência em múltiplas escalas de tempo. Em modelos hierárquicos ou profundos, a dinâmica em níveis hierárquicos mais altos geralmente codifica coisas que mudam mais lentamente (por exemplo, a frase que estou lendo) e que contextualizam coisas que mudam mais rapidamente (por exemplo, a palavra que estou lendo), que são representadas em níveis mais baixos. níveis hierárquicos (Kiebel et al.~2008; Friston, Parr e de Vries 2017).

O que precisamos incluir em um modelo para derivar comportamentos mais complexos do tipo que associaríamos à agência e aos sistemas sencientes? Uma resposta para isso é a capacidade de modelar futuros alternativos, ou diferentes maneiras pelas quais os eventos podem se desenrolar -- e selecionar entre eles. Por sua vez, considerar futuros possíveis requer um modelo generativo que tenha alguma profundidade temporal e represente explicitamente as consequências das ações. Trabalhar isso no modelo garantirá um comportamento que esteja de acordo com o mais provável desses futuros. A capacidade (contrafactual) de entreter essas alternativas pode ser o que separa o estado estacionário associado aos sistemas sencientes das criaturas mais simples. Quando futuros alternativos dizem respeito a coisas sobre as quais temos controle, nos referimos a eles como políticas ou planos. Como vimos no capítulo 2, uma forma de desambiguar esses planos é incorporar uma crença prévia em um modelo que diz que as políticas com a menor expectativa de energia livre são as mais plausíveis. Isso oferece uma maneira de caracterizar um certo tipo de sistema com um envoltório de Markov em estado estacionário -- o que parece corresponder bem a sistemas como o nosso.

\hypertarget{reconciliauxe7uxe3o-das-teorias-enativa-cibernuxe9tica-e-preditiva-sob-inferuxeancia-ativa}{%
\section{Reconciliação das Teorias Enativa, Cibernética e Preditiva sob Inferência Ativa}\label{reconciliauxe7uxe3o-das-teorias-enativa-cibernuxe9tica-e-preditiva-sob-inferuxeancia-ativa}}

Ao enfatizar a minimização da energia livre, a Inferência Ativa une e estende três perspectivas teóricas aparentemente desconexas.

Primeiro, a Inferência Ativa está de acordo com as teorias enativas da vida e da cognição, que enfatizam a auto-organização do comportamento e as interações autopoiéticas com o ambiente, que garantem que os organismos vivos permaneçam dentro de limites aceitáveis (Maturana e Varela 1980). A Inferência Ativa fornece uma estrutura formal que explica como os organismos vivos conseguem resistir à dispersão de seus estados por meio da auto-organização de uma estrutura estatística -- o envoltório de Markov -- que permite trocas recíprocas entre organismo e ambiente, ao mesmo tempo em que separa (e, em certo sentido, protege a integridade de ) os estados dos organismos a partir de dinâmicas ambientais externas.

Em segundo lugar, a Inferência Ativa está de acordo com as teorias cibernéticas, que descrevem o comportamento como intencional e teleológico. Teleologia significa que o comportamento é regulado internamente por um mecanismo que continuamente testa se um objetivo é alcançado e, se não, orienta ações corretivas (Rosenblueth et al.~1943, Wiener 1948, Ashby 1952, G. Miller et al.~1960, Powers 1973 ). Da mesma forma, os agentes de Inferência Ativa usam tanto a percepção quanto a ação para minimizar a discrepância entre os estados preferidos e detectados. A Inferência Ativa fornece uma descrição normativa e viável do processo de minimização, especificando que o que é realmente minimizado é uma quantidade estatística que o agente pode medir -- energia livre variacional -- que sob certas condições corresponde a um erro de previsão, ou a diferença entre o que é esperado e o que é sentido. Isso implica uma formulação do controle cibernético como um processo prospectivo -- o que nos leva ao próximo ponto.

Terceiro, a Inferência Ativa está de acordo com as teorias que descrevem o controle como um processo prospectivo que se baseia em um modelo do ambiente -- possivelmente implementado fisicamente no cérebro (Craik 1943). A Inferência Ativa assume que os agentes usam um modelo (generativo) para construir previsões que orientam a percepção e a ação e para avaliar suas possibilidades de ação futuras (e contrafactuais). Essa suposição é coerente com o teorema do bom regulador (Conant e Ashby 1970), que diz que qualquer controlador deve ter -- ou ser -- um bom modelo do ambiente. A Inferência Ativa reconcilia essas perspectivas baseadas em modelos sobre cérebro e comportamento sob uma caracterização rigorosa em termos de inferência Bayesiana (aproximada) e minimização de energia livre (variacional e esperada). Além disso, a Inferência Ativa é amplamente coerente com a teoria ideomotora (Herbart 1825, James 1890, Hoffmann 1993, Hommel et al.~2001), que afirma que a ação começa com um processo imaginativo, e é uma representação preditiva (das consequências da ação) que desencadeia ações -- não um estímulo, como na teoria estímulo-resposta (Skinner 1938). A Inferência Ativa lança essa ideia em uma estrutura inferencial, na qual uma ação decorre de uma crença (sobre o futuro); isso tem várias implicações, como o fato de que, para desencadear a ação, é preciso atenuar temporariamente a evidência sensorial (o que, de outra forma, falsificaria a crença que desencadeia a ação) (H. Brown et al.~2013).

A reconciliação dessas estruturas é interessante, pois muitas vezes são consideradas em desacordo. Por exemplo, a auto-organização e a teleologia são muitas vezes vistas como incompatíveis na biologia. Além disso, as teorias enativas tendem a não enfatizar a representação e o controle, que é, em vez disso, uma construção central da maioria das teorias de inferência baseada em modelos. A Inferência Ativa formaliza a dinâmica autopoiética de agentes adaptativos a partir de um ângulo incomum, que considera simultaneamente a auto-organização e a previsão. Ao conectar diferentes perspectivas, a Inferência Ativa pode nos ajudar a entender como elas iluminam umas às outras.

\hypertarget{inferuxeancia-ativa-da-emerguxeancia-da-vida-para-a-atuauxe7uxe3o}{%
\section{Inferência Ativa, da Emergência da Vida para a atuação}\label{inferuxeancia-ativa-da-emerguxeancia-da-vida-para-a-atuauxe7uxe3o}}

A Inferência Ativa parte dos primeiros princípios e os desdobra para explicar o comportamento e a cognição expressos desde as formas mais simples até as mais complexas de sistemas adaptativos e vivos. No continuum entre criaturas mais simples e mais complexas, a Inferência Ativa traça uma linha entre aquelas que minimizam a energia livre variacional e aquelas que também minimizam a energia livre esperada.

Qualquer sistema adaptativo que ativamente amostra sensações para minimizar a energia livre variacional é (equivalentemente) um agente que reúne ativamente evidências para seu modelo generativo, também conhecido como agente de autoevidência (Hohwy 2016). Esses sistemas são capazes de evitar a dissipação, autorregular-se e sobreviver alcançando os pontos de ajuste fornecidos pelos processos homeostáticos básicos. Esses sistemas podem gerar formas complexas e diversas de comportamento e também podem ter níveis de aptidão muito altos (como já é aparente no caso dos vírus). Alguns podem ter modelos generativos hierárquicos que permitem inferir eventos que mudam em diferentes escalas de tempo, de mais rápido (em níveis hierárquicos mais baixos) a mais lentos (em níveis mais altos) -- e, portanto, podem desenvolver estratégias sofisticadas para lidar com o que vivenciam. No entanto, essas criaturas também são fundamentalmente limitadas porque seus modelos generativos carecem de profundidade temporal -- ou a capacidade de planejar e considerar o futuro explicitamente (embora possam fazê-lo implicitamente, por exemplo, como resultado da evolução genética) -- e, portanto, sempre vivem no presente.

Um modelo generativo dotado de profundidade temporal abre a porta para a minimização da energia livre esperada -- ou em termos psicológicos, planejamento. Na Inferência Ativa, isso envolve muito mais do que uma maior adaptabilidade: envolve pelo menos uma forma primitiva de atuação. Para um sistema adaptativo, minimizar a energia livre esperada é equivalente a ter o (implícito) anterior que é um agente de minimização de energia livre - mas atua para minimizar a energia livre no futuro. Quando essa crença (prévia) entra no modelo generativo, o sistema adaptativo torna-se capaz de formar crenças sobre como deve se comportar no futuro e quais trajetórias seguirá. Em outras palavras, torna-se capaz de selecionar entre futuros alternativos ao invés de simplesmente selecionar como lidar com o presente percebido, como nos agentes mais simples descritos acima. Essa profundidade temporal se traduz, portanto, em uma profundidade psicológica. Perguntar sobre as maneiras pelas quais as criaturas vivas povoam o continuum entre os sistemas adaptativos mais simples e os mais complexos -- e quais formas de Inferência Ativa eles podem expressar -- é uma questão empírica.

\hypertarget{resumo-2}{%
\section{Resumo}\label{resumo-2}}

Os principais tópicos deste capítulo podem ser resumidos da seguinte forma: Os organismos vivos devem garantir que eles visitem apenas seus estados característicos ou preferidos. Se definirmos esses estados preferidos como estados esperados, podemos dizer que os organismos vivos devem minimizar a surpresa de suas observações sensoriais (e manter uma entropia ótima; veja o quadro 3.3).

Fazer isso requer que os agentes exerçam alguma autonomia da dinâmica ambiental e sejam equipados com um envoltório de Markov que separe (ou seja, expresse uma independência condicional entre) seus estados internos e os estados externos do ambiente. Agentes dentro do envoltório de Markov podem se engajar em trocas recíprocas (ação-percepção) com o ambiente. Essas trocas são formalmente descritas pela teoria da Inferência Ativa, onde tanto a percepção quanto a ação minimizam a surpresa. Eles podem fazer isso sendo equipados com um modelo generativo probabilístico de como suas observações sensoriais são geradas. Este modelo define surpresa -- ou melhor, um proxy tratável, energia livre variacional, que pode ser medida e minimizada com eficiência.

Um agente de Inferência Ativa parece realizar inferência Bayesiana (aproximada) sob um modelo generativo e maximizar a evidência para seu modelo -- isto é, é um agente autoevidente. A parte prospectiva da inferência é realizada pela seleção de cursos de ações ou políticas que se espera que minimizem a energia livre no futuro. Esse formalismo leva a uma nova visão do comportamento (ótimo) em termos do princípio hamiltoniano da menor ação -- um (primeiro) princípio que conecta a Inferência Ativa aos domínios da física estatística, termodinâmica e estados estacionários de não equilíbrio.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Quadro 3.3} Minimização de entropia e comportamento aberto
\end{minipage} \\
\midrule
\endhead
A Inferência Ativa é baseada na premissa de que os organismos vivos se esforçam para manter uma ordem relativa (ou entropia negativa), controlabilidade e previsibilidade, apesar de estarem imersos em um ambiente cujas forças naturais geram flutuações contínuas -- e uma ameaça sem fim de erosão entrópica. A manifestação mais básica dessa busca ativa da ordem é a homeostase fisiológica, com parâmetros fisiológicos críticos que precisam ser mantidos dentro de regiões viáveis. No entanto, minimizar a entropia não deve ser equiparado a um repertório rígido de respostas (por exemplo, respostas homeostáticas autonômicas), mas sim o oposto, especialmente em organismos avançados. Podemos desenvolver repertórios abertos de novos comportamentos para perseguir nossos imperativos homeostáticos originais --- por exemplo, produzir e comprar um bom vinho para satisfazer a sede e outras necessidades. Isso às vezes é chamado de ``alostase'' (Sterling 2012).Mais amplamente, buscamos ativamente alguma ordem e controlabilidade per se, sem referência necessária a um imperativo homeostático específico -- talvez porque preservar a ordem facilite muitos desses imperativos. Esculpimos ativamente nossos nichos ecológicos para torná-los mais previsíveis e menos surpreendentes. Isso fica evidente nas formas como construímos nossos espaços físicos (por exemplo, refúgios e cidades que abrigam forças naturais descontroladas) e espaços culturais (por exemplo, sociedades com leis e normas deônticas que abrigam forças sociais anárquicas). Em todos esses exemplos, geralmente precisamos aceitar algum aumento de entropia ou surpresa de curto prazo (por exemplo, quando construímos algo novo ou mudamos posições sociais) para garantir sua diminuição no longo prazo. Isso nos ajuda a entender como o requisito básico para a minimização de surpresas não está em desacordo, mas promove os imperativos epistêmicos e o comportamento de busca de novidades, curiosidade e exploração que reconhecemos como centrais para muitas espécies. Uma primeira maneira pela qual os imperativos epistêmicos se tornam aparentes é durante a minimização da energia livre variacional. Uma das maneiras de decompor a energia livre é expressá-la como uma energia de Gibbs esperada sob o posterior aproximado menos a entropia do posterior aproximado. Em outras palavras, o agente está se esforçando para aumentar a entropia. Embora isso pareça paradoxal, o paradoxo desaparece se considerarmos que esta é a entropia da crença do agente (aproximadamente posterior). Isso pode ser entendido como o imperativo de explicar as coisas com a maior precisão possível, mas também ``manter as opções em aberto'' e evitar se comprometer com qualquer explicação específica, a menos que isso seja necessário -- ou seja, o princípio da entropia máxima ( Jaynes 1957). Uma segunda maneira pela qual a dinâmica epistêmica se torna aparente é durante a minimização da energia livre esperada, onde -- curiosamente -- existem duas entropias com sinais opostos. Estes incluem a entropia preditiva posterior (quão incerto eu estou sobre quais resultados eu encontraria dada uma escolha) que deve ser maximizada -- como para crenças sobre estados na energia livre variacional -- e a entropia condicional de resultados dados estados (a ambiguidade implicada por uma política) que deve ser minimizada. Enquanto durante a minimização da energia livre variacional o imperativo é maximizar a entropia das crenças (presentes), durante a maximização da energia livre esperada o imperativo é selecionar ações que minimizem a ambiguidade das crenças (futuras). Isso dá origem a comportamentos epistêmicos, curiosos, de busca de novidades e de busca de informações, que suportam a resolução de incertezas ou a melhoria do modelo generativo -- o que, por sua vez, minimiza a surpresa a longo prazo (Seth 2013; Friston, Rigoli et al.~2015; Seth e Friston 2016; Schwartenbeck, Passecker et ai. 2019). \\
\bottomrule
\end{longtable}

\hypertarget{os-modelos-geradores-de-inferuxeancia-ativa}{%
\chapter{Os Modelos Geradores de Inferência Ativa}\label{os-modelos-geradores-de-inferuxeancia-ativa}}

Every­thing should be made as ­simple as pos­si­ble, but not simpler.
---­Albert Einstein

\hypertarget{introduuxe7uxe3o-3}{%
\section{Introdução}\label{introduuxe7uxe3o-3}}

Este capítulo complementa o tratamento conceitual da Inferência Ativa
dos capítulos anteriores com um tratamento mais formal. Especificamente,
estabelece a relação entre energia livre e inferência Bayesiana, a forma
dos modelos generativos tipicamente usados na Inferência Ativa, e a
dinâmica obtida da minimização da energia livre para esses modelos. Um
foco principal é como o tempo é representado em um modelo generativo.
Veremos a distinção entre modelos generativos formulados em tempo
contínuo e aqueles que tratam o tempo como uma sequência de eventos.
Finalmente, apresentamos a ideia de passagem de mensagens inferenciais,
que subscreve teorias proeminentes em neurobiologia --- incluindo
codificação preditiva.

\hypertarget{da-inferuxeancia-bayesiana-uxe0-energia-livre}{%
\section{Da Inferência Bayesiana à Energia Livre}\label{da-inferuxeancia-bayesiana-uxe0-energia-livre}}

Nos dois capítulos anteriores, delineamos algumas das conexões
importantes entre a Inferência Ativa e outros paradigmas estabelecidos
nas neurociências. No capítulo 2, nos concentramos na noção de cérebro
bayesiano (Knill e Pouget 2004, Doya 2007) -- um de seus parentes mais
próximos -- que fornece uma maneira útil de pensar sobre algumas das
consequências da inferência ativa de uma perspectiva mais formal.

Especificamente, ele nos ajuda a enquadrar os problemas que um agente
envolvido na Inferência Ativa deve resolver. Em termos gerais, esses são
o problema de inferir estados do mundo (percepção) e inferir um curso de
ação (planejamento). Embora seja tentador igualar a otimalidade de Bayes
com a inferência Bayesiana exata, a inferência exata geralmente é
computacionalmente intratável ou mesmo inviável. Em aplicações de
psicologia cognitiva e inteligência artificial, é comum considerar
formas limitadas de inferência e racionalidade. Destacamos alguns
exemplos no capítulo 3. Sob uma estrutura bayesiana, isso se traduz no
uso de inferência aproximada. Esses métodos compreendem métodos de
amostragem e métodos variacionais -- nos quais se baseia a inferência
ativa. Nesta seção, recapitulamos os elementos básicos da inferência
bayesiana e suas manifestações variacionais (Beal 2003, Wainwright e
Jordan 2008). Ao fazê-lo, esperamos fornecer alguma intuição para o
papel da energia livre e enfatizar a importância dos modelos generativos
na elaboração de inferências sobre o mundo.

Este capítulo é mais técnico do que os capítulos 1 a 3, apelando para um
pouco de álgebra linear, diferenciação e expansão em série de Taylor. Os
leitores interessados nos detalhes ou que precisem de uma atualização
podem recorrer aos apêndices para obter os antecedentes necessários.
Aqueles que não querem se aprofundar nos fundamentos teóricos podem
pular este capítulo. Ao longo, explicamos as principais implicações de
cada equação - para que seja possível desenvolver uma compreensão dos
pontos conceituais importantes aqui, mesmo sem seguir o argumento
formal.

Um bom ponto de partida é o teorema de Bayes. Lembre-se do capítulo 2
que esse teorema expressa uma igualdade entre o produto de uma
verossimilhança a priori e o produto de uma verossimilhança a
posteriori. Isso é reproduzido na equação 4.1:

\[P(x)P(y|x) = P(x|y)P(y)\]
\[ P(y) = \sum_x P(y|x) = \sum_x P(y|x)P(x) \qquad\qquad (4.1)\]

A primeira linha da equação 4.1 é o teorema de Bayes. A segunda linha
mostra que a verossimilhança marginal (ou evidência do modelo), \(P(y)\),
pode ser calculada diretamente a partir do anterior e da
verossimilhança.\footnote{Aqui e ao longo do capítulo, o condicionamento ao modelo é deixado
  implícito; portanto, a evidência do modelo é escrita como \(P(y)\) e
  não \(P(y|m)\).} Isso mostra que a anterior e a verossimilhança -
que juntas compõem o modelo generativo - são suficientes para
calcularmos a evidência do modelo e a probabilidade posterior. Apesar
disso, nem sempre é fácil fazê-lo. A soma (ou integração, se lidar com
variáveis contínuas) na equação 4.1 pode ser computacionalmente ou
analiticamente intratável. Uma maneira de resolver isso -- o ponto de
partida da inferência variacional -- é converter esse problema de
integração potencialmente difícil em um problema de otimização. Para
entender como isso funciona, precisamos recorrer à desigualdade de
Jensen, que diz que ``o log \footnote{Tecnicamente, isso é verdade para qualquer função côncava, mas
  estamos preocupados apenas com logaritmos aqui.} de uma média é sempre maior ou igual à
média de um log''. A Figura 4.1 fornece uma intuição gráfica de por que
esse é o caso.

\begin{figure}
\centering
\includegraphics{images/Figura_4_1.png}
\caption{\textbf{Figura 4.1} Função logarítmica fornecendo intuição para a
desigualdade de Jensen. Se tivéssemos apenas dois pontos de dados (\(x1\)
e \(x2\)), ou poderíamos pegar sua média (\(\mathbb E[x]\)) e encontrar seu
log, ou poderíamos pegar o log de cada ponto de dados e então tirar a
média desses (\(\mathbb {E}[ln x]\)). Este último (\(\mathbb{E}[ln x]\))
estará sempre abaixo do primeiro (\(ln \mathbb{E}[x]\)), devido à
concavidade da função logarítmica, a menos que os pontos de dados sejam
os mesmos (onde o logaritmo da média e a média de o log são iguais).
Essa desigualdade vale para qualquer número de pontos de
dados.}
\end{figure}

Para tirar proveito dessa propriedade, podemos reescrever a equação 4.1
multiplicando o termo dentro da soma na segunda linha por uma função
arbitrária (\(Q\)) dividida por ela mesma (isso é equivalente a
multiplicar por um, então a igualdade ainda é válida) e tomando o
logaritmo de cada lado. Matematicamente, isso não muda nada. No entanto,
agora podemos interpretar a expressão como uma expectativa
(\(\mathbb{E}\))\footnote{Uma expectativa é uma soma ponderada ou integral do termo dentro
  dos colchetes; cada termo é ponderado pela probabilidade indicada
  pelo índice (ver quadro 2.2).}: de uma razão entre duas probabilidades e assim
explorar a desigualdade de Jensen:

\[ \ln P(y) = \ln \sum_x P(y,x){Q(x)\over Q(x)}= \ln \mathbb{E_{Q(x)}[{P(y,x)\over Q(x)}]} \ge \mathbb{E}_{Q(x)} [\ln {P(y,x) \over Q(x)}] \triangleq -F[Q,y] \qquad(4.2)\]

A segunda linha desta equação usa o fato de que temos uma expectativa
logarítmica e que, pela desigualdade de Jensen, esta deve ser sempre
maior ou igual à expectativa logarítmica. Esse movimento às vezes é
chamado de amostragem de importância. O lado direito dessa desigualdade
é conhecido como energia livre variacional (negativa):\footnote{Neste livro, seguimos a convenção do físico em que a energia livre
  é um limite superior na evidência de log negativo. No entanto,
  outras disciplinas (incluindo estatística e aprendizado de máquina)
  usam a energia livre negativa como um limite inferior de evidência
  (ou ELBO). Estes são completamente equivalentes, mas podem causar
  alguma confusão na pesquisa interdisciplinar.} quanto menor
a energia livre, mais próxima está da evidência do modelo logarítmico
negativo. Com isso em mente, podemos reescrever o teorema de Bayes
(equação 4.1) na forma logarítmica, tomar sua média sob a distribuição
posterior e divulgar a relação entre isso e as quantidades da equação
4.2:

\[ \ln P(x,y) = \ln P(y) + \ln P(x|y) \Longrightarrow  \]
\[ \mathbb{E}_{P(x|y)} [\ln P(x,y)] = \ln P(y) + \mathbb{E}_{P(x|y)}[\ln P(x|y)] \qquad\qquad (4.3) \]

\[ \mathbb{E}_{Q(x)} [\ln P(x,y)] = \ln -F[Q,y] + \mathbb{E}_{Q(x)}[\ln Q(x)]\]
A segunda linha decorre do fato de que a probabilidade logarítmica de y
não é uma função de x, portanto, tomar uma expectativa sob a
distribuição a posteriori não altera essa quantidade. A Equação 4.3
fornece alguma intuição para os papéis da energia livre e da
distribuição Q --- as duas quantidades que eram difíceis de calcular sem
a aproximação variacional. A primeira desempenha o papel de evidência do
modelo logarítmico negativo, enquanto a segunda atua como se fosse a
probabilidade posterior. Mais formalmente, podemos reorganizar a energia
livre como fizemos no capítulo 2 para quantificar a relação entre a
energia livre e a evidência do modelo:

\[ F[Q,y] = \begin{matrix} \underbrace {D_{KL}[Q(x) ||P(x|y) ] } \\ divergência \end{matrix} - \begin{matrix} \underbrace {\ln P(y)} \\ Log\;da\;Evidência\;do\;modelo \end{matrix} \]

\[D_{KL}[Q(x) ||P(x|y) ] = \mathbb{E}_{Q(x)}[\ln Q(x)-\ln P(x|y)]\] A
primeira linha da equação 4.4 mostra a energia livre expressa em termos
de KL-Divergence e uma evidência de log negativo. A KL-Divergence é
definida na segunda linha como a diferença esperada entre duas
probabilidades logarítmicas. Isso é frequentemente usado como uma medida
de quão diferentes duas distribuições de probabilidade são uma da outra.

Às vezes, o uso de energia livre é motivado diretamente em função dessa
divergência. O argumento é que, se nosso objetivo é realizar inferência
Bayesiana aproximada, precisamos encontrar um posterior aproximado que
melhor corresponda ao posterior exato. Como tal, podemos selecionar uma
medida da divergência entre os dois -- da qual o KL-Divergence na
equação 4.4 é um exemplo -- e minimizá-lo. Como não sabemos o posterior
exato, não podemos usar essa divergência diretamente. Uma solução é
adicionar o termo de evidência logarítmica, que pode ser combinado com o
logaritmo posterior para formar a probabilidade conjunta (que sabemos
porque este é o modelo generativo). O resultado é a energia livre.

Uma consequência interessante dessa perspectiva é que há alguma
ambiguidade sobre qual medida de divergência usar. Se quisermos fazer o
posterior aproximado e exato o mais próximo possível, poderíamos usar o
outro KL-Divergence, onde Q e P são trocados, ou escolher entre uma
grande família de divergências, cada uma das quais enfatizando
diferentes aspectos da diferença entre distribuições. No entanto, as
ideias expostas no capítulo 3 destacam a importância da autoevidência
para os sistemas envolvidos na Inferência Ativa. Portanto, estamos
procurando principalmente um esquema de maximização de evidências
tratável e apenas secundariamente procurando minimizar a divergência.
Nessa perspectiva, não há ambiguidade quanto à medida de divergência a
ser usada. Isso emerge do uso da desigualdade de Jensen.

\hypertarget{modelos-geradores}{%
\section{Modelos Geradores}\label{modelos-geradores}}

Para calcular a energia livre, precisamos de três coisas: dados, uma
família de distribuições variacionais e um modelo generativo
(compreendendo uma a priori e uma probabilidade). Nesta seção,
descrevemos dois tipos muito gerais de modelos generativos usados para
Inferência Ativa e a forma que a energia livre assume em relação a cada
um. A primeira trata de inferências sobre variáveis categóricas (por
exemplo, identidade do objeto) e é formulada como uma sequência de
eventos. O segundo trata de inferências sobre variáveis contínuas (por
exemplo, contraste de luminância) e é formulado em tempo contínuo usando
equações diferenciais estocásticas. Antes de especificar os detalhes
desses modelos, revisamos um formalismo gráfico que expressa as
dependências implícitas em um modelo generativo.

A Figura 4.2 mostra vários exemplos de modelos generativos expressos
como gráficos de fatores, escolhidos para fornecer alguma intuição para
os tipos de coisas que podem ser articuladas dessa maneira. Estes
representam os fatores (por exemplo, anterior e probabilidade) de um
modelo generativo como quadrados e as variáveis nesse modelo (estados ou
dados ocultos) em círculos. As setas indicam a direção da causalidade
entre essas variáveis. O gráfico superior esquerdo mostra a forma mais
simples que esses modelos podem assumir, com um estado oculto \((x)\)
causando dados \((y)\). A priori neste modelo é mostrada como fator 1, e a
probabilidade é fator 2. Os outros gráficos estendem essa ideia
introduzindo variáveis adicionais. No canto superior direito, z
desempenha o papel de um segundo estado oculto, de modo que y depende
dos estados de x e z.

Como exemplo, considere um teste de diagnóstico clínico. Nesse cenário,
o gráfico simples no canto superior esquerdo pode ser interpretado como
a presença ou ausência de uma doença \((x)\) e o resultado do teste \((y)\).
O prior é então a prevalência da doença, enquanto a probabilidade
especifica as propriedades do teste. Estes incluem sua especificidade (a
probabilidade de um resultado negativo na ausência da doença) e a
sensibilidade (a probabilidade de um resultado positivo na presença da
doença). Podemos então pensar no modelo em termos do mecanismo pelo qual
um resultado de teste é obtido -- indo de cima para baixo no gráfico de
fatores. Primeiro, amostramos uma pessoa de uma população com
prevalência conhecida de uma doença. Se eles tiverem a doença, eles
gerarão um resultado de teste positivo verdadeiro com probabilidade dada
pela sensibilidade do teste e um falso negativo caso contrário. Caso não
tenham a doença, gerarão um verdadeiro negativo com probabilidade dada
pela especificidade, e um falso positivo caso contrário.

\begin{figure}
\centering
\includegraphics{images/Figura_4_2.png}
\caption{\textbf{Figura 4.2} Dependências entre variáveis em um modelo
probabilístico (gráfico). Os círculos representam variáveis aleatórias
(ou seja, as coisas sobre as quais temos crenças); os quadrados
representam as distribuições de probabilidade que descrevem as relações
entre essas variáveis. Uma seta de um círculo para outro através de um
quadrado indica que a variável do segundo círculo depende daquela do
primeiro círculo e que essa dependência é capturada na distribuição de
probabilidade representada pelo quadrado.}
\end{figure}

Seguindo o mesmo exemplo, podemos interpretar os outros gráficos de
fatores. No painel superior direito, \(x\) e \(z\) poderia ser a presença ou
ausência de duas doenças diferentes, qualquer uma das quais poderia dar
um resultado de teste positivo. No canto inferior esquerdo, \(w\)
desempenha o papel de dados. Ambos \(y\) e \(w\) são gerados por \(x\) e podem
representar (por exemplo) dois testes diagnósticos diferentes que são
informativos sobre o mesmo processo de doença. Finalmente, o gráfico
inferior direito trata \(x\) e \(v\) como estados ocultos, mas introduz uma
estrutura hierárquica na qual \(v\) causa \(x\) causa \(y\). Aqui poderíamos
pensar em \(v\) como fornecendo um contexto ou um fator predisponente (por
exemplo, polimorfismo genético) para a presença ou ausência da doença x,
que pode ser testada medindo y. Em princípio, podemos adicionar um
número arbitrário de variáveis a essa hierarquia.

Modelos generativos desse tipo são frequentemente usados para tarefas
perceptivas estáticas, como reconhecimento de objetos ou integração de
pistas. Os modelos generativos usados para inferência ativa diferem de
uma maneira importante: eles evoluem ao longo do tempo à medida que
novas observações são amostradas, e as observações que são adicionadas
dependem (via ação) de crenças sobre variáveis no modelo. Isso tem duas
implicações principais. Primeiro, as dependências condicionais incluem
as dependências de variáveis ocultas em um determinado momento daquelas
em momentos anteriores. Em segundo lugar, esses modelos às vezes incluem
hipóteses sobre ``como estou agindo'' como variáveis ocultas.

A Figura 4.3 ilustra as duas formas básicas do modelo generativo
dinâmico usado na inferência ativa (Friston, Parr e de Vries 2017) na
forma de gráfico fatorial (Loeliger 2004, Loeliger et al.~2007). O
gráfico superior mostra um Processo de Decisão Markov Parcialmente
Observável (POMDP), que expressa um modelo no qual uma sequência de
estados evolui ao longo do tempo. A cada passo de tempo, o estado atual
é condicionalmente dependente do estado no momento anterior e da
política (π ) que está sendo seguida. As políticas aqui podem ser
pensadas como indexadoras de trajetórias alternativas, ou sequências de
ações, que poderiam ser seguidas. Cada ponto no tempo está associado a
uma observação (o) que depende apenas do estado naquele momento. Esse
tipo de modelo é muito útil para lidar com tarefas de planejamento
sequencial -- por exemplo, navegar em um labirinto (Kaplan e Friston
2018) -- ou processos de tomada de decisão que envolvem a seleção entre
alternativas (por exemplo, categorização de uma cena {[}Mirza et al.~2016{]}).

\begin{figure}
\centering
\includegraphics{images/Figura_4_3.png}
\caption{\textbf{Figura 4.3} Dois modelos generativos dinâmicos (usando a mesma
notação gráfica da figura 4.2) aos quais recorreremos no restante deste
livro. Topo: Processo de Decisão Markov Parcialmente Observável (POMDP),
definido em termos de uma sequência de estados evoluindo ao longo do
tempo (indexados pelo subscrito). Abaixo: Modelo de tempo contínuo, do
tipo implícito por equações diferenciais estocásticas (com a notação
principal indicando derivadas temporais).}
\end{figure}

O gráfico inferior na figura 4.3 mostra um modelo gráfico muito
semelhante, mas expresso em tempo contínuo. Em vez de representar uma
trajetória como uma série de estados, este modelo representa a posição
atual, velocidade e aceleração (e sucessivas derivadas temporais) de um
estado (x). Esses valores (referidos como coordenadas generalizadas de
movimento) podem ser usados \hspace{0pt}\hspace{0pt}para reconstruir uma trajetória usando uma
expansão em série de Taylor (consulte o apêndice A para uma introdução
às aproximações em série de Taylor neste contexto). A relação entre um
estado e sua derivada temporal aqui depende de (lentamente variando)
causas (v) que desempenham um papel semelhante às políticas acima. Como
antes, os estados geram observações ( y). A diferença de notação (s, π,
o vs.~x, v, y) é usada para enfatizar a diferença entre variáveis
\hspace{0pt}\hspace{0pt}categóricas que evoluem em tempo discreto e variáveis \hspace{0pt}\hspace{0pt}contínuas que
evoluem em tempo contínuo. Da mesma forma, daqui em diante, usaremos p e
q minúsculo para densidades de probabilidade sobre variáveis \hspace{0pt}\hspace{0pt}contínuas
e P e Q maiúsculo para distribuições sobre variáveis \hspace{0pt}\hspace{0pt}categóricas. As
Seções 4.4 e 4.5 descompactarão esses modelos com mais detalhes e
mostrarão como a minimização da energia livre em cada caso leva a um
conjunto de equações que descrevem a dinâmica dos processos
inferenciais.

\hypertarget{inferuxeancia-ativa-em-tempo-discreto}{%
\section{Inferência ativa em tempo discreto}\label{inferuxeancia-ativa-em-tempo-discreto}}

Nesta seção, focamos no modelo de tempo discreto descrito acima. Isso é
importante para entender uma série de processos cognitivos que lidam com
inferências categóricas e seleção entre hipóteses alternativas. Esse
formalismo também facilita o exame do problema clássico de
prospecção-aproveitamento e ilustra como a inferência ativa resolve
isso.

\hypertarget{processos-de-decisuxe3o-markov-parcialmente-observuxe1veis}{%
\subsection{Processos de Decisão Markov Parcialmente Observáveis}\label{processos-de-decisuxe3o-markov-parcialmente-observuxe1veis}}

Conforme mostrado na figura 4.3, um POMDP expressa a evolução ao longo
do tempo de uma sequência de estados ocultos que dependem de uma
política. Para especificar formalmente esse processo, precisamos levar
em conta a forma de cada um dos nós de fator quadrado na figura.
Primeiro, descrevemos cada um desses fatores. Em seguida, nós os
combinamos para expressar a distribuição conjunta que constitui o modelo
generativo.

Assim como no exemplo simples da regra de Bayes dado no capítulo 2,
podemos separar os fatores entre aqueles que representam uma
probabilidade e aqueles que se combinam para formar uma a priori. A
probabilidade é semelhante à usada anteriormente e expressa a
probabilidade de um resultado (observável) dado um estado (oculto). Se
os resultados e os estados são variáveis categóricas, a probabilidade é
uma distribuição categórica, parametrizada por uma matriz, A:

\[P(o_\tau|s_\tau)=Cat(A)\]
\[A_{ij}=P(o_\tau=i | s_\tau = j) \qquad \qquad (4.5)\] A segunda linha
aqui detalha o que significa a notação Cat (ou seja, especificação de
uma distribuição categórica). Isso representa os nós rotulados como ``2''
na figura 4.3. A prioridade sobre a sequência (expressa usando o símbolo
\textasciitilde) de estados ocultos depende de duas coisas: a anterior sobre o estado
inicial (especificado por um vetor, D) e crenças sobre como o estado em
um momento transita para o estado seguinte ( especificado como uma
matriz, B):

\[P(\tilde S|\pi)=P(S_1)\prod P(S_{\tau+1 | S_{\tau}}, \pi)\]
\[P(S_1)=Cat(D) \qquad\qquad\qquad\qquad(4.6)\]
\[P(S_{\tau+1}|S_\tau,\pi)=Cat(B_{\pi\tau})\]

Juntos, eles representam os ``3'' nós na figura 4.3. Observe que as
transições são condicionalmente dependentes da política escolhida.
Assim, podemos interpretar as prioris da equação 4.6, combinadas com a
verossimilhança da equação 4.5, como expressando um modelo (π ) de uma
sequência comportamental. Para nos permitir selecionar entre esses
modelos (ou seja, para formar um plano), precisamos de uma crença prévia
sobre a sequência mais provável. Para uma criatura minimizadora de
energia livre, uma priorização autoconsistente é que as políticas mais
prováveis são aquelas que levarão à menor energia livre esperada (G) no
futuro:

\[P(\pi)=Cat(\pi_0)\]
\[\pi_0=\sigma(-G) \qquad\qquad\qquad\qquad\qquad (4.7)\]
\[G_\pi = G(\pi)=-\mathbb{E_\tilde Q[D_{KL}[Q(\tilde s|\tilde o, \pi) || Q(\tilde s| \pi)]]}-\mathbb{E_\tilde Q[\ln P(\tilde o|C)]}\]
\[\tilde Q(o_\tau, s_\tau | \pi) \triangleq P(o_\tau |s_\tau)Q(s_\tau | \pi)\]

Esta equação, sendo de fundamental importância para a Inferência Ativa,
vale a pena descompactar com mais profundidade. As duas primeiras linhas
expressam a probabilidade a priori para cada política, conforme
parametrizada por \(\pi_0\), como sendo relacionada à energia livre
esperada negativa associada àquela política . A função softmax
\((\sigma)\) impõe normalização (ou seja, garante que a probabilidade
sobre as políticas soma um)

As duas linhas finais da equação 4.7 expressam a forma da energia livre
esperada.

Observe a semelhança entre isso e a forma funcional da energia livre
(equação 4.4) - com uma probabilidade logarítmica de resultados e uma
KL-Divergência. A principal diferença aqui é que a expectativa é tomada
em relação à densidade preditiva posterior conforme definida pela
igualdade final. Essa distribuição expressa uma probabilidade conjunta
sobre estados e observações futuras. Fundamentalmente, isso significa
que podemos calcular a energia livre esperada no futuro -- algo que não
poderíamos fazer com a energia livre variacional, que depende de
observações (presentes e passadas). Além disso, observe que a
distribuição sobre os resultados depende dos parâmetros (C ) e da
reversão do sinal da KL-Divergência, que é consequência da expectativa
sob a probabilidade preditiva posterior. Este último ponto pode causar
alguma confusão, por isso vale a pena explicar explicitamente por que
isso acontece. No contexto da energia livre variacional, a
KL-Divergência foi a diferença esperada entre a probabilidade
logarítmica do posterior aproximado e a probabilidade logarítmica do
posterior exato (equação 4.4). O termo análogo na energia livre esperada
é a diferença esperada entre o posterior aproximado e o posterior exato
que obteríamos com base em toda a trajetória de resultados, usando
crenças posteriores atuais como se fossem anteriores. Descompactando
isso, temos o seguinte:

\[\mathbb E[\ln Q(\tilde s | \pi) - \ln Q(\tilde s | \tilde o, \pi) ]\]
\[= \mathbb E_{Q(\tilde o|\pi)}[ \mathbb E_{Q(\tilde s | \tilde o,\pi)}[\ln Q(\tilde s|\pi) - \ln Q(\tilde s|\tilde o, \pi) ] ]\]

\[= \mathbb E_{Q(\tilde o|\pi)}[ \mathbb E_{Q(\tilde s | \tilde o,\pi)}[\ln Q(\tilde s|\tilde o,\pi) - \ln Q(\tilde s| \pi) ] ] \qquad\qquad\qquad\qquad (4.8)\]

\[= - \mathbb E_{Q(\tilde o|\pi)}[D_{KL}[Q(\tilde s | \tilde o, \pi) || Q(\tilde s| \pi)]]\]

Aqui vemos que a ordem em que as expectativas devem ser tomadas é
importante.

Ele provoca uma inversão de sinal em relação ao termo análogo na energia
livre variacional. Isso subscreve uma diferença importante entre as duas
quantidades. A energia livre esperada é minimizada selecionando aquelas
observações que causam uma grande mudança nas crenças, em contraste com
a energia livre variacional que é minimizada quando as observações
obedecem às crenças atuais. Essa é a diferença entre otimizar as crenças
em relação aos dados que já foram coletados (minimização variacional de
energia livre) e selecionar os dados que melhor otimizarão as crenças
(minimização de energia livre esperada).

Isso reitera que a Inferência Ativa usa dois construtos, energia livre
variacional (F ) e energia livre esperada (G), que são matematicamente
relacionados, mas desempenham papéis distintos e complementares. A
energia livre variacional é a quantidade primária que é minimizada ao
longo do tempo. Ele é otimizado em relação a um modelo generativo, que
pode incluir políticas (ou sequências de ações). Assim como em todos os
outros estados ocultos, o agente precisa atribuir uma probabilidade
anterior às políticas - porque as políticas são apenas mais uma variável
aleatória no modelo generativo. A Inferência Ativa usa uma priori que é
(vagamente falando) equivalente à crença de que se minimizará a energia
livre no futuro: ou seja, a energia livre esperada. Em outras palavras,
a energia livre esperada fornece uma prioridade sobre as políticas e,
portanto, é um pré-requisito para minimizar a energia livre variacional.

No capítulo 2 vimos que, assim como a energia livre variacional, a
energia livre esperada pode ser rearranjada de várias maneiras para
revelar várias interpretações. Aqui, nos concentramos em uma
interpretação como a diferença entre o risco e a ambiguidade associada a
uma política. Isso é equivalente à expressão na equação 4.7:

\$\$\$\$

\[G(\pi)=\begin{matrix} \underbrace{-\mathbb{E_\tilde Q}[D_{KL}[Q(\tilde S | \tilde o, \pi)||Q(\tilde S | \pi)]]} \\ ganho\;de\;informação  \end{matrix} - \begin{matrix} \underbrace{-\mathbb{E_\tilde Q}[\ln P(\tilde o | C)]} \\ valor\;pragmático \end{matrix} \qquad \qquad \qquad (4.9)\]

\[\begin{matrix} \underbrace{\mathbb{E_\tilde Q}[H[P(\tilde o|\tilde s)]]} \\ ambiguidade\;esperada  \end{matrix} +  \begin{matrix} \underbrace{D_{KL}[Q(\tilde o | \pi) || P(\tilde o | C)]} \\ risco \end{matrix}\]

Lembre-se do capítulo 2 que o primeiro deles expressa o trade-off entre
buscar novas informações (ou seja, prospecção) e buscar observações
preferidas (ou seja, aproveitamento). Ao minimizar a energia livre
esperada, o equilíbrio relativo entre esses termos determina se o
comportamento é predominantemente exploratório ou explorador. Observe
que o valor pragmático surge como uma crença prévia sobre observações,
onde os parâmetros C dessa distribuição podem ser escolhidos para
refletir o tipo de sistema que estamos interessados em caracterizar (em
termos de suas características ou estados de resultado preferidos).
Seguindo a segunda linha da equação 4.9, podemos reescrever a equação
4.7 na forma algébrica linear da seguinte forma:

\[\pi_o = \sigma(-G)\]
\[G_\pi = H\cdot  s_{\pi\tau} + o_{\pi\tau} \cdot \varsigma_{\pi\tau}\]

\[\varsigma_{\pi\tau} = \ln o_{\pi\tau} - \ln C_\tau \]
\[H = -diag(A \cdot \ln A)\]

\[P(o_\tau | C) = Cat(C_\tau) \qquad \qquad (4.10)\]

\[Q(o_\tau | \pi) = Cat(o_{\pi\tau}) , o_{\pi\tau} = As_{\pi\tau} \]

\[Q(S_\tau|\pi)=Cat(s_{\pi\tau})\]
\[Q(S_\tau)=Cat(S_\tau) , s_\tau = \sum_\pi \pi_\pi s_{\pi\tau} \] A
primeira linha da equação 4.10 usa um operador softmax (exponencial
normalizado) para construir uma distribuição de probabilidade
(parametrizada com estatísticas suficientes \(π_0\) que soma um do vetor
de energia livre esperado. As linhas dois a quatro expressam os
componentes da energia livre esperada em notação algébrica linear. A
quinta linha mostra que a crença prévia sobre as observações é uma
distribuição categórica (cujas estatísticas suficientes são dadas no
vetor C). A sexta a oitava linhas especificam a relação entre as
quantidades algébricas lineares e as distribuições de probabilidade
associadas. Concluída a especificação do modelo generativo, podemos
agora expressar a energia livre em função das variáveis acima:

\[F = \pi \cdot F \]
\[F_\pi = \sum_\tau F_{\pi\tau} \qquad\qquad\qquad (4.11)\]
\[F_{\pi\tau}=s_{\pi\tau} \cdot (\ln s_{\pi \tau} - ln A \cdot o_\tau - \ln B_{\pi\tau}s_{\pi\tau-1})\]
A decomposição disso em uma soma ao longo do tempo é devido à
aproximação implícita de campo médio que assume que podemos fatorar o
posterior aproximado em um produto de fatores:

\[Q(\tilde s | \pi) = \prod_\tau Q(s_\tau|\pi)\] Na forma logarítmica,
isso se torna uma soma, assim como na equação 4.11. Essa fatoração é uma
das muitas possibilidades na inferência variacional -- e representa a
opção mais simples. Na prática, isso é muitas vezes ligeiramente
matizado, conforme detalhado no apêndice B.

\hypertarget{inferuxeancia-ativa-em-um-pomdp}{%
\subsection{Inferência ativa em um POMDP}\label{inferuxeancia-ativa-em-um-pomdp}}

Até agora, definimos os quatro ingredientes principais para um modelo
generativo de tempo discreto. Estas são a probabilidade \((A)\),
probabilidades de transição \((B)\), crenças anteriores sobre observações
\((C)\) e crenças anteriores sobre o estado inicial \((D)\). Uma vez que
essas distribuições de probabilidade são especificadas, um esquema
genérico de passagem de mensagens pode ser empregado para minimizar a
energia livre e resolver o POMDP. Para fazer inferências sobre estados
ocultos sob uma determinada política, definimos a taxa de variação de
uma variável auxiliar \((v)\), que representa o log posterior \((s)\), igual
ao gradiente de energia livre negativo. Uma função softmax (exponencial
normalizada) é então usada para calcular \(s\) de \(v\).

\[s_{\pi\tau}=\sigma(v_{\pi\tau})\]

\[\dot v_{\pi\tau} =\epsilon_{\pi\tau} \triangleq - \nabla F_{\pi\tau} \qquad (4.13)\]

\[ =\ln A \cdot o_\tau + ln B_{\pi\tau}s_{\pi\tau-1} + \ln B_{\pi\tau+1} \cdot s_{\pi\tau-1} - \ln s_{\pi\tau}  \]

A Equação 4.13 pode ser considerada como um exemplo de passagem de
mensagens variacional (ver caixa 4.1). Para atualizar crenças sobre
políticas, encontramos a posterior que minimiza a energia livre:

\[ \nabla_\pi F = 0 \Longleftrightarrow  \qquad \qquad (4.14)\]

\[ \pi = \sigma(-G-F)\]

Para a forma mais simples de POMDP, as equações 4.13 e 4.14 podem ser
usadas para resolver um problema de Inferência Ativa para qualquer
conjunto de matrizes de probabilidade; estes podem ser pensados como
descrevendo percepção e planejamento, respectivamente. Vamos destrinchar
isso com mais detalhes na segunda parte do livro, onde forneceremos
exemplos trabalhados de Inferência Ativa para percepção e planejamento
(e outras funções cognitivas).

As representações gráficas da Figura 4.4 das equações 4.10, 4.13 e 4.14
sugerem possíveis implementações neuronais de minimização de energia
livre no cérebro -- se interpretarmos nós como populações neuronais,
bordas como sinapses e mensagens como trocas sinápticas. Em capítulos
posteriores, consideraremos a extensão disso para espaços de estados
fatorados, modelos temporais profundos e a otimização dos parâmetros do
próprio modelo generativo (aprendizagem).

\hypertarget{inferuxeancia-ativa-em-tempo-contuxednuo}{%
\section{Inferência Ativa em Tempo Contínuo}\label{inferuxeancia-ativa-em-tempo-contuxednuo}}

Na seção anterior, tratamos da forma que a Inferência Ativa assume sob
uma escolha particular de modelo generativo. Esses POMDPs são uma
maneira útil de articular uma série de problemas de inferência,
incluindo aqueles que subscrevem o planejamento e a tomada de decisões.
No entanto, quando se trata de interagir com um ambiente real, os
modelos descritos em tempo discreto com variáveis categóricas ficam
aquém. Isso ocorre porque as entradas sensoriais e as saídas motoras são
variáveis em constante evolução. Para explicar isso, agora nos voltamos
para um tipo diferente de modelo generativo. Aplicamos exatamente a
mesma ideia, um gradiente descendente na energia livre variacional, a
esses modelos para encontrar os esquemas de passagem de mensagens
análogos.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Quadro 4.1 Transmissão e inferência de mensagens
\end{minipage} \\
\midrule
\endhead
\textbf{Envoltórios de Markov} Encontramos o conceito de um envoltório de Markov no capítulo 3. No entanto, vale a pena revisar brevemente a ideia aqui. Refere-se a um sistema de múltiplas variáveis que interagem. Um envoltório de Markov para uma determinada variável compreende um subconjunto daquelas que interagem com ela. Se sabemos tudo sobre esse subconjunto, o conhecimento de qualquer coisa fora desse subconjunto não aumenta nosso conhecimento da variável de interesse. A relevância aqui é que podemos fazer inferências sobre uma variável em um modelo gráfico com base em informações locais sobre seu envoltório de Markov. O envoltório de uma variável \(x\) são aquelas variáveis que causam \(x\) ( pais, \(ρ(x)\)), as variáveis que são causadas por \(x\) (filhos, \(κ (x)\)) e os pais dos filhos de \(x\). Usando esta notação, dois dos esquemas Bayesianos de passagem de mensagens mais comuns usados para inferência aproximada são definidos da seguinte forma:\textbf{Passagem de mensagem variacional}\( \ln Q(x)=\mathbb{E}_{Q(\rho(x))}[\ln P(x|\rho(x))]+\mathbb{E}_{\frac {Q(\kappa (x))Q(\rho(\kappa (x)))}{Q(x)}}[\ln P( \kappa (x) | \rho(\kappa (x)))]\)Isso envolve mensagens de todos os constituintes do envoltório de Markov de \(x\), incluindo os pais (através da probabilidade condicional de \(x\) dado seus pais) e os filhos. O último depende da probabilidade condicional dos filhos de \(x\) dados todos os seus pais -- que incluem \(x\). Observe que a expectativa inclui os filhos e os pais das crianças. Como os pais das crianças incluem \(x\), dividimos por \(Q(x)\) para garantir que a expectativa inclua apenas o envoltório.\textbf{Propagação de crenças}\(\ln Q(x) = \ln \mu_\kappa(x) + \ln \mu_\rho(x) \) \(\mu_\kappa(x)=\mathbb{E_{\frac{\mu_\kappa(\kappa(x))\mu_\rho(\kappa(x))}{\mu_x(\kappa(x))}}}[P( \kappa(x) | \rho(\kappa(x)) )]\)\(\mu_\rho(x)=\mathbb{E_{\frac{\mu_\rho(\rho(x))\mu_\kappa(\rho(x))}{\mu_x(\rho(x))}}}[P( x | \rho(x) )]\)Isso tem basicamente a mesma estrutura que a passagem de mensagens variacional, mas usa uma definição recursiva de mensagens tal que cada mensagem  \(μ_a(b)\) sendo a mensagem de \(a\) para \(b\) ) depende de outras mensagens (as mensagens para \(a\)). Há um aspecto direcional nisso, de modo que a mensagem de \(a\) para \(b\) depende de todas as mensagens para \(a\), exceto a de \(b\) (daí a divisão nas expectativas). NB: O uso ligeiramente fora do padrão do operador de expectativa aqui nos permite (1) cobrir variáveis discretas e contínuas e (2) destacar as semelhança entre a passagem de mensagens variacional e a propagação de crenças. \\
\bottomrule
\end{longtable}

\begin{figure}
\centering
\includegraphics{images/Figura_4_4.png}
\caption{\textbf{Figura 4.4} Passagem de mensagens bayesianas. Direita: Dependências
entre diferentes variáveis \hspace{0pt}\hspace{0pt}no esquema de atualização de crenças
descrito no texto principal. Intuitivamente, as crenças atuais sobre os
estados (sob cada política) em cada momento são comparadas com aquelas
que seriam previstas dadas as crenças sobre os estados em outros
momentos (1) e os resultados atuais para calcular os erros de previsão.
Esses erros então impulsionam a atualização dessas crenças (2); dadas
crenças sobre estados sob cada política, podemos então calcular os
gradientes da energia livre esperada (3). Estes são combinados com os
resultados previstos em cada política (omitidos da figura) para calcular
as crenças sobre as políticas (4). Usando uma média do modelo Bayesiano,
podemos então calcular as crenças posteriores sobre os estados
calculados sobre as políticas (5). Este resumo de alto nível da passagem
de mensagens omite algumas conexões intermediárias que podem ser
incluídas (por exemplo, a conexão (4) pode ser descompactada para
incluir explicitamente o cálculo da energia livre esperada). Esquerda:
Este esquema pode ser expandido hierarquicamente (reduzindo ao longo de
etapas de tempo e políticas para simplificar). A ideia-chave é que uma
rede de nível superior pode prever os estados e políticas no nível
inferior e usá-los para fazer inferências sobre o contexto em que
ocorrem. Descompactaremos essa ideia mais adiante no capítulo
7.}
\end{figure}

\hypertarget{um-modelo-generativo-para-codificauxe7uxe3o-preditiva}{%
\subsection{Um modelo generativo para codificação preditiva}\label{um-modelo-generativo-para-codificauxe7uxe3o-preditiva}}

Para motivar a forma de modelo generativo usado para estados contínuos,
começamos com o seguinte par de equações:

\[ \begin{matrix} \dot x = f(x,v) + \omega_x \\
 y = g (x,v) + \omega_y  \end{matrix}  \qquad\qquad\qquad\qquad (4.15) \]
A primeira delas expressa a evolução de um estado oculto ao longo do
tempo, segundo uma função determinística \(( f (x, v))\) e flutuações
estocásticas \((ω)\). A segunda equação expressa a maneira pela qual os
dados são gerados a partir do estado oculto. Em cada caso, as flutuações
são assumidas normalmente distribuídas, dando as seguintes densidades de
probabilidade para a dinâmica e a probabilidade:

\[ \begin{matrix}  
\rho(\dot x | x,v) = N(f(x,v, \prod_x)) \\
 \rho(y | x,v) = N(g(x,v, \prod_y)) 
 \end{matrix}  \qquad\qquad\qquad\qquad (4.16) \]

Os termos de precisão \((\prod)\) são a covariância inversa das
flutuações. Essas duas equações formam o modelo generativo que escreve
os filtros de Kalman-Bucy na engenharia. No entanto, esquemas desse tipo
são limitados pela suposição de flutuações não correlacionadas ao longo
do tempo (ou seja, suposições de Wiener). Isso é inadequado para
inferência em sistemas biológicos, onde as próprias flutuações são
geradas por sistemas dinâmicos e têm um grau de suavidade. Podemos
explicar isso considerando não apenas a taxa de mudança do estado oculto
e o valor atual dos dados, mas também suas velocidades, acelerações e
derivadas temporais subsequentes -- isto é, coordenadas generalizadas de
movimento (Friston, Stephan et al.~2010; ver quadro 4.2):

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Quadro 4.2 Coordenadas generalizadas de movimento
\end{minipage} \\
\midrule
\endhead
\textbf{Figura 4.5} Para representar uma trajetória em tempo contínuo, as coordenadas generalizadas de movimento fornecem uma parametrização simples. Isso é baseado em uma expansão polinomial (série de Taylor) em torno do tempo presente para fornecer uma função que nos permite extrapolar para o passado recente e futuro próximo. Os gráficos na figura 4.5 mostram uma trajetória em algum espaço \((x)\) ao longo do tempo \((\tau)\) como uma linha contínua. Da esquerda para a direita, mostram a trajetória representada em coordenadas generalizadas de movimento com uma, duas e três coordenadas (derivadas temporais sucessivas de x). Esta é a linha tracejada. A expansão aqui é em torno do ponto de tempo inicial. Com cada coordenada generalizada sucessiva, obtemos uma aproximação mais precisa da trajetória para o futuro proximal. Para a maioria das aplicações, cerca de seis coordenadas generalizadas são suficientes.\includegraphics{images/Figura_4_5.png} \\
\bottomrule
\end{longtable}

\[ \begin{matrix}  
\dot x = f(x,v) + \omega_x & \qquad \qquad y = g(x,v) + \omega_y \\
\dot x' = f'(x',v') + \omega'_x & \qquad \qquad y' = g'(x',v') + \omega'_y \\
\dot x'' = f''(x'',v'') + \omega''_x & \qquad \qquad y'' = g''(x'',v'') + \omega''_y \\
\vdots & \vdots \\
\dot x^{[i]} = f^{[i]}(x^{[i]},v^{[i]}) + \omega^{[i]}_x & \qquad \qquad y^{[i]} = g^{[i]}(x^{[i]},v^{[i]}) + \omega^{[i]}_y \\
\vdots & \vdots
 \end{matrix}  \qquad\qquad\qquad\qquad (4.17) \] Essas coordenadas
generalizadas podem ser resumidas de forma mais sucinta ao representar
uma trajetória (novamente usando o símbolo \textasciitilde) como um vetor com
elementos correspondentes às derivadas sucessivas acima:

\[\left . \begin{matrix} D\tilde x = \tilde f(\tilde x,\tilde v) + \tilde \omega_x \\ \tilde y = \tilde g(\tilde x,\tilde v) + \tilde \omega_y \end{matrix} \right \} \Longrightarrow \begin{matrix} p(\tilde x |\tilde v) = N(D \cdot \tilde f, \tilde \prod_x) \\ p(\tilde y |\tilde x,\tilde v) = N( \tilde g, \tilde \prod_y) \end{matrix} \qquad (4.18) \]
Na equação 4.18, \(D\) é uma matriz com uns acima da diagonal principal e
zeros em outros lugares. Isso efetivamente desloca todos os elementos do
vetor para cima e pode ser considerado um operador derivativo. As
matrizes de precisão generalizadas podem ser construídas com base na
suavidade que assumimos para as flutuações, conforme detalhado no
apêndice B. Equipado com uma a priori sobre a causa oculta \((v)\), cuja
relevância ficará mais clara a seguir, isso nos permite escrever as
energia livre para este modelo generativo:

\[ \begin{matrix} 
F[\mu,y] & = & -\ln p(\tilde y, \tilde \mu_x , \tilde \mu_\nu) \\ 
  & = & \frac{1}{2}\tilde \epsilon \cdot \tilde \prod \tilde \epsilon \\
  & = & \frac{1}{2}(\tilde \epsilon_y \cdot \tilde \prod_y \tilde \epsilon_y + \tilde \epsilon_x \cdot \tilde \prod_x \tilde \epsilon_x + \tilde \epsilon_v \cdot \tilde \prod_\nu \tilde \epsilon_\nu  \\
\tilde \epsilon & = & \begin{bmatrix} \tilde \epsilon_y \\ \tilde \epsilon_x \\ \tilde \epsilon_\nu \end{bmatrix} & = \begin{bmatrix} \tilde y - \tilde g(\tilde \mu_x,\tilde \mu_v)\\ D\tilde \mu_x - \tilde f(\tilde \mu_x,\tilde \mu_\nu) \\ \tilde \mu_\nu - \tilde \eta \end{bmatrix} \\
\tilde \prod & = & \begin{bmatrix} \tilde \prod_y & & \\   & \tilde \prod_y & \\  &   & \tilde \prod_y \end{bmatrix} 
\end{matrix}  \qquad \qquad \qquad (4.19)\]

Na equação 4.19, os termos \(\mu\) indicam a moda da densidade posterior
aproximada para os termos \(x\) e \(\nu\). A razão pela qual a energia livre
assume uma forma tão simples na primeira linha é que empregamos uma
aproximação de Laplace, conforme detalhado no quadro 4.3. Em resumo,
isso trata todas as densidades de probabilidade como gaussianas, o que
-- por meio de uma expansão em série de Taylor -- é equivalente a
assumir que estamos operando perto da moda da distribuição. A segunda
linha da equação expressa a probabilidade logarítmica em termos de erros
de predição ponderados de precisão quadrática. Isso omite todos os
termos que são constantes em relação ao modo posterior. A terceira linha
descompacta isso em termos de log de probabilidade, log de probabilidade
de \(x\) dado \(\nu\) e log antes de \(\nu\).

\hypertarget{inferuxeancia-ativa-como-codificauxe7uxe3o-preditiva-com-reflexos-motores}{%
\subsection{Inferência Ativa como Codificação Preditiva com Reflexos Motores}\label{inferuxeancia-ativa-como-codificauxe7uxe3o-preditiva-com-reflexos-motores}}

Como a variância do posterior aproximado é uma função analítica da moda,
sob a aproximação de Laplace, podemos otimizar a energia livre em
relação a moda. Uma maneira simples de pensar sobre isso é que
precisamos apenas encontrar as estimativas \textbf{máximas a posteriori}
(MAP) \footnote{As estimativas MAP são os estados mais prováveis considerando as
  crenças anteriores e os dados disponíveis; contraste isso com
  abordagens de máxima verossimilhança que não levam crenças em conta.} para cada estado. Estes são os meios da distribuição a
posteriori que podem ser equipados com sua precisão sem necessidade de
mais inferências através da aproximação de Laplace. (ver quadro 4.3).

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Quadro 4.3 A aproximação de Laplace
\end{minipage} \\
\midrule
\endhead
As aproximações de Laplace baseiam-se num princípio semelhante às coordenadas generalizadas de movimento descritas no quadro 4.2. A ideia é que a energia livre pode ser aproximada por uma expansão quadrática em torno do modo posterior (\(\mu\)). Em uma dimensão, é o seguinte: \( \begin{equation} F[y,q]= E_{q(x)}[\ln q(x) - \ln p(y,x) \end{equation}\) \( \begin{aligned}  \approx E_{q(x)} [ \ln q(\mu) + 
\begin{matrix}
(x-\mu)\underbrace {\partial_x \ln q(x)|_{x=\mu}}\\{=0}  
\end{matrix} + 
\frac{1}{2}(x-\mu)²\partial²_x \ln q(x)|_{x-\mu}  \\
-\ln p(y,\mu)-(x-\mu)\partial_x \ln p(y,x)|_{x=\mu} 
- \frac{1}{2}(x-\mu)^2\partial_x^2\ln p(y,x)|_{x=\mu}]
\end{aligned}\) A suposição de que uma expansão quadrática é suficiente equivale a dizer que podemos tratar as probabilidades como gaussianas (como o logaritmo de uma densidade gaussiana é quadrática). Tornando isso explícito, podemos simplificar o acima para o seguinte: \(q(x)=\mathcal{N}(\mu,\sum{}^{-1} )\) \(F[y,\mu]= -ln 2\pi\sum-\ln p(y,\mu)-1/2tr\bigg[\sum \partial_x^2 \ln p (y,\mu)\bigg|_{x=\mu} \bigg]\) Sob suposições quadráticas, o único termo que depende da moda é o segundo termo. A omissão dos outros termos leva à expressão na equação 4.19. Podemos encontrar a precisão do posterior aproximado diretamente, uma vez que conhecemos a moda, através da seguinte expansão: \( \begin{equation} 
\ln q(x) \approx \ln p(x|y) 
\\ ln p(x,y) - \ln (y)
\\ \approx \ln p(\mu, y) + (x - \mu) \cdot \underbrace{\partial_x\ln p(x,y)|_{x=\mu}}_{=0} 
\\ + \frac{1}{2} (x-\mu)\cdot \partial_x^2 \ln p(x,y)\bigg|_{x=\mu}(x-\mu)-\ln p(y)
\\ \Longrightarrow q(x) \varpropto e^{-\frac{1}{2}(x-\mu)\sum{}^{-1}(x-\mu)} , \quad \sum{}^{-1}=-\partial^2_x \ln p(x,y)\bigg|_{x=\mu}
\end{equation} \) Isso nos diz que a precisão posterior é simplesmente a segunda derivada da probabilidade conjunta avaliada na moda posterior \\
\bottomrule
\end{longtable}

\[ \begin{equation} 
\dot{\tilde \mu} = D\tilde = \mu-\nabla_{\tilde\mu}F
\\ = \nabla_\tilde{\mu} \ln p(\tilde y,\tilde\mu)
\\ = -\nabla_{\tilde\mu}\tilde \epsilon \cdot \tilde \prod \tilde \epsilon
\end{equation} \qquad\qquad(4.20)
\]

\[ \begin{equation}
\begin{bmatrix} 
\dot{\tilde \mu}_x - D\tilde \mu_x  \\ \dot{\tilde \mu}_\nu - D\tilde \mu_\nu
\end{bmatrix} 
= \begin{bmatrix} 
\nabla_{{\tilde \mu}_x}\tilde g\cdot \tilde \prod_y\tilde\epsilon_y - D\cdot\tilde\prod_x\tilde\epsilon_x + \nabla_{\tilde\mu_x}\tilde f \cdot \tilde \prod_x \tilde \epsilon_x  
\\  \nabla_{{\tilde \mu}_\nu}\tilde g\cdot \tilde \prod_y\tilde\epsilon_y + \nabla_{\tilde\mu_\nu}\tilde f \cdot \tilde \prod_x \tilde \epsilon_x - \tilde \prod_\nu \tilde \epsilon_\nu 
\end{bmatrix}  
\end{equation} \]

.Em contraste com as descidas de gradiente que vimos para o esquema de tempo discreto, o lado esquerdo da equação 4.20 é a diferença entre a taxa de variação de \(\mu\) e o operador derivativo aplicado a ela. Isso ocorre porque quando a energia livre é minimizada, não faz sentido que a taxa de variação da moda posterior seja zero se a moda posterior associado às taxas de variação for diferente de zero. Em outras palavras, ``o movimento da moda deve ser a moda do movimento'' no mínimo de energia livre. Isso garante \(\mu^{[i]}=\mu^{[i+1]}\) quando a energia livre é minimizada.

Podemos ir um passo além da equação 4.20 e tratar a causa oculta (\(\nu\)) como se fossem dados gerados por um nível hierárquico superior, com dinâmica mais lenta (de modo que \(\nu\) parece não mudar no nível inferior). Ao fazer isso, podemos encadear uma hierarquia de equações:

\[ \begin{bmatrix} 
\vdots \\ \dot{\tilde\mu_x}^{[i]}- D\tilde\mu_x^{[i]} \\ \dot{\tilde\mu_\nu}^{[i]}- D\tilde\mu_\nu^{[i]} \\ \vdots \end{bmatrix} = \begin{bmatrix} \vdots 
\\ \nabla_{{\tilde \mu}_x^{(i)}}\tilde g^{(i)}\cdot \tilde \prod_\nu^{(i-1)}\tilde\epsilon_\nu^{(i-1)} - D\cdot\tilde\prod_x^{(i)}\tilde\epsilon_x^{(i)} + \nabla_{\tilde\mu_x}^{(i)}\tilde f^{(i)} \cdot \tilde \prod_x^{(i)} \tilde \epsilon_x^{(i)} 
\\ \nabla_{{\tilde \mu}_\nu^{(i)}}\tilde g^{(i)}\cdot \tilde \prod_\nu^{(i-1)}\tilde\epsilon_\nu^{(i-1)} + \nabla_{\tilde\mu_x^{(i)}}\tilde f^{(i)} \cdot \tilde \prod_x^{(i)} \tilde \epsilon_x^{(i)}-\tilde\prod_\nu^{(i)}\tilde\epsilon_\nu^{(i)} 
\\ \vdots \end{bmatrix} \qquad (4.21)\]

\[\begin{bmatrix} \tilde \epsilon_x^{(i)} \\ \tilde \epsilon_\nu^{(i)} \end{bmatrix} = \begin{bmatrix} D\tilde\mu_x^{(i)}-f^{(i)}(\tilde\mu_x^{(i)}, \tilde\mu_\nu^{(i)}) \\ \tilde\mu_\nu^{(i)} - g^{(i+1)}(\tilde\mu_x^{(i+1)}, \tilde\mu_\nu^{(i+1)}) \end{bmatrix} \]
\[ \tilde\epsilon_\nu^{(0)} \triangleq \tilde\epsilon_y \]
A Figura 4.6 enfatiza graficamente o papel dos estados ocultos (x) na ligação entre as derivadas temporais dentro de um nível hierárquico e o papel das causas ocultas (v) na ligação entre os níveis hierárquicos. Nesse esquema de codificação preditiva (Rao e Ballard 1999, Friston e Kiebel 2009), níveis mais altos enviam previsões descendentes para níveis mais baixos, que computam erros nessas previsões e os repassam de volta para a hierarquia para atualizar as crenças.

Para completar nossa visão geral da codificação preditiva no contexto da Inferência Ativa, precisamos incorporar a ação. Dado que nosso objetivo é minimizar a energia livre e que as consequências da ação são que alteramos nossos dados sensoriais, temos o seguinte:

\[\begin{equation}\dot u = \nabla_uF = \\ -\nabla_u\tilde y(u) \cdot \tilde\prod_y \tilde\epsilon_y\end{equation} \qquad (4.22)\]
Essa equação diz que minimizamos a energia livre através da ação e que a única parte da energia livre que depende diretamente da ação é o nível mais baixo de erro de previsão. Em outras palavras, a ação simplesmente cumpre as previsões descendentes sobre os dados, minimizando o erro entre as consequências sensoriais da ação previstas e observadas. Uma maneira de pensar sobre isso é como se tivéssemos equipado um esquema de codificação preditivo com arcos reflexos clássicos no nível mais baixo da hierarquia (Adams, Shipp e Friston 2013). Nesta configuração, a Inferência Ativa é apenas codificação preditiva mais arcos reflexos. De uma perspectiva neurobiológica, a ideia é que os aferentes sensoriais entrem no tronco cerebral ou na medula espinhal e façam sinapse nos neurônios motores. Previsões descendentes da entrada sensorial são propagadas do córtex para os neurônios motores, cuja saída depende da diferença entre suas entradas corticais e sensoriais.

\begin{figure}
\centering
\includegraphics{images/Figura_4_6.png}
\caption{\textbf{Figura 4.6} Passagem de mensagens de esquemas de codificação preditivos generalizados. Esquerda: Cálculo de erros de previsão a partir de dados sensoriais, mostrando como eles podem ser propagados para cima através de uma hierarquia. Níveis mais altos enviam previsões para os níveis mais baixos que podem ser comparados com dados sensoriais para calcular esses erros. Direita: Uma única camada da hierarquia ilustra como as populações neuronais que representam diferentes ordens de movimento generalizado interagem umas com as outras.}
\end{figure}

Do ponto de vista computacional, um arco reflexo é uma das formas mais simples de controlador; esses desvios corretos nos sinais proprioceptivos previstos e observados. Comportamentos motores mais complexos requerem a geração de sequências de previsões e seu cumprimento em ordem usando arcos reflexos. Esse mecanismo diferencia a inferência ativa de outros esquemas de controle motor biológico, como o controle ótimo, que não são baseados em codificação preditiva e utilizam modelos e controladores inversos mais complexos que os arcos reflexos (Friston 2011). Outra característica peculiar da Inferência Ativa é que ela dispensa noções de valor ou custo usadas no controle ótimo (e aprendizado por reforço); estes são totalmente absorvidos pela noção (geralmente mais expressiva) de priores (ver capítulo 10 para uma discussão mais aprofundada).

\hypertarget{resumo-3}{%
\section{Resumo}\label{resumo-3}}

Este capítulo delineou as ideias formais básicas que sustentam a Inferência Ativa. A principal mensagem a ser retirada é que a inferência Bayesiana (aproximada) pode ser enquadrada como minimizando uma quantidade conhecida como energia livre variacional. Isso depende de um modelo generativo que expresse nossas crenças sobre como os dados são gerados. Examinamos duas formas de modelo generativo que podem ser empregadas dependendo do problema de inferência em questão: especificamente, se estamos interessados em variáveis categóricas ou contínuas. A solução de minimização de energia livre para ambos podem ser descompactados em termos de troca de mensagens entre populações de neurônios, incluindo os esquemas de codificação preditivos generalizados que seguem de modelos contínuos. Finalmente, notamos que a energia livre pode ser minimizada não apenas mudando as crenças -- de modo que elas se tornem consistentes com os dados -- mas também agindo no mundo para tornar os dados mais consistentes com as crenças. Nos capítulos subsequentes, apelaremos aos formalismos aqui introduzidos e os aplicaremos a configurações mais concretas, oferecendo uma oportunidade de explorar as extensões dos conceitos amplos aqui estabelecidos.

\hypertarget{passagem-de-mensagens-e-neurobiologia}{%
\chapter{Passagem de Mensagens e Neurobiologia}\label{passagem-de-mensagens-e-neurobiologia}}

Basicamente, existem dois tipos de animais: animais e animais que não têm cérebro; são chamados de plantas. Eles não precisam de um sistema nervoso porque não se movem ativamente, não arrancam suas raízes e correm em um incêndio florestal! Qualquer coisa que se mova ativamente requer um sistema nervoso; caso contrário, teria uma morte rápida. ---Rodolfo Llinas

\hypertarget{introduuxe7uxe3o-4}{%
\section{Introdução}\label{introduuxe7uxe3o-4}}

No capítulo 4, vimos a forma que a inferência variacional assume para dois tipos de modelo generativo. Neste capítulo, nos concentramos nas teorias de processo que surgem dessas dinâmicas inferenciais: teorias que explicam como o cérebro pode implementar a inferência variacional. Central para esta implementação de atualização de crença Bayesiana é a noção de passagem de mensagem Bayesiana, que engloba propagação de crença e passagem de mensagem variacional, entre outros esquemas. A ideia subjacente a esses esquemas é que nem tudo depende diretamente de todo o resto. Em vez disso, cada variável em um modelo generativo depende de relativamente poucas outras variáveis. Da mesma forma, o cérebro exibe uma estrutura de conectividade esparsa, em que a atividade de qualquer neurônio depende apenas daqueles neurônios com os quais compartilha sinapses. Este capítulo se concentra na maneira como podemos mapear a transmissão esparsa de mensagens associada à inferência variacional à estrutura de conectividade esparsa da computação biológica.

Vamos dar um passo atrás no material técnico do capítulo 4 e voltar nossa atenção para as teorias de processo que acompanham a Inferência Ativa. É importante fazer uma distinção entre um princípio (ou seja, a minimização da energia livre) e uma teoria de processo sobre como esse princípio pode ser implementado em um certo tipo de sistema, como o cérebro. Este último permite-nos desenvolver hipóteses que respondem a dados empíricos. Para abordar as maneiras pelas quais a Inferência Ativa pode se manifestar no cérebro, igualamos a transmissão de mensagens que vimos no final do capítulo 4 com a comunicação sináptica e a dinâmica do gradiente descendente com a atividade neuronal. O duplo objetivo deste capítulo é apresentar aos leitores com formação técnica a neurobiologia da Inferência Ativa e destacar aos biólogos a relevância da teoria para a neurociência prática. Ressaltamos que este capítulo não pretende ser a palavra final sobre teorias de processo para Inferência Ativa (Pezzulo, Rigoli e Friston 2015, 2018; Friston e Buzsaki 2016; Friston e Herreros 2016; Friston, FitzGerald et al.~2017; Friston, Parr et al.~2017; Parr e Friston 2018b; Parr, Markovic et al.~2019); é simplesmente a interpretação que parece mais consistente com as evidências atualmente disponíveis. Tampouco nosso objetivo é endossar uma teoria de processo específica, mas ilustrar como as ideias formuladas nos capítulos 1-4 podem ser colocadas em prática na formulação de hipóteses que respondem a medições neurobiológicas.

Este capítulo está organizado da seguinte forma. Primeiro, na seção 5.2, consideramos o papel de um microcircuito cortical. Esta é uma unidade funcional que compreende várias populações neurais conectadas umas às outras. O padrão de conectividade é replicado em muitas regiões corticais. Destacamos a relação entre este circuito estereotipado e as arquiteturas de transmissão de mensagens das figuras 4.4 e 4.6 -- elas mesmas recapituladas em níveis hierárquicos. Na seção 5.3 passamos para os sistemas efetores e a formulação do controle motor sob Inferência Ativa. Isso lida com a maneira pela qual o córtex motor sintoniza os arcos reflexos da coluna vertebral e do tronco cerebral para gerar um comportamento intencional. A Seção 5.4 aborda ideias relacionadas a estruturas subcorticais como o tálamo e os gânglios da base --- que têm papéis importantes no planejamento e na tomada de decisões. Em seguida, consideramos, na seção 5.5, a modulação da eficácia sináptica, incluindo o papel dos neurotransmissores na otimização da precisão e das mudanças plásticas na aprendizagem. Por fim, na seção 5.6 voltamos ao tema da hierarquia e da relação entre tomada de decisão e geração de movimento.

\hypertarget{microcircuitos-e-mensagens}{%
\section{Microcircuitos e Mensagens}\label{microcircuitos-e-mensagens}}

No capítulo 4, vimos que as equações de atualização de crença que mediam a inferência variacional podem ser interpretadas em termos de uma rede (neuronal). Os esquemas de inferência apresentados - para modelos contínuos e categóricos - dão origem a um circuito estereotipado cuja estrutura se repete em modelos generativos hierárquicos. Da mesma forma, a arquitetura do córtex cerebral tem uma estrutura estereotipada (Shipp 2007). O neocórtex é dividido em seis camadas (ou lâminas), numeradas de superficial (próximo da superfície do cérebro) a profunda (próximo à substância branca subcortical). Cada camada é caracterizada pela presença de tipos específicos de células e padrões de conectividade (Zeki e Shipp 1988, Felleman e Van Essen 1991, Callaway e Wiser 2009); essa conectividade está resumida no esquema de uma única coluna cortical na figura 5.1.

Uma coluna cortical em uma região do cérebro se conecta a colunas em outras regiões e a estruturas subcorticais. As regiões corticais são frequentemente representadas em uma hierarquia que (falando vagamente) atribui as regiões mais próximas da entrada sensorial ou da saída motora aos degraus mais baixos da hierarquia. À medida que nos afastamos dessas regiões -- por exemplo, do córtex visual primário para o secundário -- ascendemos na hierarquia. Essa noção de hierarquia é licenciada pela estrutura de conectividade laminar específica ilustrada na figura 5.1. Projeções ascendentes (ou seja, conexões) de áreas corticais inferiores ou núcleos talâmicos sensoriais (primários) tendem a atingir as células estreladas espinhosas na camada IV. As áreas corticais inferiores dão origem a conexões ascendentes de suas células piramidais superficiais (camadas II e III). As projeções descendentes das áreas corticais superiores atingem as camadas superficiais e profundas das áreas inferiores, com origens nas células piramidais profundas (camada VI). Além disso, células piramidais profundas (de Betz) na camada V projetam-se para vários outros alvos, incluindo núcleos subcorticais -- como os gânglios da base e núcleos talâmicos secundários -- e neurônios motores espinhais.

O esquema do meio na figura 5.1 mostra um possível mapeamento da rede para codificação preditiva (figura 4.4) para a anatomia laminar do córtex (Friston, Parr e de Vries 2017). Isso é um pouco complicado de interpretar, mas os pontos-chave são os seguintes. A entrada ascendente para as células estreladas espinhosas da camada IV está associada ao erro de previsão para causas ocultas \((\tilde \epsilon_\nu^{(i)})\).A saída ascendente das células piramidais superficiais da camada III representa o mesmo erro de previsão para a próxima camada da hierarquia \((\tilde \epsilon_\nu^{(i+1)})\).A entrada descendente representa a previsão \((\tilde g^{(i+1)})\) do nível superior, enquanto a saída descendente é a previsão para o nível inferior \((\tilde g^{(i)})\) No nível mais baixo, vemos previsões descendentes provenientes da camada V, consistentes com a saída para os neurônios motores espinhais mostrados à esquerda. Voltaremos a isso na seção 5.3. Lembre-se do capítulo 4 que o papel das causas ocultas é ligar os níveis hierárquicos de um modelo que opera em várias escalas de tempo diferentes. Isso contrasta com os estados ocultos, cujo papel está na dinâmica em uma escala de tempo específica -- consistente com seu papel na conectividade intrínseca (dentro da coluna) na Figura 5.1.

\begin{figure}
\centering
\includegraphics{images/Figura_5_1.png}
\caption{Figura 5.1 Microcircuitos corticais canônicos que ilustram a relação entre a passagem de mensagens inferenciais e a arquitetura do córtex cerebral. Esquerda: Esquema simplificado baseado em uma síntese de Miller 2003; Haeusler e Maass 2007; Expedição 2007, 2016; e Bastos et ai. 2012 (consulte estes artigos para um resumo das observações neuroanatômicas das quais esta síntese é derivada). As pontas de seta redondas indicam inibição; pontas de seta normais indicam conexões excitatórias. As populações neurais dividem-se grosseiramente em piramidal superficial (SP), piramidal profundo (DP), estrelado espinhoso (SS) e interneurônios inibitórios (II). Meio: passagem de mensagens que subscreve a codificação preditiva hierárquica. Direita: A passagem de mensagens necessária para resolver um processo de decisão de Markov parcialmente observável (POMDP).}
\end{figure}

A assimetria na passagem de mensagens é importante, pois oferece previsões empíricas sobre a diferença entre atividade ascendente e descendente. Uma dessas previsões é que podemos esperar que essas mensagens sejam comunicadas pela atividade neural em diferentes frequências temporais. A razão para isso é que as operações necessárias para calcular um erro de previsão a partir de uma expectativa são não lineares (Friston 2019b). Esta não linearidade é devido ao cálculo de previsões usando funções não lineares ( g) que tendem a aumentar a frequência de um sinal (por exemplo, uma duplicação da frequência na quadratura de uma onda senoidal). Uma previsão decorrente disso é que mensagens ascendentes -- originadas de unidades de erro -- podem ser mensuráveis \hspace{0pt}\hspace{0pt}em bandas de frequência mais altas do que mensagens descendentes -- originadas de unidades de expectativa (veja a figura 5.2). Isso é consistente com assimetrias espectrais medidas, em que conexões ascendentes são tipicamente associadas a frequências gama e conexões descendentes com bandas alfa ou beta (Arnal e Giraud 2012; Bastos, Litvak et ai. 2015).

\begin{figure}
\centering
\includegraphics{images/Figura_5_2.png}
\caption{Figura 5.2 Versão simplificada do esquema de codificação preditivo mostrado no meio da figura 5.1, descompactado para mostrar a mensagem passando entre três regiões corticais. A ênfase está na assimetria na passagem de mensagens, com linhas pontilhadas mostrando mensagens ascendentes (erros de previsão) e linhas sólidas mostrando mensagens descendentes (previsões). A Figura 5.1 é uma versão mais detalhada deste esquema, incluindo os neurônios intermediários nas conexões polissinápticas mostradas aqui. Nesta figura, granular grosseiramente a especificidade laminar e dividir o córtex em Superficial e Profundo em relação à camada IV recupera um esquema de codificação preditivo que será familiar a muitos leitores.}
\end{figure}

O esquema à direita na figura 5.1 mostra uma interpretação da passagem de mensagem para um modelo POMDP como um microcircuito cortical. Isso tem uma estrutura semelhante à arquitetura de codificação preditiva, com expectativas (s) representadas em células piramidais superficiais e profundas e propagadas em hierarquias corticais para cima e para baixo. Além disso, as unidades de erro (ε) na camada IV recebem sinais ascendentes. Em contraste com as arquiteturas de estilo de codificação preditiva, as mensagens passadas entre as regiões são uma mistura de expectativas em oposição a erros (Friston, Rosch et al.~2017; Parr, Markovic et al.~2019). No entanto, a estrutura geral de minimizar um erro (ou seja, gradiente de energia livre) atualizando as expectativas é preservada. Essa passagem de mensagens distingue entre expectativas condicionadas a uma política (subscrito π) e aquelas calculadas sob políticas. Para traduzir do primeiro para o segundo, também precisamos de crenças posteriores sobre políticas (π). Voltaremos a isso na seção 5.4, mas por enquanto vale destacar a consistência dessa mensagem que passa com o direcionamento das camadas corticais superficiais por estruturas subcorticais que poderiam computar essas crenças.

Na figura 5.1, observe a ausência de um mapeamento um-para-um entre a arquitetura à esquerda e os esquemas de passagem de mensagens no meio e à direita. Por exemplo, parece haver uma discrepância entre o meio e a esquerda: a entrada descendente na coluna da esquerda chega às camadas II e IV, mas a do gráfico do meio atinge a camada III. Isso destaca que as conexões implícitas nos esquemas de passagem de mensagens podem não se manifestar como sinapses únicas. A conexão inibitória descendente visando a camada III pode ser mediada pela combinação de uma projeção excitatória para os interneurônios inibitórios da camada IV e a projeção desses interneurônios para a camada III. Essa via dissináptica resolve a aparente discrepância entre as duas arquiteturas.

Nas seções 5.3 e 5.4, tratamos do papel dos neurônios da camada V no movimento e planejamento, correspondendo às suas projeções espinais (ou tronco cerebral) e subcorticais, respectivamente. Nas seções 5.5 e 5.6, lidamos com as maneiras pelas quais a passagem de mensagens neurais é modulada ao longo do tempo e, em seguida, retornamos à relação entre os microcircuitos para inferência categórica e contínua.

\hypertarget{comandos-do-motor}{%
\section{Comandos do Motor}\label{comandos-do-motor}}

O esquema à esquerda na figura 5.1 mostra que a camada V do córtex se projeta para os neurônios piramidais espinhais e que isso pode ser interpretado como uma previsão (Adams, Shipp e Friston 2013). Este é descompactado na figura 5.3, que mostra os componentes espinhais deste circuito; vemos uma previsão baseada nas expectativas codificadas pelas células de Betz na camada V do córtex motor primário. Isso é subtraído da entrada proprioceptiva de entrada para o corno dorsal da medula espinhal, resultando em um erro de previsão proprioceptiva. Esse erro impulsiona a atividade muscular que resulta em sua própria supressão -- à medida que os dados proprioceptivos mudam para cumprir as previsões. A ideia de um comando motor como predição é central para a Inferência Ativa, pois destaca a dualidade de ação e percepção. A parte da ação é a minimização de qualquer discrepância entre as previsões e os dados sensoriais, alterando os dados. Isso diz que a única coisa que precisamos para gerar um movimento é uma previsão das consequências sensoriais antecipadas se esse movimento for executado. O fato de que os erros de previsão proprioceptiva sempre podem ser resolvidos por reflexos (em oposição à atualização de crenças) oferece uma possível explicação para a escassez de células granulares na camada IV do córtex motor primário (Shipp, Adams e Friston 2013).

Um aspecto importante desse tipo de controle motor é a noção de atenuação sensorial (Brown et al.~2013). Considere o problema de iniciar um novo movimento. Para fazer isso, precisamos ser capazes de prever que estamos nos movendo. No entanto, até que estejamos nos movendo, os dados proprioceptivos disponíveis contradizem essa hipótese e podem levar à sua revisão. Portanto, precisamos de uma maneira de impedir que os dados sensoriais atualizem nossas expectativas, para que possamos alimentar a crença (inicialmente falsa) de que estamos nos movendo para que essa crença possa ser realizada através da ação (cf.~fenômenos ideomotores). A implicação é que precisamos ser capazes de atender longe dos dados proprioceptivos, recusando seu ganho. Tecnicamente, esse ganho é dado pela precisão (variância inversa) com que esses dados são previstos. Para atenuar isso, precisamos de tratos motores descendentes para prever não apenas os dados, mas a precisão ou confiança depositada nesses dados, diminuindo essa precisão para iniciar o movimento. Isso é conhecido como atenuação sensorial e pode ser pensado como o complemento da atenção sensorial, equipando-nos com a capacidade de ignorar certos erros de previsão, como aqueles gerados por movimentos oculares sacádicos (aqui a atenuação sensorial é conhecida como supressão sacádica). Acredita-se que as falhas na atenuação sejam centrais para uma série de síndromes neurológicas e psiquiátricas, incluindo fenômenos de passividade (Pareés et al.~2014) e -- em seus mais extremos -- estados catatônicos na esquizofrenia e na incapacidade de iniciar movimentos na doença de Parkinson.

\begin{figure}
\centering
\includegraphics{images/Figura_5_3.png}
\caption{\textbf{Figura 5.3} Neuroanatomia associada à Inferência Ativa na modulação dos reflexos motores espinhais. A partir das células de Betz (neurônios motores superiores) na camada V do córtex motor, o trato piramidal carrega previsões de entrada proprioceptiva sob o movimento acarretado pelas expectativas corticais motoras. O trato decussa (cruza) e faz sinapse -- às vezes polissinapticamente -- em neurônios motores inferiores no corno ventral da medula espinhal. Subtrair as previsões dos sinais aferentes proprioceptivos que chegam ao corno dorsal da medula espinhal resulta em um erro que diz quanta contração muscular seria necessária para atender à previsão. Os neurônios motores inferiores causam essa contração muscular (ou relaxamento), garantindo que os dados proprioceptivos resultantes correspondam às previsões descendentes.}
\end{figure}

\hypertarget{estruturas-subcorticais}{%
\section{Estruturas Subcorticais}\label{estruturas-subcorticais}}

Além de suas projeções para a medula espinhal, a camada cortical V tem como alvo várias outras estruturas. Entre eles está o corpo estriado (Shipp 2007, Wall et al.~2013)---uma estrutura profunda dentro do cérebro que compreende o núcleo caudado e o putâmen. O corpo estriado é o núcleo de entrada de uma complexa rede de estruturas conhecidas como gânglios da base. Neurônios espinhosos médios são as unidades funcionais do corpo estriado, recebendo informações do córtex e projetando-se para outros núcleos dos gânglios da base. Estes se dividem em dois tipos - aqueles que expressam receptores de dopamina D1 e aqueles que expressam receptores D2 - onde a dopamina aumenta a atividade do primeiro e a atenua para o último. As primeiras células são a origem da via direta através dos gânglios da base, conectadas por uma única sinapse inibitória aos núcleos de saída (o globo pálido interno e a substância negra pars reticulata). As células D2 dão origem à via indireta, um curso um pouco mais complexo com duas sinapses inibitórias e uma excitatória. O corpo estriado inibe o globo pálido externo, que por sua vez inibe o núcleo subtalâmico (STN). O STN projeta-se para as saídas dos gânglios da base, o que significa que os núcleos de saída são inibidos pela via direta e desinibidos pela via indireta. Como esses núcleos são eles próprios inibitórios, o resultado final da ativação dos neurônios estriatais que expressam D1 é a desinibição do comportamento, que seria suprimido pelos neurônios que expressam D2 (Freeze et al.~2013).

Dado que associamos as previsões proprioceptivas com as projeções para a medula espinhal, quais mensagens devemos associar às projeções da camada V para o corpo estriado? A inspeção da figura 5.1 oferece uma solução possível. Os resultados previstos (o) e as diferenças entre os resultados preferidos e previstos (ς ) são mostrados nesta camada, combinando-se para calcular a energia livre esperada (G) de uma política. O cálculo do último deles no corpo estriado é consistente com a noção de que os gânglios da base estão envolvidos no planejamento - isto é, na avaliação de cursos alternativos de ação. A Figura 5.4 mostra um possível mapeamento da passagem de mensagens para avaliação de políticas na anatomia dos gânglios da base.

O principal a ser extraído da Figura 5.4 é que, conforme descrito no capítulo 4, as probabilidades posteriores sobre as políticas (π) --- mostradas aqui no globo pálido interno --- são calculadas com base em sua energia livre esperada. Esse padrão segue o caminho direto da camada V do córtex através do corpo estriado até os núcleos de saída dos gânglios da base. No entanto, existem algumas sutilezas adicionais. No esquema hierárquico mostrado à esquerda na figura 4.4, vemos que as expectativas sobre os estados nos níveis mais altos podem influenciar as crenças sobre as políticas nos níveis mais baixos. A Figura 5.4 mostra isso à esquerda, onde as observações esperadas em estados de alto nível são usadas para formar a priori empírica (E) que influencia a seleção de políticas independentemente da energia livre esperada.

Voltaremos a isso no capítulo 7, mas a ideia principal é que temos crenças sobre como agimos em contextos particulares. Essas expectativas anteriores tendem a influenciar a avaliação de políticas quando nos encontramos novamente no mesmo contexto -- bem como a formação de hábitos. Nesse sentido, as influências de E e G podem ser vistas como impulsos habituais e direcionados a objetivos, respectivamente. Na aprendizagem por reforço (Lee et al.~2014), estes são às vezes chamados de sistemas \footnote{Essa nomenclatura vem de teorias de aprendizado por reforço (Daw et al.~2005), mas é um pouco enganosa, pois ambos os sistemas dependem de modelos. Sistemas ``sem modelo'' apenas usam um modelo mais simples que prevê um certo tipo de comportamento em um certo tipo de ambiente.} ``sem modelo'' e ``baseado em modelo''. que a dopamina modula o equilíbrio dos dois. Lembre-se de que a dopamina tende a promover o caminho direto e a execução de políticas específicas (Moss e Bolam 2008) -- presumivelmente aquelas associadas à menor energia livre esperada. Em contraste, pode-se esperar que a baixa dopamina favoreça os antecedentes sensíveis ao contexto na via indireta, cujo papel é suprimir políticas implausíveis em um determinado contexto. De certa forma, a dopamina estriatal pode ser pensada como modulando o equilíbrio entre inferir o que fazer e o que não fazer (Parr 2020).

O acima é consistente com perturbações do sistema dopaminérgico; sua depleção na doença de Parkinson grave causa acinesia -- uma falha na implementação de políticas específicas -- enquanto os agonistas de dopamina exógenos promovem comportamentos impulsivos (Frank 2005; Galea et al.~2012; Friston, Schwartenbeck et al.~2014). Além disso, é consistente com os modelos conceituais da função dos gânglios da base. Por exemplo, Nambu (2004) sugere que a via direta medeia uma inibição rápida e focalizada do globo pálido interno, seguida de uma excitação ampla e lenta, que causa excitação e inibição dos alvos dos gânglios da base, respectivamente. Isso é pensado para garantir um padrão ``centro-surround'' que facilita programas motores com alta especificidade, o que é consistente com os processos rápidos que computam a ação facilitadora de energia livre esperada e a contextualização mais ampla da via mais lenta comunicando a priori empírica.

A observação final a fazer sobre a Figura 5.4 é que existem dois níveis de uma hierarquia cortical (sobrescrito) contribuindo para o mesmo circuito dos gânglios da base. Isso sugere regiões temporalmente mais lentas no direcionamento de neurônios da via indireta, mas influências rápidas e lentas sobre a via direta. À medida que ascendemos nas hierarquias corticais, os neurônios tendem a representar uma dinâmica mais lenta. Por exemplo, podemos esperar que as regiões corticais frontais representem escalas de tempo mais longas do que as regiões parietais. Isso é consistente com a distribuição anatômica das entradas corticais para as vias dos gânglios da base (Wall et al.~2013). Essa granulação grosseira temporal na via indireta é complementada pela grosseria espacial, com os neurônios espinhosos médios da via direta exibindo mandris dendríticos maiores (Gertler et al.~2008), permitindo um ajuste mais fino. Portanto, a anatomia da figura 5.4 é endossada por evidências de patologia clínica (por exemplo, parkinsonismo) e morfologia celular.

Além dos gânglios da base, muitas outras estruturas subcorticais importantes contribuem para a transmissão de mensagens neuronais. Na próxima seção, discutiremos aqueles de onde se originam os sistemas neuromodulatórios; vamos concluir esta seção tocando brevemente no tálamo. Não seremos capazes de fazer plena justiça a esta estrutura altamente complexa; no entanto, podemos esboçar alguns princípios básicos. O tálamo é frequentemente dividido em núcleos primários e secundários. A Figura 5.1 mostra que os núcleos talâmicos primários podem desempenhar o mesmo papel que as regiões corticais inferiores, no sentido de que eles têm como alvo a camada IV do córtex e recebem informações das células piramidais profundas da camada VI (Thomson 2010, Olsen et al.~2012). Um exemplo é o núcleo geniculado lateral no sistema visual, muitas vezes considerado como um relay (retransmissão) entre o olho e o córtex visual. Como os neurônios que representam erros de previsão, este recebe tanto informações sensoriais do olho quanto projeções para trás do córtex, que podem ser interpretadas como previsões. Os núcleos talâmicos de segunda ordem incluem o núcleo mediodorsal e o pulvinar, que interagem com os córtices frontal e posterior, respectivamente. Estes podem ter um papel na previsão de estatísticas de segunda ordem (ou seja, precisão e variância) de entradas sensoriais ou de ordem superior e têm sido associados a tarefas de discriminação figura-fundo (Kanai et al.~2015). De forma simplista, isso sugere que a divisão do tálamo em núcleos primários e secundários pode ser uma manifestação da divisão em estatísticas de primeira e segunda ordem.

\hypertarget{neuromodulauxe7uxe3o-e-aprendizagem}{%
\section{Neuromodulação e Aprendizagem}\label{neuromodulauxe7uxe3o-e-aprendizagem}}

A neuroanatomia estrutural é importante, mas só nos dá parte do quadro do processamento neural porque a presença de uma conexão não nos diz muito sobre o modo como ela é usada. Como exemplo, considere o papel da substância negra mostrado na figura 5.4. O efeito modulatório que isso tem na conectividade estriatal subscreve saídas muito diferentes dos gânglios da base, dependendo da quantidade de dopamina liberada. A modulação rápida da eficácia sináptica desta forma pode ser contrastada com as mudanças mais lentas, porém mais persistentes, que ocorrem com o aprendizado. Nesta seção, nos concentramos nessas duas maneiras pelas quais a eficácia sináptica pode mudar.

A precisão é um conceito importante na compreensão da neuromodulação (Feldman e Friston 2010). Tocamos nisso no capítulo 4 e em nossa discussão sobre atenuação sensorial acima, onde vimos que ela atua como um peso multiplicativo nos erros de previsão. Mais amplamente, a precisão é uma medida de confiança em uma distribuição de probabilidade. A relação entre os dois é simples. Se tivermos crenças muito precisas sobre como os dados são gerados a partir de estados ocultos, nossas crenças sobre estados ocultos podem ser atualizadas observando os dados mais do que se não tivermos confiança nessas crenças. Quando as atualizações de crenças se manifestam como mudanças no disparo neuronal, uma distribuição de probabilidade mais precisa se manifesta como uma resposta neural aumentada a um determinado estímulo sensorial. Isso é essencial para as funções cognitivas da atenção (Parr e Friston 2019a) à integração multissensorial (Limanowski e Friston 2019).

\begin{figure}
\centering
\includegraphics{images/Figura_5_4.png}
\caption{Figura 5.4 Caminhos diretos e indiretos da passagem de mensagens para seleção de políticas associadas à Inferência Ativa através dos gânglios da base usando um modelo generativo POMDP. As vias do córtex cerebral culminam na estimativa de políticas. A via direta (direita ) vai do córtex ao corpo estriado e ao globo pálido interno. A via indireta (esquerda ) vai do córtex para o corpo estriado, para o globo pálido externo, para o núcleo subtalâmico (STN) e para o globo pálido interno. Ambas as vias existem bilateralmente; além disso, a substância negra pars compacta (SNpc) é mostrada modulando o equilíbrio entre as duas. (Nota: Esta é uma simplificação da conectividade dos gânglios basais.)}
\end{figure}

Essa perspectiva sobre o controle do ganho sináptico nos diz algo simples, mas importante. Se a precisão é um atributo de alguma distribuição em um modelo generativo, então deve haver diferentes precisões associadas a diferentes distribuições. Isso é intuitivamente sensato, pois podemos estar mais ou menos confiantes na confiabilidade de nossas sensações, em como as coisas evoluirão dinamicamente e até em como podemos agir (Parr e Friston 2017b). Vimos o último deles no contexto da sinalização dopaminérgica nos gânglios da base. Quanto maior a precisão associada, mais confiantes estamos de que nossas políticas minimizarão a energia gratuita esperada.

Se um dos papéis do sistema dopaminérgico -- originado na substância negra pars compacta e na área tegmental ventral do mesencéfalo -- é sinalizar confiança no que fazer, então outros sistemas neuromoduladores desempenham papéis semelhantes? A Tabela 5.1 resume as evidências que associam precisões a sistemas neuromodulatórios -- com os símbolos às vezes usados para essas precisões. Especificamente, o sistema colinérgico que surge do núcleo basal de Meynert parece sinalizar a precisão de algumas distribuições de verossimilhança. O sistema noradrenérgico, do locus coeruleus, parece desempenhar um papel na sinalização da precisão das transições ao longo do tempo. O sistema serotoninérgico parece menos claro, mas pode estar relacionado à precisão das preferências anteriores.

Por que é útil poder associar essas precisões a sistemas neuromoduladores? A resposta é tripla: nos permite explicar a biologia observada, formar hipóteses e desenvolver métodos não invasivos para medir a precisão. Destacaremos um exemplo de cada um deles. Primeiro, em relação às explicações da biologia observada, as medições empíricas dos sinais de dopamina se parecem com ``erros de previsão de recompensa'' (Schultz 1997) -- com a dopamina dos animais aumentando ao receber suco de fruta inesperado ou ao ver uma sugestão sinalizando suco de fruta iminente. A Inferência Ativa oferece uma explicação alternativa para esses achados (Schwartenbeck, FitzGerald, Mathys, Dolan e Friston 2015). Alcançar uma recompensa (ou atender às nossas preferências) ou encontrar uma pista indicativa de uma recompensa futura aumenta nossa confiança de que estamos seguindo uma política que minimiza a energia livre esperada. Esse aumento na confiança se manifesta como um pico de dopamina.

Em segundo lugar, em relação à formação de hipóteses, um exemplo diz respeito à diminuição da sinalização colinérgica associada à demência de corpos de Lewy (Parr, Benrimoh et al.~2018) -- uma condição que leva a alucinações visuais complexas. Uma explicação plausível para isso é que o acúmulo de patologia nos córtices visuais superiores leva a uma incompatibilidade entre as previsões dessas áreas e a atividade nos córtices visuais primários. Tal incompatibilidade diminui a confiança nas distribuições de probabilidade associadas e causa perda de sinalização colinérgica. A consequência dessa perda de precisão é uma falha em atualizar crenças com base em dados sensoriais, significando que a percepção perde as restrições oferecidas pela sensação. Isso poderia explicar o desenvolvimento de percepções alucinatórias nessa condição. Terceiro, em relação à medição não invasiva de parâmetros de precisão, um exemplo é a identificação de fenótipos computacionais. Há uma série de manifestações periféricas da atividade neuroquímica central, incluindo a relação entre a taxa de piscar espontâneo e a dopamina (Karson 1983) e entre o tamanho pupilar e a noradrenalina (Koss 1986). Trabalhos recentes explorando o último (Vincent et al.~2019) demonstraram uma relação entre a precisão da transição que se espera que seja inferida por um observador bayesiano ideal e a dinâmica da constrição e dilatação pupilar. A implicação é que poderíamos sondar o modelo generativo implícito de alguém (ou seja, crenças prévias empíricas) por meio de medições periféricas desse tipo.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.0734}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2085}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.7181}}@{}}
\caption{\textbf{Tabela 5.1} Papéis putativos dos neurotransmissores na Inferência Ativa}\tabularnewline
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Neurotransmissor
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Precisão
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Evidência
\end{minipage} \\
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Neurotransmissor
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Precisão
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Evidência
\end{minipage} \\
\midrule
\endhead
Acetilcolina & Probabilidade (ζ) & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\item
  Presença de receptores pré-sinápticos em aferentes talamocorticais (Sahin et al.~1992, Lavine et al.~1997)
\item
  Modulação do ganho de respostas visualmente evocadas (Gil et al.~1997, Disney et al.~2007)
\item
  Mudanças na conectividade efetiva com manipulações farmacológicas (Moran et al.~2013)
\item
  Modelagem de respostas comportamentais sob manipulação farmacológica (Vossel et al.~2014, Marshall et al.~2016)
\end{itemize}
\end{minipage} \\
Noradrenalina & Transições (ω) & • A manutenção da atividade pré-frontal persistente (período de atraso) (exigindo probabilidades de transição precisas) depende da noradrenalina (Arnsten e Li 2005, Zhang et al.~2013)

• \hspace{0pt} Respostas pupilares a sequências surpreendentes (ou seja, imprecisas) (Nassar et al.~2012, Lavín et al.~2013, Liao et al.~2016, Krishna murthy et al.~2017, Vincent et al.~2019)

• \hspace{0pt} Modelagem de respostas comportamentais sob manipulação farmacológica (Marshall et al.~2016) \\
Dopamina & Políticas (γ ) & • \hspace{0pt} Expressado pós-sinapticamente em neurônios espinhosos médios estriados (Freund et al.~1984, Yager et al.~2015)

• \hspace{0pt} A fMRI computacional revela a atividade do mesencéfalo com mudanças na precisão (Schwartenbeck, FitzGerald, Mathys, Dolan e Friston 2015)

•  \hspace{0pt}Modelagem de respostas comportamentais sob manipulação farmacológica (Marshall et al.~2016) \\
Serotonina & Preferências ou probabilidade interoceptiva (χ ) \textbar{} & • \hspace{0pt} Receptores expressos nas células piramidais da camada V (Aghajanian e Marek 1999, Lambe et al.~2000, Elliott et al.~2018) no córtex pré-frontal medial

• \hspace{0pt} Regiões corticais pré-frontais mediais fortemente implicadas no processamento interoceptivo e regulação autonômica (Marek et al.~2013, Mukherjee et al.~2016) \\
\bottomrule
\end{longtable}

Embora mudanças rápidas na precisão sejam importantes, essa é uma maneira grosseira de otimizar a conectividade efetiva; leva a um aumento ou diminuição no ganho de um sinal, mas nada mais sutil. Se quisermos mudar a maneira como o sinal é interpretado, precisamos confiar no aprendizado. Voltaremos a isso em detalhes no capítulo 7. No entanto, a ideia básica é que temos crenças não apenas sobre os estados do mundo, mas também sobre os parâmetros fixos (ou de variação lenta) que determinam as dependências entre as variáveis \hspace{0pt}\hspace{0pt}(Friston, FitzGerald et al.~al.~2016). O substrato dessas crenças é a eficácia das conexões sinápticas entre as populações neurais que representam variáveis \hspace{0pt}\hspace{0pt}que variam no tempo (como estados ocultos ou resultados). Quando observamos um resultado que acreditamos ter sido gerado por um determinado estado, podemos atualizar as crenças sobre o parâmetro que conecta os dois, refletindo um aumento na probabilidade de co-ocorrerem no futuro. Em outras palavras, obtemos um fortalecimento das sinapses entre as duas populações de neurônios. O resultado é o famoso decreto de Hebb (parafraseado): ``Células que disparam juntas, ligam juntas''.

\hfill\break
Uma característica importante da Figura 5.1 é que, tanto na codificação preditiva quanto nos esquemas de passagem de mensagens marginais, as conexões que entram e saem de uma coluna cortical se relacionam com distribuições de verossimilhança. Em contraste, as probabilidades de transição e a dinâmica contínua dependem das conexões dentro de um microcircuito. Isso sugere que a dinâmica de aprendizagem deve levar a mudanças na conectividade intrínseca, enquanto os modelos de observação de aprendizagem devem modificar a conectividade extrínseca. Usando técnicas como modelagem causal dinâmica -- que permitem a avaliação de medidas de conectividade efetivas a partir de dados de neuroimagem -- é possível testar essas hipóteses (Tsvetanov et al.~2016, Zhou et al.~2018). Isso destaca o papel das teorias de processo desse tipo: elas nos permitem ir além da teorização abstrata para formar hipóteses testáveis específicas.

\hfill\break

\hypertarget{hierarquias-contuxednuas-e-discretas}{%
\section{Hierarquias Contínuas e Discretas}\label{hierarquias-contuxednuas-e-discretas}}

Por fim, vale destacar a passagem de representações contínuas em níveis baixos de uma hierarquia neural para variáveis categóricas em níveis superiores. O ponto é que os esquemas de transmissão de mensagens discretos e contínuos que consideramos provavelmente coexistem no cérebro porque somos capazes de manter crenças de um tipo categórico (por exemplo, ao identificar o que é um objeto ou quem é uma pessoa), além de sermos capazes de para interagir com receptores e efetores sensoriais continuamente variados (por exemplo, comprimento muscular ou contraste de luminância visual). Isso se reflete na neurofisiologia, onde alguns neurônios são seletivos a estímulos específicos e outros variam em proporção à intensidade de um estímulo.

Uma observação interessante é que nossa interface com o mundo ao nosso redor está no domínio contínuo, cuja implicação é que o nível mais baixo de qualquer hierarquia no cérebro deve ser contínuo. Dito isso, vimos na figura 5.4 que a seleção de políticas nos gânglios da base pode ser enquadrada como um processo discreto, selecionando entre movimentos alternativos. Isso nos diz que podemos pensar em movimentos como uma composição de trajetórias discretas em ação intencional. Onde o nível mais baixo pode lidar com as mudanças necessárias no comprimento do músculo, a entrada descendente é baseada em decisões sobre qual movimento fazer. Do ponto de vista de um modelo generativo, isso significa associar hipóteses alternativas (discretas) sobre o mundo com a dinâmica (contínua) acarretada por essas hipóteses. No capítulo 8, retornaremos à questão de como juntá-los de uma perspectiva computacional. Aqui, simplesmente observamos que quanto mais nos afastamos dos receptores sensoriais, mais tendemos a encontrar representações discretizadas nos sistemas neurais. De fato, a própria existência de campos receptivos clássicos na neurofisiologia poderia ser interpretada como uma representação probabilística de que o mundo está em algum regime particular de um espaço de estados perceptivo -- um espaço de estados que é ladrilhado por campos receptivos e, consequentemente, dividido em muitos pequenos categorias. A Figura 5.5 reúne esses esquemas e funciona como um resumo das ideias apresentadas neste capítulo.

\hypertarget{resumo-4}{%
\section{Resumo}\label{resumo-4}}

Este capítulo procurou delinear os pontos de conexão entre os esquemas de transmissão de mensagens implícitos nos modelos generativos do capítulo 4 e a neurobiologia da inferência, ação e planejamento. O que ganhamos ao relacionar a passagem de mensagens à comunicação neuronal? Ele nos permite fazer previsões empíricas com base no modelo generativo que hipotetizamos que o cérebro está invertendo. Isso pode assumir a forma de uma resposta evocada - a mudança no potencial que é mensurável no couro cabeludo ao apresentar ao cérebro um estímulo sensorial - cujo curso de tempo dependerá da quantidade de atualização de crenças induzida por esse estímulo. Alternativamente, métodos de neuroimagem computacional podem ser usados \hspace{0pt}\hspace{0pt}para associar inferências simuladas com as regiões do cérebro que exibem dinâmica temporal semelhante (Schwartenbeck, FitzGerald, Mathys, Dolan e Friston 2015). Fazer essa associação é importante para entender a patologia - e a terapêutica - para distúrbios computacionais (ou seja, neurológicos e psiquiátricos), permitindo a expressão de patologias funcionais em termos de sua biologia.

Finalmente, vale a pena reconhecer que grande parte do cérebro esteve visivelmente ausente neste capítulo - em parte por razões de espaço, mas também porque a neurociência é um trabalho em andamento. Há muitas oportunidades para estender (ou mesmo substituir) o relato apresentado neste capítulo. Até certo ponto, podemos extrapolar o que vimos aqui. Por exemplo, partes da amígdala são citoarquitetônicamente equivalentes aos núcleos dos gânglios da base. Isso significa que existe uma classe de políticas avaliadas pela amígdala? Esta estrutura poderia ser para as políticas autonômicas o que os gânglios da base são para as do domínio esqueletomotor? Outras estruturas (como o pulvinar) podem desempenhar papéis semelhantes para outras classes de políticas (por exemplo, mentais)? Como devemos entender as arquiteturas corticais que diferem da estrutura de seis camadas da Figura 5.1? O cerebelo e a formação hipocampal exibem microcircuitos distintos, mas estereotipados (Wesson e Wilson 2011). Devemos vê-los como rearranjos anatômicos dos mesmos esquemas Bayesianos de passagem de mensagens, ou eles lidam com diferentes aspectos de um modelo generativo (Pezzulo, Kemere e van der Meer 2017; Stoianov et al.~2020)? Levantamos essas questões não para oferecer respostas, mas para destacar alguns dos excitantes caminhos de pesquisa futura em neurobiologia teórica. A Inferência Ativa e suas teorias de processo associadas oferecem uma estrutura formal e conceitual rigorosa para abordar essas questões.

\begin{figure}
\centering
\includegraphics{images/Figura_5_5.png}
\caption{A Figura 5.5 Anatomia da inferência (baseada em Friston, Parr e de Vries 2017) conecta os esquemas das figuras 5.1--5.4, fornecendo um resumo das ideias deste capítulo. Dois laços hierárquicos através do córtex e dos gânglios basais destacam a distinção entre hábitos -- baseados em informações de níveis superiores -- e o comportamento mais sensível ao contexto e direcionado a objetivos (exploratório e explorador) resultante da esperada minimização da energia livre. Observe a influência das inferências sobre políticas em s, implementando o modelo Bayesiano com média das políticas referidas no texto principal. Essa projeção dos gânglios da base para o córtex pode ser mediada por estruturas intermediárias, como o tálamo. À direita, as mensagens categóricas baseadas em POMDP são retransmitidas em uma rede de codificação preditiva contínua, envolvida na geração de ação. Cada estado categórico está associado a uma predição alternativa de variáveis \hspace{0pt}\hspace{0pt}contínuas e contribui para um erro de predição. A mensagem na direção oposta calcula a probabilidade posterior do resultado categórico associado (o), que depende de anteriores com base no resultado dependente da política (oπ ), crenças sobre a política (π ) e a probabilidade da trajetória contínua que pode ser calculado a partir de expectativas posteriores (  μ ) e variâncias (não mostradas) no nível contínuo. Mais conexões podem ser incluídas aqui; por exemplo, além dos hábitos (E), a seleção de objetivos (C do capítulo 4) provavelmente depende de níveis hierárquicos mais altos, levando ao controle hierárquico da motivação (ver Pezzulo, Rigoli e Friston 2018 para detalhes).}
\end{figure}

\hypertarget{uma-receita-para-projetar-modelos-de-inferuxeancia-ativos}{%
\chapter{Uma receita para projetar modelos de inferência ativos}\label{uma-receita-para-projetar-modelos-de-inferuxeancia-ativos}}

Dê-me seis horas para derrubar uma árvore e passarei as primeiras quatro afiando o machado. ---Abraham Lincoln

\hypertarget{introduuxe7uxe3o-5}{%
\section{Introdução}\label{introduuxe7uxe3o-5}}

Este capítulo fornece uma receita de quatro etapas para construir um modelo de Inferência Ativa, discutindo as escolhas de projeto mais importantes que se deve fazer para realizar um modelo e fornecendo algumas diretrizes para essas escolhas. Ele serve como uma introdução à segunda parte do livro, que ilustrará vários modelos computacionais específicos usando a Inferência Ativa e suas aplicações em vários domínios cognitivos.

omo a Inferência Ativa é uma abordagem normativa, ela tenta explicar o máximo possível sobre o comportamento, os processos cognitivos e neurais a partir dos primeiros princípios. Consistentemente, a filosofia de design da Inferência Ativa é de cima para baixo. Ao contrário de muitas outras abordagens da neurociência computacional, o desafio não é emular um cérebro, peça por peça, mas encontrar o modelo generativo que descreve o problema que o cérebro está tentando resolver. Uma vez que o problema é formalizado apropriadamente em termos de um modelo generativo, a solução para o problema surge sob a Inferência Ativa -- com as respectivas previsões sobre cérebros e mentes. Em outras palavras, o modelo generativo fornece uma descrição completa de um sistema de interesse. O comportamento resultante, a inferência e a dinâmica neural podem ser derivados de um modelo minimizando a energia livre.

A abordagem de modelagem generativa é usada em várias disciplinas para a realização de modelos cognitivos, modelagem estatística, análise de dados experimentais e aprendizado de máquina (Hinton 2007b; Lee e Wagenmakers 2014; Pezzulo, Rigoli e Friston 2015; Allen et al.~2019; Foster 2019). Aqui, estamos principalmente interessados \hspace{0pt}\hspace{0pt}em projetar modelos generativos que engendram processos cognitivos de interesse. Vimos essa metodologia de projeto nos capítulos anteriores. Por exemplo, usando um modelo generativo para codificação preditiva, a percepção foi lançada como uma inferência sobre a causa mais provável das sensações; usando um modelo generativo que evolui em tempo discreto, o planejamento foi lançado como uma inferência sobre o curso de ação mais provável. Dependendo do problema de interesse (por exemplo, planejamento durante a navegação espacial ou planejamento de sacadas durante a busca visual), pode-se adaptar a forma desses modelos generativos para equipá-los com diferentes estruturas (por exemplo, rasas ou hierárquicas) e variáveis \hspace{0pt}\hspace{0pt}(por exemplo, crenças sobre localizações espaciais alocêntricas ou egocêntricas). É importante ressaltar que a Inferência Ativa pode assumir muitas formas diferentes sob diferentes suposições sobre a forma do modelo generativo que está sendo otimizado. Por exemplo, suposições sobre modelos que evoluem em tempo discreto ou contínuo influenciam a forma de transmissão de mensagens (veja o capítulo 4). Isso implica que a escolha de um modelo generativo corresponde a previsões específicas sobre comportamento e neurobiologia.

Essa flexibilidade é útil, pois nos permite usar a mesma linguagem para descrever processos em vários domínios. No entanto, também pode ser confuso do ponto de vista prático, pois há uma série de escolhas que devem ser feitas para encontrar o nível apropriado de descrição para o sistema de interesse. Na segunda parte deste livro, tentaremos resolver essa confusão por meio de uma série de exemplos ilustrativos de Inferência Ativa in silico. Este capítulo apresenta uma receita geral para o projeto de modelos de Inferência Ativa, destacando algumas das principais escolhas de projeto, distinções e dicotomias que aparecerão na análise numérica de modelos computacionais descritos nos capítulos subsequentes.

\hypertarget{projetando-um-modelo-de-inferuxeancia-ativo-uma-receita-em-quatro-etapas}{%
\section{Projetando um modelo de inferência ativo: uma receita em quatro etapas}\label{projetando-um-modelo-de-inferuxeancia-ativo-uma-receita-em-quatro-etapas}}

Projetar um modelo de Inferência Ativa requer quatro etapas fundamentais, cada uma resolvendo uma questão de projeto específica:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Qual sistema estamos modelando? A primeira escolha a fazer é sempre o sistema de interesse. Isso pode não ser tão simples quanto parece; baseia-se na identificação dos limites (ou seja, envoltório de Markov) desse sistema. O que conta como agente de Inferência Ativa (modelo generativo), o que conta como ambiente externo (processo generativo) e qual é a interface (dados sensoriais e ações) entre eles?
\item
  Qual a forma mais adequada para o modelo generativo? O primeiro dos próximos três desafios práticos é decidir se é apropriado pensar em um processo mais em termos de inferências categóricas (discretas) ou inferências contínuas, motivando a escolha entre implementações discretas ou de tempo contínuo (ou uma híbrida) de Inferência Ativa. . Em seguida, precisamos selecionar a profundidade hierárquica mais adequada, motivando a escolha entre modelos rasos versus modelos profundos. Finalmente, precisamos considerar se é necessário dotar os modelos generativos de profundidade temporal e a capacidade de prever observações contingentes à ação para apoiar o planejamento.
\item
  Como configurar o modelo generativo? Quais são as variáveis e a priori mais apropriadas do modelo generativo? Quais partes são fixas e o que deve ser aprendido? Enfatizamos a importância de escolher o tipo certo de variáveis e crenças anteriores; além disso, enfatizamos uma separação em escalas de tempo entre a atualização (mais rápida) das variáveis de estado que ocorre durante a inferência e a atualização (mais lenta) dos parâmetros do modelo que ocorre durante o aprendizado.
\item
  Como configurar o processo generativo? Quais são os elementos do processo generativo (e como eles diferem do modelo generativo)?
\end{enumerate}

Essas quatro etapas (na maioria dos casos) são suficientes para projetar um modelo de Inferência Ativa. Uma vez concluído, o comportamento do sistema é determinado pelos esquemas padrão de Inferência Ativa: a descida dos estados ativo e interno sobre o funcional de energia livre associado ao modelo. De uma perspectiva mais prática, uma vez especificado o modelo generativo e o processo generativo, pode-se usar rotinas padrão do software Active Inference para obter resultados numéricos, bem como para realizar visualização de dados, análise e ajuste (por exemplo, análise de dados baseada em modelo ). A seguir, revisaremos as quatro opções de design em ordem.

\hypertarget{que-sistema-estamos-modelando}{%
\section{Que sistema estamos modelando?}\label{que-sistema-estamos-modelando}}

Um primeiro passo útil na aplicação do formalismo da Inferência Ativa é identificar os limites do sistema de interesse porque estamos interessados em caracterizar a interação entre o que é interno a um sistema e o mundo externo por meio de receptores sensoriais e efetores (por exemplo, músculos ou glândulas). Conforme discutido no capítulo 3, uma maneira formal de caracterizar a distinção entre estados internos de um sistema e variáveis externas (e variáveis intermediárias que medeiam suas interações) é em termos de um envoltório de Markov (Pearl 1988). Para reiterar o argumento, um envoltório de Markov pode ser subdividida em dois tipos de variáveis (Friston 2013): aquelas que mediam a influência do mundo externo nos estados internos do sistema de interesse (isto é, estados sensoriais) e aquelas que mediam a influência de estados internos do sistema de interesse no mundo externo (ou seja, estados ativos). Veja a figura 6.1.

É importante ressaltar que há muitas maneiras pelas quais um limite entre interno e externo pode ser definido. Na maioria das simulações que discutiremos na segunda parte deste livro, haverá uma separação (envoltório de Markov) entre um agente (aproximadamente, um organismo vivo) e seu ambiente. Isso corresponde à configuração usual de modelos cognitivos, onde um agente implementa processos cognitivos como percepção e seleção de ação com base em seus estados internos (por exemplo, cérebro) e é fornecido com sensores e efetores.

\begin{figure}
\centering
\includegraphics{images/Figura_6_1.png}
\caption{\textbf{Figura 6.1} Loop de ação-percepção entre um sistema adaptativo (aqui, o cérebro) e o ambiente, juntamente com o envoltório de Markov (composta de estados ativos e estados sensoriais) que medeia sua interação. A figura implica que o sistema adaptativo afeta apenas o ambiente realizando ações (via estados ativos) e que o ambiente afeta apenas o sistema adaptativo produzindo observações (via estados sensoriais). A figura exemplifica a distinção entre o modelo generativo do sistema adaptativo e o processo generativo (externo) que produz suas observações.}
\end{figure}

No entanto, esta não é a única possibilidade. Do ponto de vista da neurobiologia, poderíamos desenhar um envoltório de Markov em torno de um único neurônio, em torno do cérebro ou de todo o corpo. No primeiro caso, os estados sensoriais incluem ocupações de receptores pós-sinápticos e os estados ativos incluem a taxa na qual as vesículas contendo neurotransmissores se fundem com a membrana pré-sináptica. Os estados internos do neurônio (por exemplo, potenciais de membrana, concentrações de cálcio) podem ser considerados como inferindo as causas de seus estados sensoriais de acordo com algum modelo generativo (implícito) (Palacios, Isomura et al.~2019). Essa configuração trata os estados externos (que estão sendo modelados) como incluindo a rede neuronal da qual nosso neurônio participa. Isso é muito diferente da inferência que ocorre quando assumimos que toda a nossa rede é interna ao envoltório de Markov. Por exemplo, se tomarmos um sistema cujos estados sensoriais são os fotorreceptores na retina e cujos estados ativos são os músculos oculomotores, as inferências realizadas pelos estados internos são sobre coisas fora do cérebro. Isso fala da importância da escala, pois os estados internos desse envoltório de Markov incluem os estados internos da perspectiva de um único neurônio. Os últimos estados internos parecem fazer inferências sobre coisas dentro do cérebro quando o envoltório de Markov é colocado em torno de um único neurônio, mas não quando o envoltório é colocado em torno do sistema nervoso.

O acima é particularmente relevante quando se trata de perspectivas incorporadas ou estendidas sobre cognição (Clark e Chalmers 1998; Barsalou 2008; Pezzulo, Lw et al.~2011). Por exemplo, se puxarmos o envoltório ao redor do sistema nervoso, o resto do corpo se torna um estado externo, sobre o qual devemos fazer inferências a partir de estados sensoriais interoceptivos (Allen et al.~2019). Alternativamente, poderíamos colocar nosso envoltório em torno de todo o organismo. Isso faria parecer que outros órgãos além do cérebro estavam fazendo inferências sobre seu ambiente. Por exemplo, a depressão da pele em resposta a uma pressão externa pode ser enquadrada como uma inferência sobre a fonte da pressão externa. A perspectiva de cognição estendida leva isso adiante e diz que objetos externos ao corpo podem ser incorporados ao envoltório de Markov (por exemplo, o uso de uma calculadora para auxiliar na inferência implica que a calculadora é parte do espaço de estados interno do sistema de inferência ). Finalmente, poderíamos ter vários envoltórios de Markov, aninhados um no outro (por exemplo, cérebros, organismos, comunidades).

Em suma, definir o envoltório de Markov garante que saibamos o que está sendo inferido (estados externos) e o que está fazendo a inferência. De fato, a minimização da energia livre em relação a um modelo generativo envolve apenas os estados internos e ativos de um sistema: estes apenas veem os estados sensoriais, de modo que só podem inferir o estado externo do mundo vicariamente.

\hypertarget{qual-uxe9-a-forma-mais-adequada-para-o-modelo-generativo}{%
\section{Qual é a forma mais adequada para o modelo generativo?}\label{qual-uxe9-a-forma-mais-adequada-para-o-modelo-generativo}}

Uma vez que tenhamos decidido sobre os estados internos de um sistema e os estados que medeiam sua interação com o mundo exterior, precisamos especificar o modelo generativo que explica como os estados externos influenciam os estados sensoriais. Conforme discutido nos capítulos anteriores, a Inferência Ativa pode operar em diferentes tipos de modelos generativos. Portanto, precisamos especificar a forma mais apropriada do modelo generativo para o problema em questão. Isso implica fazer três escolhas principais de design. A primeira é uma escolha entre modelos que incluem variáveis \hspace{0pt}\hspace{0pt}contínuas ou discretas (ou ambas). O segundo é uma escolha entre modelos superficiais, nos quais a inferência opera em uma única escala de tempo (ou seja, todas as variáveis \hspace{0pt}\hspace{0pt}evoluem na mesma escala de tempo), e modelos hierárquicos ou profundos, nos quais a inferência opera em várias escalas de tempo (ou seja, diferentes variáveis \hspace{0pt}\hspace{0pt}evoluem em diferentes escalas de tempo). prazos). A terceira é uma escolha entre modelos que consideram apenas as observações presentes versus modelos com alguma profundidade temporal, que consideram as consequências de ações ou planos.

\hypertarget{variuxe1veis-discretas-ou-contuxednuas-ou-ambas}{%
\subsection{Variáveis Discretas ou Contínuas (ou Ambas)?}\label{variuxe1veis-discretas-ou-contuxednuas-ou-ambas}}

A primeira escolha de projeto é considerar se modelos generativos que usam variáveis discretas ou contínuas são mais apropriados. Os primeiros incluem identidades de objetos, planos de ação alternativos e representações discretizadas de variáveis contínuas. Estes são modelados através da expressão da probabilidade -- em cada passo de tempo -- de uma variável em transição para outro tipo. Os últimos incluem coisas como posição, velocidade, comprimento do músculo e luminância e requerem um modelo generativo expresso em termos de taxas de mudança.

Computacionalmente, a distinção entre os dois pode não ser clara porque uma variável contínua pode ser discretizada e uma variável discreta pode ser expressa por meio de variáveis contínuas. No entanto, essa distinção é importante conceitualmente, pois fundamenta hipóteses específicas sobre o curso de tempo (discreto ou contínuo) dos processos cognitivos de interesse.\footnote{Isso não implica em dinâmica temporal discreta de uma perspectiva neural. Em vez disso, a dinâmica neural contínua é vista como representando mudanças (contínuas) nas crenças sobre sequências (discretas) de eventos.} Na maioria das implementações atuais de Inferência Ativa, processos de decisão de alto nível, como a escolha entre cursos de ações, são modelados usando variáveis discretas, enquanto percepção mais refinada e dinâmicas de ação são implementadas usando variáveis contínuas; forneceremos exemplos de ambos nos capítulos 7 e 8, respectivamente.

Além disso, a escolha entre variáveis discretas e contínuas é relevante para a neurobiologia. Enquanto cada estilo de modelagem apela para a minimização de energia livre, a mensagem que passa por eles implica assumir formas diferentes. Na medida em que se considera a passagem de mensagens relevante para uma teoria de processo (veja o capítulo 5), isso implica que as dinâmicas neurais que realizam essa minimização são diferentes em cada tipo de modelo. Esquemas contínuos subscrevem a codificação preditiva -- uma teoria de processamento neural que se baseia em previsões de cima para baixo corrigidas por erros de previsão de baixo para cima. No entanto, as teorias de processo análogas para inferências discretas envolvem mensagens de uma forma diferente. Finalmente, os dois tipos de modelo podem ser combinados de forma que estados discretos sejam associados a variáveis contínuas. Isso significa que podemos especificar um modelo generativo em que um estado discreto (por exemplo, identidade de objeto) gera algum padrão de variáveis contínuas (por exemplo, luminância). Discutiremos um exemplo de modelo generativo híbrido ou misto que inclui variáveis discretas e contínuas no capítulo 8.

\hypertarget{escalas-de-tempo-de-inferuxeancia-modelos-rasos-versus-modelos-hieruxe1rquicos}{%
\subsection{Escalas de tempo de inferência: modelos rasos versus modelos hierárquicos}\label{escalas-de-tempo-de-inferuxeancia-modelos-rasos-versus-modelos-hieruxe1rquicos}}

A segunda opção de design diz respeito às escalas de tempo da Inferência Ativa. Pode-se selecionar modelos generativos (rasos), em que todas as variáveis evoluem na mesma escala de tempo, ou modelos (hierárquicos ou profundos), que incluem variáveis que evoluem em diferentes escalas de tempo: mais lento para níveis mais altos e mais rápido para níveis mais baixos.

Enquanto muitos modelos cognitivos simples requerem apenas modelos superficiais, estes não são suficientes quando há uma clara separação de escalas de tempo entre diferentes aspectos de um processo cognitivo de interesse. Um exemplo disso é no processamento de linguagem, em que sequências curtas de fonemas são contextualizadas pela palavra que é falada e sequências curtas de palavras são contextualizadas pela frase atual. Crucialmente, a duração da palavra transcende a de qualquer fonema na sequência e a duração da frase transcende a de qualquer palavra na sequência. Assim, para modelar o processamento da linguagem, pode-se considerar um modelo hierárquico no qual sentenças, palavras e fonemas aparecem em níveis hierárquicos diferentes (mais altos para mais baixos) e evoluem em escalas de tempo (mais lentas para mais rápidas) que são aproximadamente independentes umas das outras. Esta é apenas uma separação aproximada, pois os níveis devem influenciar uns aos outros (por exemplo, a frase influencia as próximas palavras na sequência; a palavra influencia os próximos fonemas na sequência).

No entanto, isso não significa que precisamos tentar modelar todo o cérebro para desenvolver simulações significativas de um único nível. Por exemplo, se quiséssemos focar no processamento de texto, poderíamos abordar alguns aspectos sem ter que lidar com o processamento de fonemas. Isso significa que podemos tratar a entrada de partes do cérebro fazendo inferências sobre fonemas como fornecendo observações da perspectiva de áreas de processamento de texto. Expressando isso em termos de um envoltório de Markov, isso normalmente significa que tratamos as inferências realizadas por níveis inferiores de um modelo como parte dos estados sensoriais do envoltório. Isso significa que podemos resumir as inferências realizadas na escala de tempo de interesse sem precisar especificar os detalhes dos processos inferenciais de nível inferior (mais rápidos) -- e essa fatoração hierárquica acarreta grandes benefícios computacionais.

Outro exemplo está no domínio da seleção de ações intencionais, onde o mesmo objetivo (entrar no seu apartamento) pode estar ativo por um longo período de tempo e contextualiza uma série de sub objetivos e ações (encontrar chaves, abrir porta, entrar) que são resolvidas em uma escala de tempo muito mais rápida. Essa separação de escalas de tempo, seja no domínio contínuo ou discreto, exige um modelo generativo hierárquico (profundo). Na neurociência, pode-se supor que as hierarquias corticais incorporam esse tipo de separação temporal de escalas de tempo, com estados de evolução lenta em níveis mais altos e estados de evolução rápida em níveis mais baixos, e que isso recapitula a dinâmica ambiental, que também evolui em várias escalas de tempo (por exemplo, durante tarefas perceptivas como reconhecimento de fala ou leitura). Na psicologia, esse tipo de modelo é útil na reprodução de processamento de metas hierárquicas (Pezzulo, Rigoli e Friston 2018) e tarefas de memória de trabalho (Parr e Friston 2017c) do tipo que depende da atividade do período de atraso (Funahashi et al.~1989) .

\hypertarget{profundidade-temporal-de-inferuxeancia-e-planejamento}{%
\subsection{Profundidade Temporal de Inferência e Planejamento}\label{profundidade-temporal-de-inferuxeancia-e-planejamento}}

A terceira escolha de design diz respeito à profundidade temporal da inferência. É importante fazer uma distinção entre dois tipos de modelo generativo: o primeiro tem profundidade temporal e representa explicitamente as consequências de ações ou sequências de ação (políticas ou planos), enquanto o segundo não tem profundidade temporal e considera apenas observações presentes, mas não futuras . Esses dois tipos de modelo são exemplificados na figura 4.3: o POMDP dinâmico na parte superior e o modelo de tempo contínuo na parte inferior.\footnote{\hspace{0pt}Dito isso, o uso de coordenadas generalizadas de movimento (quadro 4.2) em modelos de tempo contínuo significa que eles são temporalmente profundos em virtude de sua representação implícita de uma trajetória curta. No entanto, esses modelos não incluem (necessariamente) variáveis que representam trajetórias alternativas que se poderia seguir (ou seja, as consequências de sequências de ações).} A principal diferença entre esses dois modelos não é que eles usam variáveis discretas ou contínuas, respectivamente, mas apenas o modelo anterior (temporariamente profundo) dota as criaturas da capacidade de planejar com antecedência e selecionar entre possíveis futuros.

Imagine um roedor que planeja uma rota para um local de comida conhecido em um labirinto. Fazer isso se beneficia de um modelo temporalmente profundo, vagamente equivalente a um mapa espacial ou cognitivo (Tolman 1948), que codifica contingências entre localizações presentes e futuras condicionadas a ações (por exemplo, a localização futura após virar à direita ou à esquerda). O animal pode usar o modelo temporalmente profundo para considerar contrafactualmente vários cursos de ação (por exemplo, uma série de voltas à direita e à esquerda) e selecionar o que espera alcançar o local do alimento. Por que um modelo temporalmente profundo é necessário para o planejamento? Na Inferência Ativa, o planejamento é realizado calculando a energia livre esperada associada a diferentes ações ou políticas e, em seguida, selecionando a política associada à energia livre esperada mais baixa. A energia livre esperada não é apenas uma função das observações presentes (como a energia livre variacional), mas também um funcional das observações futuras. Este último não pode ser observado (por definição), mas apenas previsto usando um modelo temporalmente profundo, que descreve as maneiras pelas quais as ações produzem observações futuras.

Ao projetar um agente de Inferência Ativa, é útil considerar se ele deve ter capacidades de planejamento e orientadas para o futuro -- e, neste caso, selecionar um modelo temporalmente profundo. Além disso, é útil considerar a profundidade do planejamento -- isto é, até onde o processo de planejamento pode parecer no futuro. Finalmente, pode-se projetar modelos generativos que sejam hierárquicos e temporalmente profundos, em que o planejamento procede em várias escalas de tempo -- mais rápido em níveis mais baixos e mais lento em níveis mais altos. com a escolha entre modelos discretos e contínuos porque a ideia de selecionar entre futuros alternativos, definidos por sequências de ações, é articulada de forma mais simples usando modelos de tempo discreto.

\hypertarget{como-configurar-o-modelo-generativo}{%
\section{Como configurar o modelo generativo?}\label{como-configurar-o-modelo-generativo}}

Quando especificamos nosso sistema de interesse e identificamos as formas relevantes do modelo generativo (por exemplo, representação contínua ou discreta, estrutura superficial versus estrutura hierárquica), nossos próximos desafios são especificar as variáveis específicas a serem incluídas no modelo generativo e decidir quais dessas variáveis permanecem fixas ou mudam como efeito da aprendizagem.

\hypertarget{configurando-as-variuxe1veis-do-modelo-gerador}{%
\subsection{Configurando as Variáveis do Modelo Gerador}\label{configurando-as-variuxe1veis-do-modelo-gerador}}

As variáveis dos modelos generativos podem ser predefinidas ou aprendidas a partir de dados. Para fins ilustrativos, a maioria dos modelos que discutimos neste livro usa variáveis predefinidas. Ao projetar esses modelos, na prática, o principal desafio é decidir quais estados ocultos, observações e ações são mais apropriados para o problema em questão. Por exemplo, o modelo perceptivo capaz de distinguir rãs de maçãs no capítulo 2 incluía apenas dois estados ocultos (rãs, maçãs) e duas observações (salta, não pula). Um modelo mais sofisticado poderia incluir observações adicionais (por exemplo, vermelho, verde), bem como ações como tocar, que produzem efeitos sensoriais diferenciais (salto ou não salto) na presença de um sapo ou uma maçã.

A Figura 6.2 ilustra esquematicamente um modelo generativo para o conceito de um sapo saltador. O conceito é moldado como um modelo hierárquico, onde um único estado oculto (multimodal ou supramodal) no centro da figura se desdobra em uma cascata de estados ocultos (unimodais) correspondentes a perceptos em diferentes modalidades (exteroceptivo, proprioceptivo e interoceptivo; ver Quadro 6.1) e, em última análise, causando sensações nas mesmas modalidades. Esse arranjo corresponde a lançar o conceito de sapo saltitante como a causa comum de múltiplas consequências sensoriais (por exemplo, algo verde e pulando no domínio visual; um som de coaxar no domínio auditivo), algumas das quais podem ser contingentes à ação (por exemplo, o visão de algo saltando pode aumentar ao tocá-lo). A inversão do modelo generativo corresponde a uma inferência perceptiva (por exemplo, a presença de um sapo pulando) a partir de suas consequências sensoriais observadas (por exemplo, a visão de algo verde e nervoso) e integra informações em várias modalidades.

Uma vez estabelecidas essas variáveis de interesse, o próximo exercício é escrever o modelo generativo completo. Um exemplo é o modelo generativo simples para rãs e maçãs na figura 2.1, que é totalmente especificado por crenças anteriores sobre estados ocultos e um mapeamento (de probabilidade) entre estados ocultos e observações e cujos valores numéricos podem ser especificados à mão ou aprendidos a partir de dados. (ver 6.5.2).

\begin{figure}
\centering
\includegraphics{images/Figura_6_2.png}
\caption{A \textbf{Figura 6.2} (hierárquica) modelo generativo para o conceito de um sapo saltitante usa uma notação simplificada em comparação com o capítulo 4: nós dentro do círculo pontilhado correspondem a estados ocultos, enquanto nós na periferia correspondem a observações sensoriais. As crenças sobre estados ocultos, após a inversão do modelo, correspondem a percepções que podem estar vinculadas a uma modalidade sensorial (por exemplo, percepção visual) ou podem ser amodais (por exemplo, o sapo saltitante). As contingências de ação são representadas como linhas tracejadas. Dependências horizontais entre estados ocultos em diferentes modalidades, bem como dependências temporais entre estados ocultos (como vimos nos modelos generativos dinâmicos do capítulo 4), são ignoradas por questão de simplicidade.}
\end{figure}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Quadro 6.1} Variedades de modalidades sensoriais: Exteroceptivo, proprioceptivo e interoceptivo
\end{minipage} \\
\midrule
\endhead
Na Inferência Ativa, muitas vezes é feita uma distinção conceitual entre três tipos de modalidades sensoriais: exteroceptivas (por exemplo, visão e audição), proprioceptivas (por exemplo, o sentido das posições das articulações e dos membros) e interoceptivas (por exemplo, o sentido dos órgãos internos). do corpo, como coração e estômago). Em modelos generativos multimodais, muitas vezes pode-se fatorar partes do modelo que se relacionam a diferentes modalidades; isso permite representar que (por exemplo) movimentos sacádicos têm consequências visuais, mas não auditivas. É importante ressaltar que os mesmos princípios da Inferência Ativa operam em todas as modalidades. Por exemplo, da mesma forma que o processamento visual pode ser descrito como a inferência sobre (variáveis \hspace{0pt}\hspace{0pt}ocultas sobre) uma cena perceptiva, o processamento interoceptivo pode ser descrito como a inferência sobre (variáveis \hspace{0pt}\hspace{0pt}ocultas que relatam) o estado interno do corpo. Além disso, ações motoras que alteram a cena perceptiva e ações direcionadas internamente que alteram o estado interoceptivo podem ser descritas de maneira semelhante. O primeiro aciona os reflexos espinhais que atendem às previsões proprioceptivas, enquanto o último aciona os reflexos autônomos que atendem às previsões interoceptivas. Tal processamento interoceptivo suporta alostase e regulação adaptativa, e suas disfunções podem ter consequências psicopatológicas (Pezzulo 2013, Seth 2013, Pezzulo e Levin 2015, Seth e Friston 2016, Allen et al 2019) \\
\bottomrule
\end{longtable}

Além deste exemplo simples, os elementos que precisam ser especificados são totalmente determinados pela forma do modelo generativo selecionado. Por exemplo, o modelo para POMDP de tempo discreto mostrado na figura 4.3 (topo) requer a especificação das matrizes A, B, C, D e E; esquemas contínuos usam elementos análogos (embora menos alfabéticos), que serão tratados no capítulo 8. Mas mesmo nesses casos mais complexos, o exercício não é tão diferente do anterior: ou seja, especificar crenças anteriores sobre as variáveis \hspace{0pt}\hspace{0pt}de interesse (por exemplo, em implementações de tempo discreto, sobre estados ocultos na primeira etapa de tempo no vetor D e sobre observações na matriz C) e seus mapeamentos probabilísticos (por exemplo, mapeamento de probabilidade entre estados ocultos e observações na matriz A). No entanto, em alguns casos, é útil pensar em fatorações do espaço de estados do modelo generativo, o que evita considerar todas as combinações possíveis de variáveis \hspace{0pt}\hspace{0pt}caso algumas sejam desnecessárias. No capítulo 7, discutiremos um exemplo biologicamente plausível de fatoração que ocorre no processamento perceptual entre fluxos ``o quê'' e ``onde'' (Ungerleider e Haxby 1994) -- ou seja, entre variáveis \hspace{0pt}\hspace{0pt}que representam identidades e localizações de objetos, respectivamente, que podem ser tratados independentemente no modelo (portanto, simplificando-o), pois muitas vezes são invariantes entre si.

Decidir quais variáveis \hspace{0pt}\hspace{0pt}são de interesse e como elas são relacionadas ou fatoradas no modelo é geralmente a parte mais desafiadora -- mas também a mais criativa -- do projeto do modelo. É um exercício de tradução de nossas hipóteses cognitivas em uma forma matemática que suporta a Inferência Ativa. Como devemos selecionar as variáveis \hspace{0pt}\hspace{0pt}``certas''? Em última análise, trata-se de especificar alternativas plausíveis e escolher aquelas que têm a menor energia livre (cf.~comparação do modelo bayesiano). No entanto, uma perspectiva praticamente útil para a maioria dos estudos é que o modelo generativo deve ser o mais semelhante possível à forma como acreditamos que os dados são gerados. Ao apelar para a Inferência Ativa no cenário da psicologia cognitiva, isso geralmente significa pensar em como os psicólogos experimentais gerariam os estímulos que apresentam aos participantes experimentais. Ao formalizar esses processos em termos das distribuições de probabilidade necessárias, chegamos a um modelo generativo cuja dinâmica de minimização de energia livre leva naturalmente ao desempenho da tarefa em questão.

Aqui, podemos fazer uma analogia com a maioria dos modelos Bayesianos (ou observadores ideais) de percepção, nos quais os modelos são projetados para imitar (em grande medida) a estrutura da tarefa em mãos, como no exemplo do reconhecimento de um sapo. ou uma maçã (capítulo 2). Essa ideia às vezes é equiparada ao teorema do bom regulador (Conant e Ashby 1970), que diz que para regular um ambiente de forma eficaz, uma criatura (seja biológica ou sintética) deve ser um bom modelo desse sistema. Da perspectiva da construção de nicho ecológico, isso às vezes é expresso em termos da adequação (estatística) (Bruineberg et al.~2018) do modelo de uma criatura ao seu ambiente (e vice-versa). No entanto, isso não significa que o modelo generativo de um agente deva ser idêntico ao processo generativo que realmente gera os dados. Para a maioria das aplicações práticas, pode ser simplificado ou diferente. Voltaremos a este ponto mais adiante neste capítulo (6.6).

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Quadro 6.2 Prioridades e comportamento empírico
\end{minipage} \\
\midrule
\endhead
Outra perspectiva sobre a questão da seleção de prioridades baseia-se em um conjunto de resultados conhecidos como teoremas de classe completa (Wald 1947, Daunizeau et al.~2010), que afirmam que qualquer procedimento de decisão estatística (ou seja, comportamento) pode ser enquadrado como ótimo de Bayes sob o conjunto certo de crenças anteriores. Isso significa que, se estivermos interessados \hspace{0pt}\hspace{0pt}em explicar o comportamento empírico, nosso desafio é identificar o modelo generativo (compreendendo crenças anteriores) que reproduziria esse comportamento da maneira mais simples possível. Em suma, as prioridades são uma declaração de uma hipótese sobre o sistema em questão. Se outras crenças anteriores forem plausíveis, isso oferece uma oportunidade de colocar isso em dados empíricos por meio de comparação de modelos bayesianos. Isso também tem implicações para a fenotipagem computacional em populações clínicas. Que sempre haverá um conjunto de crenças anteriores que tornam o comportamento de Bayes ótimo implica que a questão-chave -- na compreensão dos déficits computacionais que dão origem a síndromes psiquiátricas ou neurológicas -- é quais são essas prioridades. Essa ideia é um pouco contra-intuitiva no início. No entanto, o teorema da classe completa significa que perguntar se um comportamento é (Bayes) ótimo não tem sentido. A questão importante é: Quais são as crenças anteriores que tornariam isso ideal? No capítulo 9, veremos como um apelo à minimização da energia livre com base em nossas próprias crenças como cientistas oferece uma maneira de responder a essa pergunta. \\
\bottomrule
\end{longtable}

\hypertarget{quais-partes-do-modelo-generativo-suxe3o-fixas-e-o-que-uxe9-aprendido}{%
\subsection{Quais partes do modelo generativo são fixas e o que é aprendido?\textbar{}}\label{quais-partes-do-modelo-generativo-suxe3o-fixas-e-o-que-uxe9-aprendido}}

Outra escolha de design é decidir quais partes do modelo generativo são fixas e quais são atualizadas ao longo do tempo como efeito do aprendizado. Em princípio, a Inferência Ativa permite que cada parte do modelo -- e até mesmo sua estrutura -- seja atualizada (ou aprendida) ao longo do tempo. Isso torna o aprendizado uma escolha de design em vez de algo obrigatório. De acordo com isso, abordaremos exemplos de modelos de Inferência Ativa que são completamente projetados à mão e exemplos em que algumas partes do modelo (por exemplo, probabilidades de transição) permanecem fixas enquanto outras (por exemplo, probabilidades) são atualizadas ao longo do tempo.

Na Inferência Ativa, a aprendizagem é lançada como um aspecto da inferência, como um processo de minimização de energia livre. Até agora, descrevemos a inferência em termos de uma atualização de crenças sobre estados do modelo generativo. Da mesma forma, podemos descrever a aprendizagem como uma atualização de crenças sobre os parâmetros do modelo generativo. Para isso, o modelo generativo deve ser dotado de crenças prévias sobre os parâmetros das distribuições a serem aprendidas, onde os parâmetros específicos dependem da distribuição de probabilidade associada a cada variável (por exemplo, média e variância para uma distribuição gaussiana). Esses valores anteriores são atualizados para formar crenças posteriores sempre que novos dados são encontrados. Como discutiremos no capítulo 7, a forma algorítmica dessa atualização é a mesma da atualização das variáveis de estado.

O fato de que tanto a inferência quanto o aprendizado usam o mesmo tipo de atualização de crenças bayesianas pode parecer confuso durante o projeto do modelo -- em parte porque decidir o que deve ser modelado como um estado ou parâmetro nem sempre é simples. No entanto, quando se trata de modelos cognitivos, há uma clara diferença entre inferência e aprendizagem. A inferência descreve mudanças (rápidas) de nossas crenças sobre estados de modelo -- por exemplo, como atualizamos nossa crença de que há uma maçã à nossa frente depois de observar algo vermelho. O aprendizado descreve mudanças (lentas) de nossas crenças sobre os parâmetros do modelo -- por exemplo, como atualizamos nossa distribuição de probabilidade para aumentar o valor do mapeamento maçãs-vermelho após observar várias ocorrências de maçãs vermelhas. As crenças sobre parâmetros geralmente variam muito mais lentamente do que aquelas sobre estados, e só podem ser atualizadas após os estados terem sido inferidos. De uma perspectiva neurobiológica, é atraente mapear a inferência para a dinâmica neuronal e o aprendizado para a plasticidade sináptica. Além disso, como discutiremos no capítulo 7, manter crenças probabilísticas sobre os parâmetros do modelo induz comportamentos de busca de novidades para que as criaturas possam selecionar os melhores dados para aprender a estrutura causal de seus mundos. Isso sugere que dotar os modelos de Inferência Ativa com a capacidade de aprender seus parâmetros (ou mesmo sua estrutura; veja o capítulo 7) é uma maneira eficaz de estudar a dinâmica comportamental da aprendizagem ativa e da exploração baseada na curiosidade.

Antes de concluir esta seção, vale a pena notar que neste livro exemplificamos modelos generativos bastante simples que são definidos usando métodos tabulares (por exemplo, com matrizes explícitas para priores e verossimilhanças) e que operam em pequenos espaços de estados. Em comparação, tipos muito mais sofisticados de modelos generativos -- e esquemas de aprendizado associados -- estão sendo desenvolvidos em campos como aprendizado de máquina, aprendizado profundo e robótica, como, por exemplo, autoencoders variacionais (Kingma e Welling 2014), redes adversárias generativas ( Goodfellow et al.~2014), redes corticais recursivas (George et al.~2017) e modelos mundiais (Ha e Schmidhuber 2018). Em princípio, pode-se emprestar qualquer um desses métodos (e muitos outros) para implementar uma ou mais partes dos modelos de Inferência Ativa (por exemplo, modelos de probabilidade ou transição). Aproveitando os métodos de aprendizado de máquina mais atualizados, seria possível escalar a Inferência Ativa para domínios e aplicativos cada vez mais desafiadores; ver, por exemplo, Ueltzhöffer (2018) e Millidge (2019).

No entanto, existem alguns pontos importantes a serem considerados ao projetar modelos de Inferência Ativa que usam modelos sofisticados de aprendizado de máquina, especialmente se estiver interessado em implicações cognitivas e neurobiológicas. Um apelo da Inferência Ativa é que ela oferece uma perspectiva integradora das funções cognitivas, assumindo que (por exemplo) a inferência perceptiva, o planejamento de ações e o aprendizado derivam do mesmo processo de minimização de energia livre. Esse poder integrador seria perdido se (por exemplo) modelos generativos justapostos que operam ou aprendem independentemente uns dos outros. Além disso, os métodos de aprendizado de máquina mencionados correspondem a modelos de processo distintos da Inferência Ativa e possuem diferentes interpretações cognitivas e neurobiológicas. Finalmente, ao usar métodos de aprendizado de máquina, algumas das escolhas de design discutidas aqui (por exemplo, sobre a escolha de variáveis \hspace{0pt}\hspace{0pt}de modelo) podem ser ignoradas, pois são propriedades emergentes de aprendizado; no entanto, eles podem ser substituídos por diferentes opções de design, sobre (por exemplo) número de camadas, parâmetros e taxas de aprendizado de uma rede neural profunda. Essas escolhas de design potencialmente têm implicações cognitivas e neurobiológicas relevantes, que estão além do escopo do que abordamos aqui.

\hypertarget{configurando-o-processo-gerador}{%
\section{Configurando o Processo Gerador}\label{configurando-o-processo-gerador}}

Na Inferência Ativa, o processo generativo descreve a dinâmica do mundo externo ao agente da Inferência Ativa, que corresponde ao processo que determina as observações do agente (ver figura 6.1). Pode parecer bizarro ter adiado a definição do processo generativo para depois de descrever o modelo generativo do agente. Afinal, um modelador teria alguma tarefa (e processo generativo) em mente desde o início, então faria todo o sentido reverter essa ordem e projetar o processo generativo antes do modelo generativo, especialmente em aplicações onde o modelo generativo tem que ser aprendidas durante interações situadas, como em configurações de jogo ou robóticas (Ueltzhöffer 2018, Millidge 2019, Sancaktar et al.~2020).

A razão pela qual adiamos o projeto do processo generativo é que, em muitas aplicações práticas discutidas neste livro, simplesmente assumimos que a dinâmica do processo generativo é a mesma ou muito semelhante ao modelo generativo. Em outras palavras, geralmente assumimos que o modelo generativo do agente imita de perto o processo que gera suas observações. Isso não é o mesmo que dizer que o agente tem perfeito conhecimento do ambiente. De fato, mesmo que o agente conheça o processo que gera suas observações, ele pode estar incerto sobre (por exemplo) seu estado inicial no processo, como foi o caso do exemplo da maçã versus rã. Na linguagem da Inferência Ativa em tempo discreto, pode-se projetar um modelo no qual tanto o modelo generativo quanto o processo generativo são caracterizados pela mesma matriz A, mas no qual a crença do agente sobre seu estado inicial (vetor D), que faz parte de seu modelo generativo, é diferente -- ou mesmo inconsistente -- com o verdadeiro estado inicial do processo generativo. Uma coisa sutil a notar é que mesmo que tanto o modelo generativo quanto o processo generativo sejam caracterizados pelas mesmas matrizes A e B, suas semânticas são diferentes. A matriz A do processo generativo é uma propriedade objetiva do ambiente (às vezes chamada de distribuição de medição nos modelos Bayesianos), enquanto a matriz A do modelo generativo codifica a crença subjetiva de um agente (chamada de função de verossimilhança nos modelos Bayesianos).

Claro, exceto nos casos mais simples, não é obrigatório que o modelo generativo e o processo generativo sejam os mesmos. Em implementações práticas de Inferência Ativa, pode-se sempre especificar o processo generativo separadamente do modelo generativo, seja usando equações que diferem daquelas do modelo generativo ou usando outros métodos, como simuladores de jogos, que tomam ações como entradas e fornecem observações como saídas (Cullen et al.~2018), seguindo assim o ciclo usual de ação-percepção implícito no envoltório de Markov da figura 6.1.

Existem algumas implicações filosóficas de projetar modelos generativos que são semelhantes ou diferentes do processo generativo (Hohwy 2013; Clark 2015; Pezzulo, Donnarumma et al.~2017; Nave et al.~2020, Tschantz et al.~2020). Como discutido acima, o teorema do bom regulador (Conant e Ashby 1970) diz que uma criatura adaptativa eficaz deve ter ou ser um bom modelo do sistema que regula. No entanto, isso pode ser alcançado de várias maneiras. Primeiro, como discutido até agora, o modelo generativo da criatura pode imitar (pelo menos em grande medida) o processo generativo. Os modelos desenvolvidos dessa forma podem ser chamados de modelos explícitos ou ambientais, dada a semelhança entre seus estados internos e os estados externos do ambiente. Em segundo lugar, o modelo generativo da criatura pode ser muito mais parcimonioso do que (e até significativamente diferente) do processo generativo, na medida em que administra corretamente os aspectos do ambiente que são úteis para agir de forma adaptativa nele e atingir os objetivos da criatura. Os modelos desenvolvidos dessa maneira podem ser chamados de sensório-motores ou orientados para a ação, pois codificam principalmente contingências de observação de ação (ou sensório-motoras) e seu papel principal é apoiar ações direcionadas a objetivos, em vez de fornecer uma descrição precisa do ambiente.

A diferença entre modelos explícitos e orientados para a ação pode ser apreciada se considerarmos diferentes maneiras de modelar (por exemplo) um roedor tentando escapar de um labirinto no qual alguns corredores são becos sem saída. Um modelo generativo explícito pode se assemelhar a um mapa cognitivo do labirinto e fornecer uma caracterização detalhada de entidades externas, como locais específicos, corredores e becos sem saída. Este modelo pode permitir que o roedor escape do labirinto usando a navegação baseada em mapas. Um modelo orientado para a ação pode codificar contingências entre os movimentos do bigode e as sensações de toque. Este último modelo permitiria a seleção de estratégias contextualmente apropriadas, como avançar (se nenhuma sensação de toque for experimentada ou esperada) ou mudar de direção (no caso oposto) - eventualmente permitindo que o roedor escape do labirinto sem representar explicitamente os locais , corredores ou becos sem saída. Esses dois tipos de modelo levam a diferentes interpretações filosóficas da Inferência Ativa, considerando os modelos generativos como formas de reconstruir o ambiente externo (explícito) ou proporcionar controle preciso da ação (orientado à ação).

Finalmente, como discutido no campo da computação morfológica (Pfeifer e Bongard 2006), alguns aspectos do controle de uma criatura ou robô podem ser terceirizados para o corpo e, portanto, não precisam ser codificados em seu modelo generativo. Um exemplo é o caminhante dinâmico passivo: um objeto físico semelhante a um corpo humano, composto por duas ``pernas'' e dois ``braços'', que é capaz de caminhar em um declive sem sensores, motores ou controladores (Collins et al.~2016). . Este exemplo implica que pelo menos alguns aspectos da locomoção (ou outras habilidades) podem ser alcançados com a mecânica corporal que é cuidadosamente ajustada para explorar contingências ambientais (por exemplo, um peso corporal ou tamanho apropriado para andar sem escorregar); portanto, essas contingências não precisam ser codificadas no modelo generativo da criatura. Isso sugere uma maneira alternativa de projetar agentes de Inferência Ativa (e seus corpos) que são -- e não têm -- bons modelos de seu ambiente. No entanto, todas as maneiras de projetar modelos de Inferência Ativa não são mutuamente alternativas, mas podem ser combinadas adequadamente, dependendo do problema de interesse.

\hypertarget{simulando-visualizando-analisando-e-ajustando-dados-usando-inferuxeancia-ativa}{%
\section{Simulando, Visualizando, Analisando e Ajustando Dados Usando Inferência Ativa}\label{simulando-visualizando-analisando-e-ajustando-dados-usando-inferuxeancia-ativa}}

Na maioria das aplicações práticas, uma vez que o modelo generativo e o processo generativo tenham sido definidos, basta usar o procedimento padrão de Inferência Ativa - a descida dos estados ativo e interno no funcional de energia livre associado ao modelo - para obter resultados numéricos . Indiscutivelmente, os objetivos dos modeladores são simular, visualizar, analisar e ajustar dados (por exemplo, realizar análise de dados baseada em modelo). Rotinas padrão para Active Inference que fornecem suporte para todas essas funções estão disponíveis gratuitamente (\url{https://www}\hspace{0pt}.fil\hspace{0pt}.ion\hspace{0pt}.ucl\hspace{0pt}.ac\hspace{0pt}.uk\hspace{0pt}/spm\hspace{0pt}/); um exemplo anotado de como usar esses
rotinas é fornecida no apêndice C.

Embora na maioria dos casos os procedimentos de Inferência Ativa funcionem de prateleira, em algumas aplicações práticas pode-se considerar ajustes específicos ou mudanças. Por exemplo, especificar a profundidade temporal do planejamento define quantos estados futuros são considerados durante os cálculos de energia livre esperados. A configuração de uma profundidade temporal limitada, juntamente com outras aproximações para busca exaustiva, como amostragem (Fountas et al.~2020), pode ser útil em aplicações práticas de Inferência Ativa em grandes espaços de estados.

Outro exemplo de adaptação do funcionamento padrão da Inferência Ativa é a remoção seletiva de partes da equação de energia livre esperada. Esta ablação pode ser útil para comparar a Inferência Ativa padrão (que usa energia livre esperada) com versões reduzidas, nas quais algumas partes da energia livre esperada são suprimidas para torná-las formalmente análogas a (por exemplo) controle KL ou sistemas de maximização de utilidade (Friston , Rigoli et al.~2015). Além disso, pode-se também ampliar os modelos de Inferência Ativa com mecanismos adicionais, como aprendizado habitual (Friston, FitzGerald et al.~2016) ou modulação da taxa de aprendizado (Sales et al.~2019), com a ressalva de que manter o caráter normativo da Inferência Ativa requerem lançar esses mecanismos adicionais em termos de minimização de energia livre.

Finalmente, outros ajustes ou mudanças na Inferência Ativa podem ser úteis para caracterizar distúrbios de inferência e condições psicopatológicas - por exemplo, para explorar as consequências comportamentais e neuronais de dotar o modelo generativo de uma criatura com antecedentes excessivamente fortes (ou fracos) por meio de (ou baixos) níveis de neuromoduladores. Forneceremos alguns exemplos de modelos de Inferência Ativa que são relevantes para a psicopatologia no capítulo 9.

\hypertarget{resumo-5}{%
\section{Resumo}\label{resumo-5}}

Neste capítulo, descrevemos as escolhas de projeto mais importantes que devem ser feitas na configuração de um modelo de Inferência Ativa. Fornecemos uma receita em quatro etapas e algumas diretrizes para enfrentar os desafios usuais que os designers de modelos enfrentam. Claro, não é necessário seguir a receita de forma rígida. Algumas etapas podem ser invertidas (por exemplo, projetar o processo generativo antes do modelo generativo) ou combinadas. Mas, em geral, essas etapas são todas necessárias. Isso configura o restante deste livro, que coloca essas ideias em prática por meio de uma série de exemplos ilustrativos projetados para mostrar os princípios teóricos apresentados na primeira metade do livro. Em tudo o que segue, as únicas diferenças entre os exemplos estão nas escolhas de design que destacamos aqui. A Parte 2 ilustra sistemas com limites diferentes, com dinâmicas discretas ou contínuas em diferentes escalas de tempo, para os quais a escolha de crenças anteriores é fundamental para reproduzir o comportamento em muitos domínios diferentes, mas todos implementando a mesma Inferência Ativa.

\hypertarget{inferuxeancia-ativa-em-tempo-discreto-1}{%
\chapter{Inferência ativa em tempo discreto}\label{inferuxeancia-ativa-em-tempo-discreto-1}}

O que eu não posso criar, eu não entendo. --- Richard Feynman

\hypertarget{introduuxe7uxe3o-6}{%
\section{Introdução}\label{introduuxe7uxe3o-6}}

Até agora, discutimos os princípios da Inferência Ativa em um nível relativamente abstrato. Este capítulo trata de exemplos específicos --- e como eles podem ser especificados em um cenário prático. Focamos em modelos de variáveis categóricas em tempo discreto. Por meio de uma série de exemplos, construídos em complexidade, ilustramos modelos de processamento perceptual, tomada de decisão, busca de informações, aprendizado e inferência hierárquica. Esses exemplos são escolhidos para destacar as propriedades emergentes da forma mais simples possível -- incluindo fisiologia e comportamento mensuráveis -- dos esquemas de Inferência Ativa.

\hypertarget{processamento-perceptivo}{%
\section{Processamento Perceptivo}\label{processamento-perceptivo}}

Começamos considerando o processamento perceptual e a inversão do tipo de modelos de tempo discreto introduzidos no capítulo 4. Mais adiante neste capítulo, construímos um processo de decisão Markov parcialmente observável completo (POMDP). No entanto, começamos com um caso especial de um POMDP no qual podemos ignorar escolhas e comportamento: um modelo oculto de Markov (HMM), que pode ser usado para inferência perceptual de uma classificação sequencial e categórica (veja a figura 7.1). Para motivar isso, vamos recorrer a um exemplo simples. Imagine ouvir uma apresentação de uma pequena peça de música. A sequência de notas que são escritas na partitura pode ser pensada como estados ocultos (não observados), enquanto a sequência de notas que realmente ouvimos são os resultados (observáveis). Se o intérprete é um músico profissional, a correspondência entre os estados ocultos e os resultados pode ser muito próxima. No entanto, se for um amador, pode haver um grau adicional de estocasticidade no mapeamento (de probabilidade) da nota que deve ser tocada para a que é ouvida. Nesse cenário, ainda pode ser possível inferir qual nota deveria ter sido ouvida, dadas as crenças prévias sobre a probabilidade de cada nota ser precedida ou sucedida por outra.

\begin{figure}
\centering
\includegraphics{images/Figura_7_1.png}
\caption{\textbf{Figura 7.1} Este modelo oculto de Markov usa a mesma notação introduzida no capítulo 4 para expressar uma sequência de estados que evoluem ao longo do tempo. A cada vez, eles dão origem a um resultado observável (o). O estado em um momento depende apenas do estado no momento anterior (com essa dependência expressa em B). O primeiro estado na sequência tem probabilidade anterior D. A geração de resultados dos estados depende da distribuição de verossimilhança (A). Esta especificação de um HMM é genérica, com modelos generativos específicos dependendo de escolhas específicas para A, B e D.}
\end{figure}

O exemplo de escuta do músico amador pode ser formalizado da seguinte forma. Primeiro, decidimos com que confiabilidade nosso músico realmente toca a nota (resultado) que ela pretende (estado oculto). Podemos expressar isso através da matriz A, cujos elementos indicam a probabilidade de um resultado (linhas) dado um estado (colunas). Em nosso exemplo de brinquedo, definimos isso da seguinte forma:

\[ A = \frac{1}{10}\begin{bmatrix} 
7 & 1 & 1 & 1  \\ 
1 & 7 & 1 & 1  \\
1 & 1 & 7 & 1  \\ 
1 & 1 & 1 & 7  \\ 
\end{bmatrix} \qquad\qquad\qquad (7.1) \]

Isso diz que 70\% das vezes, nosso músico atinge a nota pretendida. Em seguida, especificamos as probabilidades de transição na matriz B, que explicam a probabilidade do próximo estado (linhas) dado o estado atual (colunas)

\[ B = \frac{1}{100}\begin{bmatrix} 
1 & 1 & 1 & 97  \\ 
97 & 1 & 1 & 1  \\
1 & 97 & 7 & 1  \\ 
1 & 1 & 97 & 1  \\ 
\end{bmatrix} \qquad\qquad\qquad (7.2) \]

Isso diz que há uma probabilidade de 97\% de a primeira nota ser seguida pela segunda, a segunda pela terceira e assim por diante. Se sabemos que a sequência sempre começa com a primeira nota, definimos a probabilidade anterior:

\[ D = \begin{bmatrix} 
1  \\ 
0 \\ 
0 \\ 
0 \\ 
\end{bmatrix} \qquad\qquad\qquad (7.3) \]

Juntas, as equações 7.1--7.3 especificam completamente o modelo generativo HMM mostrado na figura 7.1. Em outras palavras, eles fornecem uma descrição de nossas crenças sobre como a música que ouvimos é gerada por nosso músico amador. Usando a equação 4.12 e substituindo em nosso modelo generativo, podemos simular a dinâmica da atualização da crença Bayesiana induzida por uma sequência de resultados. Isso é mostrado na figura 7.2. Observe o aumento na confiança mostrado no gráfico superior esquerdo à medida que mais dados são acumulados ao longo do tempo, exceto para o terceiro passo de tempo, onde ocorreu um resultado inesperado. Esse resultado pode ser explicado de duas maneiras. Primeiro, pode ser que a nota pretendida realmente fosse uma nota incomum sob nossas crenças anteriores na equação 7.2. Isso é menos provável pela raridade de tais transições sob a matriz B deste modelo. A explicação alternativa, mais plausível, é que o músico tocou a nota errada por engano. Conforme mostrado na terceira coluna do gráfico superior direito, esta é a explicação que nosso ouvinte simulado estabelece. No entanto, uma probabilidade diferente de zero é atribuída à possibilidade de que, afinal, fosse a nota certa. A capacidade de relatar esse tipo de incerteza é uma característica fundamental da perspectiva Bayesiana proporcionada pela Inferência Ativa.

O modelo mostrado aqui pode ser mais sofisticado de várias maneiras, mas talvez o mais simples dependa da fatoração do espaço de estados (Mirza et al.~2016). Um exemplo pode ser o tom e a dinâmica da nota (com uma distinção semelhante nos resultados). Em uma tarefa de inferência visual, a fatoração pode ser em quê e onde, o que tem muito valor na neurobiologia (Ungerleider e Haxby 1994). Nas seções subsequentes, apelaremos a esse tipo de fatoração para separar os estados que podem ser influenciados pela criatura em questão daqueles que não podem. Para ler mais sobre esse tipo de modelo (sem ações em jogo) e os tipos de esquema de transmissão de mensagens neuronais que podem ser usados para invertê-lo minimizando a energia livre, veja Parr, Markovic et al.~(2019).

\begin{figure}
\centering
\includegraphics{images/Figura_7_2.png}
\caption{Figura 7.2 Esses gráficos de inferência perceptiva simulados ilustram o processo de atualização de crenças em um exemplo de tentativa baseado no modelo generativo descrito no texto principal. Superior esquerdo: Crenças (probabilidades posteriores) sobre cada nota na sequência em cada passo de tempo. Superior direito: Como os valores numéricos dessas crenças são difíceis de rastrear as crenças no final da sequência, tendo ouvido cada nota (ou seja, crenças retrospectivas) são mostradas. Cada coluna mostra crenças (retrospectivas) sobre os estados ocultos em um determinado intervalo de tempo. Cada linha representa uma hipótese alternativa para esse estado oculto. Quanto mais escuro o sombreamento, mais provável é que a nota tenha sido (com o preto indicando uma probabilidade de um e o branco uma probabilidade de zero). Inferior esquerdo: gradientes de energia livre (negativos) (ou seja, erros de previsão) ao longo do tempo. A taxa de mudança das crenças no gráfico superior esquerdo é determinada pelo valor desses erros em cada passo de tempo. Inferior direito: Sequência de notas musicais apresentadas ao nosso agente sintético (ou seja, as observações que ele recebe durante os passos de tempo 1 a 5). Observe que enquanto no terceiro passo de tempo (o3) o ouvinte ouviu a segunda nota (terceira coluna do gráfico inferior direito), ele infere a terceira nota com maior probabilidade (terceira coluna do gráfico superior direito).}
\end{figure}

\hypertarget{tomada-de-decisuxe3o-e-planejamento-como-inferuxeancia}{%
\section{Tomada de decisão e planejamento como inferência}\label{tomada-de-decisuxe3o-e-planejamento-como-inferuxeancia}}

O HMM usado acima ilustra uma forma muito simples de inferência categórica baseada em uma sequência de resultados. No entanto, o tipo de criatura (séssil) que isso descreve é bastante desinteressante. Criaturas autônomas são claramente mais do que recipientes passivos de dados sensoriais. Em vez disso, eles mudam ativamente seu ambiente e se envolvem em uma troca bidirecional com seu sensório. Isso fala da importância de converter um HMM em um POMDP, pelo qual devemos inferir não apenas como nosso ambiente está mudando, mas também como nosso curso de ação escolhido o altera e qual curso de ação escolher.

A Figura 7.3 mostra um modelo generativo do POMDP. Isso é o mesmo que foi apresentado no capítulo 4, onde os detalhes da inferência nesse tipo de modelo são descompactados. Observe a semelhança dessa estrutura com o HMM na figura 7.1 e a adição de uma variável extra (π ), na qual estão condicionadas as probabilidades de transição (B). Isso significa que podemos considerar hipóteses alternativas sobre a dinâmica dos estados. Essas hipóteses podem ser interpretadas como planos entre os quais uma criatura pode selecionar. Essa perspectiva equipara avaliação de políticas com comparação de modelos e diz que uma política é simplesmente uma explicação
variável para uma sequência observada de sensações (autogeradas).

\begin{figure}
\centering
\includegraphics{images/Figura_7_3.png}
\caption{Figura 7.3 POMDP da figura 4.3, descompactando as distribuições de probabilidade em termos de fatores de estado ocultos e modalidades de resultado. (A Figura 7.1 é um caso especial dessa estrutura.) Três pontos a serem observados: Primeiro, a fatoração dos estados ocultos agora significa que a distribuição codificada por A tem (potencialmente) muitos fatores de estado em seu conjunto de condicionamento e não pode mais ser codificada por uma matriz. Em vez disso, isso se torna um objeto tensor, no qual cada índice corresponde a um fator de estado. Em segundo lugar, a separação dos resultados em diferentes modalidades significa que haverá um tensor A separado para cada modalidade. Terceiro, enquanto C e E aparecem no painel à direita, eles não aparecem no gráfico de fatores à esquerda porque só entram no modelo generativo por meio de crenças anteriores sobre políticas. Para uma perspectiva alternativa sobre isso, ver Parr e Friston (2018d) e van de Laar e de Vries (2019).}
\end{figure}

O modelo da figura 7.3 difere sutilmente daquele apresentado no capítulo 4: ele permite a fatoração de estados (sobrescrito n) e de resultados (sobrescrito m). A utilidade disso é óbvia quando consideramos a fatoração do mundo visual em onde um objeto está e o que é. Claramente, seria extremamente ineficiente (e incorreria em um alto custo de complexidade) para representar todas as combinações possíveis de localização e identidade, quando a identidade é (normalmente) invariável à localização e vice-versa. Um argumento semelhante pode ser usado para fatoração de tempo de identidade e localização (Friston e Buzsaki 2016). O benefício de introduzir essa fatoração neste estágio é que podemos separar os estados do mundo sobre os quais uma criatura tem controle daqueles que ela não tem. Embora as probabilidades de transição que governam a primeira sejam diferentes em cada política, a segunda será invariável a isso.

Com essas preliminares em vigor, agora esboçamos um exemplo simples de uma tarefa (Friston, FitzGerald et al.~2017) que requer planejamento e ilustra alguns dos principais aspectos da inferência ativa usando POMDPs. Isso envolve um rato em um labirinto em T contendo um estímulo aversivo em um braço, um estímulo atraente em outro e uma pista que indica a localização dos dois estímulos no braço final. Essa configuração significa que o rato pode se comportar de duas maneiras (amplamente). Ele poderia optar por ir direto para um dos dois braços que poderiam conter o estímulo atrativo, arriscando o estímulo aversivo. Alternativamente, ele pode optar por buscar a dica informativa e, em seguida, ir para o braço com maior probabilidade de conter o estímulo atraente.

Essa escolha remete ao clássico dilema prospecção-aproveitamento em psicologia: um dilema que é resolvido sob a Inferência Ativa. A resolução decorre da minimização da energia livre esperada exigida por crenças anteriores sobre políticas. Para revisar isso brevemente (veja o capítulo 4 para detalhes), as políticas mais prováveis (para uma criatura que minimiza sua energia livre variacional) são aquelas que levam à menor energia livre esperada. A energia livre esperada tem a seguinte forma:

\[G(\pi) = 
\begin{matrix} \underbrace {\mathbb E_{Q(\tilde s | \pi)}[H[P(\tilde o| \tilde s)]]-H[Q(\tilde o|\pi)]]} \\ Valor\;epistêmico\;negativo\;(−\mathcal I(\pi)) \end{matrix} - 
\begin{matrix}\underbrace {\mathbb E_{Q(\tilde s | \pi)}[\ln P(\tilde o | C)] } \\ Valor\;Pragmático  \end{matrix}\qquad (7.4)\]
Essa decomposição da energia livre esperada em valor epistêmico e pragmático destaca o impulso (epistêmico) para a coleta de informações e o impulso (pragmático) para a realização de crenças anteriores (C na figura 7.3).

Tentaremos fornecer uma intuição mais profunda para o valor epistêmico na próxima seção, mas pode ser pensado simplesmente como a quantidade de informação que podemos obter sob uma política específica. A forma do valor pragmático trata efetivamente a probabilidade de resultados, calculada a média de todas as políticas, como se fosse um . Para colocar isso em termos mais intuitivos, se considerarmos um certo tipo. Ao fazê-lo, aquelas políticas com consequências consistentes com este prévio tornam-se mais prováveis, pois estão associadas a menor energia livre de observação esperada para serem muito prováveis, agiremos para cumprir nossa crença de que as encontraremos. Portanto, a probabilidade logarítmica dos resultados pode ser considerada equivalente a uma função de utilidade em outros formalismos, como teoria de controle ótimo e aprendizado por reforço. O fato de que a utilidade e o valor da informação emergem como dois componentes da energia livre esperada significa que não precisamos nos preocupar em equilibrar exploração e exploração. Ambos estão a serviço de otimizar a mesma função.

\begin{figure}
\centering
\includegraphics{images/Figura_7_4.png}
\caption{Figura 7.4 Probabilidade no contexto 1. Esquerda: configuração do labirinto em T de pistas e estímulos: o estímulo atrativo está à direita e o estímulo aversivo está à esquerda. Direita: Probabilidade ou modelo de observação especifica o mapeamento probabilístico da localização para pistas exteroceptivas (A1) e para pistas interoceptivas (A2). Cada elemento dessas matrizes é a probabilidade do resultado ilustrado no final da linha, condicionado ao contexto ser um e estar no local indicado pela linha. Os resultados exteroceptivos são entradas visuais ou proprioceptivas associadas a cada local, em que a localização do sinal pode dar origem a um sinal para a direita ou para a esquerda. Os resultados interoceptivos são ausentes (círculo com contorno pontilhado), atrativos (círculo preenchido) ou aversivos (círculo não preenchido).}
\end{figure}

Para ver como isso se desenrola no exemplo do labirinto em T, precisamos formalizar o modelo generativo da mesma forma que no HMM acima. As Figuras 7.4--7.6 ilustram as probabilidades de verossimilhança e de transição que compõem o modelo generativo para o labirinto em T. Examinaremos isso com alguns detalhes, pois este exemplo mínimo fornece os blocos de construção a partir dos quais os leitores podem construir seus próprios modelos generativos. A primeira coisa a fazer é decidir sobre o número de modalidades de resultados que representam os dados (sensoriais) que nosso modelo deve explicar. Isso nos diz o número de matrizes A que devemos especificar. Aqui, temos duas modalidades que representam dados exteroceptivos referentes a onde o rato está no labirinto (A1) e qual modalidade pode ser os dados interoceptivos que o rato experimenta quando encontra o estímulo atraente (comestível) (A2). Os níveis nessas modalidades (ou seja, as observações alternativas que podem ser feitas em cada uma) determinam as linhas de cada matriz A. A próxima decisão é o número de fatores de estado ocultos que podem ser usados \hspace{0pt}\hspace{0pt}para explicar esses dados; este é o número de matrizes B que precisamos. Consideramos dois fatores aqui: a posição do rato no labirinto e o contexto (estímulo atrativo à esquerda ou à direita). Estes têm quatro e dois níveis, respectivamente. Agora devemos especificar, para cada combinação de estados ocultos, a probabilidade de cada resultado. O contexto 1 é mostrado na figura 7.4; o contexto 2 é mostrado na figura 7.5.

\begin{figure}
\centering
\includegraphics{images/Figura_7_5.png}
\caption{Figura 7.5 Probabilidade no contexto 2. Quase idêntica à figura 7.4 --- neste contexto, os estímulos aversivos e atrativos foram trocados. Isso se reflete na probabilidade dos resultados exteroceptivos na localização da pista e nas probabilidades dos resultados interoceptivos nos braços direito e esquerdo do labirinto.}
\end{figure}

Para a primeira modalidade, nosso A1 associa cada local a um resultado com probabilidade um. A localização do ``cue''(?) pode estar associada a um ``cue''(?) esquerdo ou direito, dependendo do contexto. A modalidade interoceptiva (A2) associa um resultado neutro com os locais de início e ``sugestão''(?) e uma chance de 98 por cento de encontrar o resultado atraente quando o contexto corresponde ao braço do labirinto em que o rato entrou. Tecnicamente, essas matrizes A são quantidades de tensores, porque seus elementos são especificados por três números (resultado, localização e contexto), enquanto uma matriz é especificada apenas por dois (linha e coluna).

Em seguida, precisamos especificar as probabilidades de transição. As matrizes B especificam a probabilidade de transição de um estado (coluna) para outro estado (linha), dependendo da escolha da política (π ). Estes especificam as transições referentes à posição do rato no labirinto (B1) e as transições no contexto (B2). A Figura 7.6 mostra as transições B1 controláveis. Cada matriz mostra as probabilidades sob uma escolha de ação diferente (subscrito). Estes permitem um movimento de qualquer local para qualquer outro local, exceto dos dois braços do labirinto, que são estados absorventes. Isso significa que, uma vez lá, o rato deve permanecer lá, independentemente das ações que escolher. Em contraste, o rato não tem controle sobre o contexto (ou seja, se está no contexto 1, mostrado na figura 7.4, ou no contexto 2, mostrado na figura 7.5). O contexto permanece constante ao longo do tempo e pode ser representado como uma matriz de identidade:

\[ B^2_\pi = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \qquad (7.5)\]
Aqui cada coluna (e linha) refere-se a um estado indexando a figura 7.4 ou a figura 7.5. Isso significa que qualquer contexto em que começamos permanece constante (transições para si mesmo ) ao longo do tempo. Isso é verdade independentemente da política selecionada. O vetor C1 mostra preferências anteriores para cada um dos resultados nesta modalidade, com preferências uniformes, exceto por uma leve aversão (−1) ao local de início.

\begin{figure}
\centering
\includegraphics{images/Figura_7_6.png}
\caption{\textbf{Figura 7.6} Probabilidades de transição controláveis para movimentação entre os diferentes locais. Cada uma das quatro matrizes corresponde a uma ação alternativa que o rato pode escolher. Estes permitem uma mudança de qualquer estado (exceto o braço direito e esquerdo) para qualquer outro estado. Os braços direito e esquerdo são estados absorventes, nos quais o rato deve permanecer uma vez inserido.}
\end{figure}

O vetor C2 especifica preferências (+6) para o estímulo atrativo e aversão (-6) para o estímulo aversivo. A ausência de qualquer um é considerada neutra (0).

\[ \begin{equation} 
C^1 = \sigma([-1,0,0,0,0]^T) \qquad\qquad\qquad\\ 
C^2 = \sigma([0,6,-6]^T)
\end{equation} \qquad\qquad\qquad (7.6) \]
A ordem dos elementos nesses vetores corresponde à ordem das linhas nas matrizes A correspondentes. A função softmax (σ ) permite especificar preferências em termos de valores positivos e negativos (correspondentes a probabilidades logarítmicas não normalizadas), que são então convertidas em probabilidades. Isso preserva a diferença nas probabilidades de log (ou a probabilidade relativa) enquanto garante a normalização. Praticamente, esta formulação significa que o estímulo atrativo é considerado e6 (≈ 400) vezes mais provável que o estímulo neutro no modelo generativo do rato. Esta é uma preferência muito forte que significa que o rato acredita que suas ações são muito mais propensas a levar ao resultado atraente. Essa restrição à inferência sobre a ação é crucial para o comportamento que se segue. Finalmente, os vetores D especificam as probabilidades anteriores para os estados iniciais:

\[ \begin{equation} 
D^1 = [1,0,0,0,0]^T \qquad\qquad\qquad\\ 
D^2 =\frac{1}{2}[1,1]^T
\end{equation} \qquad\qquad\qquad (7.7) \]

A ordem dos elementos nestes vetores coincide com a das matrizes B. O vetor D1 indica uma crença confiante em começar no centro do labirinto. O vetor D2 indica que os dois contextos (figura 7.4 ou 7.5) são considerados igualmente prováveis no início.

A Figura 7.7 mostra o que acontece quando invertemos o modelo generativo das figuras 7.4--7.6. A linha superior ilustra o que veríamos se observássemos o comportamento do rato. Começa no centro e depois vai para a dica informativa. Isso se deve ao alto valor epistêmico associado a esse local (ou seja, as observações feitas nesse local têm o potencial de resolver a incerteza sobre o contexto). Ao ver a pista que indica um contexto à esquerda (contexto 1), o rato escolhe o braço esquerdo do labirinto e encontra o estímulo recompensador. Este movimento é impulsionado pelo alto valor pragmático atribuído a este local. Os gráficos inferiores ilustram a atualização de crenças que ocorre durante este teste simples. Como na figura 7.2, isso é mostrado na forma que poderíamos esperar observar em um rato idealizado se estivéssemos medindo a atividade neuronal (ou seja, taxas de disparo e potenciais de campo locais {[}LFPs{]}). Observe a rápida mudança nas crenças no segundo passo de tempo, quando o rato atinge o local da dica informativa e a LFP associada (linha tracejada).

\begin{figure}
\centering
\includegraphics{images/Figura_7_7.png}
\caption{\textbf{Figura 7.7} Comportamento epistêmico e pragmático simulado de um rato forrageando em um labirinto em T. O rato começa no local central, mas depois escolhe amostrar a sugestão informativa no braço inferior do labirinto. Esta localização está associada ao maior valor epistêmico, pois observar a deixa neste local revela o contexto (recompensa direita ou esquerda) em que o rato se encontra. LFP (ε ). Sem mais incertezas para resolver, o rato seleciona a opção pragmaticamente valiosa e vai para o braço esquerdo do labirinto. Os dois gráficos à direita mostram as crenças mantidas pelo rato no final da tentativa sobre todos os tempos anteriores (ou seja, são crenças retrospectivas e não as crenças do rato no momento da decisão). Ele acredita (corretamente) que começou no local central, foi para o braço do taco e depois foi para o braço esquerdo. Para o fator de estado oculto do contexto, o rato acredita que o contexto foi o contexto da esquerda por toda parte.}
\end{figure}

\hypertarget{busca-de-informauxe7uxf5es}{%
\section{Busca de informações}\label{busca-de-informauxe7uxf5es}}

A simulação na seção 7.2 ilustra um exemplo simples de um trade-off prospecção-aproveitamento, que é resolvido pela busca de informações até que a incerteza seja resolvida, então explorando o que foi inferido para atender às preferências anteriores. Nesta seção, descompactamos o conceito de valor epistêmico com mais detalhes. Como vimos na equação 7.4, isso compreende dois termos:

\$\$
\begin{equation}
\begin{matrix} \underbrace{\mathcal I(\pi)} \\ valor\;epistêmico\end{matrix} 
= \begin{matrix} \underbrace{H(Q(\tilde o|\pi))} \\ entropia\;preditiva\;posterior \end{matrix}
- \begin{matrix} \underbrace{E_{Q(\tilde s|\pi)}[H[P(\tilde o| \tilde s)]]} \\ ambiguidade\;esperada\end{matrix} \\
= \begin{matrix} \underbrace{D_{KL}[P(\tilde o | \tilde s)Q(\tilde o | \tilde \pi) || Q(\tilde o | \tilde \pi) Q(\tilde s | \tilde \pi)]} \\ informação\;mútua \end{matrix} \qquad\qquad\qquad (7.8) \\
= \begin{matrix} \underbrace{E_{Q(\tilde o | \tilde \pi)}[D_{KL}][Q(\tilde s |\pi, \tilde o) || Q(\tilde s | \pi)]} ; Q(\tilde s|\pi, \tilde o) \triangleq \frac{P(\tilde o| \tilde s)Q(\tilde s | \pi)}{Q(\tilde o | \pi)} \\ ganho\;de\;informação,\;saliência,\;surpresa\;Bayesiana \end{matrix}  \\

\end{equation}
\$\$
Estas são a entropia preditiva posterior e a ambiguidade esperada, respectivamente. Abaixo destes, destacamos a correspondência entre estes e outros rearranjos. Para descompactá-los de forma intuitiva, vamos enquadrar isso em termos de um paradigma visual, onde sacadas alternativas (π ) levam a diferentes transições entre locais de fixação (s). Além dos locais de fixação, os estados ocultos incluem a identidade de um estímulo em cada local. Uma combinação de estímulo e fixação gera consequências visuais e proprioceptivas (o). Com isso em mente, podemos interpretar a entropia preditiva posterior como a dispersão (ou incerteza) associada ao ``o que eu veria se realizasse esse movimento ocular''. Do ponto de vista de um cientista, isso quantifica o quão incertos podemos estar sobre os dados que obteríamos ao realizar um determinado experimento. Sob essa perspectiva, faz sentido selecionarmos as sacadas (ou experimentos) que estão associadas à maior entropia preditiva posterior, pois oferecem o maior potencial de resolução de incertezas. Não ganharíamos nada realizando um experimento se já soubéssemos quais seriam os resultados com um alto grau de confiança.

No entanto, a entropia preditiva apenas nos diz a quantidade total de incerteza. Não nos diz quanta incerteza é realmente solucionável. Sempre estaremos incertos sobre o próximo número em uma sequência de números gerados aleatoriamente, mas nunca resolveremos nossa incerteza sobre o processo que os gerou fixando neles. É aí que entra a ambiguidade esperada. Isso quantifica o grau em que as observações e os estados são independentes um do outro. Se os estados sempre gerarem a mesma observação, essa quantidade será zero. Será máximo se, como no gerador de números aleatórios, não houver associação entre estados e resultados. No domínio visual, isso implica que a melhor sacada será aquela em direção a um estímulo bem iluminado, onde há pouca ambiguidade sobre ``o que eu veria se olhasse para esse estímulo''. Tomados em conjunto, isso diz que as melhores sacadas (ou seja, experimentos perceptivos) são aquelas para as quais há a maior incerteza para resolver (entropia preditiva posterior), mas somente se essa incerteza puder ser resolvida (ambiguidade negativa). Curiosamente, isso tem exatamente a mesma forma que as expressões desenvolvidas em estatística para pontuar o projeto experimental em termos de ganho de informação (Lindley 1956).

A Figura 7.9 ilustra o que acontece em um paradigma sacádico (Parr e Friston 2017b) quando simulamos manipulações para a ambiguidade e entropia preditiva posterior. Isso mostra quatro estímulos (quadrados), cada um dos quais pode mudar de cor a cada momento. Sobreposto a estes está um traço de rastreamento ocular simulado, como se estivéssemos medindo para onde um participante experimental estava olhando. Crucialmente, especificamos crenças anteriores sobre resultados como uniformes (ou seja, valor pragmático a ser ausente), impedindo quaisquer escolhas baseadas em preferências. Isso significa que cada sacada é selecionada para maximizar o valor epistêmico. Quando o modelo generativo trata todos os quatro estímulos como equivalentes (imagem da esquerda), todos são amostrados com aproximadamente a mesma frequência. No entanto, podemos modular a incerteza associada a cada estímulo (ver caixa 7.1). Se definirmos um estímulo para ter uma ambiguidade maior (aumentando o valor dos elementos fora da diagonal da matriz A correspondente), esse quadrado será ignorado (imagem do meio). Este é um exemplo do famoso efeito ``streetlight'' (Demirdjian et al.~2005), que leva o nome da metáfora de pessoas que perderam suas chaves tarde da noite. O primeiro lugar que eles podem procurar é sob a luz da rua - não porque as chaves provavelmente estejam lá, mas porque é o melhor lugar para encontrar informações de alta qualidade, inequívocas e que resolvem incertezas. A simulação mostra como a praça ambígua (por exemplo, mal iluminada) é ignorada, reproduzindo um efeito ``streetlight'' in silico.

Em contraste, a imagem da direita na Figura 7.8 mostra o que acontece quando tornamos as transições menos previsíveis para o quadrado inferior esquerdo. Acumulamos incerteza sobre esta localização muito rapidamente, garantindo uma alta entropia preditiva posterior sem alteração da ambiguidade. Como podemos ver, isso leva a uma fixação mais frequente nesse local, pois sempre há novas incertezas a serem resolvidas aqui. Intuitivamente, se eu sei que algo tem uma dinâmica muito previsível, não preciso olhar para ele com muita frequência para ter certeza de seu estado. Por outro lado, se algo pode ter mudado no tempo em que estive olhando para outra coisa, vale a pena olhar para trás para verificar. Essas simulações são projetadas para oferecer uma intuição para as duas partes do valor epistêmico, para ver como a minimização da energia livre esperada garante que selecionemos ativamente nossos dados sensoriais para descobrir o mundo.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Quadro 7.1 Incerteza e precisão
\end{minipage} \\
\midrule
\endhead
O exemplo da Figura 7.7 apela ao conceito de precisão -- uma ideia importante neste livro. A precisão é o inverso da variância e pontua nossa confiança em uma determinada distribuição de probabilidade. Isso está intimamente relacionado à entropia negativa (negentropia) de uma distribuição:\( -H[P(s)]=\mathbb E_{P(x)}[\ln P(s)]\)Uma maneira simples de parametrizar uma distribuição de forma que ela possa ser mais ou menos precisa é usar uma forma de Gibbs com um parâmetro de temperatura inverso (\(omega\)) tem a seguinte forma: \( P(s |\omega )=Cat(\sigma(\omega\ln D))\)Observe que a precisão multiplica o log anterior, para que possa ser interpretado como um dispositivo de controle de ganho (amplificador em vez de adicionar sinais neurais). Os gráficos na figura 7.8 mostram como a distribuição de probabilidade (cada coluna representando a probabilidade de um estado alternativo) muda para um dado D quando variamos ω. Observe o aumento da confiança com o aumento da precisão.\includegraphics{images/Figura_7_8.png}Este tipo de parametrização pode ser aplicado a qualquer uma das distribuições utilizadas em um POMDP. Além disso, podemos definir a priori sobre a precisão e inferir isso da mesma forma que inferimos outras variáveis latentes (ou seja, através da minimização da energia livre). Supondo que o prior tenha uma distribuição Gamma (excluindo valores negativos da precisão), obtemos as seguintes atualizações (consulte o apêndice B para obter detalhes):\(P(\omega)=\ \Gamma(1,\pmb{\beta}_\omega)\)\(Q(\omega)=\Gamma(1,\beta_\omega)\)\(\Longrightarrow\pmb{\dot\beta_\omega}=(\pmb{D}^{\beta_\omega^{-1}}-s)\cdot\ln \pmb{D}+\beta_w-{\pmb{\beta}_w}\)Há um crescente reconhecimento de que o substrato biológico desses parâmetros de precisão podem ser os sistemas neuromoduladores que determinam o ganho das respostas neurais. O Capítulo 5 discute as evidências que relacionam esses parâmetros a neuroquímicos específicos. \\
\bottomrule
\end{longtable}

\begin{figure}
\centering
\includegraphics{images/Figura_7_9.png}
\caption{Figura 7.9 Paradigma de busca visual epistêmica simulada (Parr e Friston 2017b) com o traço sintético de rastreamento ocular sobreposto aos quatro locais de estímulo. Cada estímulo (quadrado sombreado) está associado a uma matriz de transição que pode ser mais ou menos previsível e uma matriz de probabilidade que pode ser mais ou menos ambígua. Esquerda: Quando as transições e probabilidades são igualmente previsíveis para todas as quatro localizações, todas as localizações são amostradas com aproximadamente a mesma frequência. Meio: O visualizador mostra aversão ao quadrado superior esquerdo quando é especificado com um mapeamento de probabilidade menos preciso (mais ambíguo). Direita: O quadrado inferior esquerdo é epistemicamente atraente quando as probabilidades de transição são especificadas como mais incertas.}
\end{figure}

\hypertarget{aprendizado-e-novidade}{%
\section{Aprendizado e Novidade}\label{aprendizado-e-novidade}}

As seções 7.2--7.4 estabelecem tudo o que é necessário para a maioria das aplicações práticas da Inferência Ativa. No entanto, assumimos que o modelo generativo já é conhecido e não muda como efeito da aprendizagem. Em algumas aplicações práticas, podemos querer considerar como uma ou mais partes do modelo generativo (por exemplo, a matriz A ou B) são aprendidas durante um experimento ou, mais amplamente, como otimizamos a estrutura do próprio modelo generativo , dados alguns dados (Friston, FitzGerald et al.~2016). Ao fazer isso, a Inferência Ativa se estende ao aprendizado ativo, e a saliência (equação 7.5) que descreve o ganho de informação sobre os estados é complementada pela novidade, que trata da resolução da incerteza sobre (por exemplo) os elementos da matriz A mostrada na equação 7.1, a matriz B mostrada na equação 7.2, ou quaisquer outros parâmetros do modelo generativo. Essas crenças agora podem variar com o tempo, em vez de serem fixas, como se supunha até agora (Schwartenbeck et al.~2019). Para chegar a isso, primeiro temos que estender o modelo generativo como na Figura 7.10 para incluir crenças sobre esses parâmetros do modelo.

\begin{figure}
\centering
\includegraphics{images/Figura_7_10.png}
\caption{\textbf{Figura 7.10} Esse modelo generativo para aprendizado usa a mesma estrutura POMDP da figura 7.3, mas as prioridades para cada um dos estados ocultos agora dependem de variáveis \hspace{0pt}\hspace{0pt}(em círculos), que agora vêm equipadas com crenças anteriores. Estas têm a forma de distribuições de Dirichlet, que são conjugadas (ver quadro 7.2) às distribuições categóricas consideradas até agora. O modelo mostra como a probabilidade de resultados dados estados agora também depende de uma variável A (que é a mesma para todos os pontos de tempo), as probabilidades de transição agora estão condicionadas a uma variável B, as preferências dependem de C, os estados iniciais dependem em D, e a política de forma fixa a priori depende de E. Ao tornar explícitas as crenças prévias sobre os parâmetros do modelo generativo, essa figura enfatiza que tanto a inferência quanto o aprendizado são processos de minimização de energia livre, mas são distintos. Em suma, a inferência descreve a otimização de crenças sobre o estado do mundo como ele é (s), incluindo crenças sobre a maneira como estamos agindo (π ). Em contraste, a aprendizagem descreve a otimização de crenças sobre as relações entre essas variáveis \hspace{0pt}\hspace{0pt}(A,  B,  C,  D ou E ). As últimas variam muito mais lentamente que as primeiras e só podem ser aprendidas quando os estados foram inferidos. Voltaremos a essa separação de escalas de tempo abaixo quando considerarmos os modelos generativos hierárquicos.}
\end{figure}

Conceitualmente, incluir crenças sobre parâmetros no modelo generativo permite tratar a aprendizagem como outra forma de inferência Bayesiana -- ou seja, como a passagem de crenças anteriores para posteriores sobre parâmetros do modelo. Isso destaca a semelhança fundamental entre percepção e aprendizado: da mesma forma que a percepção pode ser descrita como a inversão de um modelo generativo para inferir estados ocultos a partir de observações, o aprendizado pode ser descrito como a inversão de um modelo generativo para incluir crenças sobre parâmetros ( embora normalmente esta inversão possa operar em uma escala de tempo mais lenta).

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Quadro 7.2 Antecedentes do Conjugado
\end{minipage} \\
\midrule
\endhead
Ao configurar um modelo generativo da forma da figura 7.10, é importante selecionar cuidadosamente a distribuição apropriada para crenças anteriores. Normalmente, esta será a distribuição anterior conjugada associada à probabilidade. Uma crença prévia conjugada significa que, quando usada para realizar inferência Bayesiana, a crença posterior será do mesmo tipo de distribuição. Por exemplo, usando a regra de Bayes:\(P(D|s)\propto P(D) P(s|D)\) Se \(P(s|D)\) é uma distribuição categórica, quando escolhemos uma distribuição de Dirichlet (conjugada para categórica ) para \(P(D)\), podemos garantir que \(P(D|s)\) também é uma distribuição de Dirichlet. Colocando formalmente:\(\begin{matrix}P(D)=Dir(d) \\ P(s|D)=Cat(D)\end{matrix}\bigg \}\Rightarrow P(D|s) = Dir(d)\) \\
\bottomrule
\end{longtable}

A maneira mais simples de escolher o tipo certo de a priori é procurar a priori conjugada para qualquer forma que a distribuição de verossimilhança assuma. Para as distribuições categóricas usadas aqui, uma distribuição de Dirichlet é a escolha apropriada para crenças sobre parâmetros (ver caixa 7.2). Tendo incluído essas crenças anteriores adicionais, podemos agora otimizar as crenças posteriores sobre a estrutura do modelo generativo. Isso significa incorporá-los à energia livre (como fizemos para os estados no capítulo 4) e encontrar os mínimos de energia livre.

\[\begin{equation} 
\theta = (A, B, C,D,E) \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\quad\\ 
F=\mathbb E_{Q(\pi,\theta)}[F(\pi,\theta)]+D_{KL}[Q(\theta)||P(\theta)]+D_{KL}[Q(\pi)||P(\pi)] 
\end{equation} \qquad (7.9)\]
As distribuições de Dirichlet são parametrizadas por contagens (ou pseudocontagens) que indexam o número de vezes que uma determinada variável categórica foi vista (ou, no caso das anteriores, como se tivesse sido vista esse número de vezes). Para a derivação das regras de atualização para esses parâmetros, consulte o apêndice B. Por enquanto, resumimos a regra de atualização e as principais propriedades de uma distribuição de Dirichlet, focando nos parâmetros a e a de concentração associados ao anterior e posterior sobre A.

\[ \begin{equation} \qquad
\pmb{a} = a + \sum_{\tau}\pmb{s}_\tau \otimes\theta_\tau \\
\mathbb E_Q[A_{ij}]=\pmb{A}_{ij} \approx \frac{\pmb{a}_{ij}}{\pmb{a}_{0,j}} \qquad\\
\mathbb E_Q[\ln A_{ij}]= \ln \pmb{A}_{ij}=\psi(\pmb{a}_{ij})-psi(\pmb{a}_{oj})  \qquad (7.10) \\
\pmb{a}_{oj} \triangleq \sum_k \pmb{a}_{kj}
\end{equation}
\]

A primeira linha aqui expressa a atualização dos parâmetros de concentração anteriores para posteriores seguindo uma série de observações, com crenças sobre os estados que os causaram. A cruz no círculo indica um produto tensorial de Kronecker (ou produto externo no caso de dois vetores), aqui dando origem a uma matriz em que cada elemento é o produto de um par de elementos em \(o_\tau\) e \(\pmb{s}_\tau\) . Esta regra de atualização pode ser interpretada simplesmente como uma forma de plasticidade dependente da atividade. Quando um resultado é observado em combinação com uma crença posterior de que um determinado estado o causou, o elemento da matriz que representa a relação entre os dois é incrementado.

A segunda linha da equação destaca a interpretação dos parâmetros de concentração de Dirichlet em termos de contagens. Para um determinado estado (coluna), cada elemento de a é o número de vezes que o resultado correspondente foi visto. Dividindo pela soma dos elementos na coluna (número total de observações ou pseudo-observações) dá a probabilidade de cada resultado dado aquele estado. Para entender por que esse (pseudo) método de contagem faz sentido intuitivo, considere o exemplo do músico amador do início deste capítulo. Se contarmos quantas vezes o músico toca a primeira nota quando pretende fazê-lo (primeira linha e coluna), quantas vezes ele toca a segunda nota quando pretende fazê-lo (segunda linha e coluna), e assim por diante, e dividi-los pelo número total de vezes que ela pretende cada nota, um acabará por convergir para os valores numéricos corretos da matriz A mostrada na equação 7.1 - ou seja, que o músico atinge todas as notas pretendidas 70\% das vezes. O método de contagem tem outra consequência importante à qual retornaremos: o número de contagens ou pseudocontagens que precedem uma observação nos diz a probabilidade de atualizarmos nossas crenças ao fazer a observação. Imagine jogar uma moeda cinco vezes e obter cinco caras seguidas. Isso pode nos levar a atualizar nossas crenças para favorecer a hipótese de que esta é uma moeda injusta. No entanto, se isso tivesse sido precedido por 100 lançamentos com 50 caras e 50 coroas, as cinco caras finais fariam pouco para influenciar nossas crenças sobre se esta é uma moeda justa. A terceira linha da equação 7.10 mostra uma identidade útil associada às distribuições de Dirichlet: o logaritmo esperado da variável aleatória é dado pela diferença em duas funções digamma (derivada de uma função gama).

A abordagem inferencial ao aprendizado destaca uma diferença importante entre a Inferência Ativa e a maioria das outras abordagens de neurociência computacional e aprendizado de máquina, que incorporam várias regras de aprendizado (por exemplo, regras Hebbianas ou retropropagação de erros) que são consideradas biologicamente realista ou computacionalmente eficiente. Na Inferência Ativa, as regras de atualização que governam o aprendizado são derivadas de considerações estatísticas, mas acabam sendo notavelmente semelhantes às regras biologicamente motivadas para plasticidade dependente de atividade (veja as considerações acima na primeira linha da equação 7.10). Isso exemplifica um dos apelos das abordagens normativas, que partem dos primeiros princípios para explicar o que sabemos sobre cérebros e comportamento -- e coisas que não sabíamos.

Outra diferença entre a Inferência Ativa e a maioria das abordagens de aprendizado de máquina é que o aprendizado é naturalmente descrito como um processo ativo, no qual as criaturas selecionam de forma autônoma os dados mais apropriados para melhorar seus modelos generativos. Isso fica evidente se considerarmos que ao incluir crenças sobre parâmetros no modelo, a energia livre esperada adquire um termo adicional:

\[
\begin{equation}
G(\pi)= \begin{matrix}\underbrace{D_{KL}[Q(\tilde o|\pi)||P(\tilde o|C)]} \\ Risco \end{matrix}+ 
\begin{matrix}\underbrace{\mathbb E_{Q(\tilde s|\pi)}[H[P(\tilde o|\tilde s)]] } \\ Ambiguidade \end{matrix} \\
\begin{matrix}\underbrace{+ \mathbb E_{\tilde Q(\tilde o,\tilde s, \tilde \theta | \pi )}[\ln Q(\theta) - \ln P(\theta)|\tilde o, \tilde s) ] } \\ Parâmetro \;de\; Ganho\;de\;informação \end{matrix} \\
\begin{matrix}\underbrace{= - \mathbb E_{Q(\tilde o, \tilde s| \pi)}[D_{KL}[Q(\tilde s|\pi,\tilde o)||Q(\tilde s| \pi )]] } \\ Saliência \end{matrix} \\
\begin{matrix}\underbrace{- \mathbb E_{Q(\tilde o,\tilde  s|\pi)}[D_{KL}[Q(\theta|\tilde o,\tilde s)|| Q(\theta )]] } \\ novidade \end{matrix} -
\begin{matrix}\underbrace{\mathbb E_{Q(\tilde o |\pi)}[\ln P(\tilde o|C)] } \\ Valor\;pragmático \end{matrix} 
\end{equation}
\]
Os termos de saliência e valor pragmático já existiam na equação 7.4, mas o termo novidade é novo. A igualdade final aqui mostra um arranjo que destaca a relação entre saliência e novidade. Em suma, a saliência é inferir o que a novidade é para a aprendizagem. Ambos são expressões da mudança nas crenças antecipadas uma vez que um experimento perceptual (ou seja, uma ação em uma política) é realizado. Tal como acontece com os experimentos científicos, quanto maior a mudança nas crenças após a coleta de dados, melhor o experimento. Voltando à analogia de jogar uma moeda e acumular contagens, isso nos diz algo útil. Se tivermos duas moedas e pudermos jogar qualquer uma delas, podemos provocar a maior mudança nas crenças jogando a moeda que havíamos lançado apenas cinco vezes antes, em vez da moeda com 100 jogadas anteriores. Há uma maior novidade associada ao lançamento da moeda anterior (menos familiar). Da mesma forma, se tivermos crenças anteriores confiantes como se tivéssemos observado algo muitas vezes, as políticas que questionam essas variáveis \hspace{0pt}\hspace{0pt}estão associadas a menos novidade do que aquelas sobre as quais temos crenças menos confiantes.

Para ilustrar como isso funciona na prática, imagine que temos uma criatura muito míope de pé sobre um piso de ladrilhos. Esta criatura só pode ver a cor do ladrilho em que está e só pode mover um ladrilho de cada vez. Para qualquer paisagem adequadamente grande com muitos ladrilhos, é computacionalmente muito caro representar a cor de cada ladrilho como um estado oculto diferente. No entanto, uma forma mais simples de modelo está disponível. Se associarmos estados ocultos apenas com localização e cores apenas com resultados, podemos representar com eficiência crenças sobre ``o que eu veria se fosse até lá'' na matriz A que gera ladrilhos coloridos a partir de locais. Ao acumular parâmetros de Dirichlet (equação 7.10), nossa criatura pode otimizar essas crenças com base em observações. Podemos interpretar isso como uma forma de memória sináptica em oposição à manutenção da atividade persistente em neurônios que representam crenças sobre a cor de um determinado azulejo. Dado esse tipo de modelo generativo, em que toda a incerteza está nos parâmetros da distribuição de verossimilhança, é interessante ver o que acontece na ausência de quaisquer preferências (ou seja, quando o termo novidade da equação 7.11 domina a seleção de políticas). A Figura 7.11 mostra uma simulação de um ambiente simples composto por 64 ladrilhos pretos ou brancos. À medida que cada ladrilho é visitado, as crenças sobre a probabilidade de observar preto ou branco naquele local são atualizadas através do acúmulo de parâmetros de Dirichlet. Como grandes parâmetros de Dirichlet impedem grandes atualizações de crenças, o impulso para a resolução de novidade dada pela minimização de energia livre esperada leva nossa criatura simulada a evitar quaisquer locais visitados anteriormente.

Os mesmos princípios podem ser aplicados a uma série de outros paradigmas (por exemplo, se reinterpretarmos o caminho percorrido por nossa criatura como um caminho de varredura sacádica, isso pode ser aplicado à amostragem visual ativa). No domínio da visão ativa, isso foi usado para simular os tipos de comportamento de busca visual induzidos por tarefas de cancelamento de alvo (Parr e Friston 2017a). Posteriormente, foram demonstradas evidências da plasticidade de curto prazo necessária para acumular parâmetros de Dirichlet nesse cenário (Parr, Mirza et al.~2019).

Assim como podemos estender ideias sobre inferência para aprendizado, é possível ir (pelo menos) um passo adiante e pensar em aprendizado de estrutura: o processo de não apenas otimizar os parâmetros no modelo, mas selecionar entre diferentes modelos com mais ou menos parâmetros em jogo. O Quadro 7.3 apresenta uma maneira de fazer isso que envolve comparações post hoc eficientes de modelos hipotéticos alternativos. Isso tem sido usado como uma metáfora para o sono (Friston, Lin et al.~2017) e atividade espontânea em repouso (Pezzulo, Zorzi e Corbetta 2020), onde não são coletados novos dados, mas a estrutura do modelo ainda pode ser refinada e simplificada .

\begin{figure}
\centering
\includegraphics{images/Figura_7_11.png}
\caption{\textbf{Figura 7.11} A aprendizagem ativa é demonstrada por uma criatura sintética explorando um mundo simples de azulejos pretos e brancos (Bruineberg et al.~2018, Kaplan e Friston 2018). Esquerda: Caminho percorrido pela criatura, mostrando quais peças são brancas e quais são pretas (os pontos correspondem aos locais visitados). Direita: Uma matriz da criatura e as crenças (em termos de contagens de Dirichlet normalizadas) que a criatura tem sobre o que veria indo para locais diferentes. As células na matriz A são brancas (ou pretas) se a criatura acredita fortemente que a peça correspondente é branca (ou preta); eles são cinzas se a criatura não tiver certeza sobre a cor. Crucialmente, essas crenças influenciam o caminho que ele toma por meio do termo novidade da energia livre esperada. Aqueles locais sobre os quais ele tem crenças confiantes oferecem relativamente poucas oportunidades para a resolução de incertezas, então ele não os revisita. Em outras palavras, o fenômeno da ``inibição do retorno'' (Posner et al.~1985) surge naturalmente da minimização da energia livre esperada.}
\end{figure}

\hypertarget{inferuxeancia-hieruxe1rquica-ou-profunda}{%
\section{Inferência Hierárquica ou Profunda}\label{inferuxeancia-hieruxe1rquica-ou-profunda}}

Na seção anterior, vimos um método para extensão hierárquica do modelo generativo original baseado na definição de priors sobre os parâmetros do modelo generativo. A Figura 7.12 mostra uma segunda forma de hierarquia que se refere ao aninhamento de escalas temporais. Este modelo generativo para inferência hierárquica ou profunda pode ser concebido como uma extensão hierárquica do modelo raso mostrado na figura 7.3: inclui uma série de modelos POMDP no nível inferior que são os mesmos da Figura 7.3 (um exemplo é delineado com a caixa tracejada), contextualizada por um POMDP de nível superior.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Quadro 7.3} Aprendizado de estrutura e redução de modelo
\end{minipage} \\
\midrule
\endhead
A discussão na seção 7.4 trata de uma forma importante, mas limitada, de aprendizado (paramétrico). O próximo nível de sofisticação -- aprender sobre a estrutura do mundo -- vai além da otimização dos parâmetros do modelo e pergunta se devemos expandir ou podar a estrutura do modelo. Isso pode ser colocado como uma questão de comparação de modelos (Friston, Lin et al.~2017). Em outras palavras, minha energia livre aumentaria ou diminuiria se eu (por exemplo) eliminasse elementos de uma matriz de probabilidade? Ao comparar modelos com e sem esses elementos, podemos responder a essa pergunta. No entanto, pode ser muito caro ter que inverter explicitamente vários modelos. Felizmente, um método eficiente para fazer isso - conhecido como redução do modelo bayesiano (Friston, Litvak et al.~2016; Friston, Parr e Zeidman 2018) - está disponível e requer apenas a inversão de um único modelo completo. Em um cenário geral, a comparação entre um modelo completo e um com anteriores alternativos (indicado por \textasciitilde) pode ser alcançada através das seguintes fórmulas:\(\begin{equation} \Delta F = F[P(\theta)]-F[P(\theta)]=\ln \mathbb E_{Q(\theta)}\Big [\frac{P(\theta)}{\tilde P(\theta)}\Big] \\ \tilde Q(\theta) \propto exp(\ln Q(\theta)+\ln \tilde P(\theta)) - \ln P(\theta)) +\Delta F) \end{equation}\)Para os priors de Dirichlet usados na seção 7.5, isso assume a forma (onde B é a função beta multivariada):\(\begin{equation} \Delta F = \ln B(\tilde d)- \ln B(d) + \ln B(\pmb d)-\ln B(\tilde {\pmb d}) \\ \pmb {\tilde d}=\pmb d+\tilde d-d \end{equation}\)Essa forma de redução do modelo pode ser importante para entender a otimização do modelo offline, do tipo que pode ocorrer durante o sono. Revisitaremos brevemente a redução do modelo bayesiano no capítulo 8, ao considerar a otimização de modelos hierárquicos com componentes discretos e contínuos. \\
\bottomrule
\end{longtable}

É importante ressaltar que esse modelo generativo inclui variáveis que evoluem em diferentes escalas de tempo: mais lento para níveis mais altos e mais rápido para níveis mais baixos (Friston 2008; Friston, Rosch et al.~2017; Pezzulo, Rigoli e Friston 2018). Isso fica evidente se considerarmos que os modelos POMDP no nível 1 evoluem ao longo de três etapas de tempo, mas cada uma dessas curtas trajetórias de estados e resultados depende de um único estado no nível superior (nível 2) que persiste ao longo de toda a trajetória no nível nível mais baixo. Em outras palavras, para cada passo de tempo da perspectiva do nível superior, existem vários (aqui, três) passos de tempo para o nível inferior.

Para obter alguma intuição para essa separação de escalas de tempo -- que subscreve uma profunda inferência temporal -- vale a pena pensar em um exemplo simples de hierarquia na vida cotidiana: a leitura. Fazemos inferências sobre palavras que se combinam para formar frases. As frases se combinam para formar parágrafos, páginas, livros, bibliotecas e assim por diante. Se imaginarmos que cada estado no nível inferior da figura 7.12 é uma palavra, cada estado no nível superior pode ser pensado como uma sentença. Crucialmente, a duração da frase transcende a de qualquer palavra na sequência.

\begin{figure}
\centering
\includegraphics{images/Figura_7_12.png}
\caption{\textbf{Figura 7.12} Podemos estender o modelo generativo (superficial) apresentado na Figura 7.3 para que ele permita inferência hierárquica ou profunda, que evolui em várias escalas de tempo. O modelo generativo completo inclui um contexto de mudança lenta (no nível 2) que gera uma série de trajetórias curtas no nível 1 inferior e mais rápido. A forma do POMDP é a mesma no nível superior e no nível inferior (um dos POMDPs é delineado com a caixa tracejada). A única diferença é que ele se estende no tempo (horizontal) e que os resultados que gera não são observados diretamente. Em vez disso, eles formam priores empíricos para o nível inferior, o que gera resultados observáveis.}
\end{figure}

O exemplo de leitura é ilustrado com mais detalhes na figura 7.13, que é baseada no exemplo de Friston, Rosch et al.~(2017), ao qual nos referimos para mais detalhes. O modelo está estruturado como na figura 7.12 e representa frases (no nível superior) e palavras (no nível inferior) extraídas de uma linguagem muito simples. Esta linguagem compreende três palavras possíveis ( fugir, alimentar, esperar) que podem ser organizadas em seis possíveis frases de quatro palavras. Se a frase for ``fuja, espere, alimente, espere'', o nível mais alto prevê a palavra fugir para o primeiro dos POMDPs de nível inferior, aguarde o segundo e assim por diante. No nível inferior, começamos com uma prévia empírica (D) baseada no nível superior, que nos diz quais palavras são mais plausíveis. Por exemplo, se começamos com uma distribuição uniforme sobre as sentenças mostradas no painel superior da figura 7.13, vemos que a primeira palavra é esperar em dois terços das sentenças e fugir no outro terço. Isso significa que na primeira etapa de tempo do primeiro POMDP de baixo nível, nosso vetor D deve atribuir essas probabilidades a essas palavras.

As palavras no nível inferior geram observações, entradas visuais com base em qual parte da palavra está atualmente . Assim como no exemplo da figura 7.9, o POMDP permite a seleção de diferentes alvos foveais para acumular evidências a favor ou contra cada palavra hipotética. Isso apela para os mesmos processos de minimização de energia livre esperados descritos acima; portanto, não detalharemos as específicas feitas aqui, mas notamos que a cada passo de tempo no nível inferior, há um aumento na confiança sobre a palavra em jogo. Na sequência mostrada na figura 7.13, vemos que a evidência é acumulada para a palavra fugir no nível inferior ao longo dos primeiros passos de tempo (na escala rápida, τ (1)). Essa inferência é propagada de volta ao nível superior, onde fornece evidências para a primeira e a quarta sentenças (cada uma das quais começa com essa palavra). Ao longo das etapas de tempo subsequentes, a evidência acumulada no nível inferior é consistente com ambas as sentenças. No quarto passo (na escala lenta, τ (2)), prevemos esperar na primeira sentença e fugir na segunda. Ao inferir espera na escala de tempo rápida, a primeira sentença é inferida na escala lenta. Na etapa final, a simulação seleciona a frase correta e é recompensada com o feedback correto. A atualização de crença resultante é vista no gráfico LFP na parte inferior da figura 7.12.

\begin{figure}
\centering
\includegraphics{images/Figura_7_13.png}
\caption{Figura 7.13 A atualização de crenças ocorre em várias escalas de tempo invertendo um modelo de inferência hierárquica simulado. Isso se baseia em um modelo generativo com uma separação de escalas de tempo (mostrada como uma escala de tempo lenta---τ    (2)---e uma escala de tempo rápida---τ (1)). A atualização de crenças no nível superior (s(2) ), representando sentenças, é mais lenta do que no nível inferior (s(1)), representando palavras. Painel inferior: LFPs, ou seja, a taxa de mudança das expectativas de log - que é proporcional aos erros de previsão (ε ) mostrados nas figuras anteriores.}
\end{figure}

Modelos temporais profundos desse tipo foram usados para simular leitura (Friston, Rosch et al.~2017), tarefas de memória de trabalho de período de atraso (Parr e Friston 2017c) e cálculo de priors empíricos para inferência visual (Parr, Benrimoh et al.~2018). Além disso, eles foram alavancados em explicações teóricas de motivação e controle (Pezzulo, Rigoli e Friston 2018). Em princípio, esses modelos podem ser estendidos a um número arbitrário de níveis, representando um mundo profundamente estruturado com dinâmicas que se desenrolam em muitas escalas temporais diferentes.

Podemos traçar um paralelo interessante entre os modelos hierárquicos do tipo das figuras 7.12 e 7.13 e os modelos de aprendizagem do tipo da figura 7.10. Modelos de aprendizagem podem ser considerados modelos generativos hierárquicos, que destacam uma separação de escalas de tempo entre dinâmicas inferenciais mais rápidas (atualizações de crenças sobre estados) e dinâmicas de aprendizagem mais lentas (atualizações de crenças sobre parâmetros). Os modelos mostrados nas figuras 7.10 e 7.12 também podem ser combinados a níveis arbitrários de complexidade, onde as próprias relações entre variáveis em diferentes níveis podem ser aprendidas. Isso permite projetar modelos generativos cada vez mais sofisticados que abordam questões cognitivas e neurobiológicas em nível de sistema.

\hypertarget{resumo-6}{%
\section{Resumo}\label{resumo-6}}

Neste capítulo, vimos algumas das maneiras pelas quais os modelos generativos de tempo discreto podem ser construídos para abordar uma série de problemas cognitivos e neurobiológicos, como inferência perceptual, tomada de decisão e planejamento, exploração e exploração de equilíbrio, aprendizado paramétrico e de estrutura , e busca de novidades. Isso está longe de ser um resumo exaustivo das aplicações de modelos discretos em Inferência Ativa, mas serve para ilustrar os princípios-chave desse tipo de modelagem. Os modelos descritos acima podem ser combinados hierarquicamente, com priorização adicionada sobre parâmetros e com priorização sensível ao contexto para políticas ou preferências. É importante ressaltar que a inferência usando modelos generativos simples e mais complexos sempre pode proceder através da minimização da energia livre, o que ilustra a generalidade da abordagem. O fato de que diferentes aspectos da Inferência Ativa se tornam aparentes sob modelos generativos distintos (por exemplo, busca de novidades com prioris sobre os parâmetros do modelo) abre a possibilidade de explorar um conjunto aberto de problemas cognitivos e biológicos projetando os modelos generativos apropriados.

\hypertarget{inferuxeancia-ativa-em-tempo-contuxednuo-1}{%
\chapter{Inferência ativa em tempo contínuo}\label{inferuxeancia-ativa-em-tempo-contuxednuo-1}}

Tudo flui, nada fica parado. ---Heráclito, 501 aC

\hypertarget{introduuxe7uxe3o-7}{%
\section{Introdução}\label{introduuxe7uxe3o-7}}

Este capítulo complementa o capítulo 7, continuando nossa discussão sobre como construir um modelo generativo. Nosso foco aqui é em modelos de espaço de estados contínuos, que são bem adequados para modelar as flutuações físicas que atingem os receptores sensoriais e para o movimento contínuo dos efetores (por exemplo, músculos) que usamos para mudar o mundo ao nosso redor. Existem muitas aplicações desses modelos. Neste capítulo, definimos os princípios por trás de seu uso. Destacamos os tipos de modelos usados no controle motor e os sistemas dinâmicos que desempenham um papel em tais modelos, e tocamos no conceito de sincronia generalizada. Finalmente, discutimos a reconciliação de modelos generativos discretos e contínuos.

\hypertarget{controles-de-movimento}{%
\section{Controles de movimento}\label{controles-de-movimento}}

Como vimos no capítulo 4, o modelo generativo que subscreve a inferência ativa em tempo contínuo pode ser escrito como um par de equações estocásticas que determinam como os estados \((x)\) geram dados \((y)\) e como os estados evoluem ao longo do tempo dependendo de alguma variável estática \((\nu)\):

\[\begin{equation} 
y=g(x)+\omega_y \qquad\qquad\qquad\qquad\quad\quad\quad  \\ 
\dot x = f(x,\nu) + \omega_x \qquad\qquad\qquad\qquad (8.1)
\end{equation}\]

Essas equações e a precisão associada às flutuações \((\omega)\) determinam o modelo utilizado para fazer inferências sobre as causas das sensações.
Observe que a ação está ausente da equação 8.1. Isso ocorre porque (como descrito no capítulo 6), a ação é parte do processo generativo, não do modelo generativo. O modelo generativo lida apenas com aquelas variáveis que são diretamente influenciadas por estados externos a um envoltório de Markov. Se fôssemos escrever a dinâmica do mundo real (ou seja, o processo generativo), teríamos que incluir a ação \((u)\):

\[\begin{equation} 
y=\pmb g(x)+\omega_y \qquad\qquad\qquad\qquad\quad\quad\quad  \\ 
\dot x =\pmb f(x,u) + \omega_x \qquad\qquad\qquad\qquad (8.2)
\end{equation}\]

Observe que as funções \(g\) e \(f\) (e as precisões de \$\omega \$) usadas para definir o modelo gerativo (equação 8.1) não são necessariamente as mesmas usadas para definir o processo gerativo (equação 8.2). Como vimos nos capítulos 2 a 4, as ações alteram os dados sensoriais de modo que a energia livre é minimizada. Isso significa que não precisamos escrever explicitamente a dinâmica da ação no modelo generativo -- elas emergem das escolhas feitas para os termos da equação 8.1. Para obter alguma intuição para isso, começamos com um tipo muito simples de modelo generativo:

\[\begin{equation} 
g(x) = x \qquad\qquad\qquad\qquad\quad\quad\quad  \\ 
f(x,\nu) = \nu - x \qquad\qquad\qquad\qquad (8.3)
\end{equation}\]

A Equação 8.3 diz que o estado oculto representa o valor esperado para os dados e que tem uma dinâmica consistente com um atrator simples (ou seja, ponto). Por atrator, queremos dizer que quando x é menor que v, a taxa de variação esperada de x é positiva e vice-versa. Isso significa que x sempre fluirá em direção a v (ou seja, v é um ponto de atração ou fixo). Para gerar dados, definimos um simples processo gerador:

\[\begin{equation} 
\pmb g(x) = x \qquad\qquad\qquad\qquad\quad\quad\quad  \\ 
\pmb f(x,u) = u \qquad\qquad\qquad\qquad (8.4)
\end{equation}\]

Ao minimizar a energia livre, isso significa que a ação mudará para cumprir as previsões da equação 8.3. Se \(\mu\) for o valor esperado de \(x\), isso significa que a ação que minimiza a diferença entre os dados previstos \((g(\mu))\) e os dados observados \((y)\) é igualar \(u\) a \(\nu − \mu\). Esta é uma expressão da ``hipótese do ponto de equilíbrio'' (Feldman e Levin 2009), que trata o controle motor como encenado por arcos reflexos que simplesmente atraem os membros em direção a pontos de equilíbrio definidos por sinais motores descendentes. Na Inferência Ativa, esses sinais são previsões -- especificamente, previsões proprioceptivas sobre, por exemplo, a posição esperada de membros ou olhos (Adams, Shipp e riston 2013). Portanto, o controle do movimento resulta do cumprimento de previsões (proprioceptivas) pela ação, conforme ilustrado esquematicamente na figura 8.1. Observe que este esquema não requer a especificação de ``modelos inversos'' (ou seja, mapeamentos de consequências desejadas para os comandos motores para alcançá-los) que são amplamente utilizados em outras formulações de controle motor (Wolpert e Kawato 1998).

A expressão na equação 8.3 é o tipo mais simples de sistema atrator que podemos empregar em um modelo generativo. No entanto, é muito simples em muitos cenários, onde se aplicam dinâmicas newtonianas mais realistas. Um modelo mais sofisticado reconhece que as forças -- geradas pelos músculos -- alteram a velocidade (ou seja, induzem uma aceleração), não a posição. A Equação 8.5 estabelece isso explicitamente com \(x_1\) como a posição e \(x_2\) como a velocidade:

\[\begin{equation} 
f(x, \nu) = \begin{bmatrix}  x_2\\ \frac{\kappa}{m}(\nu-x_1) \end{bmatrix} \qquad\qquad\qquad\qquad (8.5)
\end{equation}\]

Esta expressão é equivalente à dinâmica de uma mola obedecendo à lei de Hooke. A taxa de mudança da posição (primeiro elemento) é simplesmente a velocidade. A taxa de variação da velocidade (segundo elemento) é proporcional à distância entre a posição atual e o ponto \(\nu\), com a constante de proporcionalidade: uma razão entre a massa do objeto \((m)\) e uma constante (mola) \((\kappa)\) ). Multiplicando ambos os lados pela massa, temos a força\footnote{Muitas vezes é necessário adicionar termos de amortecimento para levar em conta o atrito e/ou viscosidade para evitar soluções oscilatórias.} gerada por uma mola \((κ (\nu − x_1))\) presa aos pontos \(\nu\) e \(x_1\) igual à massa multiplicada pela taxa de variação da velocidade. Esta é apenas a segunda lei de Newton. Em outras palavras, podemos escrever um modelo generativo que prevê a dinâmica que se desenrolaria se houvesse uma mola puxando um membro para um local desejado. Ao prever os dados (proprioceptivos) decorrentes dessa mecânica newtoniana, podemos decretar o movimento que cumpre essas previsões.

\hypertarget{sistemas-dinuxe2micos}{%
\section{Sistemas Dinâmicos}\label{sistemas-dinuxe2micos}}

Conforme descrito na seção 8.2, as formulações de tempo contínuo da Inferência Ativa são bem adequadas à caracterização de movimentos. Mais geralmente, eles são apropriados na especificação de modelos generativos de sistemas dinâmicos não lineares em que a discretização de tempo e espaço é ineficiente. A forma mais simples de sistema dinâmico é o atrator da equação 8.3, mas um comportamento muito mais rico pode ser desenvolvido a partir de sistemas mais complexos. No espaço limitado deste livro, não podemos fazer justiça ao grande corpo de trabalho desenvolvendo modelos com sistemas dinâmicos mais complexos (mas veja a tabela 8.1 para alguns dos principais avanços). Em vez disso, nos concentramos em alguns dos princípios necessários para entender esses sistemas. Nesta seção, apresentamos brevemente dois sistemas dinâmicos usados \hspace{0pt}\hspace{0pt}na formulação de modelos generativos desse tipo: a dinâmica de Lotka-Volterra e os sistemas de Lorenz. Os primeiros podem ser utilizados na caracterização de sistemas com aspecto sequencial à sua dinâmica, enquanto os segundos representam sistemas caóticos.

\begin{figure}
\centering
\includegraphics{images/Figura_8_1.png}
\caption{\textbf{Figura 8.1} Reflexos espinhais, ilustrando a distinção entre um processo generativo (lá fora no mundo) e um modelo generativo no cenário de geração de ação. O modelo assume que a posição \((x)\) de um membro (ou mão ou outra parte do corpo) é traçada em direção a algum ponto \((\nu)\). A seta tracejada no gráfico superior mostra essa crença. Crenças sobre \(x(\mu_x)\) podem ser substituídas no lugar de \(x\) e usadas para atualizar crenças sobre sua taxa de mudança. O \(\mu_x\) resultante é então usado para prever dados sensoriais \((y)\) por meio da função \(g\) no modelo generativo. Os dados sensoriais são realmente gerados pelo processo generativo por meio da função \(g\), que recebe o valor ``real'' de \(x\) como argumento. O erro \((\epsilon_y)\) então conduz mudanças na ação \((u)\) de modo que o erro seja resolvido. Essa resolução acontece através do modelo generativo, pois a ação determina a taxa de variação de \(x\) via \(\pmb f\). Isso faz com que \(x\) se mova para o local no espaço que gera dados \(y\) consistentes com a previsão \((g(\mu_x))\), definindo \(\epsilon_y\) e, portanto, a taxa de mudança de \(a\) para zero.}
\end{figure}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Quadro 8.1} Precisão, atenção e atenuação sensorial
\end{minipage} \\
\midrule
\endhead
Abordamos a importância da precisão no capítulo 7, mas vale a pena recapitular seu papel em sistemas de tempo contínuo. De muitas maneiras, esse conceito é abordado de forma mais natural nesse cenário, pois a variável \(\Pi\) aparece como uma consequência direta da aproximação de Laplace. Isso atua diretamente como um ganho multiplicativo na dinâmica inferencial (ver figura 8.1), com diferentes precisões ponderando influências alternativas sobre a atualização de crenças.\( \) A interpretação da precisão como ganho sináptico a conecta a vários aspectos importantes da neurobiologia. De um ponto de vista empírico, uma precisão mais alta implica uma atualização de crença mais vigorosa do tipo que pode ser medido em pesquisas eletrofisiológicas como uma resposta evocada de grande amplitude com um pico precoce ou em gravações de célula única como um efeito multiplicativo nas taxas de disparo neuronal em resposta a um estímulo colocado no campo receptivo dessa célula. Esses achados são frequentemente associados ao processamento atencional, onde um canal sensorial (ou subconjunto de canais) é favorecido em relação aos outros. Do ponto de vista da inferência ativa, precisão e atenção são sinônimos. O primeiro tem sido usado para reproduzir uma série de fenômenos atencionais in silico, incluindo o paradigma de Posner (Feldman e Friston 2010). Especificamente, usar uma sugestão para prever a precisão da entrada sensorial de um dos dois locais reproduz a descoberta empírica de que as respostas aos estímulos no local indicado são mais rápidas do que aquelas que aparecem no local alternativo.\( \) Um segundo aspecto importante do controle de precisão é seu papel na geração de movimento. Para entender isso, vale pensar no que acontece na ausência desse controle. Imagine, primeiro, que os dados sensoriais sejam previstos com alta precisão. As mensagens desses dados, portanto, têm alto ganho sináptico e levam a inferências verídicas sobre a posição de alguma parte do corpo. O problema com isso é a equivalência entre comandos motores e previsões sob Inferência Ativa. Uma crença precisa de que ``não estou me movendo'' não pode ser usada para prever as consequências sensoriais do movimento, vitais para o início desse movimento. Com entrada sensorial de alta precisão, a crença de que ``estou me movendo'' é imediatamente corrigida diante de evidências em contrário; portanto, nenhum movimento é executado. Isso nos diz algo importante: para gerar movimento, devemos ser capazes de ignorar as consequências sensoriais desse movimento para formar a crença (inicialmente falsa) de que ``estou me movendo''. Uma vez estabelecida essa crença, as consequências proprioceptivas (e outras sensoriais) desse movimento podem ser previstas e encenadas por meio dos mecanismos descritos na figura 8.1. Esse processo de ignorar evidências em contrário é conhecido como ``atenuação sensorial'' e representa a diminuição da precisão necessária para que um movimento ocorra (Brown, Adams et al.~2013; Pezzulo 2013; Set 2013; Pezzulo, Rigoli e Friston 2015; Seth e Friston 2016; Allen et ai. 2019).\( \) Claramente, é útil entre os movimentos restaurar essa precisão, tirar as inferências apropriadas da entrada sensorial. Isso implica um processo cíclico de atenuação e movimento (por exemplo, a supressão cíclica da entrada visual durante as sacadas, depois uma supressão das sacadas). Predizer o movimento na suspensão da atenção tem estreitas relações com uma teoria ideomotora que se originou no século XIX para explicar os movimentos induzidos sob hipnose. \\
\bottomrule
\end{longtable}

A dinâmica de Lotka-Volterra é herdada das caracterizações da dinâmica predador-presa em ecologia. Embora desde então tenham encontrado aplicação em várias disciplinas, os sistemas predador-presa continuam sendo um exemplo útil para fornecer alguma intuição sobre seu funcionamento. Quando a população de predadores é pequena, a presa pode aumentar seu número para se tornar uma população relativamente grande. Isso fornece comida adicional para os predadores, cujo tamanho da população cresce. O aumento da predação causa uma diminuição no número de espécies de presas e, portanto, uma diminuição no número de predadores. A partir daqui, o ciclo continua. Isso fornece um padrão oscilatório em que o tamanho da população de presas atinge o pico, depois os predadores, depois as presas novamente e assim por diante. Ao generalizar isso para mais de duas populações (por exemplo, populações carnívoras, herbívoras e vegetais), podemos gerar uma sequência de picos. A Figura 8.2 ilustra a dinâmica generalizada de Lotka-Volterra com três populações, que obedecem a dinâmicas da seguinte forma:

\[ f(x,\nu)= x \circ (\nu + \pmb Ax) \qquad \qquad \qquad \qquad (8.6) \]

Aqui, \(x\) é um vetor como antes. O símbolo \(\circ\) significa um produto elementar. As taxas intrínsecas de natalidade e mortalidade são dadas pelo vetor \(\nu\), e \(A\) é uma matriz cujos elementos são positivos se as espécies indexadas pela coluna predam aquelas indexadas pela linha e negativas se a relação for invertida.

\begin{figure}
\centering
\includegraphics{images/Figura_8_2.png}
\caption{Figura 8.2 Dinâmica sequencial generalizada que emerge dos sistemas Lotka-Volterra fornece um importante ponto de conexão com a dinâmica sequencial discreta assumida no capítulo 7. Essa dinâmica pode ser aplicada a uma variedade de sistemas, mas são enquadradas aqui em termos de relações predador-presa para facilitar de interpretação. Acima: A população muda ao longo do tempo. O tamanho da população é expresso em termos de unidades arbitrárias (a.u.). Os picos são rotulados com base em qual espécie tem a maior população naquele ponto. O padrão repetido de p, h, c pode ser visto como uma sequência de três passos de tempo discretos (não necessariamente uniformemente espaçados). Abaixo: Trajetórias enfatizando o padrão (aproximadamente) periódico que cada uma segue.}
\end{figure}

A Figura 8.2 deixa claro que ter um modelo generativo que incorpore a dinâmica Lotka-Volterra permite o sequenciamento temporal (Huerta e Rabino vich 2004) -- dependendo do pico mais alto atual. Cada linha pode ser pensada como representando um estado oculto, no lugar de uma espécie. A Figura 8.3 destaca dois exemplos importantes em que essas dinâmicas foram exploradas para gerar comportamento Um é um modelo hierárquico que usa a dinâmica sequencial oferecida por um sistema Lotka-Volterra para cronometrar a resposta de um piscar de olhos em relação a um estímulo condicionado (Friston e Herreros 2016). O paradigma é baseado naqueles usados na investigação da função cerebelar. Um estímulo incondicionado (um sopro de ar direcionado para o olho de um animal) provoca uma resposta (piscando).

\begin{figure}
\centering
\includegraphics{images/Figura_8_3.png}
\caption{Figura 8.3 Duas aplicações da dinâmica sequencial generalizada de Lotka-Volterra na Inferência Ativa. Esquerda: Condicionamento de piscar de olhos usado para investigar empiricamente a função cerebelar (Friston e Herreros 2016). Começando no nível mais alto da coluna, os estados esperados mostram o mesmo tipo de padrão sequencial da figura 8.2. Isso passa para o próximo nível para prever causas ocultas sequenciais; os vários picos aqui predizem estados no próximo nível abaixo, onde o primeiro pico é o estímulo condicionado (CS) e o segundo é o estímulo incondicionado (US). Finalmente, os EUA previstos induzem à ação -- um piscar de olhos. Direita: Picos sequenciais usando um ponto de atração como na equação 8.5, mas selecionando o atrator específico com base em qual população de um sistema Lotka-Volterra é atualmente mais alta; isso leva a uma visita sequencial de cada ponto, dando origem a uma forma de escrita à mão (Friston, Mattout e Kilner 2011).}
\end{figure}

Um estímulo condicionado (um tom auditivo) pode ser reproduzido antes do estímulo incondicionado em várias ocasiões. Aprendendo (veja o quadro 8.2) o número de picos na dinâmica de Lotka-Volterra que separa o estímulo condicionado do estímulo incondicionado, o animal aprende a antecipar o sopro de ar e cronometrar o piscar apropriado. Esta é uma forma de aprendizado temporal, uma vez que o número de picos fornece uma estimativa implícita da duração do intervalo temporal entre os estímulos condicionados e incondicionados. No segundo exemplo da figura 8.3, cada pico sequencial está associado a um ponto de atração alternativo que direciona os movimentos para uma série de pontos de atração dispostos para sugerir escrita à mão (Friston, Mattout e Kilner 2011). Como os dois exemplos ilustram, os sistemas Lotka-Volterra generalizados fornecem modelos úteis de dinâmica sequencial usando um sistema dinâmico contínuo.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Quadro 8.2 Aprendizagem em modelos contínuos
\end{minipage} \\
\midrule
\endhead
Conforme discutido no capítulo 7, o aprendizado é o processo de otimizar crenças sobre os parâmetros \((\theta)\) de um modelo generativo. No domínio de tempo contínuo, isso significa acumular evidências ao longo do tempo. Isso funciona como se tratássemos dados em uma série de intervalos de tempo infinitesimalmente pequenos como obedecendo a i.i.d. (independentes e identicamente distribuídos) e formular um modelo generativo que gera observações a partir de parâmetros (invariantes no tempo):\(\begin{equation} \ln p(\tilde y, \theta) = \ln p(\theta) + \int \ln p(y(t)| \theta)dt \\ \approx \ln p(\theta) - \int F[y(t)|\theta]dt \end{equation}\)Isso pode ser usado para formular um funcional \((S)\) que desempenha o papel de uma energia livre para parâmetros usando a integral no tempo da energia livre condicionada aos parâmetros. Usando uma aproximação de Laplace, obtemos o seguinte, em que α atua para acumular gradientes de energia livre (ou seja, gradientes de evidência):\( \begin{equation}S(\theta)=\mathbb E_{q(\theta)}[\ln q(\theta)+ \int F[y(t)|\theta]dt - \ln p(\theta)] \\ \approx \int F[y(t)|\mu_\theta]dt - \ln p(\mu_\theta)\qquad\qquad  \\ \dot \mu_\theta = \partial_{\mu_\theta} S(\mu_\theta) \qquad\qquad\qquad\qquad\qquad\qquad \\ = \partial_{\mu_\theta} \ln p(\mu_\theta) - \int \partial_{\mu_\theta} F[y(t)|\mu_\theta]dt \\ = \partial \ln p(\mu_{\theta})-\alpha \qquad\qquad\qquad\qquad \\ \dot \alpha = \partial_{\mu_\theta}F[y(t)| \mu_\theta]   \end{equation}\) \\
\bottomrule
\end{longtable}

A formulação POMDP do capítulo 7 substituiu amplamente o uso de sistemas Lotka-Volterra generalizados em aplicações de Inferência Ativa. No entanto, é útil ter esse tipo de dinâmica em mente como um sistema contínuo plausível que pode subscrever a dinâmica sequencial discreta do capítulo 7. Além disso, os sistemas Lotka-Volterra tornam explícita a distinção entre representações de sequências envolvidas no planejamento temporalmente profundo e representações de taxas de mudança em coordenadas generalizadas de movimento (ver capítulo 4). Cada um tem seu lugar, mas lida com diferentes tipos de problemas.
O segundo tipo de sistema dinâmico que encontrou ampla aplicação na pesquisa de inferência ativa é o sistema de Lorenz:

\[\dot x = \begin{bmatrix}  \sigma (x_2 - x_1) \\ x_1(\rho - x_3) - x_2 \\ x_1x_2 - \beta x_3  \end{bmatrix} \qquad\qquad\qquad\qquad (8.7)\]

Os parâmetros são conhecidos como o número de Prandtl \((\sigma)\), o número de Rayleigh \((\rho)\) e uma constante \((\beta)\) que se relaciona com a física do sistema. Dependendo dos valores que eles assumem, o sistema pode se comportar de maneiras muito diferentes. Os atratores de Lorenz foram inicialmente formulados para explicar a dinâmica da convecção atmosférica. Seu comportamento itinerante (errante) estimulou seu uso em modelos generativos para simular problemas de inferência desafiadores. Um exemplo importante disso está na simulação do canto dos pássaros, que descompactamos na próxima seção. Esses sistemas também têm sido usados para simular sistemas físicos simples e investigar as condições sob as quais seu comportamento começa a parecer senciente. A Figura 8.4 mostra como o sistema Lorenz se comporta em configurações de parâmetros de exemplo.

\hypertarget{sincronia-generalizada}{%
\section{Sincronia Generalizada}\label{sincronia-generalizada}}

Como mencionado acima, um exemplo-chave de aplicação de modelos de espaço de estados contínuos está em uma série de estudos baseados em pássaros sintéticos (Friston e Frith 2015b). Um aspecto importante desses estudos analisa a comunicação e os problemas de inferência multiagentes. A ideia aqui se baseia na capacidade de uma criatura de sincronizar seus estados internos com algo lá fora no mundo (ou seja, inferência). Quando o que está lá fora é outra criatura com um modelo semelhante, essa sincronização significa que os estados internos de uma criatura devem se assemelhar aos estados internos da outra: um tipo primitivo de teoria da mente.

\begin{figure}
\centering
\includegraphics{images/Figura_8_4.png}
\caption{Figura 8.4 Comportamento de um atrator do sistema Lorenz (usando o mesmo formato da figura 8.2), mostrando como esse sistema tridimensional evolui. Caracteristicamente, parece caótico e imprevisível, passando algum tempo orbitando uma parte do espaço antes de mudar para outra órbita. Esta itinerância e aparente autonomia tornam este interessante sistema bem adequado para inclusão em modelos de fenômenos biológicos.}
\end{figure}

A Figura 8.5 mostra o tipo de modelo generativo usado para simular pássaros canoros. Neste modelo hierárquico, os estados de alto nível (nível 2) evoluem de acordo com um sistema de Lorenz lento. Uma dimensão deste sistema é então usada para parametrizar o número Rayleigh de um sistema Lorenz mais rápido no nível inferior (nível 1). As variáveis de nível inferior são mapeadas para dados sensoriais (sonográficos). Analogamente à figura 8.1, o processo generativo inclui adicionalmente ação; aqui, em vez de mover um membro, as ações influenciam a laringe, de modo que os dados ultrassonográficos podem ser influenciados pela ave. Como antes, a ação é gerada para resolver o erro de previsão. Isso significa que, se um pássaro ouve o canto que está prevendo, não há necessidade de gerá-lo. No entanto, se ele prevê uma música que não é ouvida, ele deve começar a cantar para resolver qualquer erro.

\begin{figure}
\centering
\includegraphics{images/Figura_8_5.png}
\caption{Figura 8.5 Sincronização e comunicação. Esquerda: Modelo generativo subscrevendo as simulações de canto de pássaros descritas no texto principal. Este é um modelo hierárquico, com atratores de Lorenz em cada nível. Direita: Sincronização multipla de expectativas no segundo nível para dois pássaros antes e depois de terem aprendido um sobre o outro. Depois de aprender os parâmetros dos modelos generativos um do outro, a trajetória conjunta dos dois pássaros é confinada a um subespaço (quase) unidimensional, indicando sincronização.}
\end{figure}

Essa dinâmica se torna mais interessante quando há dois pássaros em jogo, com modelos generativos estruturados de forma semelhante. Enquanto um pássaro estiver cantando, o outro não precisa, pois não há erro a ser resolvido. No entanto, se um pássaro parar de cantar, o outro precisa continuar a mesma música. Isso leva a uma forma de troca de turnos, às vezes expressa como ``cantar da mesma folha de hino'', com cada pássaro contribuindo com seções da mesma música. O que leva a essa virada? Por que um pássaro não continua cantando a música inteira para seu coespecífico? A resposta está relacionada à questão da atenuação sensorial (ver quadro 8.1), pois atuar para gerar o canto dos pássaros requer uma redução na precisão das previsões sobre as consequências da ação. Assim como nos movimentos oculares sacádicos, isso implica na alternância entre a atenção aos dados sensoriais (visuais ou auditivos) e a atenuação durante a ação (sacádica ou vocal) destinada a alterar esses dados. Quando há dois agentes envolvidos, isso leva a uma alternância entre ouvir o outro e cantar -- uma forma simples de conversa.

Para que essa conversa sintética funcione, é essencial que os dois pássaros se sincronizem e saibam onde estão no canto (ou trajetória conversacional). Isso implica que as inferências sobre estados ocultos no modelo generativo devem ser alinhadas entre as aves. No canto superior direito da figura 8.5, mostramos um coletor de sincronização de duas aves que ainda não otimizaram seus modelos generativos uma em relação à outra; isso traça uma trajetória das crenças que cada ave tem sobre os estados ocultos de nível superior. A sincronização implica que quando uma ave infere um valor de estado oculto específico, a outra ave deve inferir o mesmo; portanto, esperaríamos que a trajetória permanecesse fixa à linha x  =  y (tecnicamente chamada sincronização idêntica do caos). Flutuações em torno desta linha implicam sincronização imperfeita, como mostra este gráfico. Após a exposição um ao outro e o aprendizado dos parâmetros dos modelos generativos de cada um (veja o quadro 8.2), a sincronização é quase perfeita (gráfico inferior direito). A implicação é que cada pássaro aprendeu sobre o outro e é capaz de inferir o que está acontecendo na cabeça do outro. Em suma, eles aprenderam a compartilhar a mesma narrativa e ``cantar da mesma folha de hinos''.

Uma forma mais geral de sincronização não requer sincronização ao longo da linha x  =  y. Na sincronização generalizada, o comportamento da junta ocupa um espaço unidimensional inferior ao espaço bidimensional superior que poderia ser ocupado por esse comportamento. No entanto, esse espaço de baixa dimensão (o coletor de sincronização) pode ser curvo ou ter alguma outra forma; isso é análogo ao espaço bidimensional que ocupamos na superfície do planeta, apesar da superfície ser curvada em uma esfera tridimensional. Além de seu papel central no comportamento social, a sincronização generalizada -- ocupação de uma região de baixa dimensão de um espaço de articulação de alta dimensão -- é muito importante na caracterização de sistemas biológicos como envolvidos em inferência (sincronia generalizada entre estados internos e externos). Embora não tenhamos espaço para destrinchar este assunto extenso aqui, a perspectiva inferencial fala sobre o fracasso da sincronia generalizada associada a síndromes neuropsiquiátricas como o autismo. Esse tipo de sincronia é importante não apenas em modelos de tempo contínuo, mas também em modelos POMDP de comunicação linguística entre múltiplos agentes (Friston, Parr et al.~2020).

\hypertarget{modelos-huxedbridos-discretos-e-contuxednuos}{%
\section{Modelos Híbridos (Discretos e Contínuos)}\label{modelos-huxedbridos-discretos-e-contuxednuos}}

Como vimos neste e no capítulo anterior, os modelos discretos e contínuos têm aplicações importantes na Inferência Ativa. Embora muitos cenários exijam um ou outro, uma perspectiva mais holística reconhece que ambos provavelmente estão em jogo. Isso significa que precisamos de uma maneira de combinar esses modelos generativos para que um único modelo inclua variáveis contínuas e discretas (Friston, Parr e de Vries 2017). Tais modelos híbridos ou mistos permitem inferências sobre planos de ação sequenciais e traduções dessas decisões em movimentos por meio de um modelo contínuo. A Figura 8.6 mostra a forma desses modelos, com um POMDP no nível superior, comportando-se conforme descrito no capítulo 7, que gera um modelo contínuo da ordenação abordada neste capítulo a cada passo de tempo discreto. Isso decompõe o tempo contínuo em uma sequência discreta de trajetórias contínuas curtas.

\begin{figure}
\centering
\includegraphics{images/Figura_8_6.png}
\caption{Figura 8.6 Modelos generativos mistos na forma de um modelo hierárquico muito parecido com o da figura 7.12. No entanto, há uma diferença importante entre a forma do modelo no nível superior e no nível inferior. Enquanto o modelo de nível inferior (um exemplo é destacado pela caixa tracejada) é da mesma forma que os outros modelos considerados neste capítulo - ou seja, é enquadrado em termos de estados contínuos e tempo contínuo e usa coordenadas generalizadas de movimento - O modelo de nível superior é um modelo POMDP do tipo que vimos ao longo do capítulo 7 - ou seja, é enquadrado em termos de estados e tempos discretos. Efetivamente, isso significa que podemos selecionar (em intervalos de tempo regulares) entre segmentos alternativos de uma trajetória contínua.}
\end{figure}

Para traduzir os resultados do nível discreto para o nível contínuo, precisamos associar cada resultado alternativo a um ponto em algum espaço contínuo. Para desenvolver a intuição para essa ideia, consideramos o exemplo de uma tarefa oculomotora com período de atraso -- frequentemente usada em pesquisas com primatas; veja a figura 8.7. Essa tarefa envolve três etapas. Primeiro, um alvo aparece em um dos (por exemplo) quatro locais possíveis, enquanto um macaco mantém a fixação em uma cruz de fixação central. Em seguida, o alvo desaparece e deve ser lembrado durante um período de atraso. Por fim, é dado um sinal para que o macaco faça uma sacada, momento em que deve olhar para o local onde o alvo original apareceu. Para completar esta tarefa, o macaco deve ser capaz de fazer inferências sobre sequências (qual estágio da tarefa está em jogo) e inferir qual dos quatro locais visar. Estes são problemas de inferência categórica adequados a uma formulação POMDP. No entanto, uma vez que o local apropriado tenha sido selecionado, o macaco deve realizar o movimento do olho que traz sua fóvea para as coordenadas (contínuas) do local alvo.

A Figura 8.7 ilustra o funcionamento de um modelo generativo misto que resolve esse problema. No painel superior, o nível superior do modelo toma decisões categóricas: ele calcula as crenças posteriores sobre quatro locais de destino discretos em quatro períodos de tempo. Nos gráficos do meio e do fundo, o nível inferior do modelo computa trajetórias comportamentais contínuas (movimentos oculares) resultantes de inferências discretas no nível superior.

Transformar decisões sobre locais de alvos discretos em movimentos oculares contínuos requer que cada local de alvo discreto \((o)\) seja associado a uma distribuição sobre causas ocultas contínuas \((\nu)\), que identifica as coordenadas do alvo. As coordenadas anteriores sobre o alvo podem ser calculadas tomando a média do modelo Bayesiano sobre esses locais, ponderada pelas inferências no nível POMDP:

\[P(\tilde \nu| o_\tau)= \mathcal N(\tilde \eta_{o_{\tau}}, \tilde \Pi_\nu) \]
\[P(\tilde \nu) \approx \mathcal N( \pmb {\tilde \eta}, \tilde \Pi_\nu)  \qquad (8.8)\]

\[ \pmb {\tilde \eta} = \mathbb E_{Q(o_\tau)}[\tilde \eta]= \pmb o_\tau \cdot \tilde \eta  \]
Para inferir qual alvo discreto explica melhor os dados contínuos, precisamos ser capazes de calcular a evidência associada a cada alvo hipotético -- que é uma função dos dados contínuos observados. Isso exemplifica o fato de que modelos mistos requerem interações recíprocas entre níveis hierárquicos superiores e inferiores. Como vemos na figura 8.7, isso facilita a formação de crenças sobre onde realizar as sacadas e a execução dessas sacadas nos momentos apropriados. No primeiro passo de tempo discreto (até 250 ms na escala contínua), o macaco é capaz de inferir com alguma confiança que seus olhos estão centrados na cruz de fixação durante o primeiro passo de tempo, que manterá essa fixação no segundo passo de tempo (até 500 ms), e que o curso de ação mais provável após isso resultará em ``foveting'' o local superior. Isso pode ser visto nas taxas de disparo discretas (gráfico superior). Isso se traduz no comportamento contínuo que, quando implementado, aumenta a confiança nas crenças sobre os estados discretos (observe o aumento na probabilidade de uma sacada ascendente no terceiro passo de tempo, uma vez que os dados contínuos se tornam disponíveis entre 500 e 750 ms). Este exemplo simples, baseado em pesquisa cognitiva experimental, ilustra os princípios básicos de tradução entre planos de ação discretos e sua implementação contínua.

\begin{figure}
\centering
\includegraphics{images/Figura_8_7.png}
\caption{Figura 8.7 Transformando decisões em movimento usando modelos mistos ou híbridos (Parr e Friston 2019b). Este exemplo simples usa o paradigma do período de atraso oculomotor descrito no texto principal. Acima: Taxas de disparos neuronais representando crenças posteriores sobre a localização do alvo. O alvo pode estar em quatro locais diferentes e há quatro etapas de tempo neste experimento sintético, portanto, existem 16 populações neurais representando cada uma dessas combinações. As linhas correspondentes ao estado de coisas final inferido são anotadas explicitamente. Observe a atualização da crença na primeira etapa (de 0 a 250 ms), quando o alvo aparece inicialmente, e na terceira etapa (de 500 a 750 ms), quando o agente se observa realizando um movimento sacádico para aquele local. Médio: Comportamento (ou seja, um movimento sacádico do local central para o local de destino). Durante o primeiro trimestre do experimento, o destino fica visível no local superior. Em seguida, há um período de atraso, durante o qual a fixação é mantida. Em seguida, um movimento sacádico é realizado no local correto. Finalmente, há um período durante o qual a fixação é mantida no local alvo. Inferior: Trajetórias comportamentais contínuas que resultam das inferências discretas do gráfico superior.}
\end{figure}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Quadro 8.3 Modelos de mistura e agrupamento
\end{minipage} \\
\midrule
\endhead
A questão de combinar modelos generativos categóricos e contínuos fora da Inferência Ativa foi principalmente enquadrada pelas lentes do agrupamento. Aqui, o objetivo é atribuir cada ponto de dados (contínuo) a um cluster (discreto). Uma variedade de algoritmos foi empregada para resolver este problema, mas a maioria deles implicitamente se baseia em um modelo generativo semelhante ao usado aqui. Esta é uma mistura de gaussianos (também conhecido como modelo de mistura gaussiana):\(P(\tilde y, \tilde s, \pmb D, \eta, \Pi)=P(\pmb D)P(\eta)P(\Pi)\prod_iP(s_i|\pmb D)P(y_i|s_i,\eta,\Pi)\) \(P(\pmb D) = Dir(d)\) \(P(S_i| \pmb D)= Cat(\pmb D)\) \(P(y_i|s_i,\eta,\Pi)=\mathcal N(\eta_{s_i}, \Pi_{s_i}) \)O problema nas abordagens de agrupamento é inferir a média e a precisão (η e Π, respectivamente) de cada agrupamento e a probabilidade posterior de que cada ponto de dados \((y_i)\) pertença a um determinado agrupamento \(P(s_i|y_i)\). Para nossos propósitos (conforme descrito na seção 8.5), assumimos prioritários precisos (função delta) para η e Π e calculamos \(Q(s_i)≈P(s_i | y_i)\) via redução do modelo Bayesiano (ver Quadro 7.3). \\
\bottomrule
\end{longtable}

\hypertarget{resumo-7}{%
\section{Resumo}\label{resumo-7}}

Neste capítulo, apresentamos uma visão geral das aplicações de modelos generativos de tempo contínuo sob Inferência Ativa. Este é um tópico enorme, e muito foi deixado de fora (veja a tabela 8.1 para leitura adicional). No entanto, os amplos conceitos descritos aqui fornecem uma base a partir da qual esses modelos podem ser mais explorados. Especificamente, consideramos a geração de movimento em termos de cumprimento de previsões. Isso simplifica muito o tratamento de problemas de controle motor, pois não precisamos de nenhuma maquinaria adicional ou modelos inversos - apenas arcos reflexos da coluna vertebral ou do tronco cerebral. Destacamos o papel da precisão e da atenuação sensorial no controle motor desse tipo. Dado que uma vantagem chave dos esquemas contínuos é articular modelos generativos em termos de sistemas dinâmicos, descrevemos dois tipos onipresentes de sistemas dinâmicos que encontraram ampla aplicação na pesquisa de Inferência Ativa. Os sistemas generalizados Lotka-Volterra agem para fornecer sequenciamento temporal em um contexto contínuo, enquanto os atratores Lorenz podem ser usados \hspace{0pt}\hspace{0pt}para gerar simulações ricas, incluindo o canto dos pássaros sintéticos. Em seguida, consideramos o conceito de sincronia generalizada. A sincronização dos estados internos de um sistema com os estados externos forma a base dos tratamentos inferenciais da função cerebral e é crucial nas explicações dos sistemas sociais -- onde os estados externos compreendem em grande parte coespecíficos (ou seja, criaturas como eu). Finalmente, estabelecemos a unificação dos modelos discretos e contínuos dos capítulos 7 e 8, reunindo a dinâmica esperada de minimização de energia livre (exploração e exploratória) das formulações de POMDP, a execução dos comportamentos que estes exigem por meio de processos contínuos e a recíproca passagem de mensagens que medeia essa interação. Em suma, isso nos leva de decisões a movimentos -- e de volta.

\textbf{Tabela 8.1} Principais avanços em modelos de tempo contínuo

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\centering
Aplicação
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Origens
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Notas
\end{minipage} \\
\midrule
\endhead
Synthetic birdsong & Friston and Frith 2015a Friston and Frith 2015b Isomura, Parr, and Friston 2019 & Esta série de artigos trata da comunicação e da interação entre agentes sintéticos, um par (ou grupo) simulado de pássaros cantando um para o outro. Os estudos descompactam fenômenos desde a sincronia generalizada até a inferência perceptiva até a atenuação sensorial. \\
Atrasos oculomotores & Perrinet, Adams, and Friston 2014 & Aproveitando-se de crenças sobre o passado próximo e futuro implícitas em modelos formulados em coordenadas generalizadas de movimento, é possível dar conta dos atrasos sensório-motores por meio de projeções a curto caminho no futuro ou no passado. \\
Reflexos condicionados & Friston and Herreros 2016 & Usando um modelo baseado no sistema Lotka-Volterra, a relação temporal entre um estímulo condicionado e um incondicionado é aprendida e usada para gerar um piscar antecipado. \\
Movimentos oculares de perseguição suave & Adams, Perrinet, and Friston 2012 & Este trabalho analisa o papel dos movimentos oculares de perseguição suave, seguindo um alvo visual. Tem como objetivo reproduzir diferenças entre indivíduos neurotípicos e esquizofrênicos em resposta à perseguição com e sem oclusão visual. \\
Psicose & Adams, Stephan et al.~2013 & Com base nos modelos de pássaros canoros e de perseguição suave, esta pesquisa analisa como inferências falsas e psicóticas podem surgir de crenças anteriores abaixo do ideal. \\
Ilusões & Brown e Friston 2012 Brown, Adams et al.~2013 & As ilusões oferecem uma ferramenta útil para revelar as crenças anteriores às quais nossos cérebros apelam na presença de informações sensoriais incertas ou ambíguas. Esses artigos pegam vários exemplos de ilusões comuns e demonstram a otimalidade de inferências ilusórias sob certas crenças anteriores. \\
Movimentos sacádicos & Friston, Adams et al.~2012 Donnarumma et al.~2017 Parr and Friston 2018a & Assim como as simulações de perseguição suave, esses artigos consideram o controle do movimento dos olhos. No entanto, aqui os olhos não seguem simplesmente um alvo, mas devem se mover para um dos vários locais de alvo possíveis. Eles lidam com os modelos generativos que precisamos para poder fazer isso e (uma vez que os modelos tenham sido especificados) as arquiteturas e fisiologia emergentes. \\
Observação de ação & Friston, Mattout, and Kilner 2011 & Este trabalho considera o papel do sistema de neurônios-espelho e formaliza a ideia de que modelos generativos de nossas próprias ações também podem ser usados para modelar e replicar o comportamento observado em outros. \\
Atenção & Feldman and Friston 2010 Kanai et al.~2015 & Por meio da precisão da previsão, selecionamos implicitamente os dados que acreditamos serem mais informativos. Este trabalho destaca como implementações dessa ideia reproduzem achados psicofísicos clássicos no paradigma de Posner e tarefas de discriminação figura-fundo. \\
Modelos híbridos & Friston, Parr, and de Vries 2017 Parr and Friston 2018c Parr and Friston 2019b & Esses modelos fazem uso de modelos POMDP discretos em combinação com esquemas de codificação preditivos. A maioria dos exemplos atuais dessa modelagem são enquadrados em termos de comportamento de busca visual ou controle oculomotor. Isso requer selecionar onde procurar e, em seguida, implementar o processo de procurar lá. \\
Auto-organização & Friston 2013 Friston, Levin et al.~2015 Palacios et al.~2020 & Essa linha de pesquisa se baseia na ideia de que grupos de células podem se organizar em uma estrutura pré-definida quando cada célula possui o mesmo modelo generativo implícito dessa estrutura. Especificamente, eles devem saber que tipo de entrada sensorial eles preveriam se fossem um tipo específico de célula. \\
\bottomrule
\end{longtable}

\hypertarget{anuxe1lise-de-dados-baseada-em-modelo}{%
\chapter{Análise de dados baseada em modelo}\label{anuxe1lise-de-dados-baseada-em-modelo}}

Só porque temos o melhor martelo não significa que todo problema é um prego. ---Barack Obama

\hypertarget{introduuxe7uxe3o-8}{%
\section{Introdução}\label{introduuxe7uxe3o-8}}

Em última análise, os modelos descritos neste livro só são úteis se puderem responder a questões científicas. Neste capítulo, nos concentramos nas maneiras pelas quais a Inferência Ativa pode ser aplicada na compreensão de dados empíricos. A ideia central é que nós, como cientistas, podemos recorrer à mesma matemática que supusemos que o cérebro usa nos capítulos anteriores. Nosso objetivo geral é recuperar os parâmetros do modelo generativo que o cérebro de um sujeito usa para produzir comportamento -- o modelo subjetivo. Para isso, podemos usar nosso próprio modelo generativo (de como o modelo subjetivo produz comportamento) -- o modelo objetivo. Podemos inverter nosso modelo objetivo com base no comportamento que observamos para fazer inferências sobre os parâmetros do modelo generativo subjetivo. Essa inferência meta-Bayesiana oferece a oportunidade de testar hipóteses sobre o modelo que assumimos que o cérebro usa e fenotipar os indivíduos com base nas crenças anteriores que eles teriam que manter para que seu comportamento fosse o ideal de Bayes. A fenotipagem computacional baseada em crenças desse tipo é promissora nos campos emergentes da psiquiatria computacional, neuropsicologia e neurologia.

\hypertarget{muxe9todos-meta-bayesianos}{%
\section{Métodos Meta-Bayesianos}\label{muxe9todos-meta-bayesianos}}

Este capítulo trata da utilidade das formulações de Inferência Ativa na análise de dados de experimentos comportamentais. Isso vai além das simulações de prova de princípio que vimos nos capítulos anteriores e, em vez disso, explora a Inferência Ativa para responder a questões científicas. Já vimos que o modelo generativo de um sujeito é o principal determinante do comportamento sob Inferência Ativa. Isso implica que as hipóteses sobre as causas das medidas comportamentais empíricas devem ser enquadradas em termos dos modelos generativos alternativos usados para selecionar essas ações. Nosso desafio, então, é ajustar um esquema de Inferência Ativa aos dados observados, manipulando os parâmetros (ou seja, crenças anteriores) do modelo generativo.

De um modo geral, existem duas razões (relacionadas) para ajustar um modelo computacional ao comportamento observado. A primeira é estimar os parâmetros de interesse desse modelo que melhor explicam o comportamento de um determinado sujeito ou grupo de sujeitos. Isso é útil para caracterizar o comportamento subjetivo em termos dos cálculos que o geram, um processo conhecido como fenotipagem computacional (Montague et al.~2012, Schwartenbeck e Friston 2016, Friston 2017). Os fenótipos computacionais podem ser usados em combinação com outras medidas (por exemplo, para estabelecer ligações entre achados de neuroimagem e função) ou podem ser usados sozinhos na previsão de comportamentos em outros ambientes (por exemplo, após uma intervenção terapêutica).

A segunda razão é comparar hipóteses alternativas, expressas como modelos, que representam diferentes explicações para um fenômeno comportamental (Mirza et al.~2018). Essas duas agendas -- estimativa de parâmetros e comparação de modelos -- mapeiam para um lado do teorema de Bayes. A estimativa de parâmetros é o processo de encontrar a probabilidade posterior, sob um modelo, de um ajuste de parâmetros. A comparação de modelos baseia-se em encontrar as probabilidades marginais (ou seja, evidências) para cada modelo. Para recapitular, o teorema de Bayes é

\[ \begin{matrix}\underbrace {P(u|\theta,m)} \\ Verossimilhança \end{matrix}
\begin{matrix}\underbrace {P(\theta|m)} \\ Prior \end{matrix}
= \begin{matrix}\underbrace {P(\theta|u, m)} \\ Posterior \end{matrix}
\begin{matrix}\underbrace {P(u,m)} \\ Evidência \end{matrix}
(9.1)\]

O lado direito lida com a probabilidade posterior de parâmetros \((\theta)\) dados dados comportamentais \((u)\) sob um modelo \((m)\) e a evidência do modelo, e o lado esquerdo nos diz o que precisamos especificar para nosso modelo: precisamos de crenças prévias sobre nossos parâmetros de interesse e uma função de verossimilhança.

É importante ressaltar que, embora apelamos para o mesmo esquema de inferência bayesiana usado nos capítulos anteriores, nosso objetivo é diferente aqui. Isso se baseia no fato de que existem dois processos de inferência acontecendo (figura 9.1). A primeira é que as criaturas usam seu modelo dos processos que geram seus dados sensoriais para fazer inferências sobre seu mundo (e sobre como agir). Este foi o foco dos capítulos anteriores. A segunda é que nós, como cientistas objetivos, observamos o comportamento da criatura e procuramos fazer inferências sobre o modelo generativo (subjetivo) que ela está usando invertendo nosso próprio modelo generativo (objetivo). A implicação aqui é que estamos fazendo inferências sobre um processo inferencial -- às vezes chamado de inferência ``metabayesiana'' (Daunizeau et al.~2010).

\begin{figure}
\centering
\includegraphics{images/Figura_9_1.png}
\caption{Figura 9.1 Relação entre os modelos subjetivo e objetivo de inferência metabayesiana. Caixa tracejada interna: Modelo subjetivo assumido para ser usado por um sujeito experimental. Este poderia ser um modelo POMDP como ilustrado ou alguma outra forma de modelo. As características importantes são que depende de parâmetros \((\theta)\) cujo valor não sabemos e que gera dados sensoriais \((o)\). Caixa tracejada externa: O modelo objetivo do experimentador \((m)\) inclui crenças prévias sobre os parâmetros e prediz o comportamento \((u)\) que esperaríamos ao apresentar estímulos experimentais (dados sensoriais da perspectiva do modelo subjetivo). Fundamentalmente, a distribuição de verossimilhança do modelo objetivo depende do modelo subjetivo. Isso significa que avaliamos a probabilidade de os parâmetros assumirem um valor específico da seguinte maneira. Primeiro, incorporamos os parâmetros no modelo subjetivo. Em seguida, usamos os esquemas de Inferência Ativa descritos nos capítulos anteriores para resolver esse modelo, apresentando nossos estímulos experimentais como dados sensoriais e inferindo uma distribuição sobre o curso de ação mais provável. Por fim, avaliamos a probabilidade das ações ou escolhas observadas, dada essa distribuição. Esta é a probabilidade do comportamento observado dados parâmetros e estímulos - ou seja, a distribuição de verossimilhança no modelo objetivo.}
\end{figure}

Mais formalmente, essa abordagem define a distribuição de verossimilhança em termos da solução de um problema de Inferência Ativa. Ao usar uma determinada configuração de parâmetro, podemos simular o comportamento sob Inferência Ativa e quantificar a probabilidade de que uma série de ações tenha sido executada. Equipados com crenças anteriores sobre o valor desses parâmetros, temos um modelo generativo de como uma criatura usa seu modelo generativo para produzir ações. Embora nosso foco seja a Inferência Ativa (e modelos de tempo discreto especificamente), os métodos genéricos usados aqui podem ser usados com qualquer função de verossimilhança arbitrária. Outros modelos normativos de comportamento (como os usados no aprendizado por reforço) podem ser substituídos pelos modelos de Inferência Ativa.

As seções a seguir descompactam um exemplo de um esquema de inferência genérico que pode ser usado para inferência meta-Bayesiana (ou seja, Laplace variacional) e o uso de modelos hierárquicos para comparação de modelos. Em seguida, fornecemos uma receita simples para análise de dados baseada em modelo e, finalmente, revisamos um exemplo-chave desse procedimento. É importante enfatizar que não é necessário entender os detalhes técnicos para usar esses métodos de forma eficaz; assim, os leitores desinteressados nesses detalhes são convidados a pular as seções 9.3 e 9.4.

Em resumo, a ideia básica é avaliar a probabilidade de qualquer conjunto observado de escolhas, dados os parâmetros desconhecidos de interesse -- ou seja, os parâmetros das crenças anteriores de um sujeito. Em seguida, combinamos essa verossimilhança com nosso objetivo anterior sobre esses parâmetros para avaliar o posterior sobre os antecedentes do sujeito, da maneira usual. Se tivermos vários sujeitos, esses posteriores podem ser combinados para fazer inferências sobre efeitos de grupo ou entre sujeitos, usando Bayes empíricos paramétricos (PEB). A probabilidade necessária é simplesmente a probabilidade de amostragem da sequência observada de escolhas, sob as crenças posteriores do sujeito sobre a ação. Essas crenças posteriores dependem do que o sujeito vê (ou seja, pistas ou estímulos) e suas crenças anteriores -- e são avaliadas de maneira direta, resolvendo o esquema de Inferência Ativa apropriado. Observe que estamos usando procedimentos bayesianos duas vezes: primeiro para avaliar as crenças posteriores do sujeito sobre a ação e, segundo, para avaliar nossas crenças posteriores sobre os antecedentes desconhecidos que caracterizam o sujeito. Agora ensaiamos as várias partes desse procedimento metabayesiano.

\hypertarget{laplace-variacional}{%
\section{Laplace Variacional}\label{laplace-variacional}}

Variational Laplace é um esquema de inferência baseado nos mesmos princípios da codificação preditiva (Friston, Mattout et al.~2007). No entanto, pode ser usado para funções de verossimilhança mais genéricas do que aquelas encontradas anteriormente -- que foram definidas como gaussianas. Começaremos esta seção com uma visão geral da função de verossimilhança \(\mathcal L(\theta)\) de interesse aqui. Isso deve fornecer a probabilidade de ações para um esquema de Inferência Ativa com um modelo generativo com parâmetros definidos no valor \(\theta\). As ações selecionadas dependem das observações feitas:

\[ \mathcal L(\theta)=\ln P(\tilde u |\theta,m,\tilde o )\]
\[ P(\tilde u |\theta,m,\tilde o ) = \tilde u \cdot \sigma (\theta_\alpha ln  \pmb {\tilde u}) \qquad\qquad (9.2)\]
\[ \pmb {\tilde u} = \pmb \pi \cdot U\]

\[ \pmb \pi =arg \;min\; F \]

Descompactando isso, o primeiro termo fornece a probabilidade logarítmica de uma sequência observada de ações \((\tilde u)\) em função dos parâmetros \((\theta)\), do modelo \((m)\) e de uma sequência de estímulos \((\tilde o)\) apresentada durante um experimento real. A probabilidade dessas ações é encontrada usando os parâmetros para definir as crenças anteriores em um modelo POMDP do tipo descrito no capítulo 7. Podemos então resolver o POMDP conforme descrito nos capítulos 4 e 7, forçando a simulação a realizar a ação observada sequência e apresentando-a com os mesmos estímulos experimentais. Como descrevemos nos capítulos anteriores, isso envolve calcular as crenças \((\pi)\) que um sujeito sintético mantém sobre a política ou curso de ação que ele escolhe seguir. Isso minimiza a energia livre \((F)\) associada ao seu modelo generativo do mundo. Podemos então pegar essas crenças e calcular a probabilidade média de seguir uma sequência de ação. Isso exige que distribuamos a probabilidade de cada política pelas ações implícitas nessa política (indexadas por uma matriz \(U\) ). Finalmente, um parâmetro de temperatura softmax \((θ_\alpha)\) é aplicado para levar em conta a aleatoriedade (tremor) no comportamento não contabilizado pelo modelo. Se esse parâmetro softmax for um, estamos efetivamente assumindo que o sujeito amostra suas ações a partir de crenças posteriores sobre suas ações; às vezes, isso é chamado de comportamento de correspondência. Alternativamente, se o parâmetro softmax for muito grande, a ação emitida é a ação com maior posterior subjetiva, ou seja, o sujeito sempre escolhe a opção mais provável. Este parâmetro softmax pode ser estimado.

O resultado é a probabilidade das ações sob o modelo, dada uma sequência de estímulos e parâmetros -- isto é, uma probabilidade de dados comportamentais dado um modelo. Equipando os parâmetros objetivos com priors gaussianas\footnote{Praticamente, muitas vezes é útil definir parâmetros como parâmetros de escala de log: o parâmetro atua como um fator de escala não negativo e não pode ser caracterizado por uma distribuição normal, que aloca números negativos em uma densidade de probabilidade finita. Assumir que o log do parâmetro de escala é normalmente distribuído garante positividade quando exponenciado para obter o próprio parâmetro de escala. O mesmo objetivo pode ser alcançado modelando a raiz quadrada de um parâmetro como sendo normalmente distribuído.} \$ (\theta \sim \mathcal N (\eta, \Pi\^{}\{(1)\}) \$, podemos usar a suposição de Laplace para expressar a (energia livre) aproximação à evidência do modelo:

\[\begin{equation}
\ln P(\tilde u| m, \tilde o) \approx \mathcal L(\mu)- \frac{1}{2} \Big(\epsilon \cdot \Pi^{(1)}\epsilon + \ln \Big| \nabla_{\mu\mu} \mathcal L (\mu)-\Pi^{(1)} \Big| \Big) \\ 
e = \eta - \mu  \qquad \qquad (9.3)\\
\mu = arg \; max \Big\{ \mathcal L(\mu)- \frac{1}{2} \Big(\epsilon \cdot \Pi^{(1)}\epsilon + \ln \Big| \nabla_{\mu\mu} \mathcal L (\mu)-\Pi^{(1)} \Big| \Big)  \Big\}
\end{equation}\]

A Equação 9.3 é a mesma que foi descompactada na Quadro 4.3 (generalizada para um espaço de parâmetros multidimensional), mas aqui substituímos uma forma explícita para a covariância posterior e assumimos uma distribuição a priori normalmente. No capítulo 4 e nas aplicações do capítulo 8, ignoramos os termos da equação 9.3 que não dependiam da moda. No entanto, é importante incluí-los aqui quando consideramos problemas de comparação de modelos.

Para encontrar o valor de μ que maximiza a última linha da equação 9.3, realizamos uma subida de gradiente. Sob suposições quadráticas, isso se reduz ao seguinte:

\[ \mu = \nabla_\mu \mathcal L(\mu) + \Pi^{(1)}\epsilon \qquad\qquad\qquad (9.4) \]

Embora uma forma explícita para o gradiente da probabilidade logarítmica usada aqui possa não estar disponível, métodos de diferenças finitas \footnote{Por exemplo, \(∂x f(x) ≈ 2Δx f(x + Δx) − f(x − Δx)).\)} podem ser usados para calcular uma aproximação numérica razoável. Eles também podem ser usados para encontrar a precisão posterior, que é a segunda derivada (ou Hessiana) da probabilidade logarítmica negativa mais a precisão anterior. A Equação 9.4 é a forma mais simples de atualização, mas geralmente são usados métodos mais sofisticados baseados na curvatura local.

\hypertarget{bayes-empuxedricos-paramuxe9tricos-peb}{%
\section{Bayes Empíricos Paramétricos (PEB)}\label{bayes-empuxedricos-paramuxe9tricos-peb}}

O procedimento variacional de Laplace na seção anterior nos permite fazer inferências e quantificar a evidência de um modelo de comportamento de escolha. Isso nos permite fenotipar computacionalmente um indivíduo e comparar hipóteses alternativas sobre esse indivíduo. No entanto, as questões interessantes geralmente estão em nível de grupo. Por exemplo, podemos estar interessados em como um parâmetro -- como a precisão de preferências anteriores -- varia com a idade. Para responder a essa pergunta, podemos usar a abordagem da seção 9.3 para ajustar modelos ao comportamento de participantes individuais com uma faixa de idades. Formulamos então um modelo linear geral que gera o parâmetro de interesse, levando em consideração a idade:

\[ P(\theta| \beta, X) = \mathcal N(X\beta, \Pi^{(2)}) \qquad\qquad\qquad (9.5) \]
Aqui, \(X\) é uma matriz cujas colunas são variáveis explicativas alternativas e cujas linhas indicam cada participante. A primeira coluna de \(X\) normalmente compreende uma matriz de uns (para indicar o efeito do parâmetro médio sobre os sujeitos). A segunda coluna, em nosso exemplo, pode ser a idade de cada participante. O vetor \(\beta\) indica o tamanho do efeito de cada uma das variáveis explicativas em \(X\). O primeiro elemento de \(\beta\) é então o valor médio da precisão (ou qualquer outro parâmetro), enquanto o segundo é o efeito da idade na precisão. Esse valor é a inclinação da linha em um gráfico de idade (eixo \(x\)) em relação à precisão prevista (eixo \(y\)). Pode haver um número arbitrário de colunas de \(X\), com um número arbitrário de elementos em \(\beta\).

Uma vez ajustado o modelo expresso na equação 9.5, suplementado com a priori para os valores de \(\beta\), podemos fazer perguntas sobre o papel das variáveis explicativas. Por exemplo, podemos perguntar se a idade tem efeito sobre a precisão das preferências anteriores comparando a evidência de um modelo no qual o segundo elemento de \(\beta\) pode desviar-se de zero com a evidência de um modelo com uma crença precisa de que é zero. Praticamente falando, isso pode ser feito sem múltiplas inversões de modelo por meio do uso da redução do modelo Bayesiano (Friston, Parr e Zeidman 2018).

\hypertarget{instruuxe7uxf5es-para-anuxe1lise-baseada-em-modelo}{%
\section{Instruções para Análise Baseada em Modelo}\label{instruuxe7uxf5es-para-anuxe1lise-baseada-em-modelo}}

Na prática, seguimos os passos descritos abaixo para analisar o comportamento de escolha empírica usando inferência ativa (Schwartenbeck e Friston 2016). Estas se referem às rotinas relevantes disponíveis no pacote SPM12 Matlab.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Colete dados comportamentais}, incluindo as escolhas feitas e a entrada sensorial disponível para a pessoa que faz essa escolha. Além disso, colete dados de interesse para análise de segundo nível entre sujeitos (por exemplo, se o sujeito é um paciente ou um sujeito de controle, informações demográficas relevantes e assim por diante).
\item
  \textbf{Formule um modelo POMDP} como no capítulo 7. Esta deve ser uma função que recebe parâmetros como entradas e saídas de um POMDP totalmente especificado (mas ainda não resolvido).
\item
  \textbf{Especifique uma função de verossimilhança} (ou seja, equação 9.2). Isso nos diz como o modelo deve ser usado para calcular uma probabilidade. Isso normalmente chama um solucionador POMDP (como a rotina spm\_MDP\_VB\_X.m) para simular o comportamento e quantificar a probabilidade de ações observadas.
\item
  \textbf{Especifique crenças prévias} sobre os parâmetros em termos de expectativas e precisões. Muitas vezes, eles serão centrados em zero, com precisões refletindo intervalos plausíveis.
\item
  \textbf{Resolva a probabilidade posterior e a evidência do modelo}. Isso usa um esquema de inferência padrão, como o procedimento variacional de Laplace descrito acima (equação 9.4). A rotina spm\_nlsi\_Newton.m fará isso automaticamente.
\item
  \textbf{Realizar análise em nível de grupo}. Isso normalmente faz uso do PEB, que trata os parâmetros estimados para cada indivíduo como se fossem gerados por um modelo de segundo nível. Isso nos permite testar hipóteses sobre as causas desses parâmetros. Praticamente, isso pode ser feito usando a rotina spm\_dcm\_peb.m. As análises alternativas incluem testes estatísticos padrão de associação entre os parâmetros inferidos para cada sujeito e outras medidas específicas do sujeito. Por exemplo, uma análise de variáveis canônicas pode ser usada para avaliar a relação entre as pontuações do questionário e os parâmetros inferidos.
\end{enumerate}

O resumo dessas instruções da Figura 9.2 é baseado no comportamento do rato na tarefa do labirinto em T descrita no capítulo 7. Primeiro, colocamos um rato em um labirinto em T com um estímulo recompensador no braço esquerdo ou direito e uma dica informativa no braço central. Em seguida, registramos a sequência de ações realizadas pelo rato. Este procedimento pode ser repetido em vários ensaios para registrar o comportamento aprendido e pode ser repetido para vários ratos diferentes sob diferentes intervenções (por exemplo, farmacológicas ou optogenéticas).

Uma vez que esses dados comportamentais tenham sido obtidos, precisamos de uma função de verossimilhança que nos permita quantificar a probabilidade do comportamento (para um determinado rato em uma determinada condição) sob configurações de parâmetros específicos. Podemos fazer isso formulando o modelo POMDP que consideramos no capítulo 7. Isso deve ser parametrizado em termos dos parâmetros cuja probabilidade procuramos encontrar. Por exemplo, se quisermos avaliar a precisão associada às preferências, podemos incluir um parâmetro de escala logarítmica que torne a distribuição de preferências mais ou menos intensa.

Tendo estabelecido o modelo generativo (da perspectiva do rato), podemos resolver automaticamente o POMDP usando as equações de atualização de crença no capítulo 4. Isso nos permite calcular a probabilidade dos dados (ou seja, a sequência de braços visitados) condicionados no modelo com o parâmetro de escala (preferências) em um valor específico. A combinação dessa probabilidade com nossa anterior completa a especificação de um modelo generativo para o comportamento (da perspectiva do cientista). Isso pode ser resolvido usando Laplace variacional para encontrar uma distribuição de probabilidade posterior sobre o parâmetro de escala para cada rato

\begin{figure}
\centering
\includegraphics{images/Figura_9_2.png}
\caption{Figura 9.2 Roteiro do procedimento de inversão de seis etapas para análise de dados baseada em modelo, conforme descrito no texto principal (com referência aos capítulos onde mais detalhes podem ser encontrados). As setas indicam as dependências entre cada parte do processo. O modelo POMDP deve ser definido para que a probabilidade seja avaliada. A inversão do modelo requer dados coletados e a probabilidade e os antecedentes; a análise do PEB não pode ocorrer antes da inversão do modelo para cada sujeito. As etapas 4 e 5 esquematizam a atualização de uma distribuição anterior sobre parâmetros sob um modelo para uma distribuição posterior. A evidência e a posterior de cada modelo podem então ser combinadas usando PEB para encontrar densidades a posteriori (mostradas como expectativas com intervalos confiáveis) para os coeficientes β de um modelo linear que prevê esses parâmetros.}
\end{figure}

Na prática, antes de analisar dados reais, podemos querer verificar a validade aparente do modelo POMDP usando-o para gerar dados fictícios -- e considerando se eles são qualitativamente plausíveis, dado o problema em questão. Um segundo teste sensato para o modelo é a recuperação de parâmetros. Isso implica gerar dados fictícios sob alguma parametrização (conhecida) para ver se esses parâmetros podem ser recuperados ao inverter o modelo. Isso é útil para verificar se alguns parâmetros (ou suas combinações) são possíveis de serem recuperados (ou seja, identificáveis).

Finalmente, podemos construir uma matriz de projeto para um modelo linear, cada linha representando um fenótipo computacional (por exemplo, uma densidade posterior sobre as preferências de cada sujeito), com colunas representando diferentes atributos desses sujeitos. Esses atributos são variáveis que podem explicar diferenças nas preferências de um rato. Além de uma coluna indicando as preferências médias em relação a todos os ratos, isso incluirá coisas como idade, se uma droga foi administrada e assim por diante. Com este modelo de efeitos entre sujeitos, agora realizamos uma análise PEB para avaliar a contribuição dessas variáveis explicativas para as preferências anteriores.

9.6  Exemplos de modelos generativos

Nesta seção, aproveitamos dois exemplos na literatura que ilustram o uso de modelos generativos contínuos e discretos. Em primeiro lugar, apresentamos brevemente os métodos utilizados por Adams, Aponte et al.~(2015) e Adams, Bauer et al.~(2016) (doravante nesta seção, Adams et al.) para modelar movimentos oculares de perseguição suave como forma de quantificar os parâmetros de precisão dos modelos generativos de cada sujeito. Um aspecto importante desse projeto foi a coleta simultânea de dados eletrofisiológicos (via magnetoencefalografia) que permitiram aos autores fazer perguntas sobre os substratos neurobiológicos de codificação de precisão ou confiança. Passamos então a uma análise dos movimentos oculares sacádicos de Mirza et al.~(2018; doravante nesta seção, Mirza et al.) formulado como um modelo POMDP. Cada um dos experimentos associados está desenhado na figura 9.3. Nossa esperança é que esses exemplos ajudem os leitores a entender como os métodos genéricos descritos acima podem ser usados \hspace{0pt}\hspace{0pt}empiricamente para responder a questões científicas.

Em termos da sequência de etapas descritas na figura 9.2, Adams et al.~dados coletados (passo 1) de uma tarefa em que os sujeitos tinham que manter a fixação em um alvo visual em movimento. Os detalhes não são importantes, mas essa tarefa compreendia duas condições.

\begin{figure}
\centering
\includegraphics{images/Figura_9_3.png}
\caption{Figura 9.3 Dois experimentos descritos na seção 9.5. Os detalhes não são importantes, mas destacam onde a inferência meta-Bayesiana foi explorada com sucesso e os tipos de dados comportamentais aos quais ela pode ser aplicada. Esquerda: Experimento de Adams et al., que mediram movimentos oculares de perseguição suave enquanto os sujeitos seguiam um alvo em movimento. Direita: Experimento de Mirza et al., que mediu movimentos oculares sacádicos durante uma tarefa de exploração. A exibição visual foi dividida em quatro quadrantes, dois dos quais incluíam estímulos (gato e pássaro). Diferentes categorias de cena envolveram diferentes configurações de estímulos, o que significa que os participantes tiveram que selecionar quais quadrantes fovear para obter informações suficientes para categorizar a cena. A tarefa de Adams (esquerda ) gera dados contínuos de rastreamento ocular, enquanto a tarefa de Mirza (direita ) leva a uma sequência de fixações e pode ser discretizada. Estes são os dados comportamentais (u) da etapa 1 na figura 9.2.}
\end{figure}

No primeiro, o alvo se movia de acordo com uma senóide previsível. Na segunda, seguiu a mesma trajetória com ruído gaussiano aditivo. Os dados coletados incluíram as trajetórias dos movimentos dos olhos. Os autores formularam um modelo subjetivo (passo 2). Ao contrário do modelo POMDP mostrado na figura 9.2, eles optaram por um modelo contínuo do tipo descrito no capítulo 8. Em resumo, o modelo previu a entrada proprioceptiva e visual dos olhos, onde o ponto de fixação foi considerado atraído para o local alvo . A probabilidade (etapa 3) é construída usando os esquemas de codificação preditiva (ativos) descritos no capítulo 4. Isso quantifica a probabilidade das ações (movimentos oculares) sob um conjunto de parâmetros de precisão de log e o modelo estabelecido na etapa 2. Continuando para a etapa 4, os autores especificaram crenças anteriores como distribuições normais sobre as precisões logarítmicas. Eles inverteram o modelo (passo 5) para encontrar distribuições posteriores sobre esses parâmetros de precisão. A etapa 6 não usou uma análise de PEB, mas usou os dados de neuroimagem coletados simultaneamente com a tarefa comportamental. Os autores usaram modelagem causal dinâmica para estimar o ganho de células piramidais superficiais no córtex visual primário. Isso significa que eles tinham estimativas de precisão e ganho sináptico para cada sujeito. Isso permitiu que os autores realizassem uma análise em nível de grupo, avaliando a correlação entre os parâmetros do modelo subjetivo e seus substratos biológicos. A demonstração dessa correlação fornece um exemplo importante de como as formulações de comportamento da Inferência Ativa nos permitem fazer (e responder) perguntas sobre a relação entre atualização de crenças e neurobiologia.

Em nosso segundo exemplo, Mirza et al.~usaram a formulação POMDP de Inferência Ativa para abordar o papel do ganho de informação na condução do comportamento humano. Novamente, descompactamos isso em termos das etapas da Figura 9.2. Mirza et ai. coletaram dados comportamentais (etapa 1) enquanto os sujeitos realizavam uma tarefa de forrageamento visual. Aqui, o objetivo era classificar uma cena visual em um dos vários grupos. Cada elemento da cena só foi revelado quando os sujeitos fixaram esses locais; isso significava que várias fixações eram necessárias para adquirir evidências suficientes para uma determinada categoria de cena. Os dados coletados pelos autores incluíram a sequência de movimentos sacádicos (movimentos rápidos dos olhos) realizada. O modelo (passo 2) utilizado foi um modelo POMDP descrito em Mirza et al.~(2016) que previam resultados proprioceptivos, visuais e de feedback discretizados, condicionados ao local de fixação atual e à categoria da cena. As preferências (veja o capítulo 7) foram colocadas sobre o resultado do feedback de modo que o modelo antecipa (e, portanto, prefere) estar correto na categorização. A função de verossimilhança (passo 3) foi obtida resolvendo o modelo usando o esquema descrito no capítulo 4 sob diferentes configurações de parâmetros. Os parâmetros em questão incluíam (entre outros) um parâmetro de escala de log para a precisão da distribuição de preferências. Os autores especificaram distribuições prévias (etapa 4) sobre a escala de log (e outros parâmetros) e inverteram o modelo para cada sujeito (etapa 5). Eles usaram a evidência logarítmica estimada para cada sujeito para avaliar a evidência de modelos que motivaram ou não o comportamento usando o componente epistêmico da energia livre esperada, encontrando maior evidência para aqueles modelos que incluíam affordance epistêmica em todos os sujeitos. Eles então empregaram uma análise PEB (etapa 6) para avaliar as mudanças nas crenças anteriores para os sujeitos ao longo de vários ensaios, encontrando evidências a favor de mudanças nos parâmetros de crença (ou seja, aprendizado ativo). Finalmente, eles usaram uma análise de covariáveis \hspace{0pt}\hspace{0pt}canônicas para avaliar a relação entre combinações lineares das variáveis \hspace{0pt}\hspace{0pt}fenotípicas estimadas para cada sujeito (por exemplo, precisão de preferências) e combinações lineares de medidas de desempenho (por exemplo, porcentagem correta e tempo de reação).

\hypertarget{modelos-de-falsa-inferuxeancia}{%
\section{Modelos de falsa inferência}\label{modelos-de-falsa-inferuxeancia}}

Os homens em geral são rápidos em acreditar naquilo que desejam que seja verdade. ---Júlio César

Dada a relevância desses métodos para campos como a psiquiatria computacional (Friston, Stephan et al.~2014), terminamos com uma visão geral da falsa inferência, que é central para a noção de psicopatologia como falha na atualização de crenças. Um benefício de usar uma estrutura inferencial como a Inferência Ativa é que ela aborda simultaneamente múltiplas dimensões de transtornos psiquiátricos, ligando comportamento desadaptativo (por exemplo, compulsões ou vícios) e nível psicológico (por exemplo, falsas crenças) e fenômenos de nível biológico (por exemplo, anormalidades de neuromoduladores).

Como não podemos fazer justiça aqui à extensa literatura que usa a Inferência Ativa na modelagem de processos de doença, esta seção fornece a mais breve das visões gerais para sugerir uma estrutura para pensar sobre patologias computacionais. Veja a tabela 9.1 para uma amostragem não exaustiva de exemplos ilustrativos, que incluem modelos especificados em tempo discreto e contínuo (com base nos capítulos 7 e 8, respectivamente). Em nossa discussão, apelaremos para a estrutura de modelos do tipo POMDP; os princípios que sustentam a falsa inferência nessas configurações são basicamente os mesmos.

A hipótese subjacente às abordagens inferenciais (como a Inferência Ativa) é que as condições psicopatológicas podem ser conceituadas como distúrbios de inferência. O termo transtorno não implica necessariamente que o mecanismo inferencial seja falho (por exemplo, gera probabilidades posteriores incorretas). Na maioria dos estudos revisados na tabela 9.1, o mecanismo inferencial opera normalmente, mas com base em um modelo generativo falho (ou seja, um modelo generativo dotado de crenças anteriores aberrantes). Isso significa que, em última análise, a patologia é uma consequência de crenças anteriores aberrantes - e pode-se recuperar essas anteriores usando a análise de dados baseada em modelo descrita neste capítulo.

Tabela 9.1 Patologia computacional

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Patologia
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Fontes
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notas
\end{minipage} \\
\midrule
\endhead
Dependência, impulsividade e compulsividade & FitzGerald, Schwartenbeck et al.~2015 Schwartenbeck, FitzGerald, Mathys, Dolan, Wurst et al.~2015 Mirza et al.~2019 Fradkin et al.~2020 & O vício é um exemplo importante de comportamento que parece aberrante, mas pode ser enquadrado como uma inferência ótima sob o tipo certo de modelo generativo. Trabalho de Schwartenbeck et al.~ilustrou isso usando uma tarefa de oferta limitada em que os participantes estão mais ou menos confiantes sobre se receberão uma recompensa por esperar. A baixa confiança leva a um comportamento compulsivo do tipo associado ao vício. Trabalhos subsequentes sobre este tema examinam as crenças anteriores associadas a comportamentos mais ou menos impulsivos, usando o paradigma de deixar manchas, e examinam o papel da precisão anterior atenuada no transtorno obsessivo-compulsivo. \\
Delírios & Brown et al.~2013 Friston, Parr et al.~2020 & Os delírios, caracterizados por crenças falsas e fixas, são simplesmente articulados na Inferência Ativa como distribuições de probabilidade posteriores precisas na ausência de evidências de suporte. Se suficientemente precisos, eles serão fixados mesmo diante de evidências contraditórias (posteriores). Os mecanismos subjacentes a cada delírio podem ser diferentes. Por exemplo, falhas de atenuação sensorial podem ser centrais para delírios de ação. Trabalhos recentes fornecem um exemplo de um delírio compartilhado (folie à deux), que depende de dois agentes -- sem nenhuma informação -- chegarem a um consenso confiante sobre o estado do mundo \\
Alucinações & Adams, Stephan et ai. 2013 Benrimoh et al.~2018 Parr, Benrimoh et al.~2018 Corlett et al.~2019 & Essas simulações se baseiam em desequilíbrios entre precisões anteriores e de probabilidade. Superinterpretação de dados sensoriais espúrios devido a uma falha na atenuação da precisão da verossimilhança, ou uma falha na correção de crenças anteriores devido à atenuação excessiva, cada uma oferece mecanismos para falsa inferência perceptiva. \\
Interpessoal e distúrbios de personalidade & Moutoussis et ai. 2014 Prosser et al.~2018 & A inferência interpessoal depende de ter modelos sobre outras pessoas e como elas podem reagir às nossas decisões. Isso levou ao desenvolvimento de modelos de jogos de confiança, que dependem de interações entre duas (ou mais) partes, e jogos de caridade. Estes últimos têm sido usados para reproduzir o auto-engrandecimento e a falta de remorso associados à psicopatia. Esses traços são simulados modulando o grau em que as crenças sobre a autoestima dependem de decisões de ser caridoso versus egoísta e sensibilidade à aprovação dos outros. \\
Síndromes oculomotoras & Adams, Perrinet, and Friston 2012 Parr and Friston 2018a & Nestes artigos, modelos generativos de tempo contínuo são empregados para prever a evolução dinâmica de sistemas newtonianos. Ao tornar vários aspectos do modelo generativo condicionalmente independentes de outros, podem ser induzidas síndromes oculomotoras, como oftalmoplegias internucleares. \\
Farmacoterapia & Parr e Friston 2019b & Dadas as associações que propusemos entre parâmetros de precisão e neuroquímicos no capítulo 5, deve ser possível simular as consequências da manipulação farmacológica desses sistemas. Este trabalho ilustra as consequências de várias intervenções farmacológicas sintéticas no desempenho de uma tarefa oculomotora do período de atraso, fornecendo uma prova de princípio de que esses métodos podem ser usados para simular não apenas a patologia, mas também a influência da terapêutica. \\
Síndromes pré-frontais & Parr, Rikhye et al.~2019 & Essas simulações estabelecem uma diferença entre as síndromes pré-frontais medial e lateral, atenuando a precisão das transições para prejudicar o desempenho de uma tarefa guiada pela memória (lateral) versus a precisão de uma probabilidade interoceptiva que determina a motivação para se envolver na tarefa (medial). \\
Negligência visual & Parr and Friston 2017a & A desatenção ao lado esquerdo do espaço pode ser induzida por várias lesões prévias alternativas. Entre estes, um aumento nos parâmetros de Dirichlet para este lado do espaço reduz a novidade associada às sacadas à esquerda, aumentando a amostragem visual da direita. Alternativamente, definir preferências consistentes com resultados proprioceptivos ou visuais do lado direito ou aumentar o envolvimento habitual em sacadas do lado direito reproduz um comportamento qualitativamente semelhante. \\
Distúrbios de inferência interoceptiva & Barrett et al.~2016 Allen et al.~2019 Maisto, Barca et al.~2019 Pezzulo, Maisto et al.~2019 Barca and Pezzulo 2020 Tschantz et al.~2021 & Simulações de inferência interoceptiva (ou inferência ativa no domínio interoceptivo) sugerem que desequilíbrios entre precisões anteriores e de probabilidade sobre (por exemplo) sinais cardíacos ou gástricos podem causar falsas crenças sobre o estado interno do corpo, percepções errôneas de sintomas corporais e alucinações psicossomáticas . Além disso, eles podem ter efeitos em cascata na regulação autonômica e na seleção de ações, causando vários tipos de comportamento desadaptativo, como hipervigilância, uso excessivo de medicamentos e restrições alimentares excessivas. \\
\bottomrule
\end{longtable}

Prioridades aberrantes podem ser sobre estados ou precisões, ou podem ser a priori estruturais sobre a forma do modelo generativo. Uma maneira útil de pensar sobre as causas do comportamento patológico é pensar sobre a crença anterior usada para políticas e sobre como cada parte disso pode ser interrompida para dar origem a uma seleção anormal de políticas. As políticas anteriores dependem da energia livre esperada, que por sua vez depende das crenças posteriores, do potencial de ganho de informação e das preferências anteriores (C). Prioridades sobre as apólices também podem ser equipadas com um termo de forma fixa (E ), representando vieses habituais.

Tomando cada um destes por sua vez: Crenças posteriores dependem de anteriores e probabilidades. Para formar uma crença posterior aberrante, uma ou ambas devem ser rompidas. Normalmente, essa ruptura assume a forma de sub ou superestimação do equilíbrio de precisões. A probabilidade excessivamente alta, em comparação com a precisão anterior, leva a uma interpretação exagerada da entrada sensorial (potencialmente barulhenta). Isso leva ao overfitting no sentido de que conclusões injustificadas podem ser tiradas de dados espúrios. Se o equilíbrio é interrompido na direção oposta, favorecendo a confiança no anterior, as percepções geradas internamente tornam-se resistentes a entradas sensoriais conflitantes. Ambos os mecanismos têm sido associados ao desenvolvimento de alucinações, e os dois podem coexistir quando são empregados modelos hierárquicos. Dada a associação de várias precisões com substâncias químicas neuromoduladoras (ver capítulo 5), parece sensato que condições como a demência por corpos de Lewy, na qual a sinalização colinérgica é prejudicada, e a esquizofrenia, com anormalidades do sistema dopaminérgico, apresentem fenômenos alucinatórios -- isto é, falsa inferência perceptual.

Em seguida, consideramos o papel do ganho de informação. Aqui, a precisão da probabilidade e a precisão das crenças anteriores nos dizem o grau em que a incerteza pode ser resolvida e a quantidade de incerteza que há para resolver, respectivamente. A precisão das crenças anteriores se aplica tanto aos parâmetros do modelo generativo (ou seja, influencia a novidade) quanto aos estados (ou seja, influencia a saliência). Interpretar os parâmetros de probabilidades condicionais como eficácias sinápticas ou as precisões como ganhos sinápticos sugere que as síndromes de desconexão sináptica podem ser consideradas como ruptura de um ou ambos. Sinapses ausentes não podem ser moduladas, então isso é como ter crenças anteriores extremamente confiantes sobre uma probabilidade condicional, pois novos dados não podem atualizar a eficácia associada. Isso tem implicações importantes para o potencial ganho de informação de diferentes políticas, como tem sido explorado na modelagem de síndromes de negligência sensorial.

Finalmente, as preferências e as políticas anteriores fornecem uma clara influência sobre o comportamento. Estes podem sustentar o desenvolvimento de hábitos viciantes ou a apatia associada a várias síndromes psiquiátricas e neurológicas (Hezemans, Wolpe e Rowe 2020). Em resumo, crenças anteriores defeituosas em vários lugares nos modelos generativos descritos acima fornecem uma explicação funcional ou teleológica para o comportamento patológico.

\hypertarget{resumo-8}{%
\section{Resumo}\label{resumo-8}}

Neste capítulo, delineamos uma abordagem que utiliza os modelos teóricos descritos nos capítulos anteriores para colocar questões aos dados empíricos. Isso nos permite usar a Inferência Ativa como uma ferramenta não invasiva para investigar os processos computacionais que os indivíduos usam para tomar decisões. Nós nos concentramos em alguns exemplos simples. No entanto, modelos baseados em Inferência Ativa foram desenvolvidos para tarefas mais realistas e complicadas (Cullen et al.~2018) projetadas para evocar um comportamento mais rico para fenotipagem computacional. Além de estabelecer um processo de seis etapas para análise baseada em modelos, destacamos dois exemplos do uso desses métodos. Isso traz variações importantes em como isso pode ocorrer, incluindo os tipos de comportamento medidos (trajetórias suaves ou escolhas discretas), a escolha do modelo (contínuo ou discreto) e as diferentes questões científicas que estão sendo feitas. A última delas é a mais importante, pois determina as escolhas anteriores. Vimos o uso de fenotipagem computacional em combinação com neuroimagem (Adams, Bauer et al.~2016) para fazer perguntas sobre a relação entre ganho sináptico e precisão. Além disso, vimos como a inversão de modelo pode ser usada para avaliar as contribuições de impulsos comportamentais alternativos e preditores de desempenho (Mirza et al.~2018). Em última análise, as seis etapas na Figura 9.1 fornecem um método genérico para projetar experimentos para interrogar de forma não invasiva os modelos generativos implícitos que as pessoas (ou outros animais) usam para direcionar o comportamento. Isso oferece uma oportunidade para responder a perguntas sobre a função do sistema nervoso na saúde e na doença.

\hypertarget{inferuxeancia-ativa-como-uma-teoria-unificada-do-comportamento-sensuxedvel}{%
\chapter{Inferência ativa como uma teoria unificada do comportamento sensível}\label{inferuxeancia-ativa-como-uma-teoria-unificada-do-comportamento-sensuxedvel}}

Em geral, nós estamos menos cientes do que nossas mentes fazem de melhor---Marvin Minsky

\hypertarget{introduuxe7uxe3o-9}{%
\section{Introdução}\label{introduuxe7uxe3o-9}}

Neste capítulo, encerramos os principais pontos teóricos da Inferência Ativa (da primeira parte do livro) e suas implementações práticas (da segunda parte). Em seguida, conectamos os pontos: nos abstraímos dos modelos específicos de Inferência Ativa discutidos nos capítulos anteriores para focar nos aspectos integrativos da estrutura. Um benefício da Inferência Ativa é que ela fornece uma solução completa para os problemas adaptativos que os organismos sencientes precisam resolver. Portanto, oferece uma perspectiva unificada sobre problemas como percepção, seleção de ações, atenção e regulação de emoções, que geralmente são tratados isoladamente em psicologia e neurociência -- e abordados usando abordagens computacionais distintas em inteligência artificial. Discutiremos a perspectiva de Inferência Ativa em cada um desses problemas (e mais) no contexto de teorias estabelecidas, como cibernética, teoria da ação ideomotora, aprendizado por reforço e controle ótimo. Finalmente, discutimos brevemente como o escopo da Inferência Ativa pode ser estendido para cobrir outros tópicos biológicos, sociais e tecnológicos que não são discutidos em profundidade neste livro.

\hypertarget{empacotando}{%
\section{Empacotando}\label{empacotando}}

Este livro oferece um relato sistemático dos fundamentos teóricos e implementações práticas da Inferência Ativa. Aqui, resumimos brevemente a discussão dos primeiros nove capítulos. Isso oferece uma oportunidade de ensaiar as principais construções da Inferência Ativa que serão úteis no restante deste capítulo.

\textbf{No capítulo 1}, introduzimos a Inferência Ativa como uma abordagem normativa para entender as criaturas sencientes que fazem parte de laços de ação-percepção com seu ambiente (Fuster 2004). Explicamos que as abordagens normativas partem dos primeiros princípios para derivar e testar previsões empíricas sobre o fenômeno de interesse -- aqui, as maneiras pelas quais os organismos vivos persistem enquanto se envolvem em trocas adaptativas (loops de percepção de ação) com seu ambiente. Também consideramos que se poderia chegar à Inferência Ativa seguindo uma estrada baixa ou uma estrada alta.

No \textbf{capítulo 2}, ilustramos o caminho para a Inferência Ativa. Esse caminho parte da ideia de que o cérebro é uma máquina de previsão, dotada de um modelo generativo: uma representação probabilística de como as causas ocultas no mundo geram sensações (por exemplo, como a luz refletida em uma maçã estimula a retina). Ao inverter esse modelo, ele infere as causas de suas sensações (por exemplo, se estou vendo uma maçã, já que minha retina é estimulada de certa forma). Essa visão da percepção (também conhecida como percepção-como-inferência) tem suas raízes históricas na noção helmholtziana de inferência inconsciente e, mais recentemente, na hipótese do cérebro bayesiano. A Inferência Ativa estende essa visão trazendo controle de ação e planejamento dentro do compasso da inferência (também conhecido como controle-como-inferência, planejamento-como-inferência). Mais importante ainda, mostra que percepção e ação não são processos essencialmente separáveis, mas cumprem o mesmo objetivo. Descrevemos primeiro esse objetivo de maneira mais informal, como a minimização de uma discrepância entre o modelo de alguém e o mundo (o que geralmente se reduz à surpresa ou minimização do erro de previsão). Simplificando, pode-se minimizar a discrepância entre um modelo e o mundo de duas maneiras: mudando a mente para se adequar ao mundo (percepção) ou mudando o mundo para se adequar ao modelo (ação). Estes podem ser descritos em termos de inferência Bayesiana. No entanto, a inferência exata é muitas vezes intratável, então a Inferência Ativa usa uma aproximação (variacional) (observando que a inferência exata pode ser vista como um caso especial de inferência aproximada). Isso leva à segunda descrição mais formal do objetivo comum de percepção e ação, como minimização de energia livre variacional. Esta é a quantidade central usada na Inferência Ativa e pode ser descompactada em termos de suas partes constituintes (por exemplo, energia e entropia, complexidade e precisão, ou surpresa e divergência). Finalmente, introduzimos um segundo tipo de energia livre: a energia livre esperada. Isso é particularmente importante durante o planejamento, pois oferece uma maneira de pontuar políticas alternativas considerando o resultado futuro que se espera que elas gerem. Isso também pode ser descompactado em termos de suas partes constituintes (por exemplo, ganho de informação e valor pragmático, ambiguidade e risco esperados).

No \textbf{capítulo 3}, ilustramos o caminho para a Inferência Ativa. Esse caminho alternativo parte do imperativo deflacionário para que os organismos biológicos preservem sua integridade e evitem a dissipação, o que pode ser descrito como evitar estados surpreendentes. Introduzimos então a noção de um envoltório de Markov: uma formalização da separação estatística entre os estados internos do organismo e os estados externos do mundo. Fundamentalmente, os estados internos e externos só podem influenciar um ao outro indiretamente por meio de variáveis intermediárias (ativas e sensoriais), chamadas de estados de cobertura. Essa separação estatística -- mediada pelo envoltório de Markov -- é crucial para dotar um organismo de algum grau de autonomia em relação ao mundo externo. Para entender por que essa é uma perspectiva útil, considere as três consequências a seguir.

Primeiro, um organismo com um envoltório de Markov parece modelar o ambiente externo em um sentido bayesiano: seus estados internos correspondem - em média - a uma crença posterior aproximada sobre estados externos do mundo. Em segundo lugar, a autonomia é garantida pelo fato de que o modelo do organismo (seus estados internos) não é imparcial, mas prescreve algumas pré-condições existenciais (ou preferências prévias) que devem ser mantidas -- por exemplo, para um peixe, estar na água. Em terceiro lugar, equipado com esse formalismo, é possível descrever o comportamento ótimo (em relação às preferências anteriores) como a maximização da evidência do modelo (bayesiano) por percepção e ação. Ao maximizar a evidência do modelo (ou seja, auto-evidente), um organismo garante que ele realize suas preferências anteriores (por exemplo, um peixe permanece na água) e evita estados surpreendentes. Por sua vez, a maximização da evidência do modelo é (aproximadamente) matematicamente equivalente à minimização da energia livre variacional - portanto, chegamos novamente (de outra maneira) ao mesmo construto central da Inferência Ativa discutido no capítulo 2. Finalmente, detalhamos a relação entre minimizar a surpresa e o princípio da menor ação de Hamilton. Isso evidencia a relação formal entre a Inferência Ativa e os primeiros princípios da física estatística.

No \textbf{capítulo 4}, delineamos os aspectos formais da Inferência Ativa. Nós nos concentramos na passagem da inferência bayesiana para uma aproximação tratável - inferência variacional - e o objetivo resultante para os organismos minimizarem a energia livre variacional por meio da percepção e da ação. O insight desse tratamento é a importância do modelo generativo que as criaturas usam para dar sentido ao seu mundo. Introduzimos dois tipos de modelos generativos que expressam nossas crenças sobre como os dados são gerados, usando variáveis discretas ou contínuas. Explicamos que ambos fornecem a mesma Inferência Ativa, mas se aplicam quando estados de coisas são formulados em tempo discreto (como problemas de decisão de Markov parcialmente observados) ou em tempo contínuo (como equações diferenciais estocásticas), respectivamente.

No \textbf{capítulo 5}, comentamos sobre a diferença entre o princípio normativo da minimização da energia livre e uma teoria de processo sobre como esse princípio pode ser implementado pelo cérebro -- e explicamos que este último gera previsões testáveis. Em seguida, delineamos aspectos das teorias de processo que acompanham a Inferência Ativa, que abrange domínios como a passagem de mensagens neuronais, incluindo circuitos neuroanatômicos (por exemplo, alças córtico-subcorticais) e neuromodulação. Por exemplo, em um nível anatômico, a passagem de mensagens mapeia bem para um microcircuito cortical canônico, com previsões que derivam de camadas corticais profundas em um nível e visam camadas corticais superficiais no nível abaixo (Bastos et al.~2012). Em um nível mais sistêmico, discutimos como inferência Bayesiana, aprendizado e ponderação de precisão correspondem à dinâmica neuronal, plasticidade sináptica e neuromodulação, respectivamente, e como a mensagem neural de cima para baixo e de baixo para cima passa de mapas de codificação preditiva para mais lento ( por exemplo, alfa ou beta) e ritmos cerebrais mais rápidos (por exemplo, gama). Esses e outros exemplos ilustram que, após projetar um modelo específico de Inferência Ativa, pode-se extrair implicações neurobiológicas da forma de seu modelo generativo.

No \textbf{capítulo 6}, fornecemos uma receita para projetar modelos de Inferência Ativa. Vimos que, embora todas as criaturas minimizem sua energia livre variacional, elas se comportam de maneiras diferentes, às vezes opostas, porque são dotadas de diferentes modelos generativos. Portanto, o que distingue criaturas diferentes (por exemplo, mais simples de mais complexas) é apenas seu modelo generativo. Existe um rico repertório de possíveis modelos generativos, que correspondem a diferentes implementações biológicas (por exemplo, neuronais) e produzem diferentes comportamentos adaptativos -- ou mal adaptativos -- em diferentes contextos e nichos ecológicos. Isso torna a Inferência Ativa igualmente apropriada para caracterizar criaturas simples como bactérias que detectam e buscam gradientes de nutrientes, criaturas complexas como nós que perseguem objetivos sofisticados e se envolvem em ricas práticas culturais, ou mesmo indivíduos diferentes -- na medida em que caracterizam adequadamente seus respectivos modelos generativos . A evolução parece ter descoberto estruturas de design cada vez mais sofisticadas para cérebros e corpos que tornaram os organismos capazes de lidar (e moldar) ricos nichos ecológicos. Os modeladores podem fazer engenharia reversa desse processo e especificar os projetos para cérebros e corpos de criaturas de interesse, em termos de modelos generativos, com base nos tipos de nicho que ocupam. Isso corresponde a uma série de escolhas de projeto (por exemplo, modelos usando variáveis \hspace{0pt}\hspace{0pt}discretas ou categóricas, modelos superficiais ou hierárquicos) -- que descompactamos no capítulo.

Nos \textbf{capítulos 7 e 8}, fornecemos vários exemplos de modelos de Inferência Ativa em tempo discreto e contínuo, que abordam problemas de inferência perceptiva, navegação direcionada a objetivos, aprendizado de modelos, controle de ação e muito mais. Esses exemplos foram projetados para mostrar a variedade de comportamentos emergentes sob esses modelos e detalhar os princípios de como eles são especificados na prática.

No \textbf{capítulo 9}, discutimos como usar a Inferência Ativa para análise de dados baseada em modelo e recuperar os parâmetros do modelo generativo de um indivíduo, que explicam melhor o comportamento do sujeito em uma tarefa. Essa fenotipagem computacional usa a mesma forma de inferência bayesiana discutida no restante do livro, mas de uma maneira diferente: ajuda a projetar e avaliar modelos (objetivos) de modelos (subjetivos) de outros.

\hypertarget{conectando-os-pontos-a-perspectiva-integrativa-da-inferuxeancia-ativa}{%
\section{Conectando os Pontos: A Perspectiva Integrativa da Inferência Ativa}\label{conectando-os-pontos-a-perspectiva-integrativa-da-inferuxeancia-ativa}}

Algumas décadas atrás, o filósofo Dennett lamentou que os cientistas cognitivos dedicassem muito esforço para modelar subsistemas isolados (por exemplo, percepção, compreensão da linguagem) cujos limites são frequentemente arbitrários. Ele sugeriu tentar modelar ``toda a iguana'': uma criatura cognitiva completa (talvez uma simples) e um nicho ambiental para ela lidar (Dennett 1978).

Um benefício da Inferência Ativa é que ela oferece um primeiro relato de princípio das maneiras pelas quais os organismos resolvem seus problemas adaptativos. A abordagem normativa adotada neste livro pressupõe que é possível partir do princípio da minimização variacional da energia livre e derivar implicações sobre processos cognitivos específicos, como percepção, seleção de ação, regulação de atenção e emoção e seus fundamentos neuronais.

Imagine uma criatura simples que deve resolver problemas como encontrar comida ou abrigo. Quando lançado como Inferência Ativa, os problemas da criatura podem ser descritos em termos enativos, como agindo para solicitar sensações preferidas (por exemplo, sensações relacionadas à comida). Na medida em que essas sensações preferidas são incluídas (como crenças anteriores) em seu modelo generativo, o organismo está efetivamente reunindo evidências para seu modelo -- ou, mais alegoricamente, para sua existência (ou seja, maximizando a evidência do modelo ou autoevidência). Esse princípio simples tem ramificações para funções psicológicas tradicionalmente consideradas isoladamente, como percepção, controle de ação, memória, atenção, intenção, emoção e muito mais. Por exemplo, percepção e ação são autoevidentes, no sentido de que uma criatura pode alinhar o que espera, dado seu modelo gerador, com o que sente, seja mudando suas crenças (sobre a presença de comida) ou mudando o mundo. (solicitando sensações relacionadas à comida). Memória e atenção também podem ser pensadas como otimizando o mesmo objetivo. A memória de longo prazo se desenvolve através do aprendizado dos parâmetros de um modelo generativo. A memória de trabalho é a atualização de crenças quando as crenças são sobre estados externos no passado e no futuro. A atenção é a otimização das crenças sobre a precisão da entrada sensorial. Formas de planejamento (e intencionalidade) podem ser conceituadas apelando para a capacidade de (algumas) criaturas de selecionar entre futuros alternativos, o que, por sua vez, requer modelos generativos temporalmente profundos. Estes prevêem os resultados que resultariam de um curso de ação e são otimistas sobre esses resultados. Esse otimismo se manifesta como a crença de que os resultados futuros levarão a resultados preferidos. Modelos temporais profundos também podem nos ajudar a entender formas sofisticadas de prospecção (onde crenças sobre o presente são usadas para derivar crenças sobre o futuro) e retrospecção (onde crenças sobre o presente são usadas para atualizar crenças sobre o passado). Formas de regulação interoceptiva e emoção podem ser conceituadas apelando para modelos generativos de fisiologia interna que predizem as consequências alostáticas de eventos futuros.

Como os exemplos acima ilustram, há uma consequência importante de estudar a cognição e o comportamento da perspectiva de uma teoria normativa do comportamento senciente. Tal teoria não começa reunindo funções cognitivas separadas, como percepção, tomada de decisão e planejamento. Em vez disso, começa fornecendo uma solução completa para os problemas que os organismos precisam resolver e, em seguida, analisando a solução para derivar implicações sobre as funções cognitivas. Por exemplo, quais mecanismos permitem que um organismo vivo ou criatura artificial (por exemplo, um robô) perceba o mundo, lembre-se dele ou planeje (Verschure et al.~2003, 2014; Verschure 2012; Pezzulo, Barsalou et al.~2013; Krakauer et al.~al.~2017)? Este é um movimento importante, pois as taxonomias das funções cognitivas - usadas em livros de psicologia e neurociência - herdam em grande parte das primeiras teorias filosóficas e psicológicas (às vezes chamadas de categorias jamesianas). Apesar de seu grande valor heurístico, eles podem ser bastante arbitrários -- ou podem não corresponder a processos cognitivos e neurais separados (Pezzulo e Cisek 2016, Buzsaki 2019, Cisek 2019). De fato, essas categorias jamesianas podem ser candidatas a como nossos modelos generativos explicam nosso envolvimento com o sensório -- em oposição a explicar esse envolvimento. Por exemplo, a hipótese solipsista de que ``estou percebendo'' é apenas minha explicação para estados atuais de coisas que incluem minha atualização de crenças.

Adotar uma perspectiva normativa também pode ajudar na identificação de analogias formais entre fenômenos cognitivos estudados em diferentes domínios. Um exemplo é o trade-off entre prospecção e aproveitamento , que aparece em várias formas (Hills et al.~2015). Essa troca é frequentemente estudada durante o forrageamento, quando as criaturas devem escolher entre explorar planos anteriores de sucesso e explorar novos (potencialmente melhores). No entanto, a mesma troca ocorre durante a pesquisa de memória e deliberação com recursos limitados (por exemplo, limitações de tempo ou esforço de pesquisa), quando as criaturas têm a escolha entre explorar seu melhor plano atual versus investir mais tempo e esforço cognitivo para explorar possibilidades adicionais. Caracterizar esses fenômenos aparentemente desconectados em termos de energia livre pode revelar semelhanças profundas (Friston, Rigoli et al.~2015; Pezzulo, Cartoni et al.~2016; Gottwald e Braun 2020).

Finalmente, além de uma perspectiva unificada sobre fenômenos psicológicos, a Inferência Ativa oferece um meio baseado em princípios para entender as computações neurais correspondentes. Em outras palavras, oferece uma teoria de processo que conecta o processamento cognitivo à dinâmica neuronal (esperada). A Inferência Ativa assume que tudo o que importa sobre cérebros, mentes e comportamento pode ser descrito em termos da minimização da energia livre variacional. Por sua vez, essa minimização tem assinaturas neurais específicas (em termos de,
ex., passagem de mensagens ou anatomia cerebral) que podem ser validados empiricamente.

No restante deste capítulo, exploramos algumas implicações da Inferência Ativa para funções psicológicas --- como se estivéssemos esboçando um livro de psicologia. Para cada uma dessas funções, também destacamos alguns pontos de contato (ou divergência) entre a Inferência Ativa e outras teorias populares na literatura.

\hypertarget{cuxe9rebros-preditivos-mentes-preditivas-e-processamento-preditivo}{%
\section{Cérebros Preditivos, Mentes Preditivas e Processamento Preditivo}\label{cuxe9rebros-preditivos-mentes-preditivas-e-processamento-preditivo}}

Eu tenho essa foto de pura alegria
é de uma criança com uma arma
ele está mirando bem na sua frente,
atirando em algo que não está lá.
--- Afterhours, ``Quello che non c'è'' (Algo que não está lá)

As teorias tradicionais do cérebro e da cognição enfatizam as transduções de alimentação direta de estímulos externos para representações internas e, em seguida, ações motoras. Isso tem sido chamado de ``modelo sanduíche'', pois tudo o que está entre estímulos e respostas recebe o rótulo de ``cognitivo'' (Hurley 2008). Nessa perspectiva, a principal função do cérebro é transformar os estímulos recebidos em respostas contextualmente apropriadas.

A Inferência Ativa se afasta significativamente dessa visão, enfatizando aspectos preditivos e direcionados a objetivos do cérebro e da cognição. Em termos psicológicos, criaturas de Inferência Ativa (ou seus cérebros) são máquinas de inferência probabilísticas, que continuamente geram previsões baseadas em seus modelos generativos.

Criaturas auto-evidentes usam suas previsões de duas maneiras fundamentais. Primeiro, eles comparam as previsões com os dados recebidos para validar suas hipóteses (codificação preditiva) e -- em uma escala de tempo mais lenta -- revisam seus modelos (aprendizagem). Em segundo lugar, eles fazem previsões para orientar as formas de coleta de dados (Inferência Ativa). Ao fazer isso, as criaturas de Inferência Ativa cumprem dois imperativos: epistêmicos (por exemplo, explorar visualmente lugares onde estão presentes informações importantes que podem resolver incertezas sobre hipóteses ou modelos) e pragmáticos (por exemplo, mover-se para locais onde observações preferenciais, como recompensas, podem ser garantidas) . O imperativo epistêmico torna os processos de percepção e aprendizagem ativos, enquanto o imperativo pragmático torna o comportamento direcionado a metas.

\hypertarget{processamento-preditivo}{%
\subsection{Processamento Preditivo}\label{processamento-preditivo}}

Essa visão preditiva e centrada em objetivos do cérebro -- e cognição -- está intimamente relacionada (e forneceu inspiração para) processamento preditivo (PP): uma estrutura emergente na filosofia da mente e epistemologia, que vê a previsão como central para o cérebro e a cognição e apela a conceitos de ``cérebros preditivos'' ou ``mentes preditivas'' (Clark 2013, 2015; Hohwy 2013).

Às vezes, as teorias PP apelam para o funcionamento específico da Inferência Ativa e alguns de seus construtos, como modelos generativos, codificação preditiva, energia livre, controle de precisão e envoltórios de Markov, mas às vezes apelam para outros construtos, como modelos inversos e diretos acoplados , que não fazem parte da Inferência Ativa. Portanto, o termo processamento preditivo é usado em um sentido mais amplo (e menos restrito) em comparação com a Inferência Ativa.

As teorias de processamento preditivo atraíram considerável atenção na filosofia, devido ao seu potencial de unificação em muitos sentidos: em vários domínios da cognição, incluindo percepção, ação, aprendizagem e psicopatologia; de níveis mais baixos (por exemplo, sensório-motor) para níveis mais altos de processamento cognitivo (por exemplo, construções psicológicas); desde simples organismos biológicos até cérebros, indivíduos e construções sociais e culturais. Outro apelo das teorias PP é que elas fazem uso de termos conceituais, como crenças e surpresa, que falam a um nível psicológico de análise familiar aos filósofos (com a ressalva de que às vezes esses termos podem ter significados técnicos diferentes do uso comum) .

No entanto, à medida que o interesse pela PP cresce, tornou-se evidente que os filósofos têm opiniões diferentes sobre suas implicações teóricas e epistemológicas. Por exemplo, foi interpretado em termos internalistas (Hohwy 2013), incorporados ou baseados em ação (Clark 2015) e enativistas e não representacionais (Bruineberg et al.~2016, Ramstead et al.~2019). O debate em torno dessas interpretações conceituais vai além do escopo deste livro.

\hypertarget{percepuxe7uxe3o}{%
\section{Percepção}\label{percepuxe7uxe3o}}

Você não pode depender de seus olhos quando sua imaginação está fora de foco. ---Mark Twain

A Inferência Ativa considera a percepção como um processo inferencial baseado em um modelo generativo de como as observações sensoriais são geradas. A regra de Bayes essencialmente inverte o modelo para calcular uma crença sobre o estado oculto do ambiente, dadas as observações. Essa ideia de percepção-como-inferência remonta a Helmholtz (1866) e foi frequentemente reproposta em psicologia, neurociência computacional e aprendizado de máquina (por exemplo, análise por síntese) (Gregory 1980, Dayan et al.~1995, Mesulam 1998, Yuille e Kersten 2006). Essa abordagem de modelagem generativa demonstrou ser eficaz no enfrentamento de problemas de percepção desafiadores, como quebrar CAPTCHAs baseados em texto (George et al.~2017).

\hypertarget{hipuxf3tese-do-cuxe9rebro-bayesiano}{%
\subsection{Hipótese do Cérebro Bayesiano}\label{hipuxf3tese-do-cuxe9rebro-bayesiano}}

A expressão contemporânea mais proeminente dessa ideia é a hipótese do cérebro bayesiano, que tem sido aplicada a vários domínios, como tomada de decisão, processamento sensorial e aprendizado (Doya 2007). A Inferência Ativa fornece uma base normativa para essas ideias inferenciais, derivando-as do imperativo de minimizar a energia livre variacional. Como o mesmo imperativo se estende à dinâmica da ação, a Inferência Ativa naturalmente modela a percepção ativa e as maneiras pelas quais os organismos ativamente amostram observações para testar suas hipóteses (Gregory 1980). Sob a agenda do cérebro bayesiano, em vez disso, a percepção e a ação são modeladas em termos de imperativos diferentes (onde a ação requer a teoria da decisão bayesiana; veja seção 10.7.1).

Mais amplamente, a hipótese do cérebro Bayesiano refere-se a uma família de abordagens que não são necessariamente integradas e muitas vezes fazem previsões empíricas diferentes. Estes incluem, por exemplo, a proposta em nível computacional de que o cérebro realiza integração sensório-motora e multissensorial ótima de Bayes (Kording e Wolpert 2006), a proposta em nível algorítmico de que o cérebro implementa aproximações específicas de inferência Bayesiana, como decisão-por- amostragem (Stewart et al.~2006), e as propostas de nível neural sobre as maneiras específicas em que as populações neurais podem realizar cálculos probabilísticos ou codificar distribuições de probabilidade - por exemplo, como amostras ou códigos populacionais probabilísticos (Fiser et al.~2010, Pouget et al.~2013). Em cada nível de explicação, existem teorias concorrentes no campo. Por exemplo, é comum recorrer a aproximações de inferência Bayesiana exata para explicar desvios do comportamento ótimo, mas trabalhos diferentes consideram aproximações diferentes (e nem sempre compatíveis), como diferentes abordagens de amostragem. Mais amplamente, as relações entre propostas em diferentes níveis nem sempre são diretas. Isso ocorre porque os cálculos bayesianos podem ser realizados (ou aproximados) de várias maneiras algorítmicas, mesmo sem representar explicitamente as distribuições de probabilidade (Aitchison e Lengyel 2017).

A Inferência Ativa fornece uma perspectiva mais integrada que conecta princípios normativos e teorias de processo. No nível normativo, seu pressuposto central é que todos os processos minimizam a energia livre variacional. A teoria do processo correspondente para inferência usa um gradiente descendente na energia livre, que tem implicações neurofisiológicas claras, exploradas no capítulo 5 (Friston, FitzGerald et al.~2016). Mais amplamente, pode-se partir do princípio da minimização da energia livre para derivar implicações sobre as arquiteturas do cérebro.

Por exemplo, o modelo de processo canônico de inferência perceptual (em tempo contínuo) é a codificação preditiva. A codificação preditiva foi inicialmente proposta como uma teoria do processamento perceptual hierárquico por Rao e Ballard (1999) para explicar uma série de efeitos documentados de cima para baixo, que eram difíceis de conciliar com arquiteturas feedforward, bem como fatos fisiológicos conhecidos (por exemplo, a existência de conexões para frente, ou de baixo para cima, e para trás, ou de cima para baixo, nas hierarquias sensoriais). No entanto, a codificação preditiva pode ser derivada do princípio da minimização da energia livre, sob algumas premissas, como a aproximação de Laplace (Friston 2005). Além disso, a Inferência Ativa em tempo contínuo pode ser construída como uma extensão direcionada da codificação preditiva no domínio da ação -- dotando um agente de codificação preditiva com reflexos motores (Shipp et al.~2013). Isso nos leva ao próximo ponto.

\hypertarget{controle-de-auxe7uxe3o}{%
\section{Controle de Ação}\label{controle-de-auxe7uxe3o}}

Se você não pode voar, corra, se não pode correr, ande, se não puder andar, rasteje, mas faça o que fizer, continue seguindo em frente.
---Martin Luther King

Na Inferência Ativa, o processamento da ação é análogo ao processamento perceptivo, pois ambos são guiados por previsões diretas -- exteroceptivas e proprioceptivas, respectivamente. É a previsão (proprioceptiva) de que ``minha mão agarra a xícara'' que induz um movimento de agarrar. A equivalência entre ação e percepção existe também no nível neurobiológico: a arquitetura do córtex motor é organizada da mesma forma que o córtex sensorial -- como uma arquitetura de codificação preditiva, com a exceção de que pode influenciar os reflexos motores no tronco cerebral e coluna vertebral (Shipp et al.~2013) e que recebe relativamente pouca entrada ascendente. Os reflexos motores permitem controlar o movimento estabelecendo ``pontos de equilíbrio'' ao longo de uma trajetória desejada -- uma ideia que corresponde à hipótese do ponto de equilíbrio (Feldman 2009).

É importante ressaltar que iniciar uma ação -- como pegar uma xícara -- requer regulação da precisão (variância inversa) de crenças anteriores e fluxos sensoriais de forma adequada. Isso ocorre porque os valores relativos dessas precisões determinam a maneira pela qual uma criatura administra o conflito entre sua crença anterior (que ela segura a xícara) e sua entrada sensorial (sinalizando que ela não segura). Uma crença prévia imprecisa sobre pegar uma xícara pode ser facilmente revisada à luz de evidências sensoriais conflitantes -- produzindo uma mudança de opinião e nenhuma ação. Em vez disso, quando a crença anterior domina (ou seja, tem maior precisão), ela é mantida mesmo diante de evidências sensoriais conflitantes -- e induz uma ação de apreensão para resolver o conflito. Para garantir que este seja o caso, a iniciação da ação induz uma atenuação sensorial transitória (ou erros de predição sensorial de peso reduzido). A falha dessa atenuação sensorial pode ter consequências desadaptativas, como a falha em iniciar ou controlar os movimentos (Brown et al.~2013).

\hypertarget{teoria-ideomotora}{%
\subsection{Teoria Ideomotora}\label{teoria-ideomotora}}

Na Inferência Ativa, a ação decorre de previsões (proprioceptivas) e não de comandos motores (Adams, Shipp e Friston 2013). Essa ideia conecta a Inferência Ativa à teoria ideomotora da ação: uma estrutura para entender o controle da ação que remonta a William James (1890) e as teorias posteriores de ``codificação de eventos'' e ``controle comportamental antecipatório'' (Hommel et al.~2001, Hoffmann 2003). ). A teoria ideomotora sugere que as ligações ação-efeito (semelhantes aos modelos diretos) são mecanismos-chave na arquitetura da cognição. É importante ressaltar que esses links podem ser usados \hspace{0pt}\hspace{0pt}bidirecionalmente. Quando utilizados no sentido ação-efeito, permitem gerar previsões sensoriais; quando são usados \hspace{0pt}\hspace{0pt}na direção efeito-ação, eles permitem selecionar ações que alcançam as consequências perceptivas desejadas -- implicando que as ações são selecionadas e controladas com base em suas consequências previstas (daí o termo ideo + motor). Essa visão antecipatória do controle da ação é apoiada por um corpo de literatura que documenta os efeitos das consequências (antecipadas) da ação na seleção e execução da ação (Kunde et al.~2004). A Inferência Ativa fornece uma caracterização matemática dessa ideia que também inclui mecanismos adicionais, como a importância do controle de precisão e atenuação sensorial, que não são totalmente investigados na teoria ideomotora (mas são compatíveis com ela).

\hypertarget{cibernuxe9tica}{%
\subsection{Cibernética}\label{cibernuxe9tica}}

A Inferência Ativa está intimamente relacionada às ideias cibernéticas sobre a natureza intencional e direcionada a objetivos do comportamento e a importância das interações agente-ambiente (baseadas em feedback), como exemplificado pelo TOTE (Test, Operate, Test, Exit) e modelos relacionados ( Miller e outros 1960; Pezzulo, Baldassarre e outros 2006). Tanto no TOTE quanto no Active Inference, a seleção de ações é determinada pela discrepância entre um estado preferencial (objetivo) e o estado atual. Essas abordagens divergem das simples relações estímulo-resposta, como mais comumente assumidas na teoria behaviorista e estruturas computacionais como o aprendizado por reforço (Sutton e Barto, 1998).

A noção de controle de ação na Inferência Ativa é particularmente semelhante à teoria do controle perceptual (Powers 1973). Central para a teoria do controle perceptual era a noção de que o que é controlado é um estado perceptivo, não uma saída ou ação motora. Por exemplo, enquanto dirigimos, o que controlamos -- e mantemos estável ao longo do tempo diante de distúrbios -- é nossa referência ou velocidade desejada (por exemplo, 90 mph), conforme sinalizado pelo velocímetro, enquanto as ações que selecionamos para isso (por exemplo, acelerando ou desacelerando) são mais variáveis e dependentes do contexto. Por exemplo, dependendo da perturbação (por exemplo, vento, uma estrada íngreme ou outros carros), precisaríamos acelerar ou desacelerar para manter a velocidade de referência. Essa visão implementa a sugestão de William James (1890) de que ``os humanos alcançam objetivos estáveis por meios flexíveis''.

Embora tanto na Inferência Ativa quanto na teoria do controle perceptual seja uma previsão perceptiva (e especificamente uma proprioceptiva) que controla a ação, as duas teorias diferem em como o controle é operado. Na Inferência Ativa, mas não na teoria do controle perceptual, o controle da ação tem aspectos antecipatórios ou feedforward, baseados em modelos generativos. Em contraste, a teoria do controle perceptual assume que os mecanismos de feedback são amplamente suficientes para controlar o comportamento, enquanto tentar prever uma perturbação ou exercer controle feedforward (ou malha aberta) é inútil. No entanto, essa objeção destinava-se principalmente a abordar as limitações das teorias de controle que usam modelos inversos para a frente (veja a próxima seção). Sob a Inferência Ativa, modelos generativos ou diretos não são usados para prever uma perturbação, mas para prever estados e trajetórias futuras (desejadas) a serem cumpridas pela ação -- e para inferir a causa latente de eventos perceptivos.

Finalmente, outro ponto importante de contato entre a Inferência Ativa e a teoria do controle perceptual é a maneira como eles conceituam as hierarquias de controle. A teoria do controle perceptual propõe que os níveis hierárquicos mais altos controlam os níveis hierárquicos mais baixos, definindo seus pontos de referência ou pontos de ajuste (ou seja, o que eles precisam alcançar), deixando-os livres para selecionar os meios para alcançá-los, em vez de definir ou influenciar as ações que os níveis mais baixos têm que desempenhar (ou seja, como operar). Isso contrasta com a maioria das teorias de controle hierárquico e de cima para baixo, nas quais os níveis superiores selecionam diretamente os planos (Botvinick 2008) ou influenciam a seleção de ações ou comandos motores em níveis hierárquicos inferiores (Miller e Cohen 2001). Semelhante à teoria do controle perceptual, na Inferência Ativa pode-se decompor o controle hierárquico em termos de uma cascata (de cima para baixo) de objetivos e subobjetivos, que podem ser alcançados de forma autônoma nos níveis apropriados (inferiores). Além disso, na Inferência Ativa, a contribuição das metas representadas em diferentes níveis da hierarquia de controle pode ser modulada (precisão ponderada) por processos motivacionais, de forma que as metas mais salientes ou urgentes sejam priorizadas (Pezzulo, Rigoli e Friston 2015, 2018).

\hypertarget{teoria-do-controle-uxf3timo}{%
\subsection{Teoria do Controle Ótimo}\label{teoria-do-controle-uxf3timo}}

A forma como a Inferência Ativa explica o controle da ação é significativamente diferente de outros modelos de controle na neurociência, como a teoria do controle ótimo (Todorov 2004, Shadmehr et al.~2010). Essa estrutura pressupõe que o córtex motor do cérebro seleciona ações usando uma política de controle (reativa) que mapeia estímulos para respostas. A Inferência Ativa, em vez disso, assume que o córtex motor transmite previsões, não comandos.

Além disso, embora tanto a teoria de controle ótimo quanto a Inferência Ativa apelem para modelos internos, elas descrevem a modelagem interna de maneiras diferentes (Friston 2011). No controle ótimo, há uma distinção entre dois tipos de modelos internos: os modelos inversos codificam contingências estímulo-resposta e selecionam comandos motores (de acordo com alguma função de custo), enquanto os modelos diretos codificam contingências ação-resultado e fornecem modelos inversos com entradas simuladas para substituir o feedback ruidoso ou atrasado, indo além de um esquema de controle de feedback puro. Modelos inversos e diretos também podem operar em um loop que é separado da percepção de ação externa (ou seja, quando entradas e saídas são suprimidas) para dar suporte a simulações ``e se'' internas de sequências de ação. Tais simulações internas de ação têm sido associadas a várias funções cognitivas, como planejamento, percepção de ação e imitação em domínios sociais ( Jeannerod 2001, Wolpert et al.~2003), bem como vários distúrbios do movimento e psicopatologias (Frith et al.~2000 ).

Em contraste com o esquema de modelagem direta-inversa, na Inferência Ativa os modelos diretos (generativos) fazem o trabalho pesado do controle da ação, enquanto os modelos inversos são minimalistas e geralmente se reduzem a reflexos simples resolvidos no nível periférico (ou seja, no tronco cerebral ou medula espinhal). A ação é iniciada quando há uma diferença entre os estados antecipados e observados (por exemplo, posições desejadas, atuais dos braços) - ou seja, um erro de previsão sensorial. Isso significa que um comando motor é equivalente a uma previsão feita pelo modelo direto em oposição a algo calculado por um modelo inverso como no controle ótimo. O erro de previsão sensorial (mais precisamente, proprioceptivo) é resolvido por uma ação (ou seja, movimento do braço). A lacuna a ser preenchida pela ação é considerada tão pequena que não requer um modelo inverso sofisticado, mas um reflexo motor muito mais simples (Adams, Shipp e Friston 2013).\footnote{De um ponto de vista mais pragmático, a Inferência Ativa requer apenas a aquisição de modelos diretos, que são (tipicamente) mais fáceis de aprender em comparação aos modelos inversos porque são simplesmente um mapeamento direto (observável) entre ações e consequências. Modelos avançados também podem ser adquiridos por imitação ou supervisão externa -- uma técnica amplamente análoga à Inferência Ativa que é amplamente usada para treinar modelos robóticos (Nishimoto e Tani 2009)} O que torna um reflexo motor mais simples do que um modelo inverso é que ele não codifica um mapeamento de estados inferidos do mundo para ação, mas um mapeamento muito mais simples entre ação e consequências sensoriais. Ver Friston, Daunizeau et ai. (2010) para uma discussão mais aprofundada.

Outra diferença crucial entre o controle motor ótimo e a Inferência Ativa é que o primeiro usa uma noção de custo ou função de valor para motivar a ação, enquanto o segundo a substitui pela noção bayesiana de prioridade anterior (ou preferência anterior, implícita na energia livre esperada) -- como discutimos na próxima seção.

\hypertarget{utilidade-e-tomada-de-decisuxe3o}{%
\section{Utilidade e Tomada de Decisão}\label{utilidade-e-tomada-de-decisuxe3o}}

A ação expressa prioridades. ---Mahatma Gandhi

A noção de uma função de custo ou valor de estados é central em muitos campos, como controle motor ótimo, teorias econômicas de maximização de utilidade e aprendizado por reforço. Por exemplo, na teoria de controle ótimo, a política de controle ótimo para uma tarefa de alcance é frequentemente definida como aquela que minimiza uma função de custo específica (por exemplo, é mais suave ou tem um jerk mínimo). Em problemas de aprendizado por reforço, como navegar em um labirinto que inclui uma ou mais recompensas, a política ótima é aquela que permite maximizar (descontar) a recompensa enquanto também minimiza os custos de movimento. Esses problemas são muitas vezes resolvidos usando a equação de Bellman (ou a equação de Hamilton-Jacobi-Bellman em tempo contínuo), cuja ideia geral é que o valor de uma decisão pode ser decomposto em duas partes: a recompensa imediata e o valor do restante. parte do problema de decisão. Essa decomposição fornece o procedimento iterativo de programação dinâmica, que está no centro da teoria de controle e do aprendizado por reforço (RL) (Bellman 1954).

A Inferência Ativa difere da abordagem acima de duas maneiras principais. Primeiro, a Inferência Ativa não considera apenas a maximização da utilidade, mas o objetivo mais amplo da minimização da energia livre (esperada), que também inclui imperativos (epistêmicos) adicionais, como a desambiguação do estado atual e a busca de novidades (veja a figura 2.5). Esses objetivos adicionais às vezes são adicionados às recompensas clássicas -- por exemplo, como um ``bônus de novidade'' (Kakade e Dayan 2002) ou ``recompensa intrínseca'' (Schmidhuber 1991, Oudeyer et al.~2007, Baldassarre e Mirolli 2013, Gottlieb et al.~2013)---mas eles surgem automaticamente na Inferência Ativa, permitindo que ela resolva os trade-offs prospecção-aproveitamento implícitos em muitas decisões. A razão para isso é que as energias livres são funcionais de crenças, o que significa que estamos no domínio da otimização de crenças em oposição às funções de recompensa externas. Isso é essencial em problemas exploratórios, em que o sucesso depende de resolver o máximo de incertezas possível.

Em segundo lugar, na Inferência Ativa, a noção de custo é absorvida pelo anterior. O prior (ou preferência anterior) especifica um objetivo para controle -- por exemplo, uma trajetória a seguir ou um ponto final a ser alcançado. Usar priores para codificar observações (ou sequências) preferidas pode ser mais expressivo do que usar utilitários (Friston, Daunizeau e Kiebel 2009). Usando esse método, encontrar a política ótima é reformulado como um problema de inferência (de uma sequência de estados de controle que realizam a trajetória preferida) e não requer uma função de valor ou a equação de Bellman - embora possa recorrer a uma lógica recursiva semelhante (Friston , Da Costa et al.~2020). Existem pelo menos duas diferenças fundamentais entre as formas como as funções prioritárias e de valor são normalmente usadas na Inferência Ativa e RL, respectivamente. Primeiro, os métodos RL usam funções de valor de estados ou de pares estado-ação - enquanto a Inferência Ativa usa a priori sobre as observações. Em segundo lugar, as funções de valor são definidas em termos do retorno esperado de estar em um estado (ou realizar uma ação em um estado) seguindo uma política específica -- ou seja, a soma de recompensas futuras (descontadas) obtidas por começar no estado e depois execução da política. Em contraste, na Inferência Ativa, as anteriores geralmente não somam recompensas futuras, nem as descontam. Ao contrário, algo análogo ao retorno esperado só surge na Inferência Ativa quando a energia livre esperada de uma apólice é calculada. A implicação é que a energia livre esperada é o análogo mais próximo da função valor. No entanto, mesmo isso difere no sentido de que a energia livre esperada é uma função de crenças sobre estados, não uma função de estados. Dito isso, é possível construir priores que se assemelham a funções de valor de estados em RL - por exemplo, armazenando em cache os cálculos de energia livre esperada nesses estados (Friston, FitzGerald et al.~2016; Maisto, Friston e Pezzulo 2019).

Além disso, absorver a noção de utilidade no anterior tem uma importante consequência teórica: os anteriores desempenham o papel de metas e tornam o modelo gerador tendencioso - ou otimista, no sentido de que a criatura acredita que encontrará resultados preferidos. É esse otimismo que subscreve os planos inferidos que alcançam os resultados desejados na Inferência Ativa; uma falha desse tipo de otimismo pode corresponder à apatia (Hezemans et al.~2020). Isso contrasta com outras abordagens formais de tomada de decisão, como a teoria da decisão bayesiana, que separa a probabilidade dos eventos de sua utilidade. Dito isso, essa distinção é um tanto superficial, pois uma função de utilidade sempre pode ser reescrita como codificando uma crença anterior, consistente com o fato de que comportamentos que maximizam uma função de utilidade são a priori (e por design) mais prováveis. De uma perspectiva deflacionária (ligeiramente tautológica), esta é a definição de utilidade.

\hypertarget{teoria-da-decisuxe3o-bayesiana}{%
\subsection{Teoria da Decisão Bayesiana}\label{teoria-da-decisuxe3o-bayesiana}}

A teoria da decisão bayesiana é uma estrutura matemática que estende as ideias do cérebro bayesiano (discutidas acima) para os domínios da tomada de decisão, controle sensório-motor e aprendizado (Kording e Wolpert 2006, Shadmehr et al.~2010, Wolpert e Landy 2012). A teoria da decisão bayesiana descreve a tomada de decisão em termos de dois processos distintos. O primeiro processo usa cálculos Bayesianos para prever a probabilidade de resultados futuros (dependentes da ação ou da política), e o segundo processo define a preferência sobre os planos, usando uma utilidade (fixa ou aprendida) ou função de custo. O processo de decisão final (ou seleção de ação) integra ambas as correntes, selecionando assim (com maior probabilidade) o plano de ação que tem maior probabilidade de render a maior recompensa. Isso contrasta com a Inferência Ativa, na qual a distribuição prévia sinaliza diretamente o que é valioso para o organismo (ou o que foi valioso durante a história evolutiva). No entanto, paralelos podem ser traçados entre as duas correntes da teoria da decisão Bayesiana e a otimização da energia livre variacional e esperada, respectivamente. Sob a Inferência Ativa, a minimização da energia livre variacional fornece crenças precisas (e simples) sobre o estado do mundo e sua provável evolução. A crença anterior de que a energia livre esperada será minimizada através da seleção de políticas incorpora a noção de preferências.

Em alguns círculos, há preocupações sobre o status da teoria da decisão bayesiana. Isso decorre dos teoremas de classe completos (Wald 1947, Brown 1981) que dizem que para qualquer par de decisões e funções de custo, existem algumas crenças anteriores que tornam as decisões de Bayes ótimas. Isso significa que há uma dualidade implícita ou degeneração ao lidar separadamente com crenças anteriores e funções de custo. Em certo sentido, a Inferência Ativa resolve essa degeneração absorvendo funções de utilidade ou custo em crenças anteriores na forma de preferências.

\hypertarget{aprendizado-por-reforuxe7o}{%
\subsection{Aprendizado por Reforço}\label{aprendizado-por-reforuxe7o}}

Aprendizagem por reforço (RL) é uma abordagem para resolver problemas de decisão de Markov que é popular tanto na inteligência artificial quanto nas ciências cognitivas (Sutton e Barto 1998). Ele se concentra em como os agentes aprendem uma política (por exemplo, estratégia de balanceamento de pólos) por tentativa e erro: experimentando ações (por exemplo, mover para a esquerda) e recebendo reforços positivos ou negativos, dependendo do sucesso da ação (por exemplo, polo equilibrado) ou falha (por exemplo, polo caído).

A Inferência Ativa e a RL tratam de conjuntos de problemas sobrepostos, mas diferem em muitos aspectos matematicamente e conceitualmente. Como observado acima, a Inferência Ativa dispensa as noções de recompensa, funções de valor e otimalidade de Bellman que são fundamentais para as abordagens de aprendizado por reforço. Além disso, a noção de política é usada de forma diferente nas duas estruturas. Em RL, uma política denota um conjunto de mapeamentos estímulo-resposta que precisam ser aprendidos. Na Inferência Ativa, uma política faz parte do modelo generativo: denota uma sequência de estados de controle que precisam ser inferidos.

As abordagens de aprendizagem por reforço são abundantes, mas podem ser subdivididas em três famílias principais. Os dois primeiros métodos tentam aprender boas funções de valor (estado ou ação de estado), embora de duas maneiras diferentes.

Métodos livres de modelo de RL aprendem funções de valor diretamente da experiência: eles realizam ações, coletam recompensas, atualizam suas funções de valor e as usam para atualizar suas políticas. A razão pela qual eles são chamados de livres de modelo é porque eles não usam um modelo (de transição) que permite prever estados futuros - do tipo usado na Inferência Ativa. Em vez disso, eles apelam implicitamente para tipos mais simples de modelos (por exemplo, mapeamentos de ação de estado). As funções de valor de aprendizado em RL sem modelo geralmente envolvem erros de previsão de recompensa de computação, como na regra popular de diferença temporal. Embora a Inferência Ativa geralmente apele a erros de previsão, esses são erros de previsão de estado (já que não há noção de recompensa na Inferência Ativa).

Os métodos de RL baseados em modelos não aprendem funções ou políticas de valor diretamente da experiência. Em vez disso, eles aprendem um modelo da tarefa a partir da experiência, usam o modelo para planejar (simular experiências possíveis) e atualizar funções e políticas de valor dessas experiências simuladas. Embora tanto a Inferência Ativa quanto o aprendizado por reforço apelem ao planejamento baseado em modelo, eles o usam de maneira diferente. Na Inferência Ativa, o planejamento é o cálculo da energia livre esperada para cada política, não um meio de atualizar funções de valor. Indiscutivelmente, se a energia livre esperada é vista como um funcional de valor, pode-se dizer que as inferências feitas usando o modelo generativo são usadas para atualizar esse funcional -- oferecendo um ponto de analogia entre essas abordagens.

A terceira família de abordagens de RL, métodos de gradiente de política, tenta otimizar políticas diretamente, sem funções de valor intermediário, que são centrais tanto para RL baseado em modelo quanto sem modelo. Esses métodos partem de políticas parametrizadas, capazes de gerar (por exemplo) trajetórias de movimento, e depois as otimizam alterando os parâmetros para aumentar (diminuir) a probabilidade de uma política se a trajetória resultar em uma recompensa positiva alta (baixa). Essa abordagem relaciona métodos de gradiente de política à Inferência Ativa, que também dispensa funções de valor (Millidge 2019). No entanto, o objetivo geral dos gradientes de política (maximizar a recompensa cumulativa de longo prazo) difere da Inferência Ativa.

Além das diferenças formais entre Inferência Ativa e RL, existem também várias diferenças conceituais importantes. Uma diferença diz respeito a como as duas abordagens interpretam o comportamento dirigido a objetivos e o comportamento habitual. Na literatura de aprendizagem animal, as escolhas direcionadas a objetivos são mediadas pelo conhecimento (prospectivo) da contingência entre uma ação e seu resultado (Dickinson e Balleine 1990), enquanto as escolhas habituais não são prospectivas e dependem de mais simples (por exemplo, estímulo-resposta). ) mecanismos. Uma ideia popular em RL é que escolhas direcionadas a objetivos e escolhas habituais correspondem a RL baseado em modelo e livre de modelo, respectivamente, e que estas são adquiridas em paralelo e competem continuamente para controlar o comportamento (Daw et al.~2005).

A Inferência Ativa, em vez disso, mapeia as escolhas habituais e direcionadas a objetivos para diferentes mecanismos. Na Inferência Ativa (em tempo discreto), a seleção de políticas é essencialmente baseada em modelos e, portanto, se encaixa na definição de escolhas deliberativas direcionadas a objetivos. Isso é semelhante ao que acontece na RL baseada em modelo, mas com uma diferença. Na LR baseada em modelos, as ações são selecionadas de forma prospectiva (usando um modelo), mas são controladas de forma reativa (usando políticas de estímulo-resposta); na Inferência Ativa, as ações podem ser controladas de maneira proativa -- por meio do cumprimento de previsões proprioceptivas (sobre controle de ações, consulte a seção 10.6).

Na Inferência Ativa, os hábitos podem ser adquiridos executando políticas direcionadas a objetivos e, em seguida, armazenando em cache as informações sobre quais políticas são bem-sucedidas em quais contextos. As informações armazenadas em cache podem ser incorporadas como valor prévio das políticas (Friston, FitzGerald et al.~2016; Maisto, Friston e Pezzulo 2019). Este mecanismo permite a execução de políticas que tenham um alto valor a priori (em um determinado contexto) sem deliberação. Isso pode ser pensado simplesmente como observar ``o que eu faço'' e aprender que ``eu sou o tipo de criatura que tende a fazer isso'' ao longo de múltiplas exposições a uma tarefa. Em contraste com a RL livre de modelo, onde os hábitos são adquiridos independentemente da seleção de políticas direcionadas a objetivos, na Inferência Ativa os hábitos são adquiridos pela busca repetida de políticas direcionadas a objetivos (por exemplo, armazenando seus resultados em cache).

Na Inferência Ativa, mecanismos habituais e direcionados a objetivos podem cooperar em vez de apenas competir. Isso ocorre porque a crença prévia sobre as políticas depende tanto de um termo habitual (um valor prévio das políticas) quanto de um termo deliberativo (energia livre esperada). As elaborações hierárquicas da Inferência Ativa sugerem que os mecanismos reativos e direcionados a objetivos podem ser organizados em uma hierarquia e não como caminhos paralelos (Pezzulo, Rigoli e Friston 2015).

Por fim, vale notar que a Inferência Ativa e a RL diferem sutilmente na forma como concebem o comportamento e suas causas. A RL tem origem na teoria behaviorista e na ideia de que o comportamento resulta da aprendizagem por tentativa e erro mediada por reforço. A Inferência Ativa assume, em vez disso, que o comportamento é o resultado de uma inferência. Isso nos leva ao próximo ponto.

\hypertarget{planejamento-como-inferuxeancia}{%
\subsection{Planejamento como Inferência}\label{planejamento-como-inferuxeancia}}

Da mesma forma que é possível lançar problemas perceptuais como problemas de inferência, também é possível lançar problemas de controle em termos de inferência Bayesiana (aproximada) (Todorov 2008). Em consonância com isso, na Inferência Ativa, o planejamento é visto como um processo inferencial: a inferência de uma sequência de estados de controle do modelo generativo.

Essa ideia está intimamente relacionada a outras abordagens, que incluem controle como inferência (Rawlik et al.~2013, Levine 2018), planejamento como inferência (Attias 2003, Botvinick e Toussaint 2012) e controle sensível ao risco e KL ( Kappen et al.~2012). Nessas abordagens, o planejamento procede através da inferência de uma distribuição posterior sobre as ações, ou sequências de ações, usando um modelo generativo dinâmico que codifica contingências probabilísticas entre estados, ações e estados futuros (esperados). A melhor ação ou plano pode ser inferido condicionando o modelo generativo à observação de recompensas futuras (Pezzulo e Rigoli 2011, Solway e Botvinick 2012) ou trajetórias futuras ótimas (Levine 2018). Por exemplo, é possível fixar (ou seja, fixar o valor de ) o estado desejado futuro no modelo e então inferir a sequência de ações que tem mais probabilidade de preencher a lacuna do estado atual para o estado desejado futuro.

Inferência ativa, planejamento como inferência e outros esquemas relacionados usam uma forma prospectiva de controle, que começa a partir de uma representação explícita de estados futuros a serem observados, em vez de um conjunto de regras ou políticas de estímulo-resposta, como é mais tipicamente feito em teoria de controle ótimo e RL. No entanto, as implementações específicas de controle e planejamento como inferência variam ao longo de pelo menos três dimensões -- a saber, que forma de inferência eles usam (por exemplo, amostragem ou inferência variacional), o que eles inferem (por exemplo, uma distribuição posterior sobre ações ou sequências de ação) e o objetivo da inferência (por exemplo, maximizar a probabilidade marginal de uma condição de otimalidade ou a probabilidade de obter recompensa).

A Inferência Ativa adota uma perspectiva única sobre cada uma dessas dimensões. Primeiro, ele usa um esquema aproximado escalável -- inferência variacional -- para resolver os problemas computacionais desafiadores que surgem durante o planejamento como inferência. Em segundo lugar, permite o planejamento baseado em modelo, ou a inferência de um posterior sobre estados de controle - que correspondem a sequências de ação ou políticas, não ações únicas \footnote{No aprendizado de máquina, o processo de otimização de sequências de ações às vezes é chamado de otimização de política sequencial -- em oposição à otimização mais comum de políticas de ação de estado -- ou seja, ``Se estou nesse estado, o que faço?''}. inclui outros esquemas de planejamento como inferência amplamente utilizados (por exemplo, controle KL) e pode lidar com situações ambíguas (Friston, Rigoli et al.~2015).

\hypertarget{comportamento-e-racionalidade-limitada}{%
\section{Comportamento e Racionalidade Limitada}\label{comportamento-e-racionalidade-limitada}}

Os sábios são instruídos pela razão, as mentes medianas pela experiência, os estúpidos pela necessidade e os brutos pelo instinto.

---Marco Túlio Cícero

O comportamento na Inferência Ativa combina automaticamente vários componentes: deliberativo, perseverativo e habitual (Parr 2020). Imagine uma pessoa que está caminhando para uma loja perto de sua casa. Se ela prevê as consequências de suas ações (por exemplo, virar à esquerda ou à direita), ela pode elaborar um bom plano para chegar à loja. Esse aspecto deliberativo do comportamento é fornecido pela energia livre esperada, que é minimizada quando se age de forma a alcançar as observações preferidas (por exemplo, estar na loja). Observe que a energia livre esperada também inclui um impulso para reduzir a incerteza, que pode se manifestar na deliberação. Por exemplo, se a pessoa não tiver certeza sobre a melhor direção, ela pode se mover para um ponto de vista apropriado, de onde ela pode encontrar o caminho para a loja facilmente, mesmo que isso implique um caminho mais longo. Em suma, seus planos adquirem affordance epistêmica.

Se a pessoa for menos capaz de deliberar (por exemplo, porque está distraída), ela pode continuar andando depois de chegar à loja. Esse aspecto perseverativo do comportamento é fornecido pela energia livre variacional, que é minimizada quando se reúnem observações compatíveis com as crenças atuais, incluindo crenças sobre o curso atual das ações. As observações sensoriais e proprioceptivas que a pessoa reúne fornecem evidências para ``andar'' e, portanto, podem determinar perseverança na ausência de deliberação.

Observe que os aspectos deliberativos, perseverativos e habituais do comportamento coexistem e podem ser combinados na Inferência Ativa. Em outras palavras, pode-se inferir que, nessa situação, um hábito é o curso de ação mais provável. Isso é diferente das ``teorias duais'', que assumem que somos movidos por dois sistemas separados, um racional e outro intuitivo (Kahneman 2017). A mistura de aspectos deliberativos, perseverativos e habituais do comportamento depende plausivelmente de condições contextuais, como a quantidade de experiência e a quantidade de recursos cognitivos que se pode investir em processos deliberativos que podem ter um alto custo de complexidade.\footnote{A noção de implantar recursos cognitivos de forma eficiente é uma parte inerente da minimização de energia livre, porque minimizar a complexidade automaticamente maximiza a eficiência, tanto no sentido teórico da informação quanto no sentido termodinâmico. Simplificando, o caminho de menor resistência é o caminho de menor energia livre.}

O impacto dos recursos cognitivos na tomada de decisão tem sido amplamente estudado sob a rubrica da racionalidade limitada (Simon 1990). A ideia central é que enquanto um agente racional ideal deve sempre considerar completamente os resultados de suas ações, um agente racional limitado deve equilibrar os custos, esforço e pontualidade da computação -- por exemplo, os custos de processamento de informações para deliberar o melhor plano. (Todorov 2009, Gershman et al.~2015).

\hypertarget{teoria-da-energia-livre-da-racionalidade-limitada}{%
\subsection{Teoria da Energia Livre da Racionalidade Limitada}\label{teoria-da-energia-livre-da-racionalidade-limitada}}

A racionalidade limitada foi formulada em termos de minimização da energia livre de Helmholtz: uma construção termodinâmica que está estritamente relacionada à noção de energia livre variacional usada na Inferência Ativa; veja Gottwald e Braun (2020) para detalhes. A ``teoria da energia livre da racionalidade limitada'' formula as compensações da seleção de ações com capacidades limitadas de processamento de informações em termos de dois componentes da energia livre: energia e entropia (ver capítulo 2). O primeiro representa o valor esperado de uma escolha (um termo de precisão), e o último representa os custos de deliberação (um termo de complexidade). O que custa durante a deliberação é diminuir a entropia (ou complexidade) das crenças antes de uma escolha para torná-las mais precisas (Ortega e Braun 2013, Zénon et al.~2019). Intuitivamente, a escolha seria mais precisa (e potencialmente implicaria maior utilidade) com uma crença posterior mais precisa, mas como aumentar a precisão das crenças tem um custo, um tomador de decisão limitado precisa encontrar um compromisso -- minimizando a energia livre. Os mesmos trade-offs emergem na Inferência Ativa, produzindo assim formas de racionalidade limitada. A noção de racionalidade limitada também ressoa com o uso de um limite variacional na evidência (ou probabilidade marginal) que é um aspecto definitivo da Inferência Ativa. Em suma, a Inferência Ativa fornece um modelo de racionalidade (limitada) e de otimalidade, onde a melhor solução para um determinado problema resulta do compromisso entre objetivos complementares: precisão e complexidade. Esses objetivos derivam de um imperativo normativo (minimização de energia livre) que é mais rico do que os objetivos clássicos (por exemplo, maximização de utilidade) geralmente considerados na teoria econômica.

\hypertarget{valuxeancia-emouxe7uxe3o-e-motivauxe7uxe3o}{%
\section{Valência, emoção e motivação}\label{valuxeancia-emouxe7uxe3o-e-motivauxe7uxe3o}}

Considere suas origens: você não foi feito para viver como brutos, mas para seguir a virtude e o conhecimento.
---Dante Alighieri

A Inferência Ativa se concentra na energia livre (negativa) como uma medida de aptidão e da capacidade de um organismo de realizar seus objetivos. Embora a Inferência Ativa proponha que as criaturas ajam para minimizar sua energia livre, isso não significa que elas tenham que calculá-la. Geralmente, é suficiente lidar com os gradientes da energia livre. Por analogia, não precisamos saber nossa altitude para encontrar o topo de uma colina, mas podemos simplesmente seguir a inclinação para cima. No entanto, alguns sugeriram que as criaturas podem modelar como sua energia livre muda ao longo do tempo. Os proponentes dessa hipótese sugerem que ela pode permitir caracterizações de fenômenos como valência, emoção e motivação.

Nesta visão, foi proposto que a valência emocional, ou o caráter positivo ou negativo das emoções, pode ser concebida como a taxa de mudança (primeira derivada de t) da energia livre ao longo do tempo ( Joffily e Coricelli 2013). Especificamente, quando uma criatura experimenta um aumento em sua energia livre ao longo do tempo, ela pode atribuir uma valência negativa à situação; ao passo que quando experimenta uma diminuição de sua energia livre ao longo do tempo, pode atribuir-lhe uma valência positiva. Estendendo essa linha de pensamento para a dinâmica de longo prazo da energia livre (segunda derivada de t), pode ser possível caracterizar estados emocionais sofisticados; por exemplo, o alívio de passar de uma fase de baixa valência para uma fase de alta valência, ou o desapontamento de passar de uma fase de alta valência para uma fase de baixa valência. O monitoramento da dinâmica da energia livre (e dos estados emocionais que elas provocam) pode permitir a adaptação das estratégias comportamentais ou das taxas de aprendizado às estatísticas ambientais de longo prazo.

Pode parecer um salto assumir um segundo modelo generativo cujo papel é monitorar a energia livre do primeiro. No entanto, há outra maneira pela qual essas idéias podem ser interpretadas. Uma formalização interessante dessas perspectivas repousa em pensar sobre o que causa mudanças rápidas na energia livre. Como é um funcional das crenças, uma rápida mudança na energia livre deve ser devido à rápida atualização das crenças. O principal determinante dessa velocidade é a precisão, que atua como uma constante de tempo na dinâmica da codificação preditiva. Curiosamente, isso se relaciona com a noção de derivadas mais altas da energia livre, pois a precisão é o negativo da segunda derivada (ou seja, a curvatura de uma paisagem de energia livre). No entanto, isso levanta a questão de por que devemos associar precisão com valência. A resposta vem da observação de que a precisão está inversamente relacionada à ambiguidade. Quanto mais preciso algo é, menos ambígua sua interpretação. Escolher um curso de ação que minimize a energia livre esperada também significa minimizar a ambiguidade e, portanto, maximizar a precisão. Aqui vemos uma associação direta entre derivadas de alta ordem da energia livre, sua taxa de mudança e comportamento motivado.

As expectativas sobre (aumento ou diminuição da) energia livre podem desempenhar papéis motivacionais e incentivar o comportamento também. Na Inferência Ativa, uma expectativa substituta sobre mudanças (aumento ou diminuição) da energia livre é a precisão das crenças sobre as políticas. Isso novamente destaca a importância dessa estatística de segunda ordem. Por exemplo, uma crença altamente precisa sinaliza que se encontrou uma boa política - isto é, uma política que pode ser seguramente esperada para minimizar a energia livre. Curiosamente, a precisão das (crenças sobre) políticas tem sido associada à sinalização de dopamina (FitzGerald, Dolan e Friston 2015). Nessa perspectiva, os estímulos que aumentam a precisão das crenças sobre as políticas desencadeiam explosões de dopamina -- o que pode indicar sua saliência de incentivo (Berridge 2007). Essa perspectiva pode ajudar a esclarecer os mecanismos neurofisiológicos que ligam as expectativas de realização de metas ou recompensas a aumentos de atenção (Anderson et al.~2011) e motivação (Berridge e Kringelbach 2011).

\hypertarget{homeostase-alostase-e-processamento-interoceptivo}{%
\section{Homeostase, Alostase e Processamento Interoceptivo}\label{homeostase-alostase-e-processamento-interoceptivo}}

Há mais sabedoria em seu corpo do que em sua filosofia mais profunda.
---Friedrich Nietzche

O modelo generativo de uma criatura não é apenas sobre o mundo externo, mas também -- e talvez ainda mais importante -- sobre o meio interno. Um modelo generativo do interior de um corpo (ou esquema interoceptivo) tem um papel duplo: explicar como as sensações interoceptivas (corporais) são geradas e garantir a regulação correta de parâmetros fisiológicos (Iodice et al.~2019), como temperatura corporal ou níveis de açúcar No Sangue. As teorias cibernéticas (abordadas na seção 10.6.2) assumem que um objetivo central dos organismos vivos é manter a homeostase (Cannon, 1929) -- garantir que os parâmetros fisiológicos permaneçam dentro de faixas viáveis (por exemplo, a temperatura corporal nunca se torne muito alta) -- e que a homeostase só pode ser alcançado exercendo um controle bem-sucedido sobre o meio ambiente (Ashby 1952).

Esta forma de regulação homeostática pode ser alcançada na Inferência Ativa, especificando os intervalos viáveis \hspace{0pt}\hspace{0pt}de parâmetros fisiológicos como prioritários sobre observações interoceptivas. Curiosamente, a regulação homeostática pode ser alcançada de várias maneiras aninhadas. O circuito regulador mais simples é o envolvimento de reflexos autônomos (por exemplo, vasodilatação), quando certos parâmetros estão (espera-se que estejam) fora de alcance -- por exemplo, quando a temperatura corporal está muito alta. Esse controle autonômico pode ser construído como inferência interoceptiva: um processo de Inferência Ativa que opera em fluxos interoceptivos em vez de fluxos proprioceptivos, como no caso de ações direcionadas externamente (Seth et al.~2012, Seth e Friston 2016, Allen et al.~2019) . Para isso, o cérebro pode usar um modelo generativo que prevê fluxos interoceptivos e fisiológicos e desencadeia reflexos autônomos para corrigir erros de previsão interoceptiva (por exemplo, uma temperatura corporal surpreendentemente alta). Isso é análogo à maneira como os reflexos motores são ativados para corrigir erros de previsão proprioceptiva e orientar ações direcionadas externamente.

A Inferência Ativa vai além dos simples loops autonômicos: ela pode corrigir o mesmo erro de previsão interoceptiva (alta temperatura corporal) de maneiras cada vez mais sofisticadas (Pezzulo, Rigoli e Friston 2015). Ele pode usar estratégias preditivas e alostáticas (Sterling 2012, Barrett e Simmons 2015, Corcoran et al.~2020) que vão além da homeostase e controlam preventivamente a fisiologia de maneira alostática antes que os erros de previsão interoceptiva sejam acionados - por exemplo, encontrar sombra antes do superaquecimento. Outra estratégia preditiva envolve a mobilização de recursos antes das excursões esperadas dos pontos de ajuste fisiológicos -- por exemplo, aumentar o débito cardíaco antes de uma corrida longa em antecipação ao aumento da demanda de oxigênio. Isso requer modificar dinamicamente as prévias sobre as observações interoceptivas, indo além da homeostase (Tschantz et al.~2021). Eventualmente, cérebros preditivos podem desenvolver estratégias sofisticadas direcionadas a objetivos, como garantir que alguém traga água fria para a praia, atendendo ao mesmo imperativo (controlar a temperatura corporal) de maneiras mais ricas e eficazes.

A regulação biológica e interoceptiva pode ser crucial para o processamento afetivo e emocional (Barrett 2017). Durante as interações situadas, o modelo generativo do cérebro prevê constantemente não apenas o que acontecerá a seguir, mas também quais são as consequências para a interocepção e a alostase. Fluxos interoceptivos -- eliciados durante a percepção de objetos e eventos externos -- os imbuem de uma dimensão afetiva, que sinaliza o quão bons ou ruins eles são para a alostase e sobrevivência da criatura, tornando-os ``significativos''. Se essa visão estiver correta, os distúrbios desse processamento interoceptivo e alostático podem gerar desregulação emocional e várias condições psicopatológicas (Pezzulo 2013; Barrett et al.~2016; Maisto, Barca et al.~2019; Pezzulo, Maisto et al.~2019).

Há um companheiro emergente para a inferência interoceptiva -- a saber, a inferência emocional. Nesta aplicação da Inferência Ativa, as emoções são consideradas parte do modelo generativo: elas são apenas mais uma construção ou hipótese que o cérebro emprega para implantar a precisão em modelos generativos profundos. Do ponto de vista da atualização de crenças, isso significa que a ansiedade é apenas um compromisso com a crença bayesiana ``estou ansioso'' que melhor explica as filas sensoriais e interoceptivas predominantes. Do ponto de vista da atuação, as previsões (interoceptivas) subsequentes aumentam ou atenuam várias precisões (ou seja, ação encoberta) ou escravizam as respostas autônomas (ou seja, ação aberta). Isso pode parecer muito com excitação, o que confirma a hipótese de que ``estou ansioso''. Normalmente, a inferência emocional envolve a atualização de crenças que é geral de domínio, assimilando informações de fluxos sensoriais interoceptivos e exteroceptivos - daí a relação íntima entre emoção, interocepção e atenção na saúde (Seth e Friston 2016; Smith, Lane et al.~2019; Smith , Parr e Friston 2019) e doença (Peters et al.~2017, J. E. Clark et al.~2018).

\hypertarget{atenuxe7uxe3o-saliuxeancia-e-dinuxe2mica-epistuxeamica}{%
\section{Atenção, Saliência e Dinâmica Epistêmica}\label{atenuxe7uxe3o-saliuxeancia-e-dinuxe2mica-epistuxeamica}}

A verdadeira ignorância não é a ausência de conhecimento, mas a recusa em adquiri-lo. --- Karl Popper

Dado o número de vezes que nos referimos à precisão e à energia livre esperada apenas neste capítulo, seria negligente não dedicar um pouco de espaço à atenção e à saliência. Esses conceitos são recorrentes em toda a psicologia, tendo sido objeto de inúmeras redefinições e classificações. Às vezes, esses termos são usados para se referir a mecanismos de controle de ganho sináptico (Hillyard et al.~1998), que selecionam preferencialmente alguma modalidade sensorial ou subconjunto de canais dentro de uma modalidade. Às vezes, eles se referem a como nos orientamos, por meio de ação aberta ou encoberta, para obter mais informações sobre o mundo (Rizzolatti et al.~1987; Sheliga et al.~1994, 1995).

Embora a incerteza proporcionada pelos muitos significados de atenção subscreva parte da atratividade epistêmica desse campo de estudo, também há valor em resolver a ambiguidade associada. Uma das coisas oferecidas por uma perspectiva formal da psicologia é que não precisamos nos preocupar com essa ambiguidade. Podemos definir operacionalmente a atenção como a precisão associada a alguma entrada sensorial. Isso mapeia perfeitamente o conceito de controle de ganho, pois as sensações que inferimos como mais precisas terão maior influência sobre a atualização de crenças do que aquelas inferidas como imprecisas. A validade de construto desta associação foi demonstrada em relação aos paradigmas psicológicos, incluindo o famoso paradigma de Posner (Feldman e Friston 2010). Especificamente, responder a um estímulo em um local no espaço visual com maior precisão é mais rápido do que responder a estímulos em outros locais.

Isso deixa o termo saliência sem uma definição formal semelhante. Normalmente, na Inferência Ativa, associamos a saliência ao ganho de informação esperado (ou valor epistêmico): um componente da energia livre esperada. Intuitivamente, algo é mais saliente quando esperamos que produza mais informações. No entanto, isso define saliência em termos de uma ação ou política, enquanto a atenção é um atributo de crenças sobre entrada sensorial. Isso se encaixa com a noção de saliência como orientação aberta ou encoberta. Vimos no capítulo 7 que poderíamos subdividir ainda mais o ganho de informação esperado em relevância e novidade. O primeiro é o potencial para inferir, enquanto o último é o potencial para aprender. Uma analogia que expressa a diferença entre atenção e saliência (ou novidade) é o desenho e a análise de um experimento científico. Atenção é o processo de selecionar os dados da mais alta qualidade a partir do que já medimos e usá-los para informar nosso teste de hipóteses. Saliência é o design do próximo experimento para garantir dados da mais alta qualidade.

Não nos debruçamos sobre essa questão para simplesmente adicionar outra reclassificação dos fenômenos atencionais à literatura, mas para destacar uma importante vantagem em se comprometer com uma psicologia formal. Sob a Inferência Ativa, não importa se outros definem atenção (ou qualquer outro construto) de forma diferente -- pois podemos simplesmente nos referir aos construtos matemáticos em questão e evitar qualquer confusão. Um ponto final de consideração é que essas definições oferecem uma explicação simples de por que atenção e saliência são tão frequentemente confundidas. Dados altamente precisos são minimamente ambíguos. Isso significa que eles devem receber atenção e que as ações para adquirir esses dados são altamente salientes (Parr e Friston 2019a).

\hypertarget{aprendizado-de-regras-inferuxeancia-causal-e-generalizauxe7uxe3o-ruxe1pida}{%
\section{Aprendizado de regras, inferência causal e generalização rápida}\label{aprendizado-de-regras-inferuxeancia-causal-e-generalizauxe7uxe3o-ruxe1pida}}

Ontem eu era inteligente, então eu queria mudar o mundo. Hoje eu sou sábio, então estou mudando a mim mesmo.
---Rumi

Humanos e outros animais se destacam em fazer inferências causais sofisticadas, aprender conceitos abstratos e relações causais entre objetos e generalizar a partir de experiências limitadas -- em contraste com os paradigmas atuais de aprendizado de máquina, que exigem um grande número de exemplos para obter desempenho semelhante. Essa diferença sugere que as abordagens atuais de aprendizado de máquina, que são amplamente baseadas em reconhecimento de padrões sofisticados, podem não capturar totalmente as maneiras como os humanos aprendem e pensam (Lake et al.~2017).

O paradigma de aprendizagem da Inferência Ativa baseia-se no desenvolvimento de modelos generativos que capturam as relações causais entre ações, eventos e observações. Neste livro, consideramos tarefas relativamente simples (por exemplo, o exemplo do labirinto em T do capítulo 7) que requerem modelos generativos não sofisticados. Em contraste, entender e raciocinar sobre situações complexas requer modelos generativos profundos que capturem a estrutura latente do ambiente -- como regularidades ocultas que permitem generalizar em várias situações aparentemente diferentes (Tervo et al.~2016; Friston, Lin et al.~2017 ).

Um exemplo simples de uma regra oculta que governa interações sociais sofisticadas é uma interseção de trânsito. Imagine uma pessoa ingênua que observa uma encruzilhada movimentada e tem que prever (ou explicar) em que ocasiões pedestres ou carros atravessam a rua. A pessoa pode acumular estatísticas sobre a co-ocorrência de eventos (por exemplo, um carro vermelho parando e um homem alto atravessando; uma velha parando e um carro grande passando), mas a maioria acaba sendo inútil. A pessoa pode eventualmente descobrir alguns padrões estatísticos recorrentes, como os pedestres atravessam a estrada logo após todos os carros pararem em um determinado ponto da estrada. Essa determinação seria considerada suficiente em uma configuração de aprendizado de máquina se a tarefa fosse apenas prever quando os pedestres estão prestes a andar, mas não implicaria qualquer compreensão da situação. Na verdade, pode até levar à conclusão errônea de que a parada dos carros explica o movimento dos pedestres. Esse tipo de erro é típico em aplicativos de aprendizado de máquina que não apelam para modelos (causais) e não conseguem distinguir se a chuva explica a grama molhada ou a grama molhada explica a chuva (Pearl e Mackenzie 2018).

Por outro lado, inferir a regra oculta correta (por exemplo, semáforo) fornece uma compreensão mais profunda da estrutura causal da situação (por exemplo, é o semáforo que faz com que os carros parem e os pedestres andem). A regra oculta não apenas oferece melhor poder preditivo, mas também torna a inferência mais parcimoniosa, pois pode abstrair a maioria dos detalhes sensoriais (por exemplo, a cor dos carros). Por sua vez, isso permite generalizar para outras situações, como diferentes encruzilhadas ou cidades, onde a maioria dos detalhes sensoriais difere significativamente -- com a ressalva de que enfrentar encruzilhadas em algumas cidades, como Roma, pode exigir mais do que olhar os semáforos. Finalmente, aprender sobre as regras do semáforo também pode permitir um aprendizado mais eficiente em novas situações -- ou desenvolver o que é chamado de ``conjunto de aprendizado'' em psicologia ou uma habilidade de aprender a aprender em aprendizado de máquina (Harlow 1949). Ao enfrentar uma encruzilhada onde o semáforo está desligado, não se pode usar a regra aprendida, mas pode-se esperar que haja outra regra oculta semelhante em jogo -- e isso pode ajudar a entender o que o policial de trânsito está fazendo.

Como este exemplo simples ilustra, aprender modelos generativos ricos -- da estrutura latente do ambiente (também conhecido como aprendizado de estrutura) -- oferece formas sofisticadas de raciocínio causal e generalização. Ampliar modelos generativos para lidar com essas situações sofisticadas é um objetivo contínuo em modelagem computacional e ciência cognitiva (Tenenbaum et al.~2006, Kemp e Tenenbaum 2008). Curiosamente, há uma tensão entre as tendências atuais de aprendizado de máquina -- em que a ideia geral é ``quanto maior, melhor'' -- e a abordagem estatística da Inferência Ativa -- que sugere a importância de equilibrar a precisão de um modelo com sua complexidade e favorecer modelos mais simples. A redução do modelo (e a poda de parâmetros desnecessários) não é simplesmente uma maneira de evitar o desperdício de recursos - é também uma maneira eficaz de aprender regras ocultas, inclusive durante períodos offline como o sono (Friston, Lin et al.~2017), talvez se manifestando em atividade do estado de repouso (Pezzulo, Zorzi e Corbetta 2020).

\hypertarget{inferuxeancia-ativa-e-outros-campos-direuxe7uxf5es-abertas}{%
\section{Inferência ativa e outros campos: direções abertas}\label{inferuxeancia-ativa-e-outros-campos-direuxe7uxf5es-abertas}}

Tem que começar em algum lugar, tem que começar em algum momento, que lugar melhor do que aqui? Que melhor hora do que agora?
---Rage Against the Machine, ``Guerrilla Radio''

Neste livro, nos concentramos principalmente em modelos de Inferência Ativa que abordam problemas biológicos de sobrevivência e adaptação. No entanto, a Inferência Ativa pode ser aplicada em muitos outros domínios. Nesta última seção, discutimos brevemente dois desses domínios: dinâmica social e cultural e aprendizado de máquina e robótica. Abordar o primeiro requer pensar sobre as maneiras pelas quais vários agentes de Inferência Ativa interagem e os efeitos emergentes de tal interação. Abordar o último requer entender como a Inferência Ativa pode ser dotada de mecanismos de aprendizado (e inferência) mais eficazes para escalar problemas mais complexos - mas de uma maneira compatível com os pressupostos básicos da teoria. Ambos são interessantes direções abertas para a pesquisa.

\hypertarget{dinuxe2micas-sociais-e-culturais}{%
\subsection{Dinâmicas Sociais e Culturais}\label{dinuxe2micas-sociais-e-culturais}}

Muitos aspectos interessantes de nossa cognição (humana) relacionam-se a dinâmicas sociais e culturais em vez de percepções, decisões e ações individualistas (Veissière et al.~2020). Por definição, a dinâmica social requer múltiplas criaturas de Inferência Ativa que se envolvem em interações físicas (por exemplo, ações conjuntas, como praticar esportes coletivos) ou interações mais abstratas (por exemplo, eleições ou redes sociais). Demonstrações simples de inferência interativa entre organismos idênticos já produziram fenômenos emergentes interessantes, como a auto-organização de formas de vida simples que resistem à dispersão, a possibilidade de se engajar em processos morfogenéticos para adquirir e restaurar uma forma corporal e previsão e coordenação mútuas. tomada de turnos (Friston 2013; Friston e Frith 2015a; Friston, Levin et al.~2015). Outras simulações abordaram as maneiras pelas quais as criaturas podem estender sua cognição a artefatos materiais e moldar seus nichos cognitivos (Bruineberg et al.~2018). Essas simulações capturam apenas uma fração da complexidade de nossa dinâmica social e cultural, mas ilustram o potencial da Inferência Ativa para expandir de uma ciência de indivíduos para uma ciência de sociedades -- e como a cognição se estende além de nossos crânios (Nave et al.~2020 ).

\hypertarget{aprendizado-de-muxe1quina-e-robuxf3tica}{%
\subsection{Aprendizado de máquina e robótica}\label{aprendizado-de-muxe1quina-e-robuxf3tica}}

Os métodos de modelagem generativa e inferência variacional discutidos neste livro são amplamente utilizados em aprendizado de máquina e robótica. Nesses campos, a ênfase geralmente está em como aprender modelos generativos (conexionistas) --- em oposição a como usá-los para a Inferência Ativa, o foco deste livro. Isso é interessante, pois as abordagens de aprendizado de máquina são potencialmente úteis para aumentar a complexidade dos modelos generativos e dos problemas considerados neste livro - com a ressalva de que podem recorrer a teorias de processo muito diferentes da Inferência Ativa.

Embora seja impossível revisar aqui a vasta literatura sobre modelagem generativa em aprendizado de máquina, mencionamos brevemente alguns dos modelos mais populares, a partir dos quais muitas variantes foram desenvolvidas. Dois primeiros modelos generativos conexionistas, a máquina de Helmholtz e a máquina de Boltzmann (Ackley et al.~1985, Dayan et al.~1995), forneceram exemplos paradigmáticos de como aprender as representações internas de uma rede neural de forma não supervisionada. A máquina de Helmholtz está especialmente relacionada à abordagem variacional da Inferência Ativa, pois usa redes generativas e de reconhecimento separadas para inferir uma distribuição sobre variáveis \hspace{0pt}\hspace{0pt}ocultas e amostrar delas para obter dados fictícios. O sucesso prático inicial desses métodos foi limitado. Mas depois, a possibilidade de empilhar várias máquinas Boltzmann (restritas) permitiu o aprendizado de várias camadas de representações internas e foi um dos primeiros sucessos das redes neurais profundas não supervisionadas (Hinton 2007).

Dois exemplos recentes de modelos generativos conexionistas, autoencoders variacionais ou VAEs (Kingma e Welling 2014) e redes adversariais generativas ou GANs (Goodfellow et al.~2014), são amplamente utilizados em aplicações de aprendizado de máquina, como reconhecimento ou geração de imagens e vídeos. Os VAEs exemplificam uma aplicação elegante de métodos variacionais ao aprendizado em redes generativas. Seu objetivo de aprendizado, o limite inferior de evidência (ELBO), é matematicamente equivalente à energia livre variacional. Esse objetivo permite o aprendizado de uma descrição precisa dos dados (ou seja, maximiza a precisão), mas também favorece representações internas que não diferem muito de suas anteriores (ou seja, minimizam a complexidade). Este último objetivo atua como um chamado regularizador, o que ajuda a generalizar e evitar o overfitting.

As GANs seguem uma abordagem diferente: combinam duas redes, uma rede generativa e uma rede discriminativa, que competem continuamente durante o aprendizado. A rede discriminativa aprende a distinguir quais dados de exemplo produzidos pela rede generativa são reais ou fictícios. A rede generativa tenta gerar dados fictícios que enganam (ou seja, são classificados erroneamente por) a rede discriminativa. A corrida entre essas duas redes força a rede generativa a melhorar suas capacidades generativas e produzir dados fictícios de alta fidelidade -- uma capacidade que tem sido amplamente explorada para gerar, por exemplo, imagens realistas.

Os modelos generativos acima (e outros) podem ser usados para tarefas de controle. Por exemplo, Ha e Eck (2017) usaram um VAE (sequência a sequência) para aprender a prever traços de lápis. Por amostragem da representação interna do VAE, o modelo pode construir novos desenhos baseados em traços. Abordagens de modelagem generativa também têm sido usadas para controlar os movimentos do robô. Algumas dessas abordagens usam Inferência Ativa (Pio-Lopez et al.~2016, Sancaktar et al.~2020, Ciria et al.~2021) ou ideias intimamente relacionadas, mas em um cenário conexionista (Ahmadi e Tani 2019, Tani e White 2020).

Um dos principais desafios neste domínio é que os movimentos do robô são de alta dimensão e requerem (aprendizagem) modelos generativos sofisticados. Um aspecto interessante da Inferência Ativa e abordagens relacionadas é que a coisa mais importante a ser aprendida é um mapeamento direto entre ações e feedback sensorial (por exemplo, visual e proprioceptivo) na próxima etapa de tempo. Esse mapeamento direto pode ser aprendido de várias maneiras: por exploração autônoma, por demonstração ou mesmo por interação direta com um humano -- por exemplo, um professor (o experimentador) que guia as mãos do robô ao longo de uma trajetória até o objetivo, portanto, andaime para a aquisição de ações efetivas direcionadas a objetivos (Yamashita e Tani 2008). A possibilidade de aprender modelos generativos de várias maneiras expande muito o escopo das habilidades do robô que podem ser eventualmente alcançadas. Por sua vez, a possibilidade de desenvolver robôs (neuro-) mais avançados usando Inferência Ativa pode ser importante não apenas por razões tecnológicas, mas também teóricas. De fato, alguns aspectos-chave da Inferência Ativa, como as interações adaptativas agente-ambiente, a integração de funções cognitivas e a importância da incorporação, são naturalmente abordados em configurações robóticas.

\hypertarget{resumo-9}{%
\section{Resumo}\label{resumo-9}}

O lar está atrás, o mundo à frente, e há muitos caminhos para trilhar através das sombras até a beira da noite, até que as estrelas estejam todas acesas.
---J. R. R. Tolkien, O Senhor dos Anéis

Começamos este livro perguntando se é possível entender o cérebro e o comportamento a partir dos primeiros princípios. Em seguida, introduzimos a Inferência Ativa como uma teoria candidata para enfrentar esse desafio. Esperamos que o leitor tenha se convencido de que a resposta à nossa pergunta original é sim. Neste capítulo, consideramos a perspectiva unificada que a Inferência Ativa oferece sobre o comportamento senciente e quais implicações essa teoria tem para construções psicológicas familiares, como percepção, seleção de ação e emoção. Isso nos deu a oportunidade de revisitar os conceitos introduzidos ao longo do livro e nos lembrar das fascinantes questões ainda abertas para pesquisas futuras. Esperamos que este livro forneça um complemento útil para trabalhos relacionados sobre Inferência Ativa, incluindo, por um lado, a filosofia (Hohwy 2013, Clark 2015) e, por outro lado, a física (Friston 2019a).

Estamos agora no final de nossa jornada. Nosso objetivo foi oferecer uma introdução aos interessados \hspace{0pt}\hspace{0pt}em usar esses métodos - tanto em nível conceitual quanto formal. No entanto, é importante enfatizar que a Inferência Ativa não é algo que pode ser aprendido puramente na teoria. Incentivamos qualquer pessoa que tenha gostado deste livro a pensar em realizá-lo na prática. Ritos de passagem importantes na neurobiologia teórica são tentar escrever um modelo generativo, experimentar a frustração quando as simulações se comportam mal e aprender com as violações de suas crenças anteriores quando algo inesperado acontece. Independentemente de você optar ou não por seguir essa prática em um nível computacional, esperamos que você reflita sobre isso ao se envolver na Inferência Ativa no dia-a-dia. Isso pode se manifestar na compulsão de direcionar seus olhos para resolver a incerteza sobre algo em sua visão periférica. Pode ser na escolha de comer em um restaurante favorito para atender às preferências (gustativas) anteriores. Pode ser na redução do calor quando o chuveiro está muito quente para garantir que a temperatura esteja de acordo com o seu modelo de como o mundo deveria ser. Em última análise, estamos confiantes de que você continuará a buscar a Inferência Ativa de alguma forma.

\cleardoublepage

\hypertarget{appendix-apuxeandice}{%
\appendix}


\hypertarget{bases-matemuxe1ticas}{%
\chapter{Bases Matemáticas}\label{bases-matemuxe1ticas}}

\hypertarget{introduuxe7uxe3o-10}{%
\section{Introdução}\label{introduuxe7uxe3o-10}}

Este apêndice oferece uma introdução (ou uma atualização) às técnicas matemáticas básicas empregadas ao longo deste livro. Fornecemos uma visão geral introdutória (mas não exaustiva) de quatro tópicos: álgebra linear, aproximação de séries de Taylor, cálculo variacional e dinâmica estocástica. Para cada uma dessas técnicas, nos referimos a onde ela entra em jogo no livro. Nosso objetivo aqui é fornecer uma introdução focada - com ênfase na construção da intuição em oposição a provas formais e rigorosas. A matemática necessária para entender e usar a Inferência Ativa não é complicada, mas sua base multidisciplinar significa que muitas vezes é difícil encontrar recursos que reúnam os pré-requisitos necessários. Esperamos que este apêndice ajude de alguma forma a remediar isso.

\hypertarget{uxe1lgebra-linear}{%
\section{Álgebra Linear}\label{uxe1lgebra-linear}}

\hypertarget{o-buxe1sico}{%
\subsection{O básico}\label{o-buxe1sico}}

Álgebra linear refere-se a uma notação usada para expressar de forma simples e concisa combinações de multiplicações e somatórias. Ele se baseia em matrizes e vetores que compreendem matrizes de números em estruturas com várias linhas e colunas (ou várias linhas e uma única coluna, para um vetor). O elemento de uma matriz \(A\) na linha \(i\) e na coluna \(j\) é referido como \(A_{ij}\). O produto \(A\) de duas matrizes \(B\) e \(C\) (ou uma matriz e um vetor) é definido da seguinte forma:

\[ A = BC \]
\[\Longrightarrow \qquad (A.1)\]
\[ A_{ij} = \sum_k B_{ik} C_{kj} \]
Para que essa definição seja válida, precisamos que o número de colunas de B corresponda ao número de linhas de C. No entanto, digamos que o número de colunas de B corresponda às colunas de C e queremos expressar a seguinte soma:

\[ A_{ij} = \sum_k B_{ki} C_{kj} \qquad (A.2) \]

Como faríamos isso usando a notação algébrica linear? Precisamos apelar para outra operação que troque os índices subscritos de B (ou seja, reflita a matriz de modo que as colunas se tornem linhas e vice-versa). Esta é a operação de transposição, normalmente expressa usando um T sobrescrito:

\[B_{ik}^T \triangleq B_{ki}\]

\[A=B^TC \triangleq B \cdot C\]

\[ \Longrightarrow \qquad (A.3)\]
\[A_{ij} = \sum_k B_{ki}C_{kj}\]

A Equação A.3 mostra como podemos usar o operador de transposição para expressar a soma da equação A.2. A segunda linha destaca uma notação alternativa usando um operador de ponto. Essa notação é inspirada no fato de que, quando B e C têm apenas uma coluna cada, a equação A.3 se reduz a um produto vetorial vetorial.
Outra operação útil é o operador de rastreamento. Isso pega os elementos ao longo da diagonal de uma matriz quadrada e os soma:

\[ tr[A] \triangleq \sum_i A_{ij} \qquad (A.4)\]

Parte da utilidade de um operador de traço é proporcionada pela maneira como podemos permutar elementos no traço de um produto de matriz:

\[ tr[ABC] = \sum_i \sum_j \sum_k A_{ij} B_{jk} C_{ki}\]
\[ = \sum_k \sum_i \sum_j C_{ki} A_{ij} B_{jk} = tr[CAB] \]
\[ = \sum_j \sum_k \sum_i B_{jk} C_{ki} A_{ij} = tr[BCA] \qquad (A.5) \]
O principal uso que encontraremos para essa identidade neste livro é quando aplicada a grandezas escalares. Um escalar pode ser visto como uma matriz com apenas uma linha e uma coluna. Como tal, podemos aplicar um operador de rastreamento a ele, mas isso não fará nada - obtemos o mesmo escalar. Isso significa que, se um produto de matriz der origem a uma quantidade escalar, podemos permutar os termos como acima.

Por exemplo, se tivermos uma matriz quadrada \(B\) com \(N\) colunas e linhas e um vetor \(c\) com \(N\) linhas, podemos usar a equação A.5 para mostrar o seguinte:

\[ a = c \cdot Bc\]

\[ tr[c^T Bc] \]
\[ tr[Bcc^T] \qquad (A.6)\]
\[ tr[BC]\]
\[ C = c \otimes c \triangleq cc^T  \]
Isso reexpressa uma expressão quadrática (primeira linha) com o traço do produto de duas matrizes (penúltima linha). A linha final define o produto externo(em contraste com o produto escalar interno)

A Equação A.6 torna-se particularmente útil no contexto de distribuições normais multivariadas, como veremos na seção A.2.3.

Os conceitos finais de álgebra linear a serem observados são o inverso e o determinante de uma matriz. Uma inversa é definida da seguinte forma:

\[ A^{-1}A = AA^{-1} = I \qquad (A.7)\]

A Equação A.7 diz que o produto de uma matriz e sua inversa é a matriz identidade --- uma matriz quadrada com uns ao longo de sua principal e zeros em outros lugares. Multiplicar qualquer matriz pela matriz identidade retorna a matriz original, inalterada. É o equivalente algébrico linear da multiplicação escalar por 1 (que pode ser interpretado como uma matriz identidade unidimensional). Isso significa que se multiplicarmos algo por uma matriz e depois pela inversa dessa matriz, acabamos com a quantidade original.

O determinante é uma quantidade útil, mas para a qual é mais difícil desenvolver uma intuição clara. O único ponto em que aparece neste livro é como parte da constante normalizadora de uma distribuição normal multivariada. Como tal, vale a pena saber como é calculado, mas não nos deteremos neste conceito. O determinante é definido recursivamente da seguinte forma:

\[ |A| \triangleq \sum_i(-1)^{i-1}A_{}1i | A_{\setminus(1,i)} |  \]

Aqui, a notação ted. Por exemplo:
\(A_{\setminus(1, i)}\) significa a matriz A com linha 1 e coluna i omitidas. Por exemplo:

\[ A = 
\begin{bmatrix} 
  A_{11} A_{12} \\ 
  A_{21} A_{22} 
  \end{bmatrix}
  \]

\[ A_{\setminus(1,1)} = A_{22}\]
\[ A_{\setminus(1,2)} = A_{21} \qquad (A.9)\]
\[ |A| = A_{11} \; |A_{22}| -  A_{12} \;| A_{21}|\]
\[  A_{11}A_{22} - A_{12}A_{21} \]
Isso conclui nosso esboço das operações básicas da álgebra linear.

\hypertarget{derivadas}{%
\subsection{Derivadas}\label{derivadas}}

A diferenciação de grandezas matriciais e vetoriais segue diretamente da aplicação do cálculo padrão a cada elemento de uma matriz. Por exemplo, se temos uma matriz B cujos elementos são funções de um escalar x, a derivada de B em relação a x é a seguinte:

\[ A(x) = \partial_x B(x)  \]
\[ A(x)_{ij} = \partial_x B(x)_{ij} \qquad (A.10)\]
\[ \partial x \triangleq  \frac {\partial} {\partial x} \]
No entanto, algumas definições e identidades importantes serão úteis para entender os detalhes técnicos deste livro. A primeira é como obter derivadas em relação a quantidades não escalares. Se tivermos uma quantidade vetorial b que é função de outro vetor c, a derivada de b em relação a c é uma matriz:

\[ A = \partial_c b(c) \Longrightarrow A{ij} = \partial_{c_j}b(c)_i  \qquad (A.11)\]
Também faremos uso do operador gradiente, que trata de derivadas em relação a um vetor. Isso é definido da seguinte forma:

\[ \nabla_b = \begin{bmatrix} 
\partial_{b_1} &  \partial_{b_1} & \partial_{b_1} & \cdots 
\end{bmatrix}^T  \]

\[ a = \nabla_bx(b) \qquad (A.12)\]

\[ \Longrightarrow \]

\[ a_i = \partial_{b_i}x(b)\]
A definição do operador gradiente como um vetor de operadores derivativos também fornece uma definição concisa de uma quantidade relacionada - a divergência de uma função vetorial:

\[ \nabla_a \cdot b(a) = \sum_i \partial_{a_i}b(a)_i \qquad (A.13)\]

Existem muitas identidades derivadas úteis para grandezas algébricas lineares, mas não tentaremos fornecer uma visão geral abrangente; para os leitores que desejam se aprofundar mais, recomendamos The Matrix Cookbook (Petersen e Pedersen 2012). Aqui, nos limitamos a duas identidades que serão particularmente úteis. O primeiro é o gradiente de uma quantidade quadrática:

\[ d(a) = \nabla_a(b(a) \cdot Cb(a))\]
\[ \Longrightarrow\]
\[d(a)_i\]

\hypertarget{as-equauxe7uxf5es-da-inferuxeancia-ativa}{%
\chapter{As equações da inferência ativa}\label{as-equauxe7uxf5es-da-inferuxeancia-ativa}}

\hypertarget{introduuxe7uxe3o-11}{%
\section{Introdução}\label{introduuxe7uxe3o-11}}

Neste apêndice, fornecemos um resumo matemático da Inferência Ativa. Isso complementa as equações nos capítulos principais com detalhes sobre de onde elas vêm e visa preencher algumas das etapas intermediárias omitidas. Isso baseia-se diretamente no fundo matemático do apêndice A e lida com inferência em processos de decisão Markov parcialmente observados (POMDP) e arquiteturas de codificação preditivas, e aborda questões de aprendizagem de estrutura e redução de modelo aludidas no texto principal. Nosso objetivo é que isso seja relativamente autocontido, com foco particular em tópicos que frequentemente causam confusão. Os leitores devem ter certeza de que não é necessário entender tudo neste apêndice para poder aplicar utilmente a Inferência Ativa; isso é mais para quem quer maior
detalhe técnico.

\hypertarget{processos-de-decisuxe3o-de-markov}{%
\section{Processos de decisão de Markov}\label{processos-de-decisuxe3o-de-markov}}

\hypertarget{inferuxeancia-do-estado}{%
\subsection{Inferência do Estado}\label{inferuxeancia-do-estado}}

Ao resolver um problema de POMDP, nosso objetivo é selecionar o curso de ação ou política apropriado. Sob Inferência Ativa, isso é enquadrado como um problema de inferência, no qual devemos encontrar uma distribuição de probabilidade posterior sobre políticas alternativas. Para calcular uma probabilidade posterior, precisamos de duas coisas: a probabilidade anterior de políticas (abordadas na seção B.2.2) e a probabilidade de observações de uma política. Esta seção se concentra neste último.

A probabilidade de observações dada uma política não é simples de calcular. Isso ocorre porque um problema POMDP é estruturado de forma que as políticas (π) influenciem as trajetórias (indicadas por \textasciitilde) dos estados (s) que influenciam os resultados (o) sem uma influência direta das políticas nos resultados. O problema então envolve uma soma sobre trajetórias de estados para marginalizá-los e encontrar
uma probabilidade marginal de observações dadas políticas:

\[P(\tilde o | \pi ) = \sum_\tilde S P(\tilde o | \tilde s)P(\tilde s | \tilde \pi ) \qquad\qquad\qquad (B.1) \]

\cleardoublepage

\hypertarget{dicionuxe1rio}{%
\chapter*{Dicionário}\label{dicionuxe1rio}}
\addcontentsline{toc}{chapter}{Dicionário}

\textbf{enação} : uma maneira de interagir com o ambiente que se baseia no conhecimento adquirido através de ações físicas e habilidades motoras

\textbf{princípio de ação estacionária de Hamilton} o Princípio de Hamilton, por vezes conhecido como Princípio de Mínima Ação, ou popularmente por princípio do menor esforço, estabelece que a ação - uma grandeza física com dimensão equivalente à de energia multiplicada pela de tempo (joule-segundo no Sistema Internacional de Unidades) - possui um valor estacionário, seja ele máximo, mínimo ou um ponto de sela para a trajetória que será efetivamente percorrida pelo sistema em seu espaço de configuração.

\textbf{FEP} Princípio de Energia Livre é uma declaração formal que explica como os sistemas vivos e não vivos permanecem em estados estacionários de não equilíbrio, restringindo-se a um número limitado de estados. Estabelece que os sistemas minimizam uma função de energia livre de seus estados internos (não deve ser confundida com energia livre termodinâmica), o que implica crenças sobre estados ocultos em seu ambiente. A minimização implícita da energia livre está formalmente relacionada aos métodos variacionais Bayesianos e foi originalmente introduzida por Karl Friston como uma explicação para a percepção incorporada na neurociência, {[}1{]} onde também é conhecida como inferência ativa.\href{https://pt.wikipedia.org/wiki/Princ\%C3\%ADpio_da_energia_livre}{wiki}

\textbf{vicariamente} experiênciar algo através do outro

\textbf{Autopoiese} deriva do grego (autopoiesis). A origem etimológica do vocábulo é autós (por si próprio) e poiesis (criação, produção). Seu significado literal é autoprodução. Os subsistemas produzem, e reproduzem, a sua própria organização circular por meio de seus próprios componentes.

\textbf{exploration} - exploração - \textbf{prospecção}\\
\textbf{exploitation} - exploração - \textbf{aproveitamento}

\textbf{HMMs} - Hidden Markov Model (HMM) - Um \textbf{modelo oculto de Markov} é um modelo estatístico em que o sistema modelado é assumido como um processo de Markov com parâmetros desconhecidos, e o desafio é determinar os parâmetros ocultos a partir dos parâmetros observáveis. Os parâmetros extraídos do modelo podem então ser usados para realizar novas análises, por exemplo para aplicações de reconhecimento de padrões.

\textbf{POMDPs} partially observable Markov decision process (POMDP) - Um processo de decisão de Markov parcialmente observável (POMDP) é uma generalização de um processo de decisão de Markov (MDP). Um POMDP modela um processo de decisão do agente no qual é assumido que a dinâmica do sistema é determinada por um MDP, mas o agente não pode observar diretamente o estado subjacente. Em vez disso, deve manter um modelo de sensor (a distribuição de probabilidade de diferentes observações dado o estado subjacente) e o MDP subjacente. Ao contrário da função de política no MDP que mapeia os estados subjacentes às ações, a política do POMDP é um mapeamento do histórico de observações (ou estados de crença) para as ações.

\textbf{visão helmholtziana} - o objetivo de Helmholtz é demonstrar que a intuição é um conceito psicológico capaz de ser explicado por um conjunto de fatores e de processos mentais; e que, desta forma, a teoria transcendental dos axiomas geométricos de Kant t (1781/1996), segundo a qual os axiomas da geometria euclidiana seria a
priori e imanente à intuição, é incapaz de demonstrar-se verdadeira sobre a base de
evidências empíricas..
ver mais em: \href{https://periodicos.ufmg.br/index.php/memorandum/article/download/6857/4411/22713}{A teoria de Helmholtz sobre a percepção espacial: psicofísica e
filosofia transcendental}

\textbf{Divergência de Kullback-leibler}(também chamada de entropia relativa) é uma medida não-simétrica da diferença entre duas distribuições de probabilidade. Uma divergência de Kullback-Leibler igual a 0 indica que as funçõe/distribuições P e Q são muito parecidas (iguais, até), enquanto uma divergência de 1 indica que se comportam de maneira diferente.

\textbf{foveate} Angular os olhos de tal forma que as fóveas sejam direcionadas (um objeto em seu campo de visão), sendo a fóvea a porção da retina responsável pela visão central nítida.

\textbf{ELBO} The evidence lower bound = limite inferior de evidência

\textbf{Teoria da Informação} estuda a quantificação, armazenamento e comunicação da informação.

\textbf{Entropia} é a medida chave em teoria da informação. A entropia é o grau de casualidade, de indeterminação que algo possui. Ela está ligada à quantidade de informação. Quanto maior a informação, maior a desordem, maior a entropia. Quanto menor a informação, menor a escolha, menor a entropia.{[}1{]} Dessa forma, esse processo quantifica a quantidade de incerteza envolvida no valor de uma variável aleatória ou na saída de um processo aleatório.

\textbf{Navalha de Ockham} o princípio postula que de múltiplas explicações adequadas e possíveis para o mesmo conjunto de fatos, deve-se optar pela mais simples daquelas. Por ``simples'' entende-se aquela que contiver o menor número possível de variáveis e hipóteses com relações lógicas entre si, das quais o fato a ser explicado segue logicamente.

\textbf{Critério de informação de Akaike} (AIC) é uma métrica que mensura a qualidade de um modelo estatístico visando também a sua simplicidade. Fornece, portanto, uma métrica para comparação e seleção de modelos, em que menores valores de AIC representam uma maior qualidade e simplicidade, segundo este critério.

\textbf{G} Energia livre esperada : requer a consideração de observações futuras dependentes da política
\textbf{F} Energia livre variacional : considera apenas observações presentes e passadas

\textbf{PEB} abordagem empírica paramétrica de Bayes( A parametric empirical Bayes )

\(\triangleq \text versus \overset{\Delta}{=}\)

\[ \begin{align} f(x) =  x_1  \\+ x_2 \\ + x_3 \\ + x_4 + x_5 + x_6\end{align}\]

ps. E lá foi a minha equação do demônio pro vinagre.

  \bibliography{book.bib,packages.bib}

\end{document}
