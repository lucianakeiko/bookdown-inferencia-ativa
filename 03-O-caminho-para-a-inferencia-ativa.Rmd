# O caminho para a inferência ativa

Máquinas de sobrevivência que podem simular o futuro estão um salto à frente das máquinas de sobrevivência que só podem aprender com base em tentativa e erro evidentes. O problema com o julgamento aberto é que leva tempo e energia. O problema com o erro evidente é que muitas vezes é fatal. A simulação é mais segura e mais rápida.
—Richard Dawkins

## Introdução

No capítulo 2, motivamos a introdução da energia livre como meio de realizar inferência Bayesiana aproximada (ou seja, o caminho inferior para a Inferência Ativa). Aqui, introduzimos a energia livre de outra perspectiva, a da estrada principal, que inverte esse raciocínio: ela parte dos primeiros princípios da física estatística e do imperativo central de que os organismos devem manter sua existência - ou seja, evitar estados surpreendentes - e então introduz a minimização da energia livre como uma solução computacionalmente tratável para este problema. O capítulo revela a equivalência formal entre a minimização da energia livre variacional e a maximização da evidência do modelo (ou auto-evidência) em inferência Bayesiana aproximada, revelando uma conexão entre energia livre e perspectivas Bayesianas em sistemas adaptativos. Finalmente, discute como a Inferência Ativa fornece uma nova perspectiva de primeiro princípio para entender o comportamento (ótimo).

A Inferência Ativa é uma teoria de como os organismos vivos mantêm sua existência minimizando a surpresa – ou um substituto tratável para surpreender, energia livre variacional – via percepção e ação. Partindo dos primeiros princípios, avança um novo esquema baseado em crenças para entender o comportamento e a cognição, que tem inúmeras implicações empíricas.

O caminho para a Inferência Ativa parte da premissa de que, para sobreviver, qualquer organismo vivo precisa se manter em um conjunto adequado de estados preferidos, evitando outros estados não preferidos do ambiente. Esses estados preferidos são definidos em primeiro lugar por adaptações evolutivas específicas de nicho. No entanto, como veremos mais tarde, em organismos avançados, isso também pode se estender a objetivos cognitivos aprendidos. Por exemplo, para sobreviver, um peixe tem que ficar em uma zona de conforto que corresponde a um pequeno subconjunto de todos os estados possíveis do universo: tem que ficar na água. Da mesma forma, um ser humano precisa garantir que seus estados internos (por exemplo, variáveis ​​fisiológicas como temperatura corporal e frequência cardíaca) permaneçam sempre dentro de faixas aceitáveis ​​- caso contrário, eles morrerão (ou, mais precisamente, se tornarão outra coisa, como um cadáver). Essa faixa aceitável ou zona de conforto define estipulativamente os estados característicos em que algo deve estar para ser essa coisa.

Os organismos vivos resolvem esse problema biológico fundamental exercendo controle ativo sobre seus estados (por exemplo, da temperatura corporal) em muitos níveis, que variam de mecanismos reguladores automáticos, como sudorese (fisiologia), a mecanismos cognitivos, como comprar e consumir uma bebida (psicologia). ) a práticas culturais como a distribuição de sistemas de ar condicionado (ciências sociais).

De uma perspectiva mais formal, a Inferência Ativa apresenta o problema biológico da – ou explicação para – a sobrevivência como minimização de surpresas. Essa formulação se baseia em uma definição técnica de estados surpreendentes da teoria da informação – essencialmente, estados surpreendentes indexam aqueles fora da zona de conforto dos organismos vivos. Em seguida, propõe a minimização da energia livre como uma maneira prática e biologicamente fundamentada para que organismos ou sistemas adaptativos minimizem a surpresa dos encontros sensoriais.

## Envoltórios de Markov

Uma pré-condição importante para qualquer sistema adaptativo é que ele deve desfrutar de alguma separação e autonomia do ambiente – sem o qual ele simplesmente se dissiparia, dissolveria e, assim, sucumbiria à dinâmica ambiental. Na ausência dessa separação, não haveria surpresa a minimizar; deve haver algo para se surpreender e algo para se surpreender. Em outras palavras, há pelo menos duas coisas – sistema e ambiente – e elas podem ser desambiguações uma da outra. Uma maneira formal de expressar uma separação entre um sistema e o resto do ambiente é a construção estatística de um envoltório de Markov (Pearl 1988); ver quadro 3.1

 | quadro 3.1 Envoltórios de Markov | 
 | --- | 
 | Um envoltório de Markov é um importante conceito recorrente neste livro (Friston 2019a, Kirchhoff et al. 2018, Palacios et al. 2020). Tecnicamente, um envoltório (b) é definido da seguinte forma: $$ \mu \perp x|b \Longleftrightarrow p(\mu, x|b) = p(\mu|b)p(x|b)$$ Isso diz (de duas maneiras diferentes, mas equivalentes) que uma variável μ é condicionalmente independente de uma variável x se b for conhecido. Em outras palavras, se conhecemos b, conhecer x não nos daria informações adicionais sobre μ. Um exemplo comum disso é uma cadeia de Markov, onde o passado causa o presente causa o futuro. Nesse cenário, o passado só pode influenciar o futuro por meio do presente.  Isso significa que nenhuma informação adicional sobre o futuro é obtida descobrindo sobre o passado (assumindo que conhecemos o presente). Para identificar um envoltório de Markov em um sistema em que conhecemos as dependências condicionais, podemos seguir uma regra simples. O envoltório para uma determinada variável inclui seus pais (as variáveis das quais ela depende), seus filhos (as variáveis que dependem dela) e, em algumas configurações, os outros pais de seus filhos.| 
 
 Em resumo, um envoltório de Markov é o conjunto de variáveis que medeiam todas as interações (estatísticas) entre um sistema e seu ambiente. A Figura 3.1 ilustra uma interpretação de um envoltório de Markov em um cenário dinâmico. Aqui as independências condicionais foram complementadas com restrições dinâmicas, de modo que os fluxos não dependam de estados no lado oposto do envoltório.
 
 O envoltório de Markov na figura 3.1 distingue estados internos ao sistema adaptativo (ou seja, atividade cerebral) de estados externos do ambiente. Além disso, identifica dois estados adicionais, estados sensoriais rotulados e estados ativos, que formam o envoltório que (estatisticamente) separa os estados internos e externos. A separação estatística significa que, se soubéssemos sobre os estados ativo e sensorial, os estados externos não ofereceriam informações adicionais sobre os estados internos (e vice-versa). Em uma configuração dinâmica, isso é frequentemente interpretado como dizendo que os estados internos não podem alterar diretamente os estados externos, mas podem fazê-lo vicariamente alterando os estados ativos. Da mesma forma, os estados externos não podem alterar diretamente os estados internos, mas podem fazê-lo indiretamente, alterando os estados sensoriais.
 
Esta é uma reafirmação do ciclo clássico de percepção de ação, em que um sistema adaptativo e seu ambiente podem interagir (apenas) por meio de ações e observações, respectivamente. Esta reformulação tem dois benefícios principais.

![**Figura 3.1** Um envoltório de Markov dinâmico, que separa um sistema adaptativo (aqui, o cérebro) do ambiente. A dinâmica de cada conjunto de estados é determinada por um fluxo determinístico especificado como uma função $(f)$ fornecendo a taxa média de variação e flutuações estocásticas adicionais (aleatórias) $(ω)$. As setas indicam a direção da influência de cada variável sobre as taxas de variação de outras variáveis (tecnicamente, os elementos não nulos dos jacobianos associados). Isso é apenas um exemplo; pode-se usar um envoltório de Markov para separar um organismo inteiro do ambiente ou aninhar vários envoltórios de Markov um dentro do outro. Por exemplo, cérebros, organismos, díades e comunidades podem ser concebidos em termos de diferentes envoltórios de Markov que estão aninhadas umas nas outras (veja Friston 2019a; Parr, Da Costa e Friston 2020 para um tratamento formal). Confusamente, campos diferentes usam notações diferentes para as variáveis; às vezes, os estados sensoriais são denotados por $s$, estados externos $η$ e estados ativos $a$. Aqui escolhemos variáveis para consistência com os outros capítulos deste livro.](images/Figura_3_1.png)

Primeiro, formaliza o fato de que os estados internos de um sistema adaptativo são autônomos da dinâmica ambiental e, portanto, podem resistir às suas influências. Em segundo lugar, ela estrutura a maneira pela qual os sistemas adaptativos minimizam sua surpresa: destaca os estados internos, sensoriais e ativos aos quais eles têm acesso. Especificamente, a surpresa é definida em relação aos estados sensoriais, enquanto a dinâmica dos estados internos e ativos são os meios pelos quais a surpresa dos estados sensoriais pode ser minimizada.

O ponto-chave a ser observado aqui é que os estados internos de um sistema adaptativo têm uma relação formal com os estados externos. Isso se deve a um tipo de simetria em toda o envoltório de Markov, pois tanto influenciam quanto são influenciadas por estados do envoltório. Uma consequência disso é que podemos construir distribuições de probabilidade condicional para os estados internos e externos, dados os estados gerais. Como eles estão condicionados aos mesmos estados gerais, podemos associar pares de estados internos e externos esperados entre si. Em outras palavras, em média, os estados interno e externo adquirem uma espécie de sincronia (generalizada) – exatamente como poderíamos antecipar ao prender um pêndulo a cada extremidade de uma viga de madeira. Com o tempo, à medida que se sincronizam, cada pêndulo torna-se preditivo do outro através da influência vicária do feixe (Huygens 1673).

A Figura 3.2 oferece uma intuição gráfica para essa relação. Isso significa que, se pudermos escrever distribuições independentes sobre estados externos e internos, dado seu envoltório de Markov, os dois estados se tornarão informativos um sobre o outro por meio desse envoltório.

![Figura 3.2 Associação entre estados internos médios de um envoltório de Markov e distribuições de estados externos. Topo: Assumindo uma forma gaussiana linear para as probabilidades condicionais, esses gráficos mostram amostras da distribuição condicional sobre estados externos e internos, respectivamente, dados estados gerais. As linhas pretas grossas indicam a média dessas variáveis, dado o estado do envoltório associado. Inferior esquerdo: Os mesmos dados são plotados para ilustrar a sincronização de estados internos e externos proporcionada pelo compartilhamento de um envoltório de Markov – aqui, uma sincronização inversa. As linhas tracejadas e a cruz preta ilustram que se conhecêssemos o estado médio interno (linha vertical), poderíamos identificar o estado médio externo (linha horizontal) e a dispersão em torno deste ponto. Inferior direito: Podemos associar o estado interno médio com uma distribuição sobre o estado externo.](images/Figura_3_2.png)

Essa sincronia dá aos estados internos a aparência de representar (ou modelar) estados externos — o que remete à ideia de minimização da surpresa apresentada no capítulo 2. Isso porque a surpresa depende de um modelo interno de como os dados sensoriais são gerados. Para recapitular, minimizar a surpresa (probabilidade logarítmica negativa) de observações sensoriais torna-se idêntica a maximizar a evidência (probabilidade marginal) para o modelo, que é apenas a probabilidade de observações sensoriais sob esse modelo. Essa noção de minimização de surpresas pode ser entendida a partir de duas perspectivas equivalentes – bayesiana e de energia livre –, que discutiremos a seguir.

## Minimização de surpresa e auto-evidência

Sob uma perspectiva bayesiana, um agente com um envoltório de Markov parece modelar o ambiente externo no sentido de que estados internos correspondem (em média) a uma representação probabilística – uma crença posterior aproximada – de estados externos do sistema (figura 3.2). A dinâmica dos estados internos corresponde a uma forma de inferência bayesiana (aproximada) de estados externos, pois seu movimento altera a distribuição de probabilidade associada, que é proporcionada por um modelo generativo implícito de como as sensações (ou estados sensoriais no jargão do envoltório de Markov) são gerados. Se restabelecermos a noção de um agente como constituído por estados internos e gerais, podemos falar sobre o modelo generativo de um agente.

É importante ressaltar que o modelo generativo do agente não pode simplesmente imitar a dinâmica externa (caso contrário, o agente simplesmente seguiria a dinâmica dissipativa externa). Em vez disso, o modelo também deve especificar as condições preferenciais para a existência do agente, ou as regiões de estados que o agente deve visitar para manter sua existência, ou satisfazer os critérios de sua existência em termos de ocupação de estados característicos. Esses estados preferidos (ou observações) podem ser especificados como os anteriores do modelo - o que implica que o modelo assume implicitamente que suas sensações preferidas (anteriores) são mais prováveis de ocorrer (ou seja, são menos surpreendentes) se satisfizer os critérios de existência . Isso significa que tem um viés de otimismo implícito. Esse viés de otimismo é necessário para que o agente vá além da mera duplicação de dinâmicas externas para prescrever estados ativos que subscrevem seus estados preferenciais ou característicos.

Sob essa formulação, pode-se definir o comportamento ótimo (com relação às preferências anteriores) como a maximização da evidência do modelo por percepção e ação. De fato, a evidência do modelo resume quão bem o modelo generativo se ajusta ou explica as sensações. Um bom ajuste indica que o modelo explica com sucesso suas sensações (este é o lado descritivo da inferência); ao mesmo tempo, realiza suas sensações preferidas, já que são menos surpreendentes (este é o lado prescritivo da inferência). Esse bom ajuste é uma garantia de minimização da surpresa, pois maximizar a evidência do modelo $P( y)$ é matematicamente equivalente a minimizar a surpresa: $ℑ( y)  =  −ln P( y).$

Uma forma de reformular os argumentos acima de forma mais sucinta consiste em dizer que qualquer sistema adaptativo se engaja em “auto-evidência” (Hohwy 2016). Autoevidenciar aqui significa agir para reunir dados sensoriais consistentes com (ou seja, que fornece evidência para) um modelo interno, maximizando assim a evidência do modelo.

### Minimização de surpresa como um princípio hamiltoniano de menor ação


Nas seções anteriores, afirmamos que a surpresa deve ser minimizada, mas não detalhamos por que isso acontece. Embora os detalhes da física subjacente da autoevidência estejam fora do escopo deste livro (consulte Friston 2019b para obter detalhes), fornecemos aqui uma breve visão geral dos princípios. Estes são sustentados pela ideia de que criaturas biológicas – com envoltórios de Markov – persistem ao longo do tempo, resistindo aos efeitos dispersivos das flutuações ambientais. A persistência de uma envoltório de Markov implica que a distribuição de estados do envoltório permanece constante ao longo do tempo. Simplificando, isso significa que qualquer desvio de estados sensoriais (ou ativos) de regiões que são altamente prováveis ​​sob essa distribuição deve ser corrigido pelo fluxo médio de estados (que é apenas a parte determinística do fluxo na figura 3.1). Expressando isso como um físico poderia, sistemas estocásticos (aleatórios) em estado estacionário se envolvem em dinâmicas que (em média) descem uma função de energia (ou Hamiltoniana) que é interpretável como uma evidência de log negativo ou surpresa. Isso é como uma bola rolando morro abaixo de alta energia potencial gravitacional no topo da colina para baixa energia em uma bacia. Veja a figura 3.3.

Para o sistema mostrado à esquerda da figura 3.3, toda vez que uma flutuação causa um movimento para um estado menos provável, isso é corrigido por um movimento para cima no gradiente de probabilidade, de modo que o sistema ocupe regiões com densidade de probabilidade maior parte do tempo . O principal insight aqui é que esse sistema mantém os estados sensoriais dentro de uma faixa estreita, minimizando a surpresa (em média) – em contraste com o sistema da direita, para o qual a surpresa cresce indefinidamente.

![**Figura 3.3** Esquerda: Caminho tomado por um sistema dinâmico aleatório bidimensional com um estado estacionário (não-equilíbrio [^10]). Isso pode ser interpretado como minimizando sua surpresa, que é mostrada no gráfico de contorno à direita. Direita: O centro é a região menos surpreendente; os círculos que se afastam do centro representam regiões progressivamente mais surpreendentes.  Meio: Em contraste, este gráfico mostra a trajetória de um sistema começando no mesmo lugar (5, 5), com flutuações aleatórias de mesma amplitude, cuja dinâmica não guarda relação com surpresa. Não só entra em regiões mais surpreendentes do espaço; também não consegue atingir qualquer tipo de estado estacionário, dissipando-se de forma irrestrita ao longo do tempo. O escopo da Inferência Ativa é restrito a sistemas como o da esquerda – que contrariam flutuações aleatórias com seu fluxo médio e, assim, mantêm sua forma ao longo do tempo.](images/Figura_3_3.png)

[^10]:Desequilíbrio aqui se refere à ausência de equilíbrio detalhado. O equilíbrio detalhado é a invariância de um sistema sob reversão no tempo, uma vez que atingiu o estado estacionário. Podemos ver que o sistema da esquerda da figura 3.3 não possui equilíbrio detalhado, pois a trajetória tende a se curvar no sentido anti-horário em torno dos contornos de surpresa. Se fôssemos reproduzir isso ao contrário, o sistema pareceria girar no sentido horário. 


A minimização da surpresa permite que os organismos vivos resistam (temporariamente) à segunda lei da termodinâmica, que afirma que a entropia – ou a dispersão de estados sistêmicos – sempre cresce. Isso porque, em média, a entropia é a média de longo prazo da surpresa e, em média, a maximização de uma probabilidade logarítmica de observações é equivalente à minimização da entropia (Shannon) [^11]

[^11]:Isso não é o mesmo que dizer que sistemas que minimizam surpresas devem minimizar sua entropia. Como vemos na figura 3.3, o sistema não tende a uma distribuição (ponto) infinitamente precisa que minimizaria a entropia, mas mantém uma dispersão consistente ao longo do tempo – limitando a entropia de cima e de baixo.


$H[P(y)]=\mathbb{E_{P(y)}[ℑ(y)]}=-\mathbb{E_{P(y)}[\ln P(y)]}\qquad\qquad\qquad (3.1)$

Garantir que uma pequena proporção de estados sensoriais seja ocupada com alta probabilidade é equivalente a manter uma entropia particular. Essa é uma característica definidora dos sistemas auto-organizados, há muito reconhecida pelas teorias cibernéticas.

Do ponto de vista de um fisiologista, a minimização de surpresas formaliza a ideia de homeostase. À medida que um valor de sensor sai de sua faixa ideal, mecanismos de feedback negativo entram em ação que revertem esses desvios. De uma perspectiva de controle, podemos interpretar o comportamento ótimo em relação a alguma densidade de probabilidade de estado estacionário desejada. Em outras palavras, se definirmos uma distribuição de resultados preferidos, o comportamento ótimo envolverá a evolução do sistema em direção a essa distribuição e sua manutenção.

Como vimos no capítulo 2, a energia livre é um limite superior para a surpresa, sugerindo que o comportamento ótimo pode ser obtido minimizando a energia livre em face de flutuações aleatórias. Lembre-se de que a diferença entre energia livre e surpresa é a divergência entre uma probabilidade posterior exata (isto é, a distribuição de estados externos dados estados envoltórios) e uma probabilidade posterior aproximada (isto é, a distribuição sobre estados externos dados estados internos médios). Como tal, o movimento dos estados internos pode ser pensado como minimizando a divergência, o que permite que os estados ativos, em média, minimizem a surpresa que acompanha os estados sensoriais. Em outras palavras, o comportamento ótimo resultante da minimização da energia livre é aquele que é menos surpreendente e segue um caminho de menor Ação [^12] do estado atual para o estado desejado – ou seja, o princípio hamiltoniano de menor Ação aplicado ao comportamento .


[^12]: O A maiúsculo é usado para distinguir Ação como uma integral de caminho de uma Lagrangiana da ação como a dinâmica dos estados ativos de um envoltório de Markov.

A Figura 3.3 mostra um exemplo muito simples de um sistema equipado com um atrator aleatório. Isso é análogo a um termostato, que (no jargão cibernético) tem um único ponto de ajuste e não pode aprender ou planejar. A Inferência Ativa visa usar o mesmo aparato explicativo para cobrir sistemas muito mais complexos e adaptativos. Aqui, a diferença entre sistemas mais simples e mais complexos pode ser reduzida às diferentes formas de seus atratores – de pontos fixos a dinâmicas cada vez mais complexas e itinerantes. A partir dessa perspectiva, pode-se entender os organismos vivos como buscando constantemente um compromisso entre estabilidade excessiva e dispersão excessiva – e a Inferência Ativa visa explicar como esse compromisso é alcançado.


## Relações entre Inferência, Cognição e Dinâmica Estocástica

O físico E. T. Jaynes ficou famoso por argumentar que a inferência, a teoria da informação e a física estatística são perspectivas diferentes sobre a mesma coisa ( Jaynes 1957). Nas seções anteriores, discutimos como as perspectivas Bayesiana e da física estatística oferecem duas maneiras equivalentes de entender a minimização de surpresas e o comportamento ideal – adicionando efetivamente uma forma de cognição à tríade de Jaynes. Essa equivalência entre várias escolas de pensamento é atraente, mas pode ser confusa para quem não está familiarizado com os respectivos formalismos, onde muitas palavras diferentes são usadas para se referir às mesmas quantidades. Para ajudar a desmistificar isso, nesta seção elaboramos as principais equivalências entre as perspectivas Bayesiana e Física Estatística e suas interpretações cognitivas; veja a tabela 3.1 para um resumo e o quadro 3.2.

**Tabela 3.1** Física estatística, inferência bayesiana e teoria da informação - e suas interpretações cognitivas

| Física estatística| Inferência Bayesiana e Teoria da Informação | Interpretação cognitiva | 
|:-:	|:-:	|:-:	|
|Minimize a energia livre variacional| Maximize a evidência do modelo (ou probabilidade marginal); minimizar a surpresa (ou auto-informação)| Percepção e ação|
| Minimize a energia livre esperada; Hamiltoniano princípio da menor ação| Inferir o curso de ação mais provável (ou menos surpreendente) | Planejamento como inferência| 
|Atingir o estado estacionário de não equilíbrio | Realizar inferência Bayesiana aproximada | Auto-evidência |
|Fluxos de gradiente em funções de energia; gradiente descendente em energia livre | Ascensão do gradiente na evidência do modelo; descida gradiente na surpresa | Dinâmica neuronal | 


|Quadro 3.2 Energia livre em física estatística e inferência ativa|
| -- |
|A noção de energia livre é amplamente utilizada em física estatística para caracterizar (por exemplo) sistemas termodinâmicos. Embora a Inferência Ativa use exatamente as mesmas equações, ela as aplica para caracterizar o estado de crença de um agente (em relação a um modelo generativo). Assim, quando falamos de um agente de Inferência Ativa minimizando sua energia livre (variacional), estamos nos referindo a processos que mudam seu estado de crença, não (por exemplo) as partículas de seu corpo. Para evitar mal-entendidos, usamos o termo energia livre variacional, adotando uma terminologia mais comum em aprendizado de máquina. Outro ponto mais sutil é que o conceito de energia livre é frequentemente usado no contexto da termodinâmica estatística de equilíbrio. A Inferência Ativa tem como alvo organismos vivos – ou sistemas de estado estacionário de não equilíbrio que são abertos – que apresentam trocas contínuas e recíprocas com o meio ambiente. Este é um campo de romance emocionante (Friston 2019a).|

### Energia Livre Variacional, Evidência Modelo e Surpresa

Uma primeira equivalência importante é entre a maximização da evidência do modelo (ou probabilidade marginal) na inferência Bayesiana e a minimização da energia livre variacional – ambas minimizam a surpresa. Essa equivalência torna-se evidente quando se apela para uma solução aproximada específica para problemas intratáveis de inferência – inferência variacional. A inferência variacional reformula o problema de inferência como um problema de otimização minimizando a energia livre. O mínimo da energia livre é o ponto em que a aproximação da solução exata está no seu melhor. Expressar isso formalmente esclarece as relações entre as três quantidades:

$$\begin{matrix} \underbrace {ℑ(y|m)} \\ Surpresa \end{matrix} = \begin{matrix}\underbrace{-ln\;P(y|m)} \\ Evidência\; do \; modelo\end{matrix} \le \begin{matrix} \underbrace{D_{KL}[Q(x)||P(x|y,m)]- \ln P(y|m)} \\ Energia \; Livre\; Variacional \end{matrix} \qquad (3.2)$$
Na equação 3.2, diferentemente do capítulo 2, condicionamos explicitamente todas as quantidades em um modelo, m, para enfatizar que elas dependem do modelo que temos (ou somos) sobre como y são gerados, e as quantidades irão variar se modelos diferentes são usados. A equivalência dessas quantidades levanta a questão de por que é útil distingui-las. A principal razão é que, ao contrário da evidência do modelo, a energia livre variacional pode ser minimizada de forma eficiente.

Lembre-se do capítulo 2 que a energia livre variacional só é exatamente equivalente à evidência negativa do modelo ou surpresa quando o termo KL-Divergência se torna zero. Isso nem sempre é possível, mas pode ser feito próximo de zero. Assim, no processo de encontrar valores cada vez melhores para $Q(x)$, a energia livre variacional também se aproxima mais da surpresa. Já dissemos isso algumas vezes porque é importante enfatizar a relação central entre energia livre e surpresa que é a base deste livro. Especificamente, a energia livre é um limite superior para a surpresa. Pode ser o mesmo ou maior que a surpresa – onde o que é maior do que é quantificado pela KL-Divergence.

Um aspecto interessante disso é que qualquer sistema que minimize sua surpresa, incluindo o sistema muito simples da figura 3.2, também está minimizando uma energia livre, onde $Q(x)$ é sempre igual à probabilidade a posteriori exata - isto é, definindo o KL-Divergence como zero. Uma perspectiva sobre a diferença entre sistemas cognitivos e não cognitivos é que os últimos sempre têm uma divergência KL zero, enquanto os sistemas cognitivos devem passar pelo processo (perceptual) de minimizar esse termo antes que suas ações sejam garantidas para minimizar a surpresa. Observe que minimizar a divergência é a única coisa que a percepção pode fazer.

Isso dá muita ênfase ao movimento dos estados internos, de modo que a distribuição que eles parametrizam (figura 3.2) é o mais próximo possível da posterior exata. No entanto, a percepção não pode minimizar o segundo componente (evidência) da energia livre variacional que corresponde à surpresa real, porque não pode alterar as sensações que foram coletadas. Somente agindo de maneira que mude as sensações, um agente pode minimizar o segundo componente (evidência) da energia livre variacional e resolver sua surpresa – ou, equivalentemente, maximizar sua evidência de modelo. Isso coloca ênfase no movimento de estados ativos, dados estados internos, em auto-evidência.

Um exemplo ajuda a ilustrar este ponto. Imagine que seu modelo generativo preveja uma distribuição dos níveis de glicose em seu sangue, de acordo com os níveis de fome, com níveis de glicose relativamente altos versus baixos relacionados à saciedade e à fome, respectivamente. Além disso, imagine que esse modelo atribua uma probabilidade anterior mais alta à saciedade e, portanto, a níveis relativamente altos de glicose – tornando os níveis baixos de glicose surpreendentes. Imagine que você está inicialmente incerto sobre seus níveis de fome e sente a glicemia baixa. A percepção leva à inferência de que você está com fome e à experiência da fome – fechando a KL-Divergence. No entanto, a percepção não pode ir além disso para reduzir sua surpresa – e a discrepância entre o alto nível de glicose que você espera a priori e o baixo nível de glicose que você sente – porque ela não pode agir em suas sensações (baixa glicose) ou em suas sensações. causas (fisiologia). Você só pode minimizar sua surpresa agindo para mudar (a fonte oculta de) as sensações que você reúne – por exemplo, comendo uma sobremesa.

Em suma, a percepção pode minimizar a energia livre variacional ao reduzir a discrepância entre o posterior aproximado e o verdadeiro, mas não pode ir além na minimização da surpresa. O próximo passo da minimização da surpresa envolve a mudança das sensações que se obtém ao agir, que é onde a inferência vai além da percepção e se torna ativa.


### Energia Livre Esperada e Inferência da Trajetória Mais Provável

Outra equivalência importante é entre a minimização da energia livre esperada e a inferência do curso de ação ou política mais provável. Isso vai além de especificar a parte menos surpreendente do espaço de estados e trata de quão surpreendentes podem ser as rotas alternativas para essa parte ou local. Esses caminhos alternativos são expressos em termos de políticas, que são essencialmente trajetórias entre estados. É importante ressaltar que na Inferência Ativa a probabilidade de log

Outra equivalência importante é entre a minimização da energia gratuita esperada e a inferência do curso de ação ou política mais provável. Isso vai além de especificar a parte menos surpreendente do espaço de estados e lida com o quão surpreendentes podem ser as rotas alternativas para essa parte ou local. Esses caminhos alternativos são expressos em termos de políticas, que são essencialmente trajetórias entre estados. É importante ressaltar que na Inferência Ativa a probabilidade logarítmica de uma política é definida proporcionalmente à energia livre esperada se essa política for seguida. Isso implica que o caminho mais provável ou menos surpreendente é (definido para ser) aquele que minimiza a energia livre esperada. Esta formulação é equivalente à forma como Ação é definida na física, onde pontua a probabilidade de um caminho por uma integral (ou soma) de uma energia. Enquanto um sistema físico pode perseguir um espaço de trajetórias hipotéticas, o caminho que ele realmente segue é aquele para o qual Ação é minimizada – ou seja, o princípio da menor Ação de Hamilton. Essa analogia entre a Inferência Ativa e o princípio da menor Ação de Hamilton é descompactada na próxima seção.

## Inferência ativa: uma nova base para entender o comportamento e a cognição

Em campos como controle ótimo, aprendizado por reforço e economia, a otimização do comportamento resulta de uma função de valor de estados, seguindo a equação de Bellman (Sutton e Barto 1998). Essencialmente, a cada estado (ou par estado-ação) é atribuído um valor, que representa quão bom é um estado para um agente estar. O valor dos estados (ou pares estado-ação) é geralmente aprendido por tentativa e erro, por contando quantas vezes - e depois de quanto tempo - se obtém recompensa partindo desses estados. O comportamento consiste em otimizar a aquisição de recompensas alcançando estados de alto valor, portanto, capitalizando o histórico de aprendizado.

Em contraste, na Inferência Ativa, o comportamento é resultado da inferência e sua otimização é uma função das crenças. Essa formulação une noções de crença (prévia) e preferência. Como discutido acima, usar a noção de energia livre esperada equivale a dotar o agente de uma crença prévia implícita de que ele realizará suas preferências. Assim, a preferência do agente por um curso de ação torna-se simplesmente uma crença sobre o que ele espera fazer e encontrar no futuro – ou uma crença sobre futuras trajetórias de estados que ele visitará. Isso substitui a noção de valor pela noção de crença (prévia). Este é um movimento aparentemente estranho, se alguém tem experiência em aprendizado por reforço (onde valor e crença são separados) ou estatística Bayesiana (onde crença não implica nenhum valor). No entanto, é um movimento poderoso, por pelo menos três razões.

Primeiro, implica automaticamente um modelo de processo autoconsistente de comportamento intencional (ou teleológico), que é semelhante a formulações cibernéticas. Se dotarmos um agente de Inferência Ativa com alguma preferência prévia, ele agirá para realizar tais preferências - porque esse é o único curso de ação consistente com sua crença anterior de que ele agirá para cumprir suas expectativas. Observe que o curso de ação ou política resultante (preferido) é diretamente mensurável em ambientes experimentais, enquanto uma função de valor ou crença anterior precisa ser inferida e, portanto, é uma medida mais indireta, se não tautológica.

Em segundo lugar, colocar o comportamento como um funcional de crenças (distribuições de probabilidade) automaticamente implica noções como grau de crença e incerteza. Essas noções sustentam facetas importantes da ação adaptativa, mas não estão diretamente disponíveis na formulação de Bellman. Da mesma forma, essa formulação dá mais flexibilidade na modelagem de dinâmicas sequenciais e comportamentos itinerantes, que são mais difíceis de modelar em termos de uma função de valor de estados (Friston, Daunizeau e Kiebel 2009).

Terceiro, nesta formulação, o comportamento ótimo vem a seguir um princípio hamiltoniano de menor ação em física estatística. De fato, a Inferência Ativa vai um passo adiante em direção à ideia de que o comportamento é uma função de crenças: ela também assume que se torna uma função de energia – e o curso de ação mais provável de um agente de Inferência Ativa é aquele que minimiza a energia livre. Uma consequência profunda é que os organismos vivos se comportam de acordo com o princípio de Hamilton da menor ação: eles seguem um caminho de menor resistência até atingirem um estado estacionário (ou uma trajetória y de estados), como exemplificado pelo comportamento de um sistema dinâmico aleatório (mostrado na figura 3.3). Esta é uma suposição fundamental que distingue a Inferência Ativa de teorias alternativas de comportamento e cognição baseadas na formulação de Bellman.

Vale a pena esboçar brevemente o que queremos dizer ao traçar analogias entre a física hamiltoniana e a Inferência Ativa. Isto destina-se a três níveis. A primeira é que o avanço oferecido pela Inferência Ativa às ciências do comportamento e da vida é comparável ao avanço das formulações lagrangeanas [^13] e hamiltonianas oferecidas aos relatos da mecânica de Newton. Enquanto a mecânica newtoniana foi originalmente formulada em termos de equações diferenciais – incluindo a famosa terceira lei de Newton que expressa a proporcionalidade entre aceleração e força – uma perspectiva complementar sobre a mecânica foi oferecida considerando o que é conservado pelos sistemas dinâmicos. A dinâmica newtoniana pode então ser derivada dessas leis de conservação.


[^13]:Uma Lagrangiana é uma função de uma posição e velocidade que dá a diferença entre as energias cinética e potencial. Um hamiltoniano está relacionado (através de uma transformada de Legendre) e expressa a energia total do sistema em termos de posição e momento.

O segundo ponto de conexão entre a física Hamiltoniana e a Inferência Ativa surge de uma associação mais direta entre um Hamiltoniano e medidas de probabilidade. A ideia aqui é associar o Hamiltoniano conservado com a energia do sistema. Lembre-se de que as quantidades às quais nos referimos como energias até agora (aqui e no capítulo 2) tiveram todas a forma de um logaritmo de probabilidade negativo. Isso reflete uma interpretação de energia como simplesmente uma medida da improbabilidade de qualquer configuração de um sistema. Nesta visão, conservação de energia e de probabilidade são leis equivalentes. À medida que os sistemas dissipativos – acoplados a estados externos por meio de um envoltório de Markov – se movem para estados de baixa energia ou alta probabilidade, podemos associar diretamente a energia ou o Hamiltoniano à surpresa. Como tal, a Inferência Ativa é a física Hamiltoniana aplicada a um certo tipo de sistema (sistemas que apresentam um envoltório de Markov).

A terceira associação entre essas formulações é o cálculo variacional que subscreve a associação entre energias e dinâmicas. Isso é mais aparente quando a física hamiltoniana é expressa como um princípio de menor Ação, onde Ação se refere à integral de uma Lagrangiana ao longo de um caminho. Crucialmente, esta Ação é um funcional de um caminho. Aqui, um caminho é uma função do tempo cuja saída é a posição e a velocidade de uma partícula naquele caminho naquele momento. O caminho seguido por uma partícula (determinística) minimiza esta Ação. Da mesma forma, a Inferência Ativa baseia-se na ideia de que as crenças (funções de estados ocultos) devem minimizar um funcional de energia livre. O ponto chave de contato aqui é que em ambos os casos, as funções (caminhos ou crenças) devem ser otimizadas em relação aos funcionais (Ação ou energia livre, respectivamente). Isso coloca ambos no contexto do cálculo variacional, que é um ramo da matemática dedicado a encontrar extremos de funcionais. Na física, isso leva às equações de Euler-Lagrange. Na Inferência Ativa, chegamos a procedimentos de inferência variacional.


## Modelos, Políticas e Trajetórias

Na seção 3.2, destacamos que o escopo da Inferência Ativa pertence àqueles sistemas que desfrutam de alguma separação de seu ambiente e vimos que isso se traduz na presença de um envoltório de Markov. Na seção 3.3, destacamos que a persistência desse envoltório requer dinâmicas que (em média) minimizem a surpresa dos estados (sensoriais). Como isso pode ser interpretado como autoevidente, chegamos à conclusão de que o comportamento é determinado por uma distribuição de estado estacionário que pode ser interpretada como um modelo generativo de como os dados (sensoriais) são gerados.

Isso nos diz algo muito importante. Cada modelo generativo deve estar associado a diferentes tipos de comportamento. Como tal, diferentes tipos de comportamento podem ser explicados especificando diferentes modelos generativos – e implicitamente o que esse sistema acharia surpreendente. Além disso, diferentes tipos de modelo generativo podem corresponder a criaturas adaptativas ou cognitivas com vários níveis de complexidade (Corcoran et al. 2020). Modelos generativos muito simples do tipo que conduzem a dinâmica na Figura 3.3 oferecem um tipo mínimo de cognição, pois não podem considerar a possibilidade de trajetórias alternativas (ou contrafactuais). Além disso, esses modelos são superficiais, no sentido de que permitem inferência em apenas uma escala de tempo. Em contraste, os modelos generativos hierárquicos permitem inferência em múltiplas escalas de tempo. Em modelos hierárquicos ou profundos, a dinâmica em níveis hierárquicos mais altos geralmente codifica coisas que mudam mais lentamente (por exemplo, a frase que estou lendo) e que contextualizam coisas que mudam mais rapidamente (por exemplo, a palavra que estou lendo), que são representadas em níveis mais baixos. níveis hierárquicos (Kiebel et al. 2008; Friston, Parr e de Vries 2017).

O que precisamos incluir em um modelo para derivar comportamentos mais complexos do tipo que associaríamos à agência e aos sistemas sencientes? Uma resposta para isso é a capacidade de modelar futuros alternativos, ou diferentes maneiras pelas quais os eventos podem se desenrolar – e selecionar entre eles. Por sua vez, considerar futuros possíveis requer um modelo generativo que tenha alguma profundidade temporal e represente explicitamente as consequências das ações. Trabalhar isso no modelo garantirá um comportamento que esteja de acordo com o mais provável desses futuros. A capacidade (contrafactual) de entreter essas alternativas pode ser o que separa o estado estacionário associado aos sistemas sencientes das criaturas mais simples. Quando futuros alternativos dizem respeito a coisas sobre as quais temos controle, nos referimos a eles como políticas ou planos. Como vimos no capítulo 2, uma forma de desambiguar esses planos é incorporar uma crença prévia em um modelo que diz que as políticas com a menor expectativa de energia livre são as mais plausíveis. Isso oferece uma maneira de caracterizar um certo tipo de sistema com um envoltório de Markov em estado estacionário – o que parece corresponder bem a sistemas como o nosso.

## Reconciliação das Teorias Enativa, Cibernética e Preditiva sob Inferência Ativa

Ao enfatizar a minimização da energia livre, a Inferência Ativa une e estende três perspectivas teóricas aparentemente desconexas.

Primeiro, a Inferência Ativa está de acordo com as teorias enativas da vida e da cognição, que enfatizam a auto-organização do comportamento e as interações autopoiéticas com o ambiente, que garantem que os organismos vivos permaneçam dentro de limites aceitáveis (Maturana e Varela 1980). A Inferência Ativa fornece uma estrutura formal que explica como os organismos vivos conseguem resistir à dispersão de seus estados por meio da auto-organização de uma estrutura estatística – o envoltório de Markov – que permite trocas recíprocas entre organismo e ambiente, ao mesmo tempo em que separa (e, em certo sentido, protege a integridade de ) os estados dos organismos a partir de dinâmicas ambientais externas.

Em segundo lugar, a Inferência Ativa está de acordo com as teorias cibernéticas, que descrevem o comportamento como intencional e teleológico. Teleologia significa que o comportamento é regulado internamente por um mecanismo que continuamente testa se um objetivo é alcançado e, se não, orienta ações corretivas (Rosenblueth et al. 1943, Wiener 1948, Ashby 1952, G. Miller et al. 1960, Powers 1973 ). Da mesma forma, os agentes de Inferência Ativa usam tanto a percepção quanto a ação para minimizar a discrepância entre os estados preferidos e detectados. A Inferência Ativa fornece uma descrição normativa e viável do processo de minimização, especificando que o que é realmente minimizado é uma quantidade estatística que o agente pode medir – energia livre variacional – que sob certas condições corresponde a um erro de previsão, ou a diferença entre o que é esperado e o que é sentido. Isso implica uma formulação do controle cibernético como um processo prospectivo – o que nos leva ao próximo ponto.

Terceiro, a Inferência Ativa está de acordo com as teorias que descrevem o controle como um processo prospectivo que se baseia em um modelo do ambiente – possivelmente implementado fisicamente no cérebro (Craik 1943). A Inferência Ativa assume que os agentes usam um modelo (generativo) para construir previsões que orientam a percepção e a ação e para avaliar suas possibilidades de ação futuras (e contrafactuais). Essa suposição é coerente com o teorema do bom regulador (Conant e Ashby 1970), que diz que qualquer controlador deve ter – ou ser – um bom modelo do ambiente. A Inferência Ativa reconcilia essas perspectivas baseadas em modelos sobre cérebro e comportamento sob uma caracterização rigorosa em termos de inferência Bayesiana (aproximada) e minimização de energia livre (variacional e esperada). Além disso, a Inferência Ativa é amplamente coerente com a teoria ideomotora (Herbart 1825, James 1890, Hoffmann 1993, Hommel et al. 2001), que afirma que a ação começa com um processo imaginativo, e é uma representação preditiva (das consequências da ação) que desencadeia ações – não um estímulo, como na teoria estímulo-resposta (Skinner 1938). A Inferência Ativa lança essa ideia em uma estrutura inferencial, na qual uma ação decorre de uma crença (sobre o futuro); isso tem várias implicações, como o fato de que, para desencadear a ação, é preciso atenuar temporariamente a evidência sensorial (o que, de outra forma, falsificaria a crença que desencadeia a ação) (H. Brown et al. 2013).

A reconciliação dessas estruturas é interessante, pois muitas vezes são consideradas em desacordo. Por exemplo, a auto-organização e a teleologia são muitas vezes vistas como incompatíveis na biologia. Além disso, as teorias enativas tendem a não enfatizar a representação e o controle, que é, em vez disso, uma construção central da maioria das teorias de inferência baseada em modelos. A Inferência Ativa formaliza a dinâmica autopoiética de agentes adaptativos a partir de um ângulo incomum, que considera simultaneamente a auto-organização e a previsão. Ao conectar diferentes perspectivas, a Inferência Ativa pode nos ajudar a entender como elas iluminam umas às outras.

## Inferência Ativa, da Emergência da Vida para a atuação

A Inferência Ativa parte dos primeiros princípios e os desdobra para explicar o comportamento e a cognição expressos desde as formas mais simples até as mais complexas de sistemas adaptativos e vivos. No continuum entre criaturas mais simples e mais complexas, a Inferência Ativa traça uma linha entre aquelas que minimizam a energia livre variacional e aquelas que também minimizam a energia livre esperada.

Qualquer sistema adaptativo que ativamente amostra sensações para minimizar a energia livre variacional é (equivalentemente) um agente que reúne ativamente evidências para seu modelo generativo, também conhecido como agente de autoevidência (Hohwy 2016). Esses sistemas são capazes de evitar a dissipação, autorregular-se e sobreviver alcançando os pontos de ajuste fornecidos pelos processos homeostáticos básicos. Esses sistemas podem gerar formas complexas e diversas de comportamento e também podem ter níveis de aptidão muito altos (como já é aparente no caso dos vírus). Alguns podem ter modelos generativos hierárquicos que permitem inferir eventos que mudam em diferentes escalas de tempo, de mais rápido (em níveis hierárquicos mais baixos) a mais lentos (em níveis mais altos) – e, portanto, podem desenvolver estratégias sofisticadas para lidar com o que vivenciam. No entanto, essas criaturas também são fundamentalmente limitadas porque seus modelos generativos carecem de profundidade temporal – ou a capacidade de planejar e considerar o futuro explicitamente (embora possam fazê-lo implicitamente, por exemplo, como resultado da evolução genética) – e, portanto, sempre vivem no presente.

Um modelo generativo dotado de profundidade temporal abre a porta para a minimização da energia livre esperada – ou em termos psicológicos, planejamento. Na Inferência Ativa, isso envolve muito mais do que uma maior adaptabilidade: envolve pelo menos uma forma primitiva de atuação. Para um sistema adaptativo, minimizar a energia livre esperada é equivalente a ter o (implícito) anterior que é um agente de minimização de energia livre - mas atua para minimizar a energia livre no futuro. Quando essa crença (prévia) entra no modelo generativo, o sistema adaptativo torna-se capaz de formar crenças sobre como deve se comportar no futuro e quais trajetórias seguirá. Em outras palavras, torna-se capaz de selecionar entre futuros alternativos ao invés de simplesmente selecionar como lidar com o presente percebido, como nos agentes mais simples descritos acima. Essa profundidade temporal se traduz, portanto, em uma profundidade psicológica. Perguntar sobre as maneiras pelas quais as criaturas vivas povoam o continuum entre os sistemas adaptativos mais simples e os mais complexos – e quais formas de Inferência Ativa eles podem expressar – é uma questão empírica.


## Resumo

Os principais tópicos deste capítulo podem ser resumidos da seguinte forma: Os organismos vivos devem garantir que eles visitem apenas seus estados característicos ou preferidos. Se definirmos esses estados preferidos como estados esperados, podemos dizer que os organismos vivos devem minimizar a surpresa de suas observações sensoriais (e manter uma entropia ótima; veja o quadro 3.3).

Fazer isso requer que os agentes exerçam alguma autonomia da dinâmica ambiental e sejam equipados com um envoltório de Markov que separe (ou seja, expresse uma independência condicional entre) seus estados internos e os estados externos do ambiente. Agentes dentro do envoltório de Markov podem se engajar em trocas recíprocas (ação-percepção) com o ambiente. Essas trocas são formalmente descritas pela teoria da Inferência Ativa, onde tanto a percepção quanto a ação minimizam a surpresa. Eles podem fazer isso sendo equipados com um modelo generativo probabilístico de como suas observações sensoriais são geradas. Este modelo define surpresa – ou melhor, um proxy tratável, energia livre variacional, que pode ser medida e minimizada com eficiência.

Um agente de Inferência Ativa parece realizar inferência Bayesiana (aproximada) sob um modelo generativo e maximizar a evidência para seu modelo – isto é, é um agente autoevidente. A parte prospectiva da inferência é realizada pela seleção de cursos de ações ou políticas que se espera que minimizem a energia livre no futuro. Esse formalismo leva a uma nova visão do comportamento (ótimo) em termos do princípio hamiltoniano da menor ação – um (primeiro) princípio que conecta a Inferência Ativa aos domínios da física estatística, termodinâmica e estados estacionários de não equilíbrio.

| **Quadro 3.3** Minimização de entropia e comportamento aberto | 
| -- |
| A Inferência Ativa é baseada na premissa de que os organismos vivos se esforçam para manter uma ordem relativa (ou entropia negativa), controlabilidade e previsibilidade, apesar de estarem imersos em um ambiente cujas forças naturais geram flutuações contínuas – e uma ameaça sem fim de erosão entrópica. A manifestação mais básica dessa busca ativa da ordem é a homeostase fisiológica, com parâmetros fisiológicos críticos que precisam ser mantidos dentro de regiões viáveis. No entanto, minimizar a entropia não deve ser equiparado a um repertório rígido de respostas (por exemplo, respostas homeostáticas autonômicas), mas sim o oposto, especialmente em organismos avançados. Podemos desenvolver repertórios abertos de novos comportamentos para perseguir nossos imperativos homeostáticos originais — por exemplo, produzir e comprar um bom vinho para satisfazer a sede e outras necessidades. Isso às vezes é chamado de “alostase” (Sterling 2012).Mais amplamente, buscamos ativamente alguma ordem e controlabilidade per se, sem referência necessária a um imperativo homeostático específico – talvez porque preservar a ordem facilite muitos desses imperativos. Esculpimos ativamente nossos nichos ecológicos para torná-los mais previsíveis e menos surpreendentes. Isso fica evidente nas formas como construímos nossos espaços físicos (por exemplo, refúgios e cidades que abrigam forças naturais descontroladas) e espaços culturais (por exemplo, sociedades com leis e normas deônticas que abrigam forças sociais anárquicas). Em todos esses exemplos, geralmente precisamos aceitar algum aumento de entropia ou surpresa de curto prazo (por exemplo, quando construímos algo novo ou mudamos posições sociais) para garantir sua diminuição no longo prazo. Isso nos ajuda a entender como o requisito básico para a minimização de surpresas não está em desacordo, mas promove os imperativos epistêmicos e o comportamento de busca de novidades, curiosidade e exploração que reconhecemos como centrais para muitas espécies. Uma primeira maneira pela qual os imperativos epistêmicos se tornam aparentes é durante a minimização da energia livre variacional. Uma das maneiras de decompor a energia livre é expressá-la como uma energia de Gibbs esperada sob o posterior aproximado menos a entropia do posterior aproximado. Em outras palavras, o agente está se esforçando para aumentar a entropia. Embora isso pareça paradoxal, o paradoxo desaparece se considerarmos que esta é a entropia da crença do agente (aproximadamente posterior). Isso pode ser entendido como o imperativo de explicar as coisas com a maior precisão possível, mas também “manter as opções em aberto” e evitar se comprometer com qualquer explicação específica, a menos que isso seja necessário – ou seja, o princípio da entropia máxima ( Jaynes 1957). Uma segunda maneira pela qual a dinâmica epistêmica se torna aparente é durante a minimização da energia livre esperada, onde – curiosamente – existem duas entropias com sinais opostos. Estes incluem a entropia preditiva posterior (quão incerto eu estou sobre quais resultados eu encontraria dada uma escolha) que deve ser maximizada – como para crenças sobre estados na energia livre variacional – e a entropia condicional de resultados dados estados (a ambiguidade implicada por uma política) que deve ser minimizada. Enquanto durante a minimização da energia livre variacional o imperativo é maximizar a entropia das crenças (presentes), durante a maximização da energia livre esperada o imperativo é selecionar ações que minimizem a ambiguidade das crenças (futuras). Isso dá origem a comportamentos epistêmicos, curiosos, de busca de novidades e de busca de informações, que suportam a resolução de incertezas ou a melhoria do modelo generativo – o que, por sua vez, minimiza a surpresa a longo prazo (Seth 2013; Friston, Rigoli et al. 2015; Seth e Friston 2016; Schwartenbeck, Passecker et ai. 2019).|


