# Inferência ativa como uma teoria unificada do comportamento sensível

Em geral,  nós estamos menos cientes do que nossas mentes fazem de melhor—Marvin Minsky

## Introdução

Neste capítulo, encerramos os principais pontos teóricos da Inferência Ativa (da primeira parte do livro) e suas implementações práticas (da segunda parte). Em seguida, conectamos os pontos: nos abstraímos dos modelos específicos de Inferência Ativa discutidos nos capítulos anteriores para focar nos aspectos integrativos da estrutura. Um benefício da Inferência Ativa é que ela fornece uma solução completa para os problemas adaptativos que os organismos sencientes precisam resolver. Portanto, oferece uma perspectiva unificada sobre problemas como percepção, seleção de ações, atenção e regulação de emoções, que geralmente são tratados isoladamente em psicologia e neurociência – e abordados usando abordagens computacionais distintas em inteligência artificial. Discutiremos a perspectiva de Inferência Ativa em cada um desses problemas (e mais) no contexto de teorias estabelecidas, como cibernética, teoria da ação ideomotora, aprendizado por reforço e controle ótimo. Finalmente, discutimos brevemente como o escopo da Inferência Ativa pode ser estendido para cobrir outros tópicos biológicos, sociais e tecnológicos que não são discutidos em profundidade neste livro.

## Empacotando

Este livro oferece um relato sistemático dos fundamentos teóricos e implementações práticas da Inferência Ativa. Aqui, resumimos brevemente a discussão dos primeiros nove capítulos. Isso oferece uma oportunidade de ensaiar as principais construções da Inferência Ativa que serão úteis no restante deste capítulo.

**No capítulo 1**, introduzimos a Inferência Ativa como uma abordagem normativa para entender as criaturas sencientes que fazem parte de laços de ação-percepção com seu ambiente (Fuster 2004). Explicamos que as abordagens normativas partem dos primeiros princípios para derivar e testar previsões empíricas sobre o fenômeno de interesse – aqui, as maneiras pelas quais os organismos vivos persistem enquanto se envolvem em trocas adaptativas (loops de percepção de ação) com seu ambiente. Também consideramos que se poderia chegar à Inferência Ativa seguindo uma estrada baixa ou uma estrada alta.

No **capítulo 2**, ilustramos o caminho para a Inferência Ativa. Esse caminho parte da ideia de que o cérebro é uma máquina de previsão, dotada de um modelo generativo: uma representação probabilística de como as causas ocultas no mundo geram sensações (por exemplo, como a luz refletida em uma maçã estimula a retina). Ao inverter esse modelo, ele infere as causas de suas sensações (por exemplo, se estou vendo uma maçã, já que minha retina é estimulada de certa forma). Essa visão da percepção (também conhecida como percepção-como-inferência) tem suas raízes históricas na noção helmholtziana de inferência inconsciente e, mais recentemente, na hipótese do cérebro bayesiano. A Inferência Ativa estende essa visão trazendo controle de ação e planejamento dentro do compasso da inferência (também conhecido como controle-como-inferência, planejamento-como-inferência). Mais importante ainda, mostra que percepção e ação não são processos essencialmente separáveis, mas cumprem o mesmo objetivo. Descrevemos primeiro esse objetivo de maneira mais informal, como a minimização de uma discrepância entre o modelo de alguém e o mundo (o que geralmente se reduz à surpresa ou minimização do erro de previsão). Simplificando, pode-se minimizar a discrepância entre um modelo e o mundo de duas maneiras: mudando a mente para se adequar ao mundo (percepção) ou mudando o mundo para se adequar ao modelo (ação). Estes podem ser descritos em termos de inferência Bayesiana. No entanto, a inferência exata é muitas vezes intratável, então a Inferência Ativa usa uma aproximação (variacional) (observando que a inferência exata pode ser vista como um caso especial de inferência aproximada). Isso leva à segunda descrição mais formal do objetivo comum de percepção e ação, como minimização de energia livre variacional. Esta é a quantidade central usada na Inferência Ativa e pode ser descompactada em termos de suas partes constituintes (por exemplo, energia e entropia, complexidade e precisão, ou surpresa e divergência). Finalmente, introduzimos um segundo tipo de energia livre: a energia livre esperada. Isso é particularmente importante durante o planejamento, pois oferece uma maneira de pontuar políticas alternativas considerando o resultado futuro que se espera que elas gerem. Isso também pode ser descompactado em termos de suas partes constituintes (por exemplo, ganho de informação e valor pragmático, ambiguidade e risco esperados).

No **capítulo 3**, ilustramos o caminho para a Inferência Ativa. Esse caminho alternativo parte do imperativo deflacionário para que os organismos biológicos preservem sua integridade e evitem a dissipação, o que pode ser descrito como evitar estados surpreendentes. Introduzimos então a noção de um envoltório de Markov: uma formalização da separação estatística entre os estados internos do organismo e os estados externos do mundo. Fundamentalmente, os estados internos e externos só podem influenciar um ao outro indiretamente por meio de variáveis intermediárias (ativas e sensoriais), chamadas de estados de cobertura. Essa separação estatística – mediada pelo envoltório de Markov – é crucial para dotar um organismo de algum grau de autonomia em relação ao mundo externo. Para entender por que essa é uma perspectiva útil, considere as três consequências a seguir.

Primeiro, um organismo com um envoltório de Markov parece modelar o ambiente externo em um sentido bayesiano: seus estados internos correspondem - em média - a uma crença posterior aproximada sobre estados externos do mundo. Em segundo lugar, a autonomia é garantida pelo fato de que o modelo do organismo (seus estados internos) não é imparcial, mas prescreve algumas pré-condições existenciais (ou preferências prévias) que devem ser mantidas – por exemplo, para um peixe, estar na água. Em terceiro lugar, equipado com esse formalismo, é possível descrever o comportamento ótimo (em relação às preferências anteriores) como a maximização da evidência do modelo (bayesiano) por percepção e ação. Ao maximizar a evidência do modelo (ou seja, auto-evidente), um organismo garante que ele realize suas preferências anteriores (por exemplo, um peixe permanece na água) e evita estados surpreendentes. Por sua vez, a maximização da evidência do modelo é (aproximadamente) matematicamente equivalente à minimização da energia livre variacional - portanto, chegamos novamente (de outra maneira) ao mesmo construto central da Inferência Ativa discutido no capítulo 2. Finalmente, detalhamos a relação entre minimizar a surpresa e o princípio da menor ação de Hamilton. Isso evidencia a relação formal entre a Inferência Ativa e os primeiros princípios da física estatística.

No **capítulo 4**, delineamos os aspectos formais da Inferência Ativa. Nós nos concentramos na passagem da inferência bayesiana para uma aproximação tratável - inferência variacional - e o objetivo resultante para os organismos minimizarem a energia livre variacional por meio da percepção e da ação. O insight desse tratamento é a importância do modelo generativo que as criaturas usam para dar sentido ao seu mundo. Introduzimos dois tipos de modelos generativos que expressam nossas crenças sobre como os dados são gerados, usando variáveis discretas ou contínuas. Explicamos que ambos fornecem a mesma Inferência Ativa, mas se aplicam quando estados de coisas são formulados em tempo discreto (como problemas de decisão de Markov parcialmente observados) ou em tempo contínuo (como equações diferenciais estocásticas), respectivamente.

No **capítulo 5**, comentamos sobre a diferença entre o princípio normativo da minimização da energia livre e uma teoria de processo sobre como esse princípio pode ser implementado pelo cérebro – e explicamos que este último gera previsões testáveis. Em seguida, delineamos aspectos das teorias de processo que acompanham a Inferência Ativa, que abrange domínios como a passagem de mensagens neuronais, incluindo circuitos neuroanatômicos (por exemplo, alças córtico-subcorticais) e neuromodulação. Por exemplo, em um nível anatômico, a passagem de mensagens mapeia bem para um microcircuito cortical canônico, com previsões que derivam de camadas corticais profundas em um nível e visam camadas corticais superficiais no nível abaixo (Bastos et al. 2012). Em um nível mais sistêmico, discutimos como inferência Bayesiana, aprendizado e ponderação de precisão correspondem à dinâmica neuronal, plasticidade sináptica e neuromodulação, respectivamente, e como a mensagem neural de cima para baixo e de baixo para cima passa de mapas de codificação preditiva para mais lento ( por exemplo, alfa ou beta) e ritmos cerebrais mais rápidos (por exemplo, gama). Esses e outros exemplos ilustram que, após projetar um modelo específico de Inferência Ativa, pode-se extrair implicações neurobiológicas da forma de seu modelo generativo.

No **capítulo 6**, fornecemos uma receita para projetar modelos de Inferência Ativa. Vimos que, embora todas as criaturas minimizem sua energia livre variacional, elas se comportam de maneiras diferentes, às vezes opostas, porque são dotadas de diferentes modelos generativos. Portanto, o que distingue criaturas diferentes (por exemplo, mais simples de mais complexas) é apenas seu modelo generativo. Existe um rico repertório de possíveis modelos generativos, que correspondem a diferentes implementações biológicas (por exemplo, neuronais) e produzem diferentes comportamentos adaptativos – ou mal adaptativos – em diferentes contextos e nichos ecológicos. Isso torna a Inferência Ativa igualmente apropriada para caracterizar criaturas simples como bactérias que detectam e buscam gradientes de nutrientes, criaturas complexas como nós que perseguem objetivos sofisticados e se envolvem em ricas práticas culturais, ou mesmo indivíduos diferentes – na medida em que caracterizam adequadamente seus respectivos modelos generativos . A evolução parece ter descoberto estruturas de design cada vez mais sofisticadas para cérebros e corpos que tornaram os organismos capazes de lidar (e moldar) ricos nichos ecológicos. Os modeladores podem fazer engenharia reversa desse processo e especificar os projetos para cérebros e corpos de criaturas de interesse, em termos de modelos generativos, com base nos tipos de nicho que ocupam. Isso corresponde a uma série de escolhas de projeto (por exemplo, modelos usando variáveis ​​discretas ou categóricas, modelos superficiais ou hierárquicos) – que descompactamos no capítulo.

Nos **capítulos 7 e 8**, fornecemos vários exemplos de modelos de Inferência Ativa em tempo discreto e contínuo, que abordam problemas de inferência perceptiva, navegação direcionada a objetivos, aprendizado de modelos, controle de ação e muito mais. Esses exemplos foram projetados para mostrar a variedade de comportamentos emergentes sob esses modelos e detalhar os princípios de como eles são especificados na prática.

No **capítulo 9**, discutimos como usar a Inferência Ativa para análise de dados baseada em modelo e recuperar os parâmetros do modelo generativo de um indivíduo, que explicam melhor o comportamento do sujeito em uma tarefa. Essa fenotipagem computacional usa a mesma forma de inferência bayesiana discutida no restante do livro, mas de uma maneira diferente: ajuda a projetar e avaliar modelos (objetivos) de modelos (subjetivos) de outros.

## Conectando os Pontos: A Perspectiva Integrativa da Inferência Ativa

Algumas décadas atrás, o filósofo Dennett lamentou que os cientistas cognitivos dedicassem muito esforço para modelar subsistemas isolados (por exemplo, percepção, compreensão da linguagem) cujos limites são frequentemente arbitrários. Ele sugeriu tentar modelar “toda a iguana”: uma criatura cognitiva completa (talvez uma simples) e um nicho ambiental para ela lidar (Dennett 1978).

Um benefício da Inferência Ativa é que ela oferece um primeiro relato de princípio das maneiras pelas quais os organismos resolvem seus problemas adaptativos. A abordagem normativa adotada neste livro pressupõe que é possível partir do princípio da minimização variacional da energia livre e derivar implicações sobre processos cognitivos específicos, como percepção, seleção de ação, regulação de atenção e emoção e seus fundamentos neuronais.

Imagine uma criatura simples que deve resolver problemas como encontrar comida ou abrigo. Quando lançado como Inferência Ativa, os problemas da criatura podem ser descritos em termos enativos, como agindo para solicitar sensações preferidas (por exemplo, sensações relacionadas à comida). Na medida em que essas sensações preferidas são incluídas (como crenças anteriores) em seu modelo generativo, o organismo está efetivamente reunindo evidências para seu modelo – ou, mais alegoricamente, para sua existência (ou seja, maximizando a evidência do modelo ou autoevidência). Esse princípio simples tem ramificações para funções psicológicas tradicionalmente consideradas isoladamente, como percepção, controle de ação, memória, atenção, intenção, emoção e muito mais. Por exemplo, percepção e ação são autoevidentes, no sentido de que uma criatura pode alinhar o que espera, dado seu modelo gerador, com o que sente, seja mudando suas crenças (sobre a presença de comida) ou mudando o mundo. (solicitando sensações relacionadas à comida). Memória e atenção também podem ser pensadas como otimizando o mesmo objetivo. A memória de longo prazo se desenvolve através do aprendizado dos parâmetros de um modelo generativo. A memória de trabalho é a atualização de crenças quando as crenças são sobre estados externos no passado e no futuro. A atenção é a otimização das crenças sobre a precisão da entrada sensorial. Formas de planejamento (e intencionalidade) podem ser conceituadas apelando para a capacidade de (algumas) criaturas de selecionar entre futuros alternativos, o que, por sua vez, requer modelos generativos temporalmente profundos. Estes prevêem os resultados que resultariam de um curso de ação e são otimistas sobre esses resultados. Esse otimismo se manifesta como a crença de que os resultados futuros levarão a resultados preferidos. Modelos temporais profundos também podem nos ajudar a entender formas sofisticadas de prospecção (onde crenças sobre o presente são usadas para derivar crenças sobre o futuro) e retrospecção (onde crenças sobre o presente são usadas para atualizar crenças sobre o passado). Formas de regulação interoceptiva e emoção podem ser conceituadas apelando para modelos generativos de fisiologia interna que predizem as consequências alostáticas de eventos futuros.

Como os exemplos acima ilustram, há uma consequência importante de estudar a cognição e o comportamento da perspectiva de uma teoria normativa do comportamento senciente. Tal teoria não começa reunindo funções cognitivas separadas, como percepção, tomada de decisão e planejamento. Em vez disso, começa fornecendo uma solução completa para os problemas que os organismos precisam resolver e, em seguida, analisando a solução para derivar implicações sobre as funções cognitivas. Por exemplo, quais mecanismos permitem que um organismo vivo ou criatura artificial (por exemplo, um robô) perceba o mundo, lembre-se dele ou planeje (Verschure et al. 2003, 2014; Verschure 2012; Pezzulo, Barsalou et al. 2013; Krakauer et al. al. 2017)? Este é um movimento importante, pois as taxonomias das funções cognitivas - usadas em livros de psicologia e neurociência - herdam em grande parte das primeiras teorias filosóficas e psicológicas (às vezes chamadas de categorias jamesianas). Apesar de seu grande valor heurístico, eles podem ser bastante arbitrários – ou podem não corresponder a processos cognitivos e neurais separados (Pezzulo e Cisek 2016, Buzsaki 2019, Cisek 2019). De fato, essas categorias jamesianas podem ser candidatas a como nossos modelos generativos explicam nosso envolvimento com o sensório – em oposição a explicar esse envolvimento. Por exemplo, a hipótese solipsista de que “estou percebendo” é apenas minha explicação para estados atuais de coisas que incluem minha atualização de crenças.

Adotar uma perspectiva normativa também pode ajudar na identificação de analogias formais entre fenômenos cognitivos estudados em diferentes domínios. Um exemplo é o trade-off entre prospecção e aproveitamento , que aparece em várias formas (Hills et al. 2015). Essa troca é frequentemente estudada durante o forrageamento, quando as criaturas devem escolher entre explorar planos anteriores de sucesso e explorar novos (potencialmente melhores). No entanto, a mesma troca ocorre durante a pesquisa de memória e deliberação com recursos limitados (por exemplo, limitações de tempo ou esforço de pesquisa), quando as criaturas têm a escolha entre explorar seu melhor plano atual versus investir mais tempo e esforço cognitivo para explorar possibilidades adicionais. Caracterizar esses fenômenos aparentemente desconectados em termos de energia livre pode revelar semelhanças profundas (Friston, Rigoli et al. 2015; Pezzulo, Cartoni et al. 2016; Gottwald e Braun 2020).

Finalmente, além de uma perspectiva unificada sobre fenômenos psicológicos, a Inferência Ativa oferece um meio baseado em princípios para entender as computações neurais correspondentes. Em outras palavras, oferece uma teoria de processo que conecta o processamento cognitivo à dinâmica neuronal (esperada). A Inferência Ativa assume que tudo o que importa sobre cérebros, mentes e comportamento pode ser descrito em termos da minimização da energia livre variacional. Por sua vez, essa minimização tem assinaturas neurais específicas (em termos de,
ex., passagem de mensagens ou anatomia cerebral) que podem ser validados empiricamente.

No restante deste capítulo, exploramos algumas implicações da Inferência Ativa para funções psicológicas — como se estivéssemos esboçando um livro de psicologia. Para cada uma dessas funções, também destacamos alguns pontos de contato (ou divergência) entre a Inferência Ativa e outras teorias populares na literatura.

## Cérebros Preditivos, Mentes Preditivas e Processamento Preditivo

Eu tenho essa foto de pura alegria 
é de uma criança com uma arma
ele está mirando bem na sua frente, 
atirando em algo que não está lá.
— Afterhours, “Quello che non c’è” (Algo que não está lá)

As teorias tradicionais do cérebro e da cognição enfatizam as transduções de alimentação direta de estímulos externos para representações internas e, em seguida, ações motoras. Isso tem sido chamado de “modelo sanduíche”, pois tudo o que está entre estímulos e respostas recebe o rótulo de “cognitivo” (Hurley 2008). Nessa perspectiva, a principal função do cérebro é transformar os estímulos recebidos em respostas contextualmente apropriadas.

A Inferência Ativa se afasta significativamente dessa visão, enfatizando aspectos preditivos e direcionados a objetivos do cérebro e da cognição. Em termos psicológicos, criaturas de Inferência Ativa (ou seus cérebros) são máquinas de inferência probabilísticas, que continuamente geram previsões baseadas em seus modelos generativos.

Criaturas auto-evidentes usam suas previsões de duas maneiras fundamentais. Primeiro, eles comparam as previsões com os dados recebidos para validar suas hipóteses (codificação preditiva) e – em uma escala de tempo mais lenta – revisam seus modelos (aprendizagem). Em segundo lugar, eles fazem previsões para orientar as formas de coleta de dados (Inferência Ativa). Ao fazer isso, as criaturas de Inferência Ativa cumprem dois imperativos: epistêmicos (por exemplo, explorar visualmente lugares onde estão presentes informações importantes que podem resolver incertezas sobre hipóteses ou modelos) e pragmáticos (por exemplo, mover-se para locais onde observações preferenciais, como recompensas, podem ser garantidas) . O imperativo epistêmico torna os processos de percepção e aprendizagem ativos, enquanto o imperativo pragmático torna o comportamento direcionado a metas.

### Processamento Preditivo

Essa visão preditiva e centrada em objetivos do cérebro – e cognição – está intimamente relacionada (e forneceu inspiração para) processamento preditivo (PP): uma estrutura emergente na filosofia da mente e epistemologia, que vê a previsão como central para o cérebro e a cognição e apela a conceitos de “cérebros preditivos” ou “mentes preditivas” (Clark 2013, 2015; Hohwy 2013).

Às vezes, as teorias PP apelam para o funcionamento específico da Inferência Ativa e alguns de seus construtos, como modelos generativos, codificação preditiva, energia livre, controle de precisão e envoltórios de Markov, mas às vezes apelam para outros construtos, como modelos inversos e diretos acoplados , que não fazem parte da Inferência Ativa. Portanto, o termo processamento preditivo é usado em um sentido mais amplo (e menos restrito) em comparação com a Inferência Ativa.

As teorias de processamento preditivo atraíram considerável atenção na filosofia, devido ao seu potencial de unificação em muitos sentidos: em vários domínios da cognição, incluindo percepção, ação, aprendizagem e psicopatologia; de níveis mais baixos (por exemplo, sensório-motor) para níveis mais altos de processamento cognitivo (por exemplo, construções psicológicas); desde simples organismos biológicos até cérebros, indivíduos e construções sociais e culturais. Outro apelo das teorias PP é que elas fazem uso de termos conceituais, como crenças e surpresa, que falam a um nível psicológico de análise familiar aos filósofos (com a ressalva de que às vezes esses termos podem ter significados técnicos diferentes do uso comum) .

No entanto, à medida que o interesse pela PP cresce, tornou-se evidente que os filósofos têm opiniões diferentes sobre suas implicações teóricas e epistemológicas. Por exemplo, foi interpretado em termos internalistas (Hohwy 2013), incorporados ou baseados em ação (Clark 2015) e enativistas e não representacionais (Bruineberg et al. 2016, Ramstead et al. 2019). O debate em torno dessas interpretações conceituais vai além do escopo deste livro. 

## Percepção

Você não pode depender de seus olhos quando sua imaginação está fora de foco. —Mark Twain

A Inferência Ativa considera a percepção como um processo inferencial baseado em um modelo generativo de como as observações sensoriais são geradas. A regra de Bayes essencialmente inverte o modelo para calcular uma crença sobre o estado oculto do ambiente, dadas as observações. Essa ideia de percepção-como-inferência remonta a Helmholtz (1866) e foi frequentemente reproposta em psicologia, neurociência computacional e aprendizado de máquina (por exemplo, análise por síntese) (Gregory 1980, Dayan et al. 1995, Mesulam 1998, Yuille e Kersten 2006). Essa abordagem de modelagem generativa demonstrou ser eficaz no enfrentamento de problemas de percepção desafiadores, como quebrar CAPTCHAs baseados em texto (George et al. 2017).

### Hipótese do Cérebro Bayesiano

A expressão contemporânea mais proeminente dessa ideia é a hipótese do cérebro bayesiano, que tem sido aplicada a vários domínios, como tomada de decisão, processamento sensorial e aprendizado (Doya 2007). A Inferência Ativa fornece uma base normativa para essas ideias inferenciais, derivando-as do imperativo de minimizar a energia livre variacional. Como o mesmo imperativo se estende à dinâmica da ação, a Inferência Ativa naturalmente modela a percepção ativa e as maneiras pelas quais os organismos ativamente amostram observações para testar suas hipóteses (Gregory 1980). Sob a agenda do cérebro bayesiano, em vez disso, a percepção e a ação são modeladas em termos de imperativos diferentes (onde a ação requer a teoria da decisão bayesiana; veja seção 10.7.1).

Mais amplamente, a hipótese do cérebro Bayesiano refere-se a uma família de abordagens que não são necessariamente integradas e muitas vezes fazem previsões empíricas diferentes. Estes incluem, por exemplo, a proposta em nível computacional de que o cérebro realiza integração sensório-motora e multissensorial ótima de Bayes (Kording e Wolpert 2006), a proposta em nível algorítmico de que o cérebro implementa aproximações específicas de inferência Bayesiana, como decisão-por- amostragem (Stewart et al. 2006), e as propostas de nível neural sobre as maneiras específicas em que as populações neurais podem realizar cálculos probabilísticos ou codificar distribuições de probabilidade - por exemplo, como amostras ou códigos populacionais probabilísticos (Fiser et al. 2010, Pouget et al. 2013). Em cada nível de explicação, existem teorias concorrentes no campo. Por exemplo, é comum recorrer a aproximações de inferência Bayesiana exata para explicar desvios do comportamento ótimo, mas trabalhos diferentes consideram aproximações diferentes (e nem sempre compatíveis), como diferentes abordagens de amostragem. Mais amplamente, as relações entre propostas em diferentes níveis nem sempre são diretas. Isso ocorre porque os cálculos bayesianos podem ser realizados (ou aproximados) de várias maneiras algorítmicas, mesmo sem representar explicitamente as distribuições de probabilidade (Aitchison e Lengyel 2017).

A Inferência Ativa fornece uma perspectiva mais integrada que conecta princípios normativos e teorias de processo. No nível normativo, seu pressuposto central é que todos os processos minimizam a energia livre variacional. A teoria do processo correspondente para inferência usa um gradiente descendente na energia livre, que tem implicações neurofisiológicas claras, exploradas no capítulo 5 (Friston, FitzGerald et al. 2016). Mais amplamente, pode-se partir do princípio da minimização da energia livre para derivar implicações sobre as arquiteturas do cérebro.

Por exemplo, o modelo de processo canônico de inferência perceptual (em tempo contínuo) é a codificação preditiva. A codificação preditiva foi inicialmente proposta como uma teoria do processamento perceptual hierárquico por Rao e Ballard (1999) para explicar uma série de efeitos documentados de cima para baixo, que eram difíceis de conciliar com arquiteturas feedforward, bem como fatos fisiológicos conhecidos (por exemplo, a existência de conexões para frente, ou de baixo para cima, e para trás, ou de cima para baixo, nas hierarquias sensoriais). No entanto, a codificação preditiva pode ser derivada do princípio da minimização da energia livre, sob algumas premissas, como a aproximação de Laplace (Friston 2005). Além disso, a Inferência Ativa em tempo contínuo pode ser construída como uma extensão direcionada da codificação preditiva no domínio da ação – dotando um agente de codificação preditiva com reflexos motores (Shipp et al. 2013). Isso nos leva ao próximo ponto.

##  Controle de Ação

Se você não pode voar, corra, se não pode correr, ande, se não puder andar, rasteje, mas faça o que fizer, continue seguindo em frente.
—Martin Luther King

Na Inferência Ativa, o processamento da ação é análogo ao processamento perceptivo, pois ambos são guiados por previsões diretas – exteroceptivas e proprioceptivas, respectivamente. É a previsão (proprioceptiva) de que “minha mão agarra a xícara” que induz um movimento de agarrar. A equivalência entre ação e percepção existe também no nível neurobiológico: a arquitetura do córtex motor é organizada da mesma forma que o córtex sensorial – como uma arquitetura de codificação preditiva, com a exceção de que pode influenciar os reflexos motores no tronco cerebral e coluna vertebral (Shipp et al. 2013) e que recebe relativamente pouca entrada ascendente. Os reflexos motores permitem controlar o movimento estabelecendo “pontos de equilíbrio” ao longo de uma trajetória desejada – uma ideia que corresponde à hipótese do ponto de equilíbrio (Feldman 2009).

É importante ressaltar que iniciar uma ação – como pegar uma xícara – requer regulação da precisão (variância inversa) de crenças anteriores e fluxos sensoriais de forma adequada. Isso ocorre porque os valores relativos dessas precisões determinam a maneira pela qual uma criatura administra o conflito entre sua crença anterior (que ela segura a xícara) e sua entrada sensorial (sinalizando que ela não segura). Uma crença prévia imprecisa sobre pegar uma xícara pode ser facilmente revisada à luz de evidências sensoriais conflitantes – produzindo uma mudança de opinião e nenhuma ação. Em vez disso, quando a crença anterior domina (ou seja, tem maior precisão), ela é mantida mesmo diante de evidências sensoriais conflitantes – e induz uma ação de apreensão para resolver o conflito. Para garantir que este seja o caso, a iniciação da ação induz uma atenuação sensorial transitória (ou erros de predição sensorial de peso reduzido). A falha dessa atenuação sensorial pode ter consequências desadaptativas, como a falha em iniciar ou controlar os movimentos (Brown et al. 2013).

### Teoria Ideomotora

Na Inferência Ativa, a ação decorre de previsões (proprioceptivas) e não de comandos motores (Adams, Shipp e Friston 2013). Essa ideia conecta a Inferência Ativa à teoria ideomotora da ação: uma estrutura para entender o controle da ação que remonta a William James (1890) e as teorias posteriores de “codificação de eventos” e “controle comportamental antecipatório” (Hommel et al. 2001, Hoffmann 2003). ). A teoria ideomotora sugere que as ligações ação-efeito (semelhantes aos modelos diretos) são mecanismos-chave na arquitetura da cognição. É importante ressaltar que esses links podem ser usados ​​bidirecionalmente. Quando utilizados no sentido ação-efeito, permitem gerar previsões sensoriais; quando são usados ​​na direção efeito-ação, eles permitem selecionar ações que alcançam as consequências perceptivas desejadas – implicando que as ações são selecionadas e controladas com base em suas consequências previstas (daí o termo ideo + motor). Essa visão antecipatória do controle da ação é apoiada por um corpo de literatura que documenta os efeitos das consequências (antecipadas) da ação na seleção e execução da ação (Kunde et al. 2004). A Inferência Ativa fornece uma caracterização matemática dessa ideia que também inclui mecanismos adicionais, como a importância do controle de precisão e atenuação sensorial, que não são totalmente investigados na teoria ideomotora (mas são compatíveis com ela).

### Cibernética

A Inferência Ativa está intimamente relacionada às ideias cibernéticas sobre a natureza intencional e direcionada a objetivos do comportamento e a importância das interações agente-ambiente (baseadas em feedback), como exemplificado pelo TOTE (Test, Operate, Test, Exit) e modelos relacionados ( Miller e outros 1960; Pezzulo, Baldassarre e outros 2006). Tanto no TOTE quanto no Active Inference, a seleção de ações é determinada pela discrepância entre um estado preferencial (objetivo) e o estado atual. Essas abordagens divergem das simples relações estímulo-resposta, como mais comumente assumidas na teoria behaviorista e estruturas computacionais como o aprendizado por reforço (Sutton e Barto, 1998).

A noção de controle de ação na Inferência Ativa é particularmente semelhante à teoria do controle perceptual (Powers 1973). Central para a teoria do controle perceptual era a noção de que o que é controlado é um estado perceptivo, não uma saída ou ação motora. Por exemplo, enquanto dirigimos, o que controlamos – e mantemos estável ao longo do tempo diante de distúrbios – é nossa referência ou velocidade desejada (por exemplo, 90 mph), conforme sinalizado pelo velocímetro, enquanto as ações que selecionamos para isso (por exemplo, acelerando ou desacelerando) são mais variáveis e dependentes do contexto. Por exemplo, dependendo da perturbação (por exemplo, vento, uma estrada íngreme ou outros carros), precisaríamos acelerar ou desacelerar para manter a velocidade de referência. Essa visão implementa a sugestão de William James (1890) de que “os humanos alcançam objetivos estáveis por meios flexíveis”.

Embora tanto na Inferência Ativa quanto na teoria do controle perceptual seja uma previsão perceptiva (e especificamente uma proprioceptiva) que controla a ação, as duas teorias diferem em como o controle é operado. Na Inferência Ativa, mas não na teoria do controle perceptual, o controle da ação tem aspectos antecipatórios ou feedforward, baseados em modelos generativos. Em contraste, a teoria do controle perceptual assume que os mecanismos de feedback são amplamente suficientes para controlar o comportamento, enquanto tentar prever uma perturbação ou exercer controle feedforward (ou malha aberta) é inútil. No entanto, essa objeção destinava-se principalmente a abordar as limitações das teorias de controle que usam modelos inversos para a frente (veja a próxima seção). Sob a Inferência Ativa, modelos generativos ou diretos não são usados para prever uma perturbação, mas para prever estados e trajetórias futuras (desejadas) a serem cumpridas pela ação – e para inferir a causa latente de eventos perceptivos.

Finalmente, outro ponto importante de contato entre a Inferência Ativa e a teoria do controle perceptual é a maneira como eles conceituam as hierarquias de controle. A teoria do controle perceptual propõe que os níveis hierárquicos mais altos controlam os níveis hierárquicos mais baixos, definindo seus pontos de referência ou pontos de ajuste (ou seja, o que eles precisam alcançar), deixando-os livres para selecionar os meios para alcançá-los, em vez de definir ou influenciar as ações que os níveis mais baixos têm que desempenhar (ou seja, como operar). Isso contrasta com a maioria das teorias de controle hierárquico e de cima para baixo, nas quais os níveis superiores selecionam diretamente os planos (Botvinick 2008) ou influenciam a seleção de ações ou comandos motores em níveis hierárquicos inferiores (Miller e Cohen 2001). Semelhante à teoria do controle perceptual, na Inferência Ativa pode-se decompor o controle hierárquico em termos de uma cascata (de cima para baixo) de objetivos e subobjetivos, que podem ser alcançados de forma autônoma nos níveis apropriados (inferiores). Além disso, na Inferência Ativa, a contribuição das metas representadas em diferentes níveis da hierarquia de controle pode ser modulada (precisão ponderada) por processos motivacionais, de forma que as metas mais salientes ou urgentes sejam priorizadas (Pezzulo, Rigoli e Friston 2015, 2018).

### Teoria do Controle Ótimo

A forma como a Inferência Ativa explica o controle da ação é significativamente diferente de outros modelos de controle na neurociência, como a teoria do controle ótimo (Todorov 2004, Shadmehr et al. 2010). Essa estrutura pressupõe que o córtex motor do cérebro seleciona ações usando uma política de controle (reativa) que mapeia estímulos para respostas. A Inferência Ativa, em vez disso, assume que o córtex motor transmite previsões, não comandos.

Além disso, embora tanto a teoria de controle ótimo quanto a Inferência Ativa apelem para modelos internos, elas descrevem a modelagem interna de maneiras diferentes (Friston 2011). No controle ótimo, há uma distinção entre dois tipos de modelos internos: os modelos inversos codificam contingências estímulo-resposta e selecionam comandos motores (de acordo com alguma função de custo), enquanto os modelos diretos codificam contingências ação-resultado e fornecem modelos inversos com entradas simuladas para substituir o feedback ruidoso ou atrasado, indo além de um esquema de controle de feedback puro. Modelos inversos e diretos também podem operar em um loop que é separado da percepção de ação externa (ou seja, quando entradas e saídas são suprimidas) para dar suporte a simulações “e se” internas de sequências de ação. Tais simulações internas de ação têm sido associadas a várias funções cognitivas, como planejamento, percepção de ação e imitação em domínios sociais ( Jeannerod 2001, Wolpert et al. 2003), bem como vários distúrbios do movimento e psicopatologias (Frith et al. 2000 ).

Em contraste com o esquema de modelagem direta-inversa, na Inferência Ativa os modelos diretos (generativos) fazem o trabalho pesado do controle da ação, enquanto os modelos inversos são minimalistas e geralmente se reduzem a reflexos simples resolvidos no nível periférico (ou seja, no tronco cerebral ou medula espinhal). A ação é iniciada quando há uma diferença entre os estados antecipados e observados (por exemplo, posições desejadas, atuais dos braços) - ou seja, um erro de previsão sensorial. Isso significa que um comando motor é equivalente a uma previsão feita pelo modelo direto em oposição a algo calculado por um modelo inverso como no controle ótimo. O erro de previsão sensorial (mais precisamente, proprioceptivo) é resolvido por uma ação (ou seja, movimento do braço). A lacuna a ser preenchida pela ação é considerada tão pequena que não requer um modelo inverso sofisticado, mas um reflexo motor muito mais simples (Adams, Shipp e Friston 2013).[^101] O que torna um reflexo motor mais simples do que um modelo inverso é que ele não codifica um mapeamento de estados inferidos do mundo para ação, mas um mapeamento muito mais simples entre ação e consequências sensoriais. Ver Friston, Daunizeau et ai. (2010) para uma discussão mais aprofundada.

[^101]:De um ponto de vista mais pragmático, a Inferência Ativa requer apenas a aquisição de modelos diretos, que são (tipicamente) mais fáceis de aprender em comparação aos modelos inversos porque são simplesmente um mapeamento direto (observável) entre ações e consequências. Modelos avançados também podem ser adquiridos por imitação ou supervisão externa – uma técnica amplamente análoga à Inferência Ativa que é amplamente usada para treinar modelos robóticos (Nishimoto e Tani 2009)

Outra diferença crucial entre o controle motor ótimo e a Inferência Ativa é que o primeiro usa uma noção de custo ou função de valor para motivar a ação, enquanto o segundo a substitui pela noção bayesiana de prioridade anterior (ou preferência anterior, implícita na energia livre esperada) – como discutimos na próxima seção.


## Utilidade e Tomada de Decisão

A ação expressa prioridades. —Mahatma Gandhi

A noção de uma função de custo ou valor de estados é central em muitos campos, como controle motor ótimo, teorias econômicas de maximização de utilidade e aprendizado por reforço. Por exemplo, na teoria de controle ótimo, a política de controle ótimo para uma tarefa de alcance é frequentemente definida como aquela que minimiza uma função de custo específica (por exemplo, é mais suave ou tem um jerk mínimo). Em problemas de aprendizado por reforço, como navegar em um labirinto que inclui uma ou mais recompensas, a política ótima é aquela que permite maximizar (descontar) a recompensa enquanto também minimiza os custos de movimento. Esses problemas são muitas vezes resolvidos usando a equação de Bellman (ou a equação de Hamilton-Jacobi-Bellman em tempo contínuo), cuja ideia geral é que o valor de uma decisão pode ser decomposto em duas partes: a recompensa imediata e o valor do restante. parte do problema de decisão. Essa decomposição fornece o procedimento iterativo de programação dinâmica, que está no centro da teoria de controle e do aprendizado por reforço (RL) (Bellman 1954).

A Inferência Ativa difere da abordagem acima de duas maneiras principais. Primeiro, a Inferência Ativa não considera apenas a maximização da utilidade, mas o objetivo mais amplo da minimização da energia livre (esperada), que também inclui imperativos (epistêmicos) adicionais, como a desambiguação do estado atual e a busca de novidades (veja a figura 2.5). Esses objetivos adicionais às vezes são adicionados às recompensas clássicas – por exemplo, como um “bônus de novidade” (Kakade e Dayan 2002) ou “recompensa intrínseca” (Schmidhuber 1991, Oudeyer et al. 2007, Baldassarre e Mirolli 2013, Gottlieb et al. 2013)—mas eles surgem automaticamente na Inferência Ativa, permitindo que ela resolva os trade-offs prospecção-aproveitamento implícitos em muitas decisões. A razão para isso é que as energias livres são funcionais de crenças, o que significa que estamos no domínio da otimização de crenças em oposição às funções de recompensa externas. Isso é essencial em problemas exploratórios, em que o sucesso depende de resolver o máximo de incertezas possível.

Em segundo lugar, na Inferência Ativa, a noção de custo é absorvida pelo anterior. O prior (ou preferência anterior) especifica um objetivo para controle – por exemplo, uma trajetória a seguir ou um ponto final a ser alcançado. Usar priores para codificar observações (ou sequências) preferidas pode ser mais expressivo do que usar utilitários (Friston, Daunizeau e Kiebel 2009). Usando esse método, encontrar a política ótima é reformulado como um problema de inferência (de uma sequência de estados de controle que realizam a trajetória preferida) e não requer uma função de valor ou a equação de Bellman - embora possa recorrer a uma lógica recursiva semelhante (Friston , Da Costa et al. 2020). Existem pelo menos duas diferenças fundamentais entre as formas como as funções prioritárias e de valor são normalmente usadas na Inferência Ativa e RL, respectivamente. Primeiro, os métodos RL usam funções de valor de estados ou de pares estado-ação - enquanto a Inferência Ativa usa a priori sobre as observações. Em segundo lugar, as funções de valor são definidas em termos do retorno esperado de estar em um estado (ou realizar uma ação em um estado) seguindo uma política específica – ou seja, a soma de recompensas futuras (descontadas) obtidas por começar no estado e depois execução da política. Em contraste, na Inferência Ativa, as anteriores geralmente não somam recompensas futuras, nem as descontam. Ao contrário, algo análogo ao retorno esperado só surge na Inferência Ativa quando a energia livre esperada de uma apólice é calculada. A implicação é que a energia livre esperada é o análogo mais próximo da função valor. No entanto, mesmo isso difere no sentido de que a energia livre esperada é uma função de crenças sobre estados, não uma função de estados. Dito isso, é possível construir priores que se assemelham a funções de valor de estados em RL - por exemplo, armazenando em cache os cálculos de energia livre esperada nesses estados (Friston, FitzGerald et al. 2016; Maisto, Friston e Pezzulo 2019).

Além disso, absorver a noção de utilidade no anterior tem uma importante consequência teórica: os anteriores desempenham o papel de metas e tornam o modelo gerador tendencioso - ou otimista, no sentido de que a criatura acredita que encontrará resultados preferidos. É esse otimismo que subscreve os planos inferidos que alcançam os resultados desejados na Inferência Ativa; uma falha desse tipo de otimismo pode corresponder à apatia (Hezemans et al. 2020). Isso contrasta com outras abordagens formais de tomada de decisão, como a teoria da decisão bayesiana, que separa a probabilidade dos eventos de sua utilidade. Dito isso, essa distinção é um tanto superficial, pois uma função de utilidade sempre pode ser reescrita como codificando uma crença anterior, consistente com o fato de que comportamentos que maximizam uma função de utilidade são a priori (e por design) mais prováveis. De uma perspectiva deflacionária (ligeiramente tautológica), esta é a definição de utilidade.

### Teoria da Decisão Bayesiana

A teoria da decisão bayesiana é uma estrutura matemática que estende as ideias do cérebro bayesiano (discutidas acima) para os domínios da tomada de decisão, controle sensório-motor e aprendizado (Kording e Wolpert 2006, Shadmehr et al. 2010, Wolpert e Landy 2012). A teoria da decisão bayesiana descreve a tomada de decisão em termos de dois processos distintos. O primeiro processo usa cálculos Bayesianos para prever a probabilidade de resultados futuros (dependentes da ação ou da política), e o segundo processo define a preferência sobre os planos, usando uma utilidade (fixa ou aprendida) ou função de custo. O processo de decisão final (ou seleção de ação) integra ambas as correntes, selecionando assim (com maior probabilidade) o plano de ação que tem maior probabilidade de render a maior recompensa. Isso contrasta com a Inferência Ativa, na qual a distribuição prévia sinaliza diretamente o que é valioso para o organismo (ou o que foi valioso durante a história evolutiva). No entanto, paralelos podem ser traçados entre as duas correntes da teoria da decisão Bayesiana e a otimização da energia livre variacional e esperada, respectivamente. Sob a Inferência Ativa, a minimização da energia livre variacional fornece crenças precisas (e simples) sobre o estado do mundo e sua provável evolução. A crença anterior de que a energia livre esperada será minimizada através da seleção de políticas incorpora a noção de preferências.

Em alguns círculos, há preocupações sobre o status da teoria da decisão bayesiana. Isso decorre dos teoremas de classe completos (Wald 1947, Brown 1981) que dizem que para qualquer par de decisões e funções de custo, existem algumas crenças anteriores que tornam as decisões de Bayes ótimas. Isso significa que há uma dualidade implícita ou degeneração ao lidar separadamente com crenças anteriores e funções de custo. Em certo sentido, a Inferência Ativa resolve essa degeneração absorvendo funções de utilidade ou custo em crenças anteriores na forma de preferências.

### Aprendizado por Reforço

Aprendizagem por reforço (RL) é uma abordagem para resolver problemas de decisão de Markov que é popular tanto na inteligência artificial quanto nas ciências cognitivas (Sutton e Barto 1998). Ele se concentra em como os agentes aprendem uma política (por exemplo, estratégia de balanceamento de pólos) por tentativa e erro: experimentando ações (por exemplo, mover para a esquerda) e recebendo reforços positivos ou negativos, dependendo do sucesso da ação (por exemplo, polo equilibrado) ou falha (por exemplo, polo caído).
 
A Inferência Ativa e a RL tratam de conjuntos de problemas sobrepostos, mas diferem em muitos aspectos matematicamente e conceitualmente. Como observado acima, a Inferência Ativa dispensa as noções de recompensa, funções de valor e otimalidade de Bellman que são fundamentais para as abordagens de aprendizado por reforço. Além disso, a noção de política é usada de forma diferente nas duas estruturas. Em RL, uma política denota um conjunto de mapeamentos estímulo-resposta que precisam ser aprendidos. Na Inferência Ativa, uma política faz parte do modelo generativo: denota uma sequência de estados de controle que precisam ser inferidos.

As abordagens de aprendizagem por reforço são abundantes, mas podem ser subdivididas em três famílias principais. Os dois primeiros métodos tentam aprender boas funções de valor (estado ou ação de estado), embora de duas maneiras diferentes.

Métodos livres de modelo de RL aprendem funções de valor diretamente da experiência: eles realizam ações, coletam recompensas, atualizam suas funções de valor e as usam para atualizar suas políticas. A razão pela qual eles são chamados de livres de modelo é porque eles não usam um modelo (de transição) que permite prever estados futuros - do tipo usado na Inferência Ativa. Em vez disso, eles apelam implicitamente para tipos mais simples de modelos (por exemplo, mapeamentos de ação de estado). As funções de valor de aprendizado em RL sem modelo geralmente envolvem erros de previsão de recompensa de computação, como na regra popular de diferença temporal. Embora a Inferência Ativa geralmente apele a erros de previsão, esses são erros de previsão de estado (já que não há noção de recompensa na Inferência Ativa).

Os métodos de RL baseados em modelos não aprendem funções ou políticas de valor diretamente da experiência. Em vez disso, eles aprendem um modelo da tarefa a partir da experiência, usam o modelo para planejar (simular experiências possíveis) e atualizar funções e políticas de valor dessas experiências simuladas. Embora tanto a Inferência Ativa quanto o aprendizado por reforço apelem ao planejamento baseado em modelo, eles o usam de maneira diferente. Na Inferência Ativa, o planejamento é o cálculo da energia livre esperada para cada política, não um meio de atualizar funções de valor. Indiscutivelmente, se a energia livre esperada é vista como um funcional de valor, pode-se dizer que as inferências feitas usando o modelo generativo são usadas para atualizar esse funcional – oferecendo um ponto de analogia entre essas abordagens.

A terceira família de abordagens de RL, métodos de gradiente de política, tenta otimizar políticas diretamente, sem funções de valor intermediário, que são centrais tanto para RL baseado em modelo quanto sem modelo. Esses métodos partem de políticas parametrizadas, capazes de gerar (por exemplo) trajetórias de movimento, e depois as otimizam alterando os parâmetros para aumentar (diminuir) a probabilidade de uma política se a trajetória resultar em uma recompensa positiva alta (baixa). Essa abordagem relaciona métodos de gradiente de política à Inferência Ativa, que também dispensa funções de valor (Millidge 2019). No entanto, o objetivo geral dos gradientes de política (maximizar a recompensa cumulativa de longo prazo) difere da Inferência Ativa.

Além das diferenças formais entre Inferência Ativa e RL, existem também várias diferenças conceituais importantes. Uma diferença diz respeito a como as duas abordagens interpretam o comportamento dirigido a objetivos e o comportamento habitual. Na literatura de aprendizagem animal, as escolhas direcionadas a objetivos são mediadas pelo conhecimento (prospectivo) da contingência entre uma ação e seu resultado (Dickinson e Balleine 1990), enquanto as escolhas habituais não são prospectivas e dependem de mais simples (por exemplo, estímulo-resposta). ) mecanismos. Uma ideia popular em RL é que escolhas direcionadas a objetivos e escolhas habituais correspondem a RL baseado em modelo e livre de modelo, respectivamente, e que estas são adquiridas em paralelo e competem continuamente para controlar o comportamento (Daw et al. 2005).

A Inferência Ativa, em vez disso, mapeia as escolhas habituais e direcionadas a objetivos para diferentes mecanismos. Na Inferência Ativa (em tempo discreto), a seleção de políticas é essencialmente baseada em modelos e, portanto, se encaixa na definição de escolhas deliberativas direcionadas a objetivos. Isso é semelhante ao que acontece na RL baseada em modelo, mas com uma diferença. Na LR baseada em modelos, as ações são selecionadas de forma prospectiva (usando um modelo), mas são controladas de forma reativa (usando políticas de estímulo-resposta); na Inferência Ativa, as ações podem ser controladas de maneira proativa – por meio do cumprimento de previsões proprioceptivas (sobre controle de ações, consulte a seção 10.6).

Na Inferência Ativa, os hábitos podem ser adquiridos executando políticas direcionadas a objetivos e, em seguida, armazenando em cache as informações sobre quais políticas são bem-sucedidas em quais contextos. As informações armazenadas em cache podem ser incorporadas como valor prévio das políticas (Friston, FitzGerald et al. 2016; Maisto, Friston e Pezzulo 2019). Este mecanismo permite a execução de políticas que tenham um alto valor a priori (em um determinado contexto) sem deliberação. Isso pode ser pensado simplesmente como observar “o que eu faço” e aprender que “eu sou o tipo de criatura que tende a fazer isso” ao longo de múltiplas exposições a uma tarefa. Em contraste com a RL livre de modelo, onde os hábitos são adquiridos independentemente da seleção de políticas direcionadas a objetivos, na Inferência Ativa os hábitos são adquiridos pela busca repetida de políticas direcionadas a objetivos (por exemplo, armazenando seus resultados em cache).

Na Inferência Ativa, mecanismos habituais e direcionados a objetivos podem cooperar em vez de apenas competir. Isso ocorre porque a crença prévia sobre as políticas depende tanto de um termo habitual (um valor prévio das políticas) quanto de um termo deliberativo (energia livre esperada). As elaborações hierárquicas da Inferência Ativa sugerem que os mecanismos reativos e direcionados a objetivos podem ser organizados em uma hierarquia e não como caminhos paralelos (Pezzulo, Rigoli e Friston 2015).

Por fim, vale notar que a Inferência Ativa e a RL diferem sutilmente na forma como concebem o comportamento e suas causas. A RL tem origem na teoria behaviorista e na ideia de que o comportamento resulta da aprendizagem por tentativa e erro mediada por reforço. A Inferência Ativa assume, em vez disso, que o comportamento é o resultado de uma inferência. Isso nos leva ao próximo ponto.

### Planejamento como Inferência

Da mesma forma que é possível lançar problemas perceptuais como problemas de inferência, também é possível lançar problemas de controle em termos de inferência Bayesiana (aproximada) (Todorov 2008). Em consonância com isso, na Inferência Ativa, o planejamento é visto como um processo inferencial: a inferência de uma sequência de estados de controle do modelo generativo.

Essa ideia está intimamente relacionada a outras abordagens, que incluem controle como inferência (Rawlik et al. 2013, Levine 2018), planejamento como inferência (Attias 2003, Botvinick e Toussaint 2012) e controle sensível ao risco e KL ( Kappen et al. 2012). Nessas abordagens, o planejamento procede através da inferência de uma distribuição posterior sobre as ações, ou sequências de ações, usando um modelo generativo dinâmico que codifica contingências probabilísticas entre estados, ações e estados futuros (esperados). A melhor ação ou plano pode ser inferido condicionando o modelo generativo à observação de recompensas futuras (Pezzulo e Rigoli 2011, Solway e Botvinick 2012) ou trajetórias futuras ótimas (Levine 2018). Por exemplo, é possível fixar (ou seja, fixar o valor de ) o estado desejado futuro no modelo e então inferir a sequência de ações que tem mais probabilidade de preencher a lacuna do estado atual para o estado desejado futuro.

Inferência ativa, planejamento como inferência e outros esquemas relacionados usam uma forma prospectiva de controle, que começa a partir de uma representação explícita de estados futuros a serem observados, em vez de um conjunto de regras ou políticas de estímulo-resposta, como é mais tipicamente feito em teoria de controle ótimo e RL. No entanto, as implementações específicas de controle e planejamento como inferência variam ao longo de pelo menos três dimensões – a saber, que forma de inferência eles usam (por exemplo, amostragem ou inferência variacional), o que eles inferem (por exemplo, uma distribuição posterior sobre ações ou sequências de ação) e o objetivo da inferência (por exemplo, maximizar a probabilidade marginal de uma condição de otimalidade ou a probabilidade de obter recompensa). 

A Inferência Ativa adota uma perspectiva única sobre cada uma dessas dimensões. Primeiro, ele usa um esquema aproximado escalável – inferência variacional – para resolver os problemas computacionais desafiadores que surgem durante o planejamento como inferência. Em segundo lugar, permite o planejamento baseado em modelo, ou a inferência de um posterior sobre estados de controle - que correspondem a sequências de ação ou políticas, não ações únicas [^1002]. inclui outros esquemas de planejamento como inferência amplamente utilizados (por exemplo, controle KL) e pode lidar com situações ambíguas (Friston, Rigoli et al. 2015).

[^1002]: No aprendizado de máquina, o processo de otimização de sequências de ações às vezes é chamado de otimização de política sequencial – em oposição à otimização mais comum de políticas de ação de estado – ou seja, “Se estou nesse estado, o que faço?”


## Comportamento e Racionalidade Limitada

Os sábios são instruídos pela razão, as mentes medianas pela experiência, os estúpidos pela necessidade e os brutos pelo instinto.

—Marco Túlio Cícero

O comportamento na Inferência Ativa combina automaticamente vários componentes: deliberativo, perseverativo e habitual (Parr 2020). Imagine uma pessoa que está caminhando para uma loja perto de sua casa. Se ela prevê as consequências de suas ações (por exemplo, virar à esquerda ou à direita), ela pode elaborar um bom plano para chegar à loja. Esse aspecto deliberativo do comportamento é fornecido pela energia livre esperada, que é minimizada quando se age de forma a alcançar as observações preferidas (por exemplo, estar na loja). Observe que a energia livre esperada também inclui um impulso para reduzir a incerteza, que pode se manifestar na deliberação. Por exemplo, se a pessoa não tiver certeza sobre a melhor direção, ela pode se mover para um ponto de vista apropriado, de onde ela pode encontrar o caminho para a loja facilmente, mesmo que isso implique um caminho mais longo. Em suma, seus planos adquirem affordance epistêmica.

Se a pessoa for menos capaz de deliberar (por exemplo, porque está distraída), ela pode continuar andando depois de chegar à loja. Esse aspecto perseverativo do comportamento é fornecido pela energia livre variacional, que é minimizada quando se reúnem observações compatíveis com as crenças atuais, incluindo crenças sobre o curso atual das ações. As observações sensoriais e proprioceptivas que a pessoa reúne fornecem evidências para “andar” e, portanto, podem determinar perseverança na ausência de deliberação.


Observe que os aspectos deliberativos, perseverativos e habituais do comportamento coexistem e podem ser combinados na Inferência Ativa. Em outras palavras, pode-se inferir que, nessa situação, um hábito é o curso de ação mais provável. Isso é diferente das “teorias duais”, que assumem que somos movidos por dois sistemas separados, um racional e outro intuitivo (Kahneman 2017). A mistura de aspectos deliberativos, perseverativos e habituais do comportamento depende plausivelmente de condições contextuais, como a quantidade de experiência e a quantidade de recursos cognitivos que se pode investir em processos deliberativos que podem ter um alto custo de complexidade.[^1003]

[^1003]: A noção de implantar recursos cognitivos de forma eficiente é uma parte inerente da minimização de energia livre, porque minimizar a complexidade automaticamente maximiza a eficiência, tanto no sentido teórico da informação quanto no sentido termodinâmico. Simplificando, o caminho de menor resistência é o caminho de menor energia livre.

O impacto dos recursos cognitivos na tomada de decisão tem sido amplamente estudado sob a rubrica da racionalidade limitada (Simon 1990). A ideia central é que enquanto um agente racional ideal deve sempre considerar completamente os resultados de suas ações, um agente racional limitado deve equilibrar os custos, esforço e pontualidade da computação – por exemplo, os custos de processamento de informações para deliberar o melhor plano. (Todorov 2009, Gershman et al. 2015).

### Teoria da Energia Livre da Racionalidade Limitada

A racionalidade limitada foi formulada em termos de minimização da energia livre de Helmholtz: uma construção termodinâmica que está estritamente relacionada à noção de energia livre variacional usada na Inferência Ativa; veja Gottwald e Braun (2020) para detalhes. A “teoria da energia livre da racionalidade limitada” formula as compensações da seleção de ações com capacidades limitadas de processamento de informações em termos de dois componentes da energia livre: energia e entropia (ver capítulo 2). O primeiro representa o valor esperado de uma escolha (um termo de precisão), e o último representa os custos de deliberação (um termo de complexidade). O que custa durante a deliberação é diminuir a entropia (ou complexidade) das crenças antes de uma escolha para torná-las mais precisas (Ortega e Braun 2013, Zénon et al. 2019). Intuitivamente, a escolha seria mais precisa (e potencialmente implicaria maior utilidade) com uma crença posterior mais precisa, mas como aumentar a precisão das crenças tem um custo, um tomador de decisão limitado precisa encontrar um compromisso – minimizando a energia livre. Os mesmos trade-offs emergem na Inferência Ativa, produzindo assim formas de racionalidade limitada. A noção de racionalidade limitada também ressoa com o uso de um limite variacional na evidência (ou probabilidade marginal) que é um aspecto definitivo da Inferência Ativa. Em suma, a Inferência Ativa fornece um modelo de racionalidade (limitada) e de otimalidade, onde a melhor solução para um determinado problema resulta do compromisso entre objetivos complementares: precisão e complexidade. Esses objetivos derivam de um imperativo normativo (minimização de energia livre) que é mais rico do que os objetivos clássicos (por exemplo, maximização de utilidade) geralmente considerados na teoria econômica.

## Valência, emoção e motivação

Considere suas origens: você não foi feito para viver como brutos, mas para seguir a virtude e o conhecimento.
—Dante Alighieri

A Inferência Ativa se concentra na energia livre (negativa) como uma medida de aptidão e da capacidade de um organismo de realizar seus objetivos. Embora a Inferência Ativa proponha que as criaturas ajam para minimizar sua energia livre, isso não significa que elas tenham que calculá-la. Geralmente, é suficiente lidar com os gradientes da energia livre. Por analogia, não precisamos saber nossa altitude para encontrar o topo de uma colina, mas podemos simplesmente seguir a inclinação para cima. No entanto, alguns sugeriram que as criaturas podem modelar como sua energia livre muda ao longo do tempo. Os proponentes dessa hipótese sugerem que ela pode permitir caracterizações de fenômenos como valência, emoção e motivação.

Nesta visão, foi proposto que a valência emocional, ou o caráter positivo ou negativo das emoções, pode ser concebida como a taxa de mudança (primeira derivada de t) da energia livre ao longo do tempo ( Joffily e Coricelli 2013). Especificamente, quando uma criatura experimenta um aumento em sua energia livre ao longo do tempo, ela pode atribuir uma valência negativa à situação; ao passo que quando experimenta uma diminuição de sua energia livre ao longo do tempo, pode atribuir-lhe uma valência positiva. Estendendo essa linha de pensamento para a dinâmica de longo prazo da energia livre (segunda derivada de t), pode ser possível caracterizar estados emocionais sofisticados; por exemplo, o alívio de passar de uma fase de baixa valência para uma fase de alta valência, ou o desapontamento de passar de uma fase de alta valência para uma fase de baixa valência. O monitoramento da dinâmica da energia livre (e dos estados emocionais que elas provocam) pode permitir a adaptação das estratégias comportamentais ou das taxas de aprendizado às estatísticas ambientais de longo prazo.

Pode parecer um salto assumir um segundo modelo generativo cujo papel é monitorar a energia livre do primeiro. No entanto, há outra maneira pela qual essas idéias podem ser interpretadas. Uma formalização interessante dessas perspectivas repousa em pensar sobre o que causa mudanças rápidas na energia livre. Como é um funcional das crenças, uma rápida mudança na energia livre deve ser devido à rápida atualização das crenças. O principal determinante dessa velocidade é a precisão, que atua como uma constante de tempo na dinâmica da codificação preditiva. Curiosamente, isso se relaciona com a noção de derivadas mais altas da energia livre, pois a precisão é o negativo da segunda derivada (ou seja, a curvatura de uma paisagem de energia livre). No entanto, isso levanta a questão de por que devemos associar precisão com valência. A resposta vem da observação de que a precisão está inversamente relacionada à ambiguidade. Quanto mais preciso algo é, menos ambígua sua interpretação. Escolher um curso de ação que minimize a energia livre esperada também significa minimizar a ambiguidade e, portanto, maximizar a precisão. Aqui vemos uma associação direta entre derivadas de alta ordem da energia livre, sua taxa de mudança e comportamento motivado.

As expectativas sobre (aumento ou diminuição da) energia livre podem desempenhar papéis motivacionais e incentivar o comportamento também. Na Inferência Ativa, uma expectativa substituta sobre mudanças (aumento ou diminuição) da energia livre é a precisão das crenças sobre as políticas. Isso novamente destaca a importância dessa estatística de segunda ordem. Por exemplo, uma crença altamente precisa sinaliza que se encontrou uma boa política - isto é, uma política que pode ser seguramente esperada para minimizar a energia livre. Curiosamente, a precisão das (crenças sobre) políticas tem sido associada à sinalização de dopamina (FitzGerald, Dolan e Friston 2015). Nessa perspectiva, os estímulos que aumentam a precisão das crenças sobre as políticas desencadeiam explosões de dopamina – o que pode indicar sua saliência de incentivo (Berridge 2007). Essa perspectiva pode ajudar a esclarecer os mecanismos neurofisiológicos que ligam as expectativas de realização de metas ou recompensas a aumentos de atenção (Anderson et al. 2011) e motivação (Berridge e Kringelbach 2011).

## Homeostase, Alostase e Processamento Interoceptivo 

Há mais sabedoria em seu corpo do que em sua filosofia mais profunda.
—Friedrich Nietzche

O modelo generativo de uma criatura não é apenas sobre o mundo externo, mas também – e talvez ainda mais importante – sobre o meio interno. Um modelo generativo do interior de um corpo (ou esquema interoceptivo) tem um papel duplo: explicar como as sensações interoceptivas (corporais) são geradas e garantir a regulação correta de parâmetros fisiológicos (Iodice et al. 2019), como temperatura corporal ou níveis de açúcar No Sangue. As teorias cibernéticas (abordadas na seção 10.6.2) assumem que um objetivo central dos organismos vivos é manter a homeostase (Cannon, 1929) – garantir que os parâmetros fisiológicos permaneçam dentro de faixas viáveis (por exemplo, a temperatura corporal nunca se torne muito alta) – e que a homeostase só pode ser alcançado exercendo um controle bem-sucedido sobre o meio ambiente (Ashby 1952).

Esta forma de regulação homeostática pode ser alcançada na Inferência Ativa, especificando os intervalos viáveis ​​de parâmetros fisiológicos como prioritários sobre observações interoceptivas. Curiosamente, a regulação homeostática pode ser alcançada de várias maneiras aninhadas. O circuito regulador mais simples é o envolvimento de reflexos autônomos (por exemplo, vasodilatação), quando certos parâmetros estão (espera-se que estejam) fora de alcance – por exemplo, quando a temperatura corporal está muito alta. Esse controle autonômico pode ser construído como inferência interoceptiva: um processo de Inferência Ativa que opera em fluxos interoceptivos em vez de fluxos proprioceptivos, como no caso de ações direcionadas externamente (Seth et al. 2012, Seth e Friston 2016, Allen et al. 2019) . Para isso, o cérebro pode usar um modelo generativo que prevê fluxos interoceptivos e fisiológicos e desencadeia reflexos autônomos para corrigir erros de previsão interoceptiva (por exemplo, uma temperatura corporal surpreendentemente alta). Isso é análogo à maneira como os reflexos motores são ativados para corrigir erros de previsão proprioceptiva e orientar ações direcionadas externamente.

A Inferência Ativa vai além dos simples loops autonômicos: ela pode corrigir o mesmo erro de previsão interoceptiva (alta temperatura corporal) de maneiras cada vez mais sofisticadas (Pezzulo, Rigoli e Friston 2015). Ele pode usar estratégias preditivas e alostáticas (Sterling 2012, Barrett e Simmons 2015, Corcoran et al. 2020) que vão além da homeostase e controlam preventivamente a fisiologia de maneira alostática antes que os erros de previsão interoceptiva sejam acionados - por exemplo, encontrar sombra antes do superaquecimento. Outra estratégia preditiva envolve a mobilização de recursos antes das excursões esperadas dos pontos de ajuste fisiológicos – por exemplo, aumentar o débito cardíaco antes de uma corrida longa em antecipação ao aumento da demanda de oxigênio. Isso requer modificar dinamicamente as prévias sobre as observações interoceptivas, indo além da homeostase (Tschantz et al. 2021). Eventualmente, cérebros preditivos podem desenvolver estratégias sofisticadas direcionadas a objetivos, como garantir que alguém traga água fria para a praia, atendendo ao mesmo imperativo (controlar a temperatura corporal) de maneiras mais ricas e eficazes.

A regulação biológica e interoceptiva pode ser crucial para o processamento afetivo e emocional (Barrett 2017). Durante as interações situadas, o modelo generativo do cérebro prevê constantemente não apenas o que acontecerá a seguir, mas também quais são as consequências para a interocepção e a alostase. Fluxos interoceptivos – eliciados durante a percepção de objetos e eventos externos – os imbuem de uma dimensão afetiva, que sinaliza o quão bons ou ruins eles são para a alostase e sobrevivência da criatura, tornando-os “significativos”. Se essa visão estiver correta, os distúrbios desse processamento interoceptivo e alostático podem gerar desregulação emocional e várias condições psicopatológicas (Pezzulo 2013; Barrett et al. 2016; Maisto, Barca et al. 2019; Pezzulo, Maisto et al. 2019).

Há um companheiro emergente para a inferência interoceptiva – a saber, a inferência emocional. Nesta aplicação da Inferência Ativa, as emoções são consideradas parte do modelo generativo: elas são apenas mais uma construção ou hipótese que o cérebro emprega para implantar a precisão em modelos generativos profundos. Do ponto de vista da atualização de crenças, isso significa que a ansiedade é apenas um compromisso com a crença bayesiana “estou ansioso” que melhor explica as filas sensoriais e interoceptivas predominantes. Do ponto de vista da atuação, as previsões (interoceptivas) subsequentes aumentam ou atenuam várias precisões (ou seja, ação encoberta) ou escravizam as respostas autônomas (ou seja, ação aberta). Isso pode parecer muito com excitação, o que confirma a hipótese de que “estou ansioso”. Normalmente, a inferência emocional envolve a atualização de crenças que é geral de domínio, assimilando informações de fluxos sensoriais interoceptivos e exteroceptivos - daí a relação íntima entre emoção, interocepção e atenção na saúde (Seth e Friston 2016; Smith, Lane et al. 2019; Smith , Parr e Friston 2019) e doença (Peters et al. 2017, J. E. Clark et al. 2018).


##  Atenção, Saliência e Dinâmica Epistêmica

A verdadeira ignorância não é a ausência de conhecimento, mas a recusa em adquiri-lo. — Karl Popper

Dado o número de vezes que nos referimos à precisão e à energia livre esperada apenas neste capítulo, seria negligente não dedicar um pouco de espaço à atenção e à saliência. Esses conceitos são recorrentes em toda a psicologia, tendo sido objeto de inúmeras redefinições e classificações. Às vezes, esses termos são usados para se referir a mecanismos de controle de ganho sináptico (Hillyard et al. 1998), que selecionam preferencialmente alguma modalidade sensorial ou subconjunto de canais dentro de uma modalidade. Às vezes, eles se referem a como nos orientamos, por meio de ação aberta ou encoberta, para obter mais informações sobre o mundo (Rizzolatti et al. 1987; Sheliga et al. 1994, 1995).

Embora a incerteza proporcionada pelos muitos significados de atenção subscreva parte da atratividade epistêmica desse campo de estudo, também há valor em resolver a ambiguidade associada. Uma das coisas oferecidas por uma perspectiva formal da psicologia é que não precisamos nos preocupar com essa ambiguidade. Podemos definir operacionalmente a atenção como a precisão associada a alguma entrada sensorial. Isso mapeia perfeitamente o conceito de controle de ganho, pois as sensações que inferimos como mais precisas terão maior influência sobre a atualização de crenças do que aquelas inferidas como imprecisas. A validade de construto desta associação foi demonstrada em relação aos paradigmas psicológicos, incluindo o famoso paradigma de Posner (Feldman e Friston 2010). Especificamente, responder a um estímulo em um local no espaço visual com maior precisão é mais rápido do que responder a estímulos em outros locais.

Isso deixa o termo saliência sem uma definição formal semelhante. Normalmente, na Inferência Ativa, associamos a saliência ao ganho de informação esperado (ou valor epistêmico): um componente da energia livre esperada. Intuitivamente, algo é mais saliente quando esperamos que produza mais informações. No entanto, isso define saliência em termos de uma ação ou política, enquanto a atenção é um atributo de crenças sobre entrada sensorial. Isso se encaixa com a noção de saliência como orientação aberta ou encoberta. Vimos no capítulo 7 que poderíamos subdividir ainda mais o ganho de informação esperado em relevância e novidade. O primeiro é o potencial para inferir, enquanto o último é o potencial para aprender. Uma analogia que expressa a diferença entre atenção e saliência (ou novidade) é o desenho e a análise de um experimento científico. Atenção é o processo de selecionar os dados da mais alta qualidade a partir do que já medimos e usá-los para informar nosso teste de hipóteses. Saliência é o design do próximo experimento para garantir dados da mais alta qualidade.

Não nos debruçamos sobre essa questão para simplesmente adicionar outra reclassificação dos fenômenos atencionais à literatura, mas para destacar uma importante vantagem em se comprometer com uma psicologia formal. Sob a Inferência Ativa, não importa se outros definem atenção (ou qualquer outro construto) de forma diferente – pois podemos simplesmente nos referir aos construtos matemáticos em questão e evitar qualquer confusão. Um ponto final de consideração é que essas definições oferecem uma explicação simples de por que atenção e saliência são tão frequentemente confundidas. Dados altamente precisos são minimamente ambíguos. Isso significa que eles devem receber atenção e que as ações para adquirir esses dados são altamente salientes (Parr e Friston 2019a).


## Aprendizado de regras, inferência causal e generalização rápida

Ontem eu era inteligente, então eu queria mudar o mundo. Hoje eu sou sábio, então estou mudando a mim mesmo.
—Rumi

Humanos e outros animais se destacam em fazer inferências causais sofisticadas, aprender conceitos abstratos e relações causais entre objetos e generalizar a partir de experiências limitadas – em contraste com os paradigmas atuais de aprendizado de máquina, que exigem um grande número de exemplos para obter desempenho semelhante. Essa diferença sugere que as abordagens atuais de aprendizado de máquina, que são amplamente baseadas em reconhecimento de padrões sofisticados, podem não capturar totalmente as maneiras como os humanos aprendem e pensam (Lake et al. 2017).


O paradigma de aprendizagem da Inferência Ativa baseia-se no desenvolvimento de modelos generativos que capturam as relações causais entre ações, eventos e observações. Neste livro, consideramos tarefas relativamente simples (por exemplo, o exemplo do labirinto em T do capítulo 7) que requerem modelos generativos não sofisticados. Em contraste, entender e raciocinar sobre situações complexas requer modelos generativos profundos que capturem a estrutura latente do ambiente – como regularidades ocultas que permitem generalizar em várias situações aparentemente diferentes (Tervo et al. 2016; Friston, Lin et al. 2017 ).

Um exemplo simples de uma regra oculta que governa interações sociais sofisticadas é uma interseção de trânsito. Imagine uma pessoa ingênua que observa uma encruzilhada movimentada e tem que prever (ou explicar) em que ocasiões pedestres ou carros atravessam a rua. A pessoa pode acumular estatísticas sobre a co-ocorrência de eventos (por exemplo, um carro vermelho parando e um homem alto atravessando; uma velha parando e um carro grande passando), mas a maioria acaba sendo inútil. A pessoa pode eventualmente descobrir alguns padrões estatísticos recorrentes, como os pedestres atravessam a estrada logo após todos os carros pararem em um determinado ponto da estrada. Essa determinação seria considerada suficiente em uma configuração de aprendizado de máquina se a tarefa fosse apenas prever quando os pedestres estão prestes a andar, mas não implicaria qualquer compreensão da situação. Na verdade, pode até levar à conclusão errônea de que a parada dos carros explica o movimento dos pedestres. Esse tipo de erro é típico em aplicativos de aprendizado de máquina que não apelam para modelos (causais) e não conseguem distinguir se a chuva explica a grama molhada ou a grama molhada explica a chuva (Pearl e Mackenzie 2018).

Por outro lado, inferir a regra oculta correta (por exemplo, semáforo) fornece uma compreensão mais profunda da estrutura causal da situação (por exemplo, é o semáforo que faz com que os carros parem e os pedestres andem). A regra oculta não apenas oferece melhor poder preditivo, mas também torna a inferência mais parcimoniosa, pois pode abstrair a maioria dos detalhes sensoriais (por exemplo, a cor dos carros). Por sua vez, isso permite generalizar para outras situações, como diferentes encruzilhadas ou cidades, onde a maioria dos detalhes sensoriais difere significativamente – com a ressalva de que enfrentar encruzilhadas em algumas cidades, como Roma, pode exigir mais do que olhar os semáforos. Finalmente, aprender sobre as regras do semáforo também pode permitir um aprendizado mais eficiente em novas situações – ou desenvolver o que é chamado de “conjunto de aprendizado” em psicologia ou uma habilidade de aprender a aprender em aprendizado de máquina (Harlow 1949). Ao enfrentar uma encruzilhada onde o semáforo está desligado, não se pode usar a regra aprendida, mas pode-se esperar que haja outra regra oculta semelhante em jogo – e isso pode ajudar a entender o que o policial de trânsito está fazendo.

Como este exemplo simples ilustra, aprender modelos generativos ricos – da estrutura latente do ambiente (também conhecido como aprendizado de estrutura) – oferece formas sofisticadas de raciocínio causal e generalização. Ampliar modelos generativos para lidar com essas situações sofisticadas é um objetivo contínuo em modelagem computacional e ciência cognitiva (Tenenbaum et al. 2006, Kemp e Tenenbaum 2008). Curiosamente, há uma tensão entre as tendências atuais de aprendizado de máquina – em que a ideia geral é “quanto maior, melhor” – e a abordagem estatística da Inferência Ativa – que sugere a importância de equilibrar a precisão de um modelo com sua complexidade e favorecer modelos mais simples. A redução do modelo (e a poda de parâmetros desnecessários) não é simplesmente uma maneira de evitar o desperdício de recursos - é também uma maneira eficaz de aprender regras ocultas, inclusive durante períodos offline como o sono (Friston, Lin et al. 2017), talvez se manifestando em atividade do estado de repouso (Pezzulo, Zorzi e Corbetta 2020).


##  Inferência ativa e outros campos: direções abertas

Tem que começar em algum lugar, tem que começar em algum momento, que lugar melhor do que aqui? Que melhor hora do que agora?
—Rage Against the Machine, “Guerrilla Radio”


Neste livro, nos concentramos principalmente em modelos de Inferência Ativa que abordam problemas biológicos de sobrevivência e adaptação. No entanto, a Inferência Ativa pode ser aplicada em muitos outros domínios. Nesta última seção, discutimos brevemente dois desses domínios: dinâmica social e cultural e aprendizado de máquina e robótica. Abordar o primeiro requer pensar sobre as maneiras pelas quais vários agentes de Inferência Ativa interagem e os efeitos emergentes de tal interação. Abordar o último requer entender como a Inferência Ativa pode ser dotada de mecanismos de aprendizado (e inferência) mais eficazes para escalar problemas mais complexos - mas de uma maneira compatível com os pressupostos básicos da teoria. Ambos são interessantes direções abertas para a pesquisa.

### Dinâmicas Sociais e Culturais

Muitos aspectos interessantes de nossa cognição (humana) relacionam-se a dinâmicas sociais e culturais em vez de percepções, decisões e ações individualistas (Veissière et al. 2020). Por definição, a dinâmica social requer múltiplas criaturas de Inferência Ativa que se envolvem em interações físicas (por exemplo, ações conjuntas, como praticar esportes coletivos) ou interações mais abstratas (por exemplo, eleições ou redes sociais). Demonstrações simples de inferência interativa entre organismos idênticos já produziram fenômenos emergentes interessantes, como a auto-organização de formas de vida simples que resistem à dispersão, a possibilidade de se engajar em processos morfogenéticos para adquirir e restaurar uma forma corporal e previsão e coordenação mútuas. tomada de turnos (Friston 2013; Friston e Frith 2015a; Friston, Levin et al. 2015). Outras simulações abordaram as maneiras pelas quais as criaturas podem estender sua cognição a artefatos materiais e moldar seus nichos cognitivos (Bruineberg et al. 2018). Essas simulações capturam apenas uma fração da complexidade de nossa dinâmica social e cultural, mas ilustram o potencial da Inferência Ativa para expandir de uma ciência de indivíduos para uma ciência de sociedades – e como a cognição se estende além de nossos crânios (Nave et al. 2020 ).

### Aprendizado de máquina e robótica

Os métodos de modelagem generativa e inferência variacional discutidos neste livro são amplamente utilizados em aprendizado de máquina e robótica. Nesses campos, a ênfase geralmente está em como aprender modelos generativos (conexionistas) — em oposição a como usá-los para a Inferência Ativa, o foco deste livro. Isso é interessante, pois as abordagens de aprendizado de máquina são potencialmente úteis para aumentar a complexidade dos modelos generativos e dos problemas considerados neste livro - com a ressalva de que podem recorrer a teorias de processo muito diferentes da Inferência Ativa.

Embora seja impossível revisar aqui a vasta literatura sobre modelagem generativa em aprendizado de máquina, mencionamos brevemente alguns dos modelos mais populares, a partir dos quais muitas variantes foram desenvolvidas. Dois primeiros modelos generativos conexionistas, a máquina de Helmholtz e a máquina de Boltzmann (Ackley et al. 1985, Dayan et al. 1995), forneceram exemplos paradigmáticos de como aprender as representações internas de uma rede neural de forma não supervisionada. A máquina de Helmholtz está especialmente relacionada à abordagem variacional da Inferência Ativa, pois usa redes generativas e de reconhecimento separadas para inferir uma distribuição sobre variáveis ​​ocultas e amostrar delas para obter dados fictícios. O sucesso prático inicial desses métodos foi limitado. Mas depois, a possibilidade de empilhar várias máquinas Boltzmann (restritas) permitiu o aprendizado de várias camadas de representações internas e foi um dos primeiros sucessos das redes neurais profundas não supervisionadas (Hinton 2007).

Dois exemplos recentes de modelos generativos conexionistas, autoencoders variacionais ou VAEs (Kingma e Welling 2014) e redes adversariais generativas ou GANs (Goodfellow et al. 2014), são amplamente utilizados em aplicações de aprendizado de máquina, como reconhecimento ou geração de imagens e vídeos. Os VAEs exemplificam uma aplicação elegante de métodos variacionais ao aprendizado em redes generativas. Seu objetivo de aprendizado, o limite inferior de evidência (ELBO), é matematicamente equivalente à energia livre variacional. Esse objetivo permite o aprendizado de uma descrição precisa dos dados (ou seja, maximiza a precisão), mas também favorece representações internas que não diferem muito de suas anteriores (ou seja, minimizam a complexidade). Este último objetivo atua como um chamado regularizador, o que ajuda a generalizar e evitar o overfitting.

As GANs seguem uma abordagem diferente: combinam duas redes, uma rede generativa e uma rede discriminativa, que competem continuamente durante o aprendizado. A rede discriminativa aprende a distinguir quais dados de exemplo produzidos pela rede generativa são reais ou fictícios. A rede generativa tenta gerar dados fictícios que enganam (ou seja, são classificados erroneamente por) a rede discriminativa. A corrida entre essas duas redes força a rede generativa a melhorar suas capacidades generativas e produzir dados fictícios de alta fidelidade – uma capacidade que tem sido amplamente explorada para gerar, por exemplo, imagens realistas.

Os modelos generativos acima (e outros) podem ser usados para tarefas de controle. Por exemplo, Ha e Eck (2017) usaram um VAE (sequência a sequência) para aprender a prever traços de lápis. Por amostragem da representação interna do VAE, o modelo pode construir novos desenhos baseados em traços. Abordagens de modelagem generativa também têm sido usadas para controlar os movimentos do robô. Algumas dessas abordagens usam Inferência Ativa (Pio-Lopez et al. 2016, Sancaktar et al. 2020, Ciria et al. 2021) ou ideias intimamente relacionadas, mas em um cenário conexionista (Ahmadi e Tani 2019, Tani e White 2020).

Um dos principais desafios neste domínio é que os movimentos do robô são de alta dimensão e requerem (aprendizagem) modelos generativos sofisticados. Um aspecto interessante da Inferência Ativa e abordagens relacionadas é que a coisa mais importante a ser aprendida é um mapeamento direto entre ações e feedback sensorial (por exemplo, visual e proprioceptivo) na próxima etapa de tempo. Esse mapeamento direto pode ser aprendido de várias maneiras: por exploração autônoma, por demonstração ou mesmo por interação direta com um humano – por exemplo, um professor (o experimentador) que guia as mãos do robô ao longo de uma trajetória até o objetivo, portanto, andaime para a aquisição de ações efetivas direcionadas a objetivos (Yamashita e Tani 2008). A possibilidade de aprender modelos generativos de várias maneiras expande muito o escopo das habilidades do robô que podem ser eventualmente alcançadas. Por sua vez, a possibilidade de desenvolver robôs (neuro-) mais avançados usando Inferência Ativa pode ser importante não apenas por razões tecnológicas, mas também teóricas. De fato, alguns aspectos-chave da Inferência Ativa, como as interações adaptativas agente-ambiente, a integração de funções cognitivas e a importância da incorporação, são naturalmente abordados em configurações robóticas.

## Resumo

O lar está atrás, o mundo à frente, e há muitos caminhos para trilhar através das sombras até a beira da noite, até que as estrelas estejam todas acesas.
—J. R. R. Tolkien, O Senhor dos Anéis

Começamos este livro perguntando se é possível entender o cérebro e o comportamento a partir dos primeiros princípios. Em seguida, introduzimos a Inferência Ativa como uma teoria candidata para enfrentar esse desafio. Esperamos que o leitor tenha se convencido de que a resposta à nossa pergunta original é sim. Neste capítulo, consideramos a perspectiva unificada que a Inferência Ativa oferece sobre o comportamento senciente e quais implicações essa teoria tem para construções psicológicas familiares, como percepção, seleção de ação e emoção. Isso nos deu a oportunidade de revisitar os conceitos introduzidos ao longo do livro e nos lembrar das fascinantes questões ainda abertas para pesquisas futuras. Esperamos que este livro forneça um complemento útil para trabalhos relacionados sobre Inferência Ativa, incluindo, por um lado, a filosofia (Hohwy 2013, Clark 2015) e, por outro lado, a física (Friston 2019a).

Estamos agora no final de nossa jornada. Nosso objetivo foi oferecer uma introdução aos interessados ​​em usar esses métodos - tanto em nível conceitual quanto formal. No entanto, é importante enfatizar que a Inferência Ativa não é algo que pode ser aprendido puramente na teoria. Incentivamos qualquer pessoa que tenha gostado deste livro a pensar em realizá-lo na prática. Ritos de passagem importantes na neurobiologia teórica são tentar escrever um modelo generativo, experimentar a frustração quando as simulações se comportam mal e aprender com as violações de suas crenças anteriores quando algo inesperado acontece. Independentemente de você optar ou não por seguir essa prática em um nível computacional, esperamos que você reflita sobre isso ao se envolver na Inferência Ativa no dia-a-dia. Isso pode se manifestar na compulsão de direcionar seus olhos para resolver a incerteza sobre algo em sua visão periférica. Pode ser na escolha de comer em um restaurante favorito para atender às preferências (gustativas) anteriores. Pode ser na redução do calor quando o chuveiro está muito quente para garantir que a temperatura esteja de acordo com o seu modelo de como o mundo deveria ser. Em última análise, estamos confiantes de que você continuará a buscar a Inferência Ativa de alguma forma.




