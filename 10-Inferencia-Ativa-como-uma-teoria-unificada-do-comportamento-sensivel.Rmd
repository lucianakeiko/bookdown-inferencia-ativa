# Inferência ativa como uma teoria unificada do comportamento sensível

Em geral,  nós estamos menos cientes do que nossas mentes fazem de melhor—Marvin Minsky

## Introdução

Neste capítulo, encerramos os principais pontos teóricos da Inferência Ativa (da primeira parte do livro) e suas implementações práticas (da segunda parte). Em seguida, conectamos os pontos: nos abstraímos dos modelos específicos de Inferência Ativa discutidos nos capítulos anteriores para focar nos aspectos integrativos da estrutura. Um benefício da Inferência Ativa é que ela fornece uma solução completa para os problemas adaptativos que os organismos sencientes precisam resolver. Portanto, oferece uma perspectiva unificada sobre problemas como percepção, seleção de ações, atenção e regulação de emoções, que geralmente são tratados isoladamente em psicologia e neurociência – e abordados usando abordagens computacionais distintas em inteligência artificial. Discutiremos a perspectiva de Inferência Ativa em cada um desses problemas (e mais) no contexto de teorias estabelecidas, como cibernética, teoria da ação ideomotora, aprendizado por reforço e controle ótimo. Finalmente, discutimos brevemente como o escopo da Inferência Ativa pode ser estendido para cobrir outros tópicos biológicos, sociais e tecnológicos que não são discutidos em profundidade neste livro.

## Empacotando

Este livro oferece um relato sistemático dos fundamentos teóricos e implementações práticas da Inferência Ativa. Aqui, resumimos brevemente a discussão dos primeiros nove capítulos. Isso oferece uma oportunidade de ensaiar as principais construções da Inferência Ativa que serão úteis no restante deste capítulo.

**No capítulo 1**, introduzimos a Inferência Ativa como uma abordagem normativa para entender as criaturas sencientes que fazem parte de laços de ação-percepção com seu ambiente (Fuster 2004). Explicamos que as abordagens normativas partem dos primeiros princípios para derivar e testar previsões empíricas sobre o fenômeno de interesse – aqui, as maneiras pelas quais os organismos vivos persistem enquanto se envolvem em trocas adaptativas (loops de percepção de ação) com seu ambiente. Também consideramos que se poderia chegar à Inferência Ativa seguindo uma estrada baixa ou uma estrada alta.

No **capítulo 2**, ilustramos o caminho para a Inferência Ativa. Esse caminho parte da ideia de que o cérebro é uma máquina de previsão, dotada de um modelo generativo: uma representação probabilística de como as causas ocultas no mundo geram sensações (por exemplo, como a luz refletida em uma maçã estimula a retina). Ao inverter esse modelo, ele infere as causas de suas sensações (por exemplo, se estou vendo uma maçã, já que minha retina é estimulada de certa forma). Essa visão da percepção (também conhecida como percepção-como-inferência) tem suas raízes históricas na noção helmholtziana de inferência inconsciente e, mais recentemente, na hipótese do cérebro bayesiano. A Inferência Ativa estende essa visão trazendo controle de ação e planejamento dentro do compasso da inferência (também conhecido como controle-como-inferência, planejamento-como-inferência). Mais importante ainda, mostra que percepção e ação não são processos essencialmente separáveis, mas cumprem o mesmo objetivo. Descrevemos primeiro esse objetivo de maneira mais informal, como a minimização de uma discrepância entre o modelo de alguém e o mundo (o que geralmente se reduz à surpresa ou minimização do erro de previsão). Simplificando, pode-se minimizar a discrepância entre um modelo e o mundo de duas maneiras: mudando a mente para se adequar ao mundo (percepção) ou mudando o mundo para se adequar ao modelo (ação). Estes podem ser descritos em termos de inferência Bayesiana. No entanto, a inferência exata é muitas vezes intratável, então a Inferência Ativa usa uma aproximação (variacional) (observando que a inferência exata pode ser vista como um caso especial de inferência aproximada). Isso leva à segunda descrição mais formal do objetivo comum de percepção e ação, como minimização de energia livre variacional. Esta é a quantidade central usada na Inferência Ativa e pode ser descompactada em termos de suas partes constituintes (por exemplo, energia e entropia, complexidade e precisão, ou surpresa e divergência). Finalmente, introduzimos um segundo tipo de energia livre: a energia livre esperada. Isso é particularmente importante durante o planejamento, pois oferece uma maneira de pontuar políticas alternativas considerando o resultado futuro que se espera que elas gerem. Isso também pode ser descompactado em termos de suas partes constituintes (por exemplo, ganho de informação e valor pragmático, ambiguidade e risco esperados).

No **capítulo 3**, ilustramos o caminho para a Inferência Ativa. Esse caminho alternativo parte do imperativo deflacionário para que os organismos biológicos preservem sua integridade e evitem a dissipação, o que pode ser descrito como evitar estados surpreendentes. Introduzimos então a noção de um envoltório de Markov: uma formalização da separação estatística entre os estados internos do organismo e os estados externos do mundo. Fundamentalmente, os estados internos e externos só podem influenciar um ao outro indiretamente por meio de variáveis intermediárias (ativas e sensoriais), chamadas de estados de cobertura. Essa separação estatística – mediada pelo envoltório de Markov – é crucial para dotar um organismo de algum grau de autonomia em relação ao mundo externo. Para entender por que essa é uma perspectiva útil, considere as três consequências a seguir.

Primeiro, um organismo com um envoltório de Markov parece modelar o ambiente externo em um sentido bayesiano: seus estados internos correspondem - em média - a uma crença posterior aproximada sobre estados externos do mundo. Em segundo lugar, a autonomia é garantida pelo fato de que o modelo do organismo (seus estados internos) não é imparcial, mas prescreve algumas pré-condições existenciais (ou preferências prévias) que devem ser mantidas – por exemplo, para um peixe, estar na água. Em terceiro lugar, equipado com esse formalismo, é possível descrever o comportamento ótimo (em relação às preferências anteriores) como a maximização da evidência do modelo (bayesiano) por percepção e ação. Ao maximizar a evidência do modelo (ou seja, auto-evidente), um organismo garante que ele realize suas preferências anteriores (por exemplo, um peixe permanece na água) e evita estados surpreendentes. Por sua vez, a maximização da evidência do modelo é (aproximadamente) matematicamente equivalente à minimização da energia livre variacional - portanto, chegamos novamente (de outra maneira) ao mesmo construto central da Inferência Ativa discutido no capítulo 2. Finalmente, detalhamos a relação entre minimizar a surpresa e o princípio da menor ação de Hamilton. Isso evidencia a relação formal entre a Inferência Ativa e os primeiros princípios da física estatística.

No **capítulo 4**, delineamos os aspectos formais da Inferência Ativa. Nós nos concentramos na passagem da inferência bayesiana para uma aproximação tratável - inferência variacional - e o objetivo resultante para os organismos minimizarem a energia livre variacional por meio da percepção e da ação. O insight desse tratamento é a importância do modelo generativo que as criaturas usam para dar sentido ao seu mundo. Introduzimos dois tipos de modelos generativos que expressam nossas crenças sobre como os dados são gerados, usando variáveis discretas ou contínuas. Explicamos que ambos fornecem a mesma Inferência Ativa, mas se aplicam quando estados de coisas são formulados em tempo discreto (como problemas de decisão de Markov parcialmente observados) ou em tempo contínuo (como equações diferenciais estocásticas), respectivamente.

No **capítulo 5**, comentamos sobre a diferença entre o princípio normativo da minimização da energia livre e uma teoria de processo sobre como esse princípio pode ser implementado pelo cérebro – e explicamos que este último gera previsões testáveis. Em seguida, delineamos aspectos das teorias de processo que acompanham a Inferência Ativa, que abrange domínios como a passagem de mensagens neuronais, incluindo circuitos neuroanatômicos (por exemplo, alças córtico-subcorticais) e neuromodulação. Por exemplo, em um nível anatômico, a passagem de mensagens mapeia bem para um microcircuito cortical canônico, com previsões que derivam de camadas corticais profundas em um nível e visam camadas corticais superficiais no nível abaixo (Bastos et al. 2012). Em um nível mais sistêmico, discutimos como inferência Bayesiana, aprendizado e ponderação de precisão correspondem à dinâmica neuronal, plasticidade sináptica e neuromodulação, respectivamente, e como a mensagem neural de cima para baixo e de baixo para cima passa de mapas de codificação preditiva para mais lento ( por exemplo, alfa ou beta) e ritmos cerebrais mais rápidos (por exemplo, gama). Esses e outros exemplos ilustram que, após projetar um modelo específico de Inferência Ativa, pode-se extrair implicações neurobiológicas da forma de seu modelo generativo.

No **capítulo 6**, fornecemos uma receita para projetar modelos de Inferência Ativa. Vimos que, embora todas as criaturas minimizem sua energia livre variacional, elas se comportam de maneiras diferentes, às vezes opostas, porque são dotadas de diferentes modelos generativos. Portanto, o que distingue criaturas diferentes (por exemplo, mais simples de mais complexas) é apenas seu modelo generativo. Existe um rico repertório de possíveis modelos generativos, que correspondem a diferentes implementações biológicas (por exemplo, neuronais) e produzem diferentes comportamentos adaptativos – ou mal adaptativos – em diferentes contextos e nichos ecológicos. Isso torna a Inferência Ativa igualmente apropriada para caracterizar criaturas simples como bactérias que detectam e buscam gradientes de nutrientes, criaturas complexas como nós que perseguem objetivos sofisticados e se envolvem em ricas práticas culturais, ou mesmo indivíduos diferentes – na medida em que caracterizam adequadamente seus respectivos modelos generativos . A evolução parece ter descoberto estruturas de design cada vez mais sofisticadas para cérebros e corpos que tornaram os organismos capazes de lidar (e moldar) ricos nichos ecológicos. Os modeladores podem fazer engenharia reversa desse processo e especificar os projetos para cérebros e corpos de criaturas de interesse, em termos de modelos generativos, com base nos tipos de nicho que ocupam. Isso corresponde a uma série de escolhas de projeto (por exemplo, modelos usando variáveis ​​discretas ou categóricas, modelos superficiais ou hierárquicos) – que descompactamos no capítulo.

Nos **capítulos 7 e 8**, fornecemos vários exemplos de modelos de Inferência Ativa em tempo discreto e contínuo, que abordam problemas de inferência perceptiva, navegação direcionada a objetivos, aprendizado de modelos, controle de ação e muito mais. Esses exemplos foram projetados para mostrar a variedade de comportamentos emergentes sob esses modelos e detalhar os princípios de como eles são especificados na prática.

No **capítulo 9**, discutimos como usar a Inferência Ativa para análise de dados baseada em modelo e recuperar os parâmetros do modelo generativo de um indivíduo, que explicam melhor o comportamento do sujeito em uma tarefa. Essa fenotipagem computacional usa a mesma forma de inferência bayesiana discutida no restante do livro, mas de uma maneira diferente: ajuda a projetar e avaliar modelos (objetivos) de modelos (subjetivos) de outros.

## Conectando os Pontos: A Perspectiva Integrativa da Inferência Ativa

Algumas décadas atrás, o filósofo Dennett lamentou que os cientistas cognitivos dedicassem muito esforço para modelar subsistemas isolados (por exemplo, percepção, compreensão da linguagem) cujos limites são frequentemente arbitrários. Ele sugeriu tentar modelar “toda a iguana”: uma criatura cognitiva completa (talvez uma simples) e um nicho ambiental para ela lidar (Dennett 1978).

Um benefício da Inferência Ativa é que ela oferece um primeiro relato de princípio das maneiras pelas quais os organismos resolvem seus problemas adaptativos. A abordagem normativa adotada neste livro pressupõe que é possível partir do princípio da minimização variacional da energia livre e derivar implicações sobre processos cognitivos específicos, como percepção, seleção de ação, regulação de atenção e emoção e seus fundamentos neuronais.

Imagine uma criatura simples que deve resolver problemas como encontrar comida ou abrigo. Quando lançado como Inferência Ativa, os problemas da criatura podem ser descritos em termos enativos, como agindo para solicitar sensações preferidas (por exemplo, sensações relacionadas à comida). Na medida em que essas sensações preferidas são incluídas (como crenças anteriores) em seu modelo generativo, o organismo está efetivamente reunindo evidências para seu modelo – ou, mais alegoricamente, para sua existência (ou seja, maximizando a evidência do modelo ou autoevidência). Esse princípio simples tem ramificações para funções psicológicas tradicionalmente consideradas isoladamente, como percepção, controle de ação, memória, atenção, intenção, emoção e muito mais. Por exemplo, percepção e ação são autoevidentes, no sentido de que uma criatura pode alinhar o que espera, dado seu modelo gerador, com o que sente, seja mudando suas crenças (sobre a presença de comida) ou mudando o mundo. (solicitando sensações relacionadas à comida). Memória e atenção também podem ser pensadas como otimizando o mesmo objetivo. A memória de longo prazo se desenvolve através do aprendizado dos parâmetros de um modelo generativo. A memória de trabalho é a atualização de crenças quando as crenças são sobre estados externos no passado e no futuro. A atenção é a otimização das crenças sobre a precisão da entrada sensorial. Formas de planejamento (e intencionalidade) podem ser conceituadas apelando para a capacidade de (algumas) criaturas de selecionar entre futuros alternativos, o que, por sua vez, requer modelos generativos temporalmente profundos. Estes prevêem os resultados que resultariam de um curso de ação e são otimistas sobre esses resultados. Esse otimismo se manifesta como a crença de que os resultados futuros levarão a resultados preferidos. Modelos temporais profundos também podem nos ajudar a entender formas sofisticadas de prospecção (onde crenças sobre o presente são usadas para derivar crenças sobre o futuro) e retrospecção (onde crenças sobre o presente são usadas para atualizar crenças sobre o passado). Formas de regulação interoceptiva e emoção podem ser conceituadas apelando para modelos generativos de fisiologia interna que predizem as consequências alostáticas de eventos futuros.

Como os exemplos acima ilustram, há uma consequência importante de estudar a cognição e o comportamento da perspectiva de uma teoria normativa do comportamento senciente. Tal teoria não começa reunindo funções cognitivas separadas, como percepção, tomada de decisão e planejamento. Em vez disso, começa fornecendo uma solução completa para os problemas que os organismos precisam resolver e, em seguida, analisando a solução para derivar implicações sobre as funções cognitivas. Por exemplo, quais mecanismos permitem que um organismo vivo ou criatura artificial (por exemplo, um robô) perceba o mundo, lembre-se dele ou planeje (Verschure et al. 2003, 2014; Verschure 2012; Pezzulo, Barsalou et al. 2013; Krakauer et al. al. 2017)? Este é um movimento importante, pois as taxonomias das funções cognitivas - usadas em livros de psicologia e neurociência - herdam em grande parte das primeiras teorias filosóficas e psicológicas (às vezes chamadas de categorias jamesianas). Apesar de seu grande valor heurístico, eles podem ser bastante arbitrários – ou podem não corresponder a processos cognitivos e neurais separados (Pezzulo e Cisek 2016, Buzsaki 2019, Cisek 2019). De fato, essas categorias jamesianas podem ser candidatas a como nossos modelos generativos explicam nosso envolvimento com o sensório – em oposição a explicar esse envolvimento. Por exemplo, a hipótese solipsista de que “estou percebendo” é apenas minha explicação para estados atuais de coisas que incluem minha atualização de crenças.

Adotar uma perspectiva normativa também pode ajudar na identificação de analogias formais entre fenômenos cognitivos estudados em diferentes domínios. Um exemplo é o trade-off entre prospecção e aproveitamento , que aparece em várias formas (Hills et al. 2015). Essa troca é frequentemente estudada durante o forrageamento, quando as criaturas devem escolher entre explorar planos anteriores de sucesso e explorar novos (potencialmente melhores). No entanto, a mesma troca ocorre durante a pesquisa de memória e deliberação com recursos limitados (por exemplo, limitações de tempo ou esforço de pesquisa), quando as criaturas têm a escolha entre explorar seu melhor plano atual versus investir mais tempo e esforço cognitivo para explorar possibilidades adicionais. Caracterizar esses fenômenos aparentemente desconectados em termos de energia livre pode revelar semelhanças profundas (Friston, Rigoli et al. 2015; Pezzulo, Cartoni et al. 2016; Gottwald e Braun 2020).

Finalmente, além de uma perspectiva unificada sobre fenômenos psicológicos, a Inferência Ativa oferece um meio baseado em princípios para entender as computações neurais correspondentes. Em outras palavras, oferece uma teoria de processo que conecta o processamento cognitivo à dinâmica neuronal (esperada). A Inferência Ativa assume que tudo o que importa sobre cérebros, mentes e comportamento pode ser descrito em termos da minimização da energia livre variacional. Por sua vez, essa minimização tem assinaturas neurais específicas (em termos de,
ex., passagem de mensagens ou anatomia cerebral) que podem ser validados empiricamente.

No restante deste capítulo, exploramos algumas implicações da Inferência Ativa para funções psicológicas — como se estivéssemos esboçando um livro de psicologia. Para cada uma dessas funções, também destacamos alguns pontos de contato (ou divergência) entre a Inferência Ativa e outras teorias populares na literatura.

## Cérebros Preditivos, Mentes Preditivas e Processamento Preditivo

Eu tenho essa foto de pura alegria 
é de uma criança com uma arma
ele está mirando bem na sua frente, 
atirando em algo que não está lá.
— Afterhours, “Quello che non c’è” (Algo que não está lá)

As teorias tradicionais do cérebro e da cognição enfatizam as transduções de alimentação direta de estímulos externos para representações internas e, em seguida, ações motoras. Isso tem sido chamado de “modelo sanduíche”, pois tudo o que está entre estímulos e respostas recebe o rótulo de “cognitivo” (Hurley 2008). Nessa perspectiva, a principal função do cérebro é transformar os estímulos recebidos em respostas contextualmente apropriadas.

A Inferência Ativa se afasta significativamente dessa visão, enfatizando aspectos preditivos e direcionados a objetivos do cérebro e da cognição. Em termos psicológicos, criaturas de Inferência Ativa (ou seus cérebros) são máquinas de inferência probabilísticas, que continuamente geram previsões baseadas em seus modelos generativos.

Criaturas auto-evidentes usam suas previsões de duas maneiras fundamentais. Primeiro, eles comparam as previsões com os dados recebidos para validar suas hipóteses (codificação preditiva) e – em uma escala de tempo mais lenta – revisam seus modelos (aprendizagem). Em segundo lugar, eles fazem previsões para orientar as formas de coleta de dados (Inferência Ativa). Ao fazer isso, as criaturas de Inferência Ativa cumprem dois imperativos: epistêmicos (por exemplo, explorar visualmente lugares onde estão presentes informações importantes que podem resolver incertezas sobre hipóteses ou modelos) e pragmáticos (por exemplo, mover-se para locais onde observações preferenciais, como recompensas, podem ser garantidas) . O imperativo epistêmico torna os processos de percepção e aprendizagem ativos, enquanto o imperativo pragmático torna o comportamento direcionado a metas.

### Processamento Preditivo

Essa visão preditiva e centrada em objetivos do cérebro – e cognição – está intimamente relacionada (e forneceu inspiração para) processamento preditivo (PP): uma estrutura emergente na filosofia da mente e epistemologia, que vê a previsão como central para o cérebro e a cognição e apela a conceitos de “cérebros preditivos” ou “mentes preditivas” (Clark 2013, 2015; Hohwy 2013).

Às vezes, as teorias PP apelam para o funcionamento específico da Inferência Ativa e alguns de seus construtos, como modelos generativos, codificação preditiva, energia livre, controle de precisão e envoltórios de Markov, mas às vezes apelam para outros construtos, como modelos inversos e diretos acoplados , que não fazem parte da Inferência Ativa. Portanto, o termo processamento preditivo é usado em um sentido mais amplo (e menos restrito) em comparação com a Inferência Ativa.

As teorias de processamento preditivo atraíram considerável atenção na filosofia, devido ao seu potencial de unificação em muitos sentidos: em vários domínios da cognição, incluindo percepção, ação, aprendizagem e psicopatologia; de níveis mais baixos (por exemplo, sensório-motor) para níveis mais altos de processamento cognitivo (por exemplo, construções psicológicas); desde simples organismos biológicos até cérebros, indivíduos e construções sociais e culturais. Outro apelo das teorias PP é que elas fazem uso de termos conceituais, como crenças e surpresa, que falam a um nível psicológico de análise familiar aos filósofos (com a ressalva de que às vezes esses termos podem ter significados técnicos diferentes do uso comum) .

No entanto, à medida que o interesse pela PP cresce, tornou-se evidente que os filósofos têm opiniões diferentes sobre suas implicações teóricas e epistemológicas. Por exemplo, foi interpretado em termos internalistas (Hohwy 2013), incorporados ou baseados em ação (Clark 2015) e enativistas e não representacionais (Bruineberg et al. 2016, Ramstead et al. 2019). O debate em torno dessas interpretações conceituais vai além do escopo deste livro. 

## Percepção

Você não pode depender de seus olhos quando sua imaginação está fora de foco. —Mark Twain

A Inferência Ativa considera a percepção como um processo inferencial baseado em um modelo generativo de como as observações sensoriais são geradas. A regra de Bayes essencialmente inverte o modelo para calcular uma crença sobre o estado oculto do ambiente, dadas as observações. Essa ideia de percepção-como-inferência remonta a Helmholtz (1866) e foi frequentemente reproposta em psicologia, neurociência computacional e aprendizado de máquina (por exemplo, análise por síntese) (Gregory 1980, Dayan et al. 1995, Mesulam 1998, Yuille e Kersten 2006). Essa abordagem de modelagem generativa demonstrou ser eficaz no enfrentamento de problemas de percepção desafiadores, como quebrar CAPTCHAs baseados em texto (George et al. 2017).

### Hipótese do Cérebro Bayesiano

A expressão contemporânea mais proeminente dessa ideia é a hipótese do cérebro bayesiano, que tem sido aplicada a vários domínios, como tomada de decisão, processamento sensorial e aprendizado (Doya 2007). A Inferência Ativa fornece uma base normativa para essas ideias inferenciais, derivando-as do imperativo de minimizar a energia livre variacional. Como o mesmo imperativo se estende à dinâmica da ação, a Inferência Ativa naturalmente modela a percepção ativa e as maneiras pelas quais os organismos ativamente amostram observações para testar suas hipóteses (Gregory 1980). Sob a agenda do cérebro bayesiano, em vez disso, a percepção e a ação são modeladas em termos de imperativos diferentes (onde a ação requer a teoria da decisão bayesiana; veja seção 10.7.1).

Mais amplamente, a hipótese do cérebro Bayesiano refere-se a uma família de abordagens que não são necessariamente integradas e muitas vezes fazem previsões empíricas diferentes. Estes incluem, por exemplo, a proposta em nível computacional de que o cérebro realiza integração sensório-motora e multissensorial ótima de Bayes (Kording e Wolpert 2006), a proposta em nível algorítmico de que o cérebro implementa aproximações específicas de inferência Bayesiana, como decisão-por- amostragem (Stewart et al. 2006), e as propostas de nível neural sobre as maneiras específicas em que as populações neurais podem realizar cálculos probabilísticos ou codificar distribuições de probabilidade - por exemplo, como amostras ou códigos populacionais probabilísticos (Fiser et al. 2010, Pouget et al. 2013). Em cada nível de explicação, existem teorias concorrentes no campo. Por exemplo, é comum recorrer a aproximações de inferência Bayesiana exata para explicar desvios do comportamento ótimo, mas trabalhos diferentes consideram aproximações diferentes (e nem sempre compatíveis), como diferentes abordagens de amostragem. Mais amplamente, as relações entre propostas em diferentes níveis nem sempre são diretas. Isso ocorre porque os cálculos bayesianos podem ser realizados (ou aproximados) de várias maneiras algorítmicas, mesmo sem representar explicitamente as distribuições de probabilidade (Aitchison e Lengyel 2017).

A Inferência Ativa fornece uma perspectiva mais integrada que conecta princípios normativos e teorias de processo. No nível normativo, seu pressuposto central é que todos os processos minimizam a energia livre variacional. A teoria do processo correspondente para inferência usa um gradiente descendente na energia livre, que tem implicações neurofisiológicas claras, exploradas no capítulo 5 (Friston, FitzGerald et al. 2016). Mais amplamente, pode-se partir do princípio da minimização da energia livre para derivar implicações sobre as arquiteturas do cérebro.

Por exemplo, o modelo de processo canônico de inferência perceptual (em tempo contínuo) é a codificação preditiva. A codificação preditiva foi inicialmente proposta como uma teoria do processamento perceptual hierárquico por Rao e Ballard (1999) para explicar uma série de efeitos documentados de cima para baixo, que eram difíceis de conciliar com arquiteturas feedforward, bem como fatos fisiológicos conhecidos (por exemplo, a existência de conexões para frente, ou de baixo para cima, e para trás, ou de cima para baixo, nas hierarquias sensoriais). No entanto, a codificação preditiva pode ser derivada do princípio da minimização da energia livre, sob algumas premissas, como a aproximação de Laplace (Friston 2005). Além disso, a Inferência Ativa em tempo contínuo pode ser construída como uma extensão direcionada da codificação preditiva no domínio da ação – dotando um agente de codificação preditiva com reflexos motores (Shipp et al. 2013). Isso nos leva ao próximo ponto.

##  Controle de Ação

Se você não pode voar, corra, se não pode correr, ande, se não puder andar, rasteje, mas faça o que fizer, continue seguindo em frente.
—Martin Luther King

Na Inferência Ativa, o processamento da ação é análogo ao processamento perceptivo, pois ambos são guiados por previsões diretas – exteroceptivas e proprioceptivas, respectivamente. É a previsão (proprioceptiva) de que “minha mão agarra a xícara” que induz um movimento de agarrar. A equivalência entre ação e percepção existe também no nível neurobiológico: a arquitetura do córtex motor é organizada da mesma forma que o córtex sensorial – como uma arquitetura de codificação preditiva, com a exceção de que pode influenciar os reflexos motores no tronco cerebral e coluna vertebral (Shipp et al. 2013) e que recebe relativamente pouca entrada ascendente. Os reflexos motores permitem controlar o movimento estabelecendo “pontos de equilíbrio” ao longo de uma trajetória desejada – uma ideia que corresponde à hipótese do ponto de equilíbrio (Feldman 2009).

É importante ressaltar que iniciar uma ação – como pegar uma xícara – requer regulação da precisão (variância inversa) de crenças anteriores e fluxos sensoriais de forma adequada. Isso ocorre porque os valores relativos dessas precisões determinam a maneira pela qual uma criatura administra o conflito entre sua crença anterior (que ela segura a xícara) e sua entrada sensorial (sinalizando que ela não segura). Uma crença prévia imprecisa sobre pegar uma xícara pode ser facilmente revisada à luz de evidências sensoriais conflitantes – produzindo uma mudança de opinião e nenhuma ação. Em vez disso, quando a crença anterior domina (ou seja, tem maior precisão), ela é mantida mesmo diante de evidências sensoriais conflitantes – e induz uma ação de apreensão para resolver o conflito. Para garantir que este seja o caso, a iniciação da ação induz uma atenuação sensorial transitória (ou erros de predição sensorial de peso reduzido). A falha dessa atenuação sensorial pode ter consequências desadaptativas, como a falha em iniciar ou controlar os movimentos (Brown et al. 2013).

### Teoria Ideomotora

Na Inferência Ativa, a ação decorre de previsões (proprioceptivas) e não de comandos motores (Adams, Shipp e Friston 2013). Essa ideia conecta a Inferência Ativa à teoria ideomotora da ação: uma estrutura para entender o controle da ação que remonta a William James (1890) e as teorias posteriores de “codificação de eventos” e “controle comportamental antecipatório” (Hommel et al. 2001, Hoffmann 2003). ). A teoria ideomotora sugere que as ligações ação-efeito (semelhantes aos modelos diretos) são mecanismos-chave na arquitetura da cognição. É importante ressaltar que esses links podem ser usados ​​bidirecionalmente. Quando utilizados no sentido ação-efeito, permitem gerar previsões sensoriais; quando são usados ​​na direção efeito-ação, eles permitem selecionar ações que alcançam as consequências perceptivas desejadas – implicando que as ações são selecionadas e controladas com base em suas consequências previstas (daí o termo ideo + motor). Essa visão antecipatória do controle da ação é apoiada por um corpo de literatura que documenta os efeitos das consequências (antecipadas) da ação na seleção e execução da ação (Kunde et al. 2004). A Inferência Ativa fornece uma caracterização matemática dessa ideia que também inclui mecanismos adicionais, como a importância do controle de precisão e atenuação sensorial, que não são totalmente investigados na teoria ideomotora (mas são compatíveis com ela).

### Cibernética

A Inferência Ativa está intimamente relacionada às ideias cibernéticas sobre a natureza intencional e direcionada a objetivos do comportamento e a importância das interações agente-ambiente (baseadas em feedback), como exemplificado pelo TOTE (Test, Operate, Test, Exit) e modelos relacionados ( Miller e outros 1960; Pezzulo, Baldassarre e outros 2006). Tanto no TOTE quanto no Active Inference, a seleção de ações é determinada pela discrepância entre um estado preferencial (objetivo) e o estado atual. Essas abordagens divergem das simples relações estímulo-resposta, como mais comumente assumidas na teoria behaviorista e estruturas computacionais como o aprendizado por reforço (Sutton e Barto, 1998).

A noção de controle de ação na Inferência Ativa é particularmente semelhante à teoria do controle perceptual (Powers 1973). Central para a teoria do controle perceptual era a noção de que o que é controlado é um estado perceptivo, não uma saída ou ação motora. Por exemplo, enquanto dirigimos, o que controlamos – e mantemos estável ao longo do tempo diante de distúrbios – é nossa referência ou velocidade desejada (por exemplo, 90 mph), conforme sinalizado pelo velocímetro, enquanto as ações que selecionamos para isso (por exemplo, acelerando ou desacelerando) são mais variáveis e dependentes do contexto. Por exemplo, dependendo da perturbação (por exemplo, vento, uma estrada íngreme ou outros carros), precisaríamos acelerar ou desacelerar para manter a velocidade de referência. Essa visão implementa a sugestão de William James (1890) de que “os humanos alcançam objetivos estáveis por meios flexíveis”.

Embora tanto na Inferência Ativa quanto na teoria do controle perceptual seja uma previsão perceptiva (e especificamente uma proprioceptiva) que controla a ação, as duas teorias diferem em como o controle é operado. Na Inferência Ativa, mas não na teoria do controle perceptual, o controle da ação tem aspectos antecipatórios ou feedforward, baseados em modelos generativos. Em contraste, a teoria do controle perceptual assume que os mecanismos de feedback são amplamente suficientes para controlar o comportamento, enquanto tentar prever uma perturbação ou exercer controle feedforward (ou malha aberta) é inútil. No entanto, essa objeção destinava-se principalmente a abordar as limitações das teorias de controle que usam modelos inversos para a frente (veja a próxima seção). Sob a Inferência Ativa, modelos generativos ou diretos não são usados para prever uma perturbação, mas para prever estados e trajetórias futuras (desejadas) a serem cumpridas pela ação – e para inferir a causa latente de eventos perceptivos.

Finalmente, outro ponto importante de contato entre a Inferência Ativa e a teoria do controle perceptual é a maneira como eles conceituam as hierarquias de controle. A teoria do controle perceptual propõe que os níveis hierárquicos mais altos controlam os níveis hierárquicos mais baixos, definindo seus pontos de referência ou pontos de ajuste (ou seja, o que eles precisam alcançar), deixando-os livres para selecionar os meios para alcançá-los, em vez de definir ou influenciar as ações que os níveis mais baixos têm que desempenhar (ou seja, como operar). Isso contrasta com a maioria das teorias de controle hierárquico e de cima para baixo, nas quais os níveis superiores selecionam diretamente os planos (Botvinick 2008) ou influenciam a seleção de ações ou comandos motores em níveis hierárquicos inferiores (Miller e Cohen 2001). Semelhante à teoria do controle perceptual, na Inferência Ativa pode-se decompor o controle hierárquico em termos de uma cascata (de cima para baixo) de objetivos e subobjetivos, que podem ser alcançados de forma autônoma nos níveis apropriados (inferiores). Além disso, na Inferência Ativa, a contribuição das metas representadas em diferentes níveis da hierarquia de controle pode ser modulada (precisão ponderada) por processos motivacionais, de forma que as metas mais salientes ou urgentes sejam priorizadas (Pezzulo, Rigoli e Friston 2015, 2018).

### Teoria do Controle Ótimo

A forma como a Inferência Ativa explica o controle da ação é significativamente diferente de outros modelos de controle na neurociência, como a teoria do controle ótimo (Todorov 2004, Shadmehr et al. 2010). Essa estrutura pressupõe que o córtex motor do cérebro seleciona ações usando uma política de controle (reativa) que mapeia estímulos para respostas. A Inferência Ativa, em vez disso, assume que o córtex motor transmite previsões, não comandos.

Além disso, embora tanto a teoria de controle ótimo quanto a Inferência Ativa apelem para modelos internos, elas descrevem a modelagem interna de maneiras diferentes (Friston 2011). No controle ótimo, há uma distinção entre dois tipos de modelos internos: os modelos inversos codificam contingências estímulo-resposta e selecionam comandos motores (de acordo com alguma função de custo), enquanto os modelos diretos codificam contingências ação-resultado e fornecem modelos inversos com entradas simuladas para substituir o feedback ruidoso ou atrasado, indo além de um esquema de controle de feedback puro. Modelos inversos e diretos também podem operar em um loop que é separado da percepção de ação externa (ou seja, quando entradas e saídas são suprimidas) para dar suporte a simulações “e se” internas de sequências de ação. Tais simulações internas de ação têm sido associadas a várias funções cognitivas, como planejamento, percepção de ação e imitação em domínios sociais ( Jeannerod 2001, Wolpert et al. 2003), bem como vários distúrbios do movimento e psicopatologias (Frith et al. 2000 ).

Em contraste com o esquema de modelagem direta-inversa, na Inferência Ativa os modelos diretos (generativos) fazem o trabalho pesado do controle da ação, enquanto os modelos inversos são minimalistas e geralmente se reduzem a reflexos simples resolvidos no nível periférico (ou seja, no tronco cerebral ou medula espinhal). A ação é iniciada quando há uma diferença entre os estados antecipados e observados (por exemplo, posições desejadas, atuais dos braços) - ou seja, um erro de previsão sensorial. Isso significa que um comando motor é equivalente a uma previsão feita pelo modelo direto em oposição a algo calculado por um modelo inverso como no controle ótimo. O erro de previsão sensorial (mais precisamente, proprioceptivo) é resolvido por uma ação (ou seja, movimento do braço). A lacuna a ser preenchida pela ação é considerada tão pequena que não requer um modelo inverso sofisticado, mas um reflexo motor muito mais simples (Adams, Shipp e Friston 2013).[^101] O que torna um reflexo motor mais simples do que um modelo inverso é que ele não codifica um mapeamento de estados inferidos do mundo para ação, mas um mapeamento muito mais simples entre ação e consequências sensoriais. Ver Friston, Daunizeau et ai. (2010) para uma discussão mais aprofundada.

[^101]:De um ponto de vista mais pragmático, a Inferência Ativa requer apenas a aquisição de modelos diretos, que são (tipicamente) mais fáceis de aprender em comparação aos modelos inversos porque são simplesmente um mapeamento direto (observável) entre ações e consequências. Modelos avançados também podem ser adquiridos por imitação ou supervisão externa – uma técnica amplamente análoga à Inferência Ativa que é amplamente usada para treinar modelos robóticos (Nishimoto e Tani 2009)

Outra diferença crucial entre o controle motor ótimo e a Inferência Ativa é que o primeiro usa uma noção de custo ou função de valor para motivar a ação, enquanto o segundo a substitui pela noção bayesiana de prioridade anterior (ou preferência anterior, implícita na energia livre esperada) – como discutimos na próxima seção.


## Utilidade e Tomada de Decisão

A ação expressa prioridades. —Mahatma Gandhi

A noção de uma função de custo ou valor de estados é central em muitos campos, como controle motor ótimo, teorias econômicas de maximização de utilidade e aprendizado por reforço. Por exemplo, na teoria de controle ótimo, a política de controle ótimo para uma tarefa de alcance é frequentemente definida como aquela que minimiza uma função de custo específica (por exemplo, é mais suave ou tem um jerk mínimo). Em problemas de aprendizado por reforço, como navegar em um labirinto que inclui uma ou mais recompensas, a política ótima é aquela que permite maximizar (descontar) a recompensa enquanto também minimiza os custos de movimento. Esses problemas são muitas vezes resolvidos usando a equação de Bellman (ou a equação de Hamilton-Jacobi-Bellman em tempo contínuo), cuja ideia geral é que o valor de uma decisão pode ser decomposto em duas partes: a recompensa imediata e o valor do restante. parte do problema de decisão. Essa decomposição fornece o procedimento iterativo de programação dinâmica, que está no centro da teoria de controle e do aprendizado por reforço (RL) (Bellman 1954).

A Inferência Ativa difere da abordagem acima de duas maneiras principais. Primeiro, a Inferência Ativa não considera apenas a maximização da utilidade, mas o objetivo mais amplo da minimização da energia livre (esperada), que também inclui imperativos (epistêmicos) adicionais, como a desambiguação do estado atual e a busca de novidades (veja a figura 2.5). Esses objetivos adicionais às vezes são adicionados às recompensas clássicas – por exemplo, como um “bônus de novidade” (Kakade e Dayan 2002) ou “recompensa intrínseca” (Schmidhuber 1991, Oudeyer et al. 2007, Baldassarre e Mirolli 2013, Gottlieb et al. 2013)—mas eles surgem automaticamente na Inferência Ativa, permitindo que ela resolva os trade-offs prospecção-aproveitamento implícitos em muitas decisões. A razão para isso é que as energias livres são funcionais de crenças, o que significa que estamos no domínio da otimização de crenças em oposição às funções de recompensa externas. Isso é essencial em problemas exploratórios, em que o sucesso depende de resolver o máximo de incertezas possível.

Em segundo lugar, na Inferência Ativa, a noção de custo é absorvida pelo anterior. O prior (ou preferência anterior) especifica um objetivo para controle – por exemplo, uma trajetória a seguir ou um ponto final a ser alcançado. Usar priores para codificar observações (ou sequências) preferidas pode ser mais expressivo do que usar utilitários (Friston, Daunizeau e Kiebel 2009). Usando esse método, encontrar a política ótima é reformulado como um problema de inferência (de uma sequência de estados de controle que realizam a trajetória preferida) e não requer uma função de valor ou a equação de Bellman - embora possa recorrer a uma lógica recursiva semelhante (Friston , Da Costa et al. 2020). Existem pelo menos duas diferenças fundamentais entre as formas como as funções prioritárias e de valor são normalmente usadas na Inferência Ativa e RL, respectivamente. Primeiro, os métodos RL usam funções de valor de estados ou de pares estado-ação - enquanto a Inferência Ativa usa a priori sobre as observações. Em segundo lugar, as funções de valor são definidas em termos do retorno esperado de estar em um estado (ou realizar uma ação em um estado) seguindo uma política específica – ou seja, a soma de recompensas futuras (descontadas) obtidas por começar no estado e depois execução da política. Em contraste, na Inferência Ativa, as anteriores geralmente não somam recompensas futuras, nem as descontam. Ao contrário, algo análogo ao retorno esperado só surge na Inferência Ativa quando a energia livre esperada de uma apólice é calculada. A implicação é que a energia livre esperada é o análogo mais próximo da função valor. No entanto, mesmo isso difere no sentido de que a energia livre esperada é uma função de crenças sobre estados, não uma função de estados. Dito isso, é possível construir priores que se assemelham a funções de valor de estados em RL - por exemplo, armazenando em cache os cálculos de energia livre esperada nesses estados (Friston, FitzGerald et al. 2016; Maisto, Friston e Pezzulo 2019).

Além disso, absorver a noção de utilidade no anterior tem uma importante consequência teórica: os anteriores desempenham o papel de metas e tornam o modelo gerador tendencioso - ou otimista, no sentido de que a criatura acredita que encontrará resultados preferidos. É esse otimismo que subscreve os planos inferidos que alcançam os resultados desejados na Inferência Ativa; uma falha desse tipo de otimismo pode corresponder à apatia (Hezemans et al. 2020). Isso contrasta com outras abordagens formais de tomada de decisão, como a teoria da decisão bayesiana, que separa a probabilidade dos eventos de sua utilidade. Dito isso, essa distinção é um tanto superficial, pois uma função de utilidade sempre pode ser reescrita como codificando uma crença anterior, consistente com o fato de que comportamentos que maximizam uma função de utilidade são a priori (e por design) mais prováveis. De uma perspectiva deflacionária (ligeiramente tautológica), esta é a definição de utilidade.

### Teoria da Decisão Bayesiana

A teoria da decisão bayesiana é uma estrutura matemática que estende as ideias do cérebro bayesiano (discutidas acima) para os domínios da tomada de decisão, controle sensório-motor e aprendizado (Kording e Wolpert 2006, Shadmehr et al. 2010, Wolpert e Landy 2012). A teoria da decisão bayesiana descreve a tomada de decisão em termos de dois processos distintos. O primeiro processo usa cálculos Bayesianos para prever a probabilidade de resultados futuros (dependentes da ação ou da política), e o segundo processo define a preferência sobre os planos, usando uma utilidade (fixa ou aprendida) ou função de custo. O processo de decisão final (ou seleção de ação) integra ambas as correntes, selecionando assim (com maior probabilidade) o plano de ação que tem maior probabilidade de render a maior recompensa. Isso contrasta com a Inferência Ativa, na qual a distribuição prévia sinaliza diretamente o que é valioso para o organismo (ou o que foi valioso durante a história evolutiva). No entanto, paralelos podem ser traçados entre as duas correntes da teoria da decisão Bayesiana e a otimização da energia livre variacional e esperada, respectivamente. Sob a Inferência Ativa, a minimização da energia livre variacional fornece crenças precisas (e simples) sobre o estado do mundo e sua provável evolução. A crença anterior de que a energia livre esperada será minimizada através da seleção de políticas incorpora a noção de preferências.

Em alguns círculos, há preocupações sobre o status da teoria da decisão bayesiana. Isso decorre dos teoremas de classe completos (Wald 1947, Brown 1981) que dizem que para qualquer par de decisões e funções de custo, existem algumas crenças anteriores que tornam as decisões de Bayes ótimas. Isso significa que há uma dualidade implícita ou degeneração ao lidar separadamente com crenças anteriores e funções de custo. Em certo sentido, a Inferência Ativa resolve essa degeneração absorvendo funções de utilidade ou custo em crenças anteriores na forma de preferências.

### Aprendizado por Reforço

Aprendizagem por reforço (RL) é uma abordagem para resolver problemas de decisão de Markov que é popular tanto na inteligência artificial quanto nas ciências cognitivas (Sutton e Barto 1998). Ele se concentra em como os agentes aprendem uma política (por exemplo, estratégia de balanceamento de pólos) por tentativa e erro: experimentando ações (por exemplo, mover para a esquerda) e recebendo reforços positivos ou negativos, dependendo do sucesso da ação (por exemplo, polo equilibrado) ou falha (por exemplo, polo caído).
 
A Inferência Ativa e a RL tratam de conjuntos de problemas sobrepostos, mas diferem em muitos aspectos matematicamente e conceitualmente. Como observado acima, a Inferência Ativa dispensa as noções de recompensa, funções de valor e otimalidade de Bellman que são fundamentais para as abordagens de aprendizado por reforço. Além disso, a noção de política é usada de forma diferente nas duas estruturas. Em RL, uma política denota um conjunto de mapeamentos estímulo-resposta que precisam ser aprendidos. Na Inferência Ativa, uma política faz parte do modelo generativo: denota uma sequência de estados de controle que precisam ser inferidos.

As abordagens de aprendizagem por reforço são abundantes, mas podem ser subdivididas em três famílias principais. Os dois primeiros métodos tentam aprender boas funções de valor (estado ou ação de estado), embora de duas maneiras diferentes.

Métodos livres de modelo de RL aprendem funções de valor diretamente da experiência: eles realizam ações, coletam recompensas, atualizam suas funções de valor e as usam para atualizar suas políticas. A razão pela qual eles são chamados de livres de modelo é porque eles não usam um modelo (de transição) que permite prever estados futuros - do tipo usado na Inferência Ativa. Em vez disso, eles apelam implicitamente para tipos mais simples de modelos (por exemplo, mapeamentos de ação de estado). As funções de valor de aprendizado em RL sem modelo geralmente envolvem erros de previsão de recompensa de computação, como na regra popular de diferença temporal. Embora a Inferência Ativa geralmente apele a erros de previsão, esses são erros de previsão de estado (já que não há noção de recompensa na Inferência Ativa).

Os métodos de RL baseados em modelos não aprendem funções ou políticas de valor diretamente da experiência. Em vez disso, eles aprendem um modelo da tarefa a partir da experiência, usam o modelo para planejar (simular experiências possíveis) e atualizar funções e políticas de valor dessas experiências simuladas. Embora tanto a Inferência Ativa quanto o aprendizado por reforço apelem ao planejamento baseado em modelo, eles o usam de maneira diferente. Na Inferência Ativa, o planejamento é o cálculo da energia livre esperada para cada política, não um meio de atualizar funções de valor. Indiscutivelmente, se a energia livre esperada é vista como um funcional de valor, pode-se dizer que as inferências feitas usando o modelo generativo são usadas para atualizar esse funcional – oferecendo um ponto de analogia entre essas abordagens.

A terceira família de abordagens de RL, métodos de gradiente de política, tenta otimizar políticas diretamente, sem funções de valor intermediário, que são centrais tanto para RL baseado em modelo quanto sem modelo. Esses métodos partem de políticas parametrizadas, capazes de gerar (por exemplo) trajetórias de movimento, e depois as otimizam alterando os parâmetros para aumentar (diminuir) a probabilidade de uma política se a trajetória resultar em uma recompensa positiva alta (baixa). Essa abordagem relaciona métodos de gradiente de política à Inferência Ativa, que também dispensa funções de valor (Millidge 2019). No entanto, o objetivo geral dos gradientes de política (maximizar a recompensa cumulativa de longo prazo) difere da Inferência Ativa.

Além das diferenças formais entre Inferência Ativa e RL, existem também várias diferenças conceituais importantes. Uma diferença diz respeito a como as duas abordagens interpretam o comportamento dirigido a objetivos e o comportamento habitual. Na literatura de aprendizagem animal, as escolhas direcionadas a objetivos são mediadas pelo conhecimento (prospectivo) da contingência entre uma ação e seu resultado (Dickinson e Balleine 1990), enquanto as escolhas habituais não são prospectivas e dependem de mais simples (por exemplo, estímulo-resposta). ) mecanismos. Uma ideia popular em RL é que escolhas direcionadas a objetivos e escolhas habituais correspondem a RL baseado em modelo e livre de modelo, respectivamente, e que estas são adquiridas em paralelo e competem continuamente para controlar o comportamento (Daw et al. 2005).

A Inferência Ativa, em vez disso, mapeia as escolhas habituais e direcionadas a objetivos para diferentes mecanismos. Na Inferência Ativa (em tempo discreto), a seleção de políticas é essencialmente baseada em modelos e, portanto, se encaixa na definição de escolhas deliberativas direcionadas a objetivos. Isso é semelhante ao que acontece na RL baseada em modelo, mas com uma diferença. Na LR baseada em modelos, as ações são selecionadas de forma prospectiva (usando um modelo), mas são controladas de forma reativa (usando políticas de estímulo-resposta); na Inferência Ativa, as ações podem ser controladas de maneira proativa – por meio do cumprimento de previsões proprioceptivas (sobre controle de ações, consulte a seção 10.6).

Na Inferência Ativa, os hábitos podem ser adquiridos executando políticas direcionadas a objetivos e, em seguida, armazenando em cache as informações sobre quais políticas são bem-sucedidas em quais contextos. As informações armazenadas em cache podem ser incorporadas como valor prévio das políticas (Friston, FitzGerald et al. 2016; Maisto, Friston e Pezzulo 2019). Este mecanismo permite a execução de políticas que tenham um alto valor a priori (em um determinado contexto) sem deliberação. Isso pode ser pensado simplesmente como observar “o que eu faço” e aprender que “eu sou o tipo de criatura que tende a fazer isso” ao longo de múltiplas exposições a uma tarefa. Em contraste com a RL livre de modelo, onde os hábitos são adquiridos independentemente da seleção de políticas direcionadas a objetivos, na Inferência Ativa os hábitos são adquiridos pela busca repetida de políticas direcionadas a objetivos (por exemplo, armazenando seus resultados em cache).

Na Inferência Ativa, mecanismos habituais e direcionados a objetivos podem cooperar em vez de apenas competir. Isso ocorre porque a crença prévia sobre as políticas depende tanto de um termo habitual (um valor prévio das políticas) quanto de um termo deliberativo (energia livre esperada). As elaborações hierárquicas da Inferência Ativa sugerem que os mecanismos reativos e direcionados a objetivos podem ser organizados em uma hierarquia e não como caminhos paralelos (Pezzulo, Rigoli e Friston 2015).

Por fim, vale notar que a Inferência Ativa e a RL diferem sutilmente na forma como concebem o comportamento e suas causas. A RL tem origem na teoria behaviorista e na ideia de que o comportamento resulta da aprendizagem por tentativa e erro mediada por reforço. A Inferência Ativa assume, em vez disso, que o comportamento é o resultado de uma inferência. Isso nos leva ao próximo ponto.

### Planejamento como Inferência

Da mesma forma que é possível lançar problemas perceptuais como problemas de inferência, também é possível lançar problemas de controle em termos de inferência Bayesiana (aproximada) (Todorov 2008). Em consonância com isso, na Inferência Ativa, o planejamento é visto como um processo inferencial: a inferência de uma sequência de estados de controle do modelo generativo.

Essa ideia está intimamente relacionada a outras abordagens, que incluem controle como inferência (Rawlik et al. 2013, Levine 2018), planejamento como inferência (Attias 2003, Botvinick e Toussaint 2012) e controle sensível ao risco e KL ( Kappen et al. 2012). Nessas abordagens, o planejamento procede através da inferência de uma distribuição posterior sobre as ações, ou sequências de ações, usando um modelo generativo dinâmico que codifica contingências probabilísticas entre estados, ações e estados futuros (esperados). A melhor ação ou plano pode ser inferido condicionando o modelo generativo à observação de recompensas futuras (Pezzulo e Rigoli 2011, Solway e Botvinick 2012) ou trajetórias futuras ótimas (Levine 2018). Por exemplo, é possível fixar (ou seja, fixar o valor de ) o estado desejado futuro no modelo e então inferir a sequência de ações que tem mais probabilidade de preencher a lacuna do estado atual para o estado desejado futuro.

