\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\bibstyle{apalike}
\HyPL@Entry{0<</S/D>>}
\newlabel{conteuxfado}{{}{9}{Conteúdo}{chapter*.4}{}}
\@writefile{toc}{\contentsline {chapter}{Conteúdo}{9}{chapter*.4}\protected@file@percent }
\newlabel{prefuxe1cio}{{}{11}{Prefácio}{chapter*.5}{}}
\@writefile{toc}{\contentsline {chapter}{Prefácio}{11}{chapter*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Visão Geral}{15}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{visuxe3o-geral}{{1}{15}{Visão Geral}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introdução}{15}{section.1.1}\protected@file@percent }
\newlabel{introduuxe7uxe3o}{{1.1}{15}{Introdução}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Como os Organismos Vivos Persistem e Agem Adaptativamente?}{15}{section.1.2}\protected@file@percent }
\newlabel{como-os-organismos-vivos-persistem-e-agem-adaptativamente}{{1.2}{15}{Como os Organismos Vivos Persistem e Agem Adaptativamente?}{section.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces \textbf  {Figura 1.1} Um ciclo de percepção de ação conectando reciprocamente uma criatura e seu ambiente. O termo ambiente é intencionalmente genérico. Nos exemplos que discutimos, pode incluir o mundo físico, o corpo, o ambiente social e assim por diante.}}{16}{figure.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Inferência Ativa: Comportamento a partir dos Primeiros Princípios}{17}{section.1.3}\protected@file@percent }
\newlabel{inferuxeancia-ativa-comportamento-a-partir-dos-primeiros-princuxedpios}{{1.3}{17}{Inferência Ativa: Comportamento a partir dos Primeiros Princípios}{section.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Estrutura do Livro}{18}{section.1.4}\protected@file@percent }
\newlabel{estrutura-do-livro}{{1.4}{18}{Estrutura do Livro}{section.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Parte 1: Inferência Ativa na Teoria}{19}{subsection.1.4.1}\protected@file@percent }
\newlabel{parte-1-inferuxeancia-ativa-na-teoria}{{1.4.1}{19}{Parte 1: Inferência Ativa na Teoria}{subsection.1.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Figura 1.2 - duas estradas para a Inferência Ativa: a estrada principal (começando do canto superior direito) e a estrada inferior (começando do canto inferior esquerdo).}}{21}{figure.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Parte 2: Inferência Ativa na Prática}{25}{subsection.1.4.2}\protected@file@percent }
\newlabel{parte-2-inferuxeancia-ativa-na-pruxe1tica}{{1.4.2}{25}{Parte 2: Inferência Ativa na Prática}{subsection.1.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Resumo}{28}{section.1.5}\protected@file@percent }
\newlabel{resumo}{{1.5}{28}{Resumo}{section.1.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}O Caminho de baixo para a Inferência Ativa}{29}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{o-caminho-de-baixo-para-a-inferuxeancia-ativa}{{2}{29}{O Caminho de baixo para a Inferência Ativa}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introdução}{29}{section.2.1}\protected@file@percent }
\newlabel{introduuxe7uxe3o-1}{{2.1}{29}{Introdução}{section.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Percepção como Inferência}{29}{section.2.2}\protected@file@percent }
\newlabel{percepuxe7uxe3o-como-inferuxeancia}{{2.2}{29}{Percepção como Inferência}{section.2.2}{}}
\gdef \LT@i {\LT@entry 
    {1}{390.0pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces \textbf  {Figura 2.1} Um exemplo simples de inferência Bayesiana. Superior esquerdo: A crença prévia P(x) do organismo sobre o objeto que ele verá, antes de ter feito qualquer observação, ou seja, uma distribuição categórica sobre duas possibilidades, maçã (com probabilidade 0,9) e sapo (com probabilidade 0,1). Superior direito: A crença posterior do organismo P(x \textbar {} y ) após observar que o objeto salta. Crenças posteriores podem ser calculadas usando a regra de Bayes sob uma função de verossimilhança P( y \textbar {} x). Isso é mostrado abaixo do anterior e do posterior e específica que, se o objeto for uma maçã, há uma probabilidade muito pequena (0,01) de que ele pule, enquanto se for um sapo, a probabilidade de pular é muito maior ( 0,81). (As barras de probabilidade nesta figura não estão exatamente em escala.) Neste caso específico, a atualização de anterior para posterior é grande.}}{33}{figure.2.1}\protected@file@percent }
\gdef \LT@ii {\LT@entry 
    {1}{105.81006pt}\LT@entry 
    {1}{178.34637pt}\LT@entry 
    {1}{105.81006pt}}
\gdef \LT@iii {\LT@entry 
    {1}{390.0pt}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Inferência Biológica e Otimização}{37}{section.2.3}\protected@file@percent }
\newlabel{inferuxeancia-bioluxf3gica-e-otimizauxe7uxe3o}{{2.3}{37}{Inferência Biológica e Otimização}{section.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Ação como Inferência}{40}{section.2.4}\protected@file@percent }
\newlabel{auxe7uxe3o-como-inferuxeancia}{{2.4}{40}{Ação como Inferência}{section.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Minimizando a discrepância entre o modelo e o mundo}{41}{section.2.5}\protected@file@percent }
\newlabel{minimizando-a-discrepuxe2ncia-entre-o-modelo-e-o-mundo}{{2.5}{41}{Minimizando a discrepância entre o modelo e o mundo}{section.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces \textbf  {Figura 2.3} Tanto a percepção quanto a ação minimizam a discrepância entre modelo e mundo.}}{42}{figure.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Minimizando a Energia Livre Variacional}{43}{section.2.6}\protected@file@percent }
\newlabel{minimizando-a-energia-livre-variacional}{{2.6}{43}{Minimizando a Energia Livre Variacional}{section.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces \textbf  {Figura 2.4} Energia livre variacional como um limite superior na evidência logarítmica negativa.}}{46}{figure.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces \textbf  {Figura 2.5} Papéis complementares de percepção e ação na minimização da energia livre variacional.}}{48}{figure.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Energia Livre Esperada e Planejamento como Inferência}{48}{section.2.7}\protected@file@percent }
\newlabel{energia-livre-esperada-e-planejamento-como-inferuxeancia}{{2.7}{48}{Energia Livre Esperada e Planejamento como Inferência}{section.2.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}O que é energia livre esperada?}{50}{section.2.8}\protected@file@percent }
\newlabel{o-que-uxe9-energia-livre-esperada}{{2.8}{50}{O que é energia livre esperada?}{section.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces \textbf  {Figura 2.6} Vários esquemas que podem ser derivados removendo termos da equação da energia livre. O painel superior mostra os termos que contribuem para a energia livre esperada. Os painéis inferiores mostram os esquemas resultantes da remoção de preferências anteriores (1), ambiguidade (2) ou tudo, exceto as preferências anteriores. Cada uma dessas quantidades aparece em vários campos diferentes sob uma variedade de nomes, mas todas podem ser vistas como componentes de a mesma energia livre esperada.}}{55}{figure.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.9}No final da estrada baixa}{56}{section.2.9}\protected@file@percent }
\newlabel{no-final-da-estrada-baixa}{{2.9}{56}{No final da estrada baixa}{section.2.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Resumo}{57}{section.2.10}\protected@file@percent }
\newlabel{resumo-1}{{2.10}{57}{Resumo}{section.2.10}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}O caminho para a inferência ativa}{59}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{o-caminho-para-a-inferuxeancia-ativa}{{3}{59}{O caminho para a inferência ativa}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introdução}{59}{section.3.1}\protected@file@percent }
\newlabel{introduuxe7uxe3o-2}{{3.1}{59}{Introdução}{section.3.1}{}}
\gdef \LT@iv {\LT@entry 
    {1}{390.0pt}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Envoltórios de Markov}{61}{section.3.2}\protected@file@percent }
\newlabel{envoltuxf3rios-de-markov}{{3.2}{61}{Envoltórios de Markov}{section.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces \textbf  {Figura 3.1} Um envoltório de Markov dinâmico, que separa um sistema adaptativo (aqui, o cérebro) do ambiente. A dinâmica de cada conjunto de estados é determinada por um fluxo determinístico especificado como uma função \((f)\) fornecendo a taxa média de variação e flutuações estocásticas adicionais (aleatórias) \((ω)\). As setas indicam a direção da influência de cada variável sobre as taxas de variação de outras variáveis (tecnicamente, os elementos não nulos dos jacobianos associados). Isso é apenas um exemplo; pode-se usar um envoltório de Markov para separar um organismo inteiro do ambiente ou aninhar vários envoltórios de Markov um dentro do outro. Por exemplo, cérebros, organismos, díades e comunidades podem ser concebidos em termos de diferentes envoltórios de Markov que estão aninhadas umas nas outras (veja Friston 2019a; Parr, Da Costa e Friston 2020 para um tratamento formal). Confusamente, campos diferentes usam notações diferentes para as variáveis; às vezes, os estados sensoriais são denotados por \(s\), estados externos \(η\) e estados ativos \(a\). Aqui escolhemos variáveis para consistência com os outros capítulos deste livro.}}{63}{figure.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Minimização de surpresa e auto-evidência}{64}{section.3.3}\protected@file@percent }
\newlabel{minimizauxe7uxe3o-de-surpresa-e-auto-eviduxeancia}{{3.3}{64}{Minimização de surpresa e auto-evidência}{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Figura 3.2 Associação entre estados internos médios de um envoltório de Markov e distribuições de estados externos. Topo: Assumindo uma forma gaussiana linear para as probabilidades condicionais, esses gráficos mostram amostras da distribuição condicional sobre estados externos e internos, respectivamente, dados estados gerais. As linhas pretas grossas indicam a média dessas variáveis, dado o estado do envoltório associado. Inferior esquerdo: Os mesmos dados são plotados para ilustrar a sincronização de estados internos e externos proporcionada pelo compartilhamento de um envoltório de Markov -- aqui, uma sincronização inversa. As linhas tracejadas e a cruz preta ilustram que se conhecêssemos o estado médio interno (linha vertical), poderíamos identificar o estado médio externo (linha horizontal) e a dispersão em torno deste ponto. Inferior direito: Podemos associar o estado interno médio com uma distribuição sobre o estado externo.}}{65}{figure.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Minimização de surpresa como um princípio hamiltoniano de menor ação}{66}{subsection.3.3.1}\protected@file@percent }
\newlabel{minimizauxe7uxe3o-de-surpresa-como-um-princuxedpio-hamiltoniano-de-menor-auxe7uxe3o}{{3.3.1}{66}{Minimização de surpresa como um princípio hamiltoniano de menor ação}{subsection.3.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces \textbf  {Figura 3.3} Esquerda: Caminho tomado por um sistema dinâmico aleatório bidimensional com um estado estacionário (não-equilíbrio ). Isso pode ser interpretado como minimizando sua surpresa, que é mostrada no gráfico de contorno à direita. Direita: O centro é a região menos surpreendente; os círculos que se afastam do centro representam regiões progressivamente mais surpreendentes. Meio: Em contraste, este gráfico mostra a trajetória de um sistema começando no mesmo lugar (5, 5), com flutuações aleatórias de mesma amplitude, cuja dinâmica não guarda relação com surpresa. Não só entra em regiões mais surpreendentes do espaço; também não consegue atingir qualquer tipo de estado estacionário, dissipando-se de forma irrestrita ao longo do tempo. O escopo da Inferência Ativa é restrito a sistemas como o da esquerda -- que contrariam flutuações aleatórias com seu fluxo médio e, assim, mantêm sua forma ao longo do tempo.}}{68}{figure.3.3}\protected@file@percent }
\gdef \LT@v {\LT@entry 
    {1}{127.98697pt}\LT@entry 
    {1}{133.98697pt}\LT@entry 
    {1}{127.98697pt}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Relações entre Inferência, Cognição e Dinâmica Estocástica}{70}{section.3.4}\protected@file@percent }
\newlabel{relauxe7uxf5es-entre-inferuxeancia-cogniuxe7uxe3o-e-dinuxe2mica-estocuxe1stica}{{3.4}{70}{Relações entre Inferência, Cognição e Dinâmica Estocástica}{section.3.4}{}}
\gdef \LT@vi {\LT@entry 
    {1}{390.0pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Energia Livre Variacional, Evidência Modelo e Surpresa}{71}{subsection.3.4.1}\protected@file@percent }
\newlabel{energia-livre-variacional-eviduxeancia-modelo-e-surpresa}{{3.4.1}{71}{Energia Livre Variacional, Evidência Modelo e Surpresa}{subsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Energia Livre Esperada e Inferência da Trajetória Mais Provável}{73}{subsection.3.4.2}\protected@file@percent }
\newlabel{energia-livre-esperada-e-inferuxeancia-da-trajetuxf3ria-mais-provuxe1vel}{{3.4.2}{73}{Energia Livre Esperada e Inferência da Trajetória Mais Provável}{subsection.3.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Inferência ativa: uma nova base para entender o comportamento e a cognição}{74}{section.3.5}\protected@file@percent }
\newlabel{inferuxeancia-ativa-uma-nova-base-para-entender-o-comportamento-e-a-cogniuxe7uxe3o}{{3.5}{74}{Inferência ativa: uma nova base para entender o comportamento e a cognição}{section.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Modelos, Políticas e Trajetórias}{77}{section.3.6}\protected@file@percent }
\newlabel{modelos-poluxedticas-e-trajetuxf3rias}{{3.6}{77}{Modelos, Políticas e Trajetórias}{section.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Reconciliação das Teorias Enativa, Cibernética e Preditiva sob Inferência Ativa}{78}{section.3.7}\protected@file@percent }
\newlabel{reconciliauxe7uxe3o-das-teorias-enativa-cibernuxe9tica-e-preditiva-sob-inferuxeancia-ativa}{{3.7}{78}{Reconciliação das Teorias Enativa, Cibernética e Preditiva sob Inferência Ativa}{section.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Inferência Ativa, da Emergência da Vida para a atuação}{80}{section.3.8}\protected@file@percent }
\newlabel{inferuxeancia-ativa-da-emerguxeancia-da-vida-para-a-atuauxe7uxe3o}{{3.8}{80}{Inferência Ativa, da Emergência da Vida para a atuação}{section.3.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Resumo}{81}{section.3.9}\protected@file@percent }
\newlabel{resumo-2}{{3.9}{81}{Resumo}{section.3.9}{}}
\gdef \LT@vii {\LT@entry 
    {1}{390.0pt}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Os Modelos Geradores de Inferência Ativa}{85}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{os-modelos-geradores-de-inferuxeancia-ativa}{{4}{85}{Os Modelos Geradores de Inferência Ativa}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introdução}{85}{section.4.1}\protected@file@percent }
\newlabel{introduuxe7uxe3o-3}{{4.1}{85}{Introdução}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Da Inferência Bayesiana à Energia Livre}{86}{section.4.2}\protected@file@percent }
\newlabel{da-inferuxeancia-bayesiana-uxe0-energia-livre}{{4.2}{86}{Da Inferência Bayesiana à Energia Livre}{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces \textbf  {Figura 4.1} Função logarítmica fornecendo intuição para a desigualdade de Jensen. Se tivéssemos apenas dois pontos de dados (\(x1\) e \(x2\)), ou poderíamos pegar sua média (\(\symbb E[x]\)) e encontrar seu log, ou poderíamos pegar o log de cada ponto de dados e então tirar a média desses (\(\symbb {E}[ln x]\)). Este último (\(\symbb {E}[ln x]\)) estará sempre abaixo do primeiro (\(ln \symbb {E}[x]\)), devido à concavidade da função logarítmica, a menos que os pontos de dados sejam os mesmos (onde o logaritmo da média e a média de o log são iguais). Essa desigualdade vale para qualquer número de pontos de dados.}}{88}{figure.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Modelos Geradores}{90}{section.4.3}\protected@file@percent }
\newlabel{modelos-geradores}{{4.3}{90}{Modelos Geradores}{section.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces \textbf  {Figura 4.2} Dependências entre variáveis em um modelo probabilístico (gráfico). Os círculos representam variáveis aleatórias (ou seja, as coisas sobre as quais temos crenças); os quadrados representam as distribuições de probabilidade que descrevem as relações entre essas variáveis. Uma seta de um círculo para outro através de um quadrado indica que a variável do segundo círculo depende daquela do primeiro círculo e que essa dependência é capturada na distribuição de probabilidade representada pelo quadrado.}}{92}{figure.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces \textbf  {Figura 4.3} Dois modelos generativos dinâmicos (usando a mesma notação gráfica da figura 4.2) aos quais recorreremos no restante deste livro. Topo: Processo de Decisão Markov Parcialmente Observável (POMDP), definido em termos de uma sequência de estados evoluindo ao longo do tempo (indexados pelo subscrito). Abaixo: Modelo de tempo contínuo, do tipo implícito por equações diferenciais estocásticas (com a notação principal indicando derivadas temporais).}}{94}{figure.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Inferência ativa em tempo discreto}{95}{section.4.4}\protected@file@percent }
\newlabel{inferuxeancia-ativa-em-tempo-discreto}{{4.4}{95}{Inferência ativa em tempo discreto}{section.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Processos de Decisão Markov Parcialmente Observáveis}{95}{subsection.4.4.1}\protected@file@percent }
\newlabel{processos-de-decisuxe3o-markov-parcialmente-observuxe1veis}{{4.4.1}{95}{Processos de Decisão Markov Parcialmente Observáveis}{subsection.4.4.1}{}}
