<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>> 7 Inferência ativa em tempo discreto | Inferencia Ativa</title>
  <meta name="description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="> 7 Inferência ativa em tempo discreto | Inferencia Ativa" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/Figura_1_1.png" />
  <meta property="og:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="> 7 Inferência ativa em tempo discreto | Inferencia Ativa" />
  
  <meta name="twitter:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="twitter:image" content="/images/Figura_1_1.png" />

<meta name="author" content="Thomas Parr, Giovanni Pezzulo, and Karl J. Friston" />


<meta name="date" content="2022-07-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="uma-receita-para-projetar-modelos-de-inferência-ativos.html"/>
<link rel="next" href="bases-matemáticas.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Inferencia Ativa</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Conteúdo</a></li>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html"><i class="fa fa-check"></i>Prefácio</a></li>
<li class="chapter" data-level="1" data-path="visão-geral.html"><a href="visão-geral.html"><i class="fa fa-check"></i><b>1</b> Visão Geral</a>
<ul>
<li class="chapter" data-level="1.1" data-path="visão-geral.html"><a href="visão-geral.html#introdução"><i class="fa fa-check"></i><b>1.1</b> Introdução</a></li>
<li class="chapter" data-level="1.2" data-path="visão-geral.html"><a href="visão-geral.html#como-os-organismos-vivos-persistem-e-agem-adaptativamente"><i class="fa fa-check"></i><b>1.2</b> Como os Organismos Vivos Persistem e Agem Adaptativamente?</a></li>
<li class="chapter" data-level="1.3" data-path="visão-geral.html"><a href="visão-geral.html#inferência-ativa-comportamento-a-partir-dos-primeiros-princípios"><i class="fa fa-check"></i><b>1.3</b> Inferência Ativa: Comportamento a partir dos Primeiros Princípios</a></li>
<li class="chapter" data-level="1.4" data-path="visão-geral.html"><a href="visão-geral.html#estrutura-do-livro"><i class="fa fa-check"></i><b>1.4</b> Estrutura do Livro</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="visão-geral.html"><a href="visão-geral.html#parte-1-inferência-ativa-na-teoria"><i class="fa fa-check"></i><b>1.4.1</b> Parte 1: Inferência Ativa na Teoria</a></li>
<li class="chapter" data-level="1.4.2" data-path="visão-geral.html"><a href="visão-geral.html#parte-2-inferência-ativa-na-prática"><i class="fa fa-check"></i><b>1.4.2</b> Parte 2: Inferência Ativa na Prática</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="visão-geral.html"><a href="visão-geral.html#resumo"><i class="fa fa-check"></i><b>1.5</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>2</b> O Caminho de baixo para a Inferência Ativa</a>
<ul>
<li class="chapter" data-level="2.1" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#introdução-1"><i class="fa fa-check"></i><b>2.1</b> Introdução</a></li>
<li class="chapter" data-level="2.2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#percepção-como-inferência"><i class="fa fa-check"></i><b>2.2</b> Percepção como Inferência</a></li>
<li class="chapter" data-level="2.3" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#inferência-biológica-e-otimização"><i class="fa fa-check"></i><b>2.3</b> Inferência Biológica e Otimização</a></li>
<li class="chapter" data-level="2.4" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#ação-como-inferência"><i class="fa fa-check"></i><b>2.4</b> Ação como Inferência</a></li>
<li class="chapter" data-level="2.5" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-discrepância-entre-o-modelo-e-o-mundo"><i class="fa fa-check"></i><b>2.5</b> Minimizando a discrepância entre o modelo e o mundo</a></li>
<li class="chapter" data-level="2.6" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-energia-livre-variacional"><i class="fa fa-check"></i><b>2.6</b> Minimizando a Energia Livre Variacional</a></li>
<li class="chapter" data-level="2.7" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#energia-livre-esperada-e-planejamento-como-inferência"><i class="fa fa-check"></i><b>2.7</b> Energia Livre Esperada e Planejamento como Inferência</a></li>
<li class="chapter" data-level="2.8" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#o-que-é-energia-livre-esperada"><i class="fa fa-check"></i><b>2.8</b> O que é energia livre esperada?</a></li>
<li class="chapter" data-level="2.9" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#no-final-da-estrada-baixa"><i class="fa fa-check"></i><b>2.9</b> No final da estrada baixa</a></li>
<li class="chapter" data-level="2.10" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#resumo-1"><i class="fa fa-check"></i><b>2.10</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>3</b> O caminho para a inferência ativa</a>
<ul>
<li class="chapter" data-level="3.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#introdução-2"><i class="fa fa-check"></i><b>3.1</b> Introdução</a></li>
<li class="chapter" data-level="3.2" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#envoltórios-de-markov"><i class="fa fa-check"></i><b>3.2</b> Envoltórios de Markov</a></li>
<li class="chapter" data-level="3.3" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-e-auto-evidência"><i class="fa fa-check"></i><b>3.3</b> Minimização de surpresa e auto-evidência</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-como-um-princípio-hamiltoniano-de-menor-ação"><i class="fa fa-check"></i><b>3.3.1</b> Minimização de surpresa como um princípio hamiltoniano de menor ação</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#relações-entre-inferência-cognição-e-dinâmica-estocástica"><i class="fa fa-check"></i><b>3.4</b> Relações entre Inferência, Cognição e Dinâmica Estocástica</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#energia-livre-variacional-evidência-modelo-e-surpresa"><i class="fa fa-check"></i><b>3.4.1</b> Energia Livre Variacional, Evidência Modelo e Surpresa</a></li>
<li class="chapter" data-level="3.4.2" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#energia-livre-esperada-e-inferência-da-trajetória-mais-provável"><i class="fa fa-check"></i><b>3.4.2</b> Energia Livre Esperada e Inferência da Trajetória Mais Provável</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#inferência-ativa-uma-nova-base-para-entender-o-comportamento-e-a-cognição"><i class="fa fa-check"></i><b>3.5</b> Inferência ativa: uma nova base para entender o comportamento e a cognição</a></li>
<li class="chapter" data-level="3.6" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#modelos-políticas-e-trajetórias"><i class="fa fa-check"></i><b>3.6</b> Modelos, Políticas e Trajetórias</a></li>
<li class="chapter" data-level="3.7" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#reconciliação-das-teorias-enativa-cibernética-e-preditiva-sob-inferência-ativa"><i class="fa fa-check"></i><b>3.7</b> Reconciliação das Teorias Enativa, Cibernética e Preditiva sob Inferência Ativa</a></li>
<li class="chapter" data-level="3.8" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#inferência-ativa-da-emergência-da-vida-para-a-atuação"><i class="fa fa-check"></i><b>3.8</b> Inferência Ativa, da Emergência da Vida para a atuação</a></li>
<li class="chapter" data-level="3.9" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#resumo-2"><i class="fa fa-check"></i><b>3.9</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html"><i class="fa fa-check"></i><b>4</b> Os Modelos Geradores de Inferência Ativa</a>
<ul>
<li class="chapter" data-level="4.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#introdução-3"><i class="fa fa-check"></i><b>4.1</b> Introdução</a></li>
<li class="chapter" data-level="4.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#da-inferência-bayesiana-à-energia-livre"><i class="fa fa-check"></i><b>4.2</b> Da Inferência Bayesiana à Energia Livre</a></li>
<li class="chapter" data-level="4.3" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#modelos-geradores"><i class="fa fa-check"></i><b>4.3</b> Modelos Geradores</a></li>
<li class="chapter" data-level="4.4" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-tempo-discreto"><i class="fa fa-check"></i><b>4.4</b> Inferência ativa em tempo discreto</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#processos-de-decisão-markov-parcialmente-observáveis"><i class="fa fa-check"></i><b>4.4.1</b> Processos de Decisão Markov Parcialmente Observáveis</a></li>
<li class="chapter" data-level="4.4.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-um-pomdp"><i class="fa fa-check"></i><b>4.4.2</b> Inferência ativa em um POMDP</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-tempo-contínuo"><i class="fa fa-check"></i><b>4.5</b> Inferência Ativa em Tempo Contínuo</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#um-modelo-generativo-para-codificação-preditiva"><i class="fa fa-check"></i><b>4.5.1</b> Um modelo generativo para codificação preditiva</a></li>
<li class="chapter" data-level="4.5.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-como-codificação-preditiva-com-reflexos-motores"><i class="fa fa-check"></i><b>4.5.2</b> Inferência Ativa como Codificação Preditiva com Reflexos Motores</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#resumo-3"><i class="fa fa-check"></i><b>4.6</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html"><i class="fa fa-check"></i><b>5</b> Passagem de Mensagens e Neurobiologia</a>
<ul>
<li class="chapter" data-level="5.1" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#introdução-4"><i class="fa fa-check"></i><b>5.1</b> Introdução</a></li>
<li class="chapter" data-level="5.2" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#microcircuitos-e-mensagens"><i class="fa fa-check"></i><b>5.2</b> Microcircuitos e Mensagens</a></li>
<li class="chapter" data-level="5.3" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#comandos-do-motor"><i class="fa fa-check"></i><b>5.3</b> Comandos do Motor</a></li>
<li class="chapter" data-level="5.4" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#estruturas-subcorticais"><i class="fa fa-check"></i><b>5.4</b> Estruturas Subcorticais</a></li>
<li class="chapter" data-level="5.5" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#neuromodulação-e-aprendizagem"><i class="fa fa-check"></i><b>5.5</b> Neuromodulação e Aprendizagem</a></li>
<li class="chapter" data-level="5.6" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#hierarquias-contínuas-e-discretas"><i class="fa fa-check"></i><b>5.6</b> Hierarquias Contínuas e Discretas</a></li>
<li class="chapter" data-level="5.7" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#resumo-4"><i class="fa fa-check"></i><b>5.7</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><i class="fa fa-check"></i><b>6</b> Uma receita para projetar modelos de inferência ativos</a>
<ul>
<li class="chapter" data-level="6.1" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#introdução-5"><i class="fa fa-check"></i><b>6.1</b> Introdução</a></li>
<li class="chapter" data-level="6.2" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#projetando-um-modelo-de-inferência-ativo-uma-receita-em-quatro-etapas"><i class="fa fa-check"></i><b>6.2</b> Projetando um modelo de inferência ativo: uma receita em quatro etapas</a></li>
<li class="chapter" data-level="6.3" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#que-sistema-estamos-modelando"><i class="fa fa-check"></i><b>6.3</b> Que sistema estamos modelando?</a></li>
<li class="chapter" data-level="6.4" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#qual-é-a-forma-mais-adequada-para-o-modelo-generativo"><i class="fa fa-check"></i><b>6.4</b> Qual é a forma mais adequada para o modelo generativo?</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#variáveis-discretas-ou-contínuas-ou-ambas"><i class="fa fa-check"></i><b>6.4.1</b> Variáveis Discretas ou Contínuas (ou Ambas)?</a></li>
<li class="chapter" data-level="6.4.2" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#escalas-de-tempo-de-inferência-modelos-rasos-versus-modelos-hierárquicos"><i class="fa fa-check"></i><b>6.4.2</b> Escalas de tempo de inferência: modelos rasos versus modelos hierárquicos</a></li>
<li class="chapter" data-level="6.4.3" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#profundidade-temporal-de-inferência-e-planejamento"><i class="fa fa-check"></i><b>6.4.3</b> Profundidade Temporal de Inferência e Planejamento</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#como-configurar-o-modelo-generativo"><i class="fa fa-check"></i><b>6.5</b> Como configurar o modelo generativo?</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#configurando-as-variáveis-do-modelo-gerador"><i class="fa fa-check"></i><b>6.5.1</b> Configurando as Variáveis do Modelo Gerador</a></li>
<li class="chapter" data-level="6.5.2" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#quais-partes-do-modelo-generativo-são-fixas-e-o-que-é-aprendido"><i class="fa fa-check"></i><b>6.5.2</b> Quais partes do modelo generativo são fixas e o que é aprendido?|</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#configurando-o-processo-gerador"><i class="fa fa-check"></i><b>6.6</b> Configurando o Processo Gerador</a></li>
<li class="chapter" data-level="6.7" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#simulando-visualizando-analisando-e-ajustando-dados-usando-inferência-ativa"><i class="fa fa-check"></i><b>6.7</b> Simulando, Visualizando, Analisando e Ajustando Dados Usando Inferência Ativa</a></li>
<li class="chapter" data-level="6.8" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#resumo-5"><i class="fa fa-check"></i><b>6.8</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html"><i class="fa fa-check"></i><b>7</b> Inferência ativa em tempo discreto</a>
<ul>
<li class="chapter" data-level="7.1" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#introdução-6"><i class="fa fa-check"></i><b>7.1</b> Introdução</a></li>
<li class="chapter" data-level="7.2" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#processamento-perceptivo"><i class="fa fa-check"></i><b>7.2</b> Processamento Perceptivo</a></li>
<li class="chapter" data-level="7.3" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#tomada-de-decisão-e-planejamento-como-inferência"><i class="fa fa-check"></i><b>7.3</b> Tomada de decisão e planejamento como inferência</a></li>
<li class="chapter" data-level="7.4" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#busca-de-informações"><i class="fa fa-check"></i><b>7.4</b> Busca de informações</a></li>
<li class="chapter" data-level="7.5" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#aprendizado-e-novidade"><i class="fa fa-check"></i><b>7.5</b> Aprendizado e Novidade</a></li>
</ul></li>
<li class="appendix"><span><b>Apêndice</b></span></li>
<li class="chapter" data-level="A" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html"><i class="fa fa-check"></i><b>A</b> Bases Matemáticas</a>
<ul>
<li class="chapter" data-level="A.1" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#introdução-7"><i class="fa fa-check"></i><b>A.1</b> Introdução</a></li>
<li class="chapter" data-level="A.2" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#álgebra-linear"><i class="fa fa-check"></i><b>A.2</b> Álgebra Linear</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#o-básico"><i class="fa fa-check"></i><b>A.2.1</b> O básico</a></li>
<li class="chapter" data-level="A.2.2" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#derivadas"><i class="fa fa-check"></i><b>A.2.2</b> Derivadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="as-equações-da-inferência-ativa.html"><a href="as-equações-da-inferência-ativa.html"><i class="fa fa-check"></i><b>B</b> As equações da inferência ativa</a></li>
<li class="chapter" data-level="" data-path="dicionário.html"><a href="dicionário.html"><i class="fa fa-check"></i>Dicionário</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Inferencia Ativa</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inferência-ativa-em-tempo-discreto-1" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">> 7</span> Inferência ativa em tempo discreto<a href="inferência-ativa-em-tempo-discreto-1.html#inferência-ativa-em-tempo-discreto-1" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>O que eu não posso criar, eu não entendo. — Richard Feynman</p>
<div id="introdução-6" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Introdução<a href="inferência-ativa-em-tempo-discreto-1.html#introdução-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Até agora, discutimos os princípios da Inferência Ativa em um nível relativamente abstrato. Este capítulo trata de exemplos específicos — e como eles podem ser especificados em um cenário prático. Focamos em modelos de variáveis categóricas em tempo discreto. Por meio de uma série de exemplos, construídos em complexidade, ilustramos modelos de processamento perceptual, tomada de decisão, busca de informações, aprendizado e inferência hierárquica. Esses exemplos são escolhidos para destacar as propriedades emergentes da forma mais simples possível – incluindo fisiologia e comportamento mensuráveis – dos esquemas de Inferência Ativa.</p>
</div>
<div id="processamento-perceptivo" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Processamento Perceptivo<a href="inferência-ativa-em-tempo-discreto-1.html#processamento-perceptivo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Começamos considerando o processamento perceptual e a inversão do tipo de modelos de tempo discreto introduzidos no capítulo 4. Mais adiante neste capítulo, construímos um processo de decisão Markov parcialmente observável completo (POMDP). No entanto, começamos com um caso especial de um POMDP no qual podemos ignorar escolhas e comportamento: um modelo oculto de Markov (HMM), que pode ser usado para inferência perceptual de uma classificação sequencial e categórica (veja a figura 7.1). Para motivar isso, vamos recorrer a um exemplo simples. Imagine ouvir uma apresentação de uma pequena peça de música. A sequência de notas que são escritas na partitura pode ser pensada como estados ocultos (não observados), enquanto a sequência de notas que realmente ouvimos são os resultados (observáveis). Se o intérprete é um músico profissional, a correspondência entre os estados ocultos e os resultados pode ser muito próxima. No entanto, se for um amador, pode haver um grau adicional de estocasticidade no mapeamento (de probabilidade) da nota que deve ser tocada para a que é ouvida. Nesse cenário, ainda pode ser possível inferir qual nota deveria ter sido ouvida, dadas as crenças prévias sobre a probabilidade de cada nota ser precedida ou sucedida por outra.</p>
<div class="figure">
<img src="images/Figura_7_1.png" alt="" />
<p class="caption"><strong>Figura 7.1</strong> Este modelo oculto de Markov usa a mesma notação introduzida no capítulo 4 para expressar uma sequência de estados que evoluem ao longo do tempo. A cada vez, eles dão origem a um resultado observável (o). O estado em um momento depende apenas do estado no momento anterior (com essa dependência expressa em B). O primeiro estado na sequência tem probabilidade anterior D. A geração de resultados dos estados depende da distribuição de verossimilhança (A). Esta especificação de um HMM é genérica, com modelos generativos específicos dependendo de escolhas específicas para A, B e D.</p>
</div>
<p>O exemplo de escuta do músico amador pode ser formalizado da seguinte forma. Primeiro, decidimos com que confiabilidade nosso músico realmente toca a nota (resultado) que ela pretende (estado oculto). Podemos expressar isso através da matriz A, cujos elementos indicam a probabilidade de um resultado (linhas) dado um estado (colunas). Em nosso exemplo de brinquedo, definimos isso da seguinte forma:</p>
<p><span class="math display">\[ A = \frac{1}{10}\begin{bmatrix}
7 &amp; 1 &amp; 1 &amp; 1  \\
1 &amp; 7 &amp; 1 &amp; 1  \\
1 &amp; 1 &amp; 7 &amp; 1  \\
1 &amp; 1 &amp; 1 &amp; 7  \\
\end{bmatrix} \qquad\qquad\qquad (7.1) \]</span></p>
<p>Isso diz que 70% das vezes, nosso músico atinge a nota pretendida. Em seguida, especificamos as probabilidades de transição na matriz B, que explicam a probabilidade do próximo estado (linhas) dado o estado atual (colunas)</p>
<p><span class="math display">\[ B = \frac{1}{100}\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 97  \\
97 &amp; 1 &amp; 1 &amp; 1  \\
1 &amp; 97 &amp; 7 &amp; 1  \\
1 &amp; 1 &amp; 97 &amp; 1  \\
\end{bmatrix} \qquad\qquad\qquad (7.2) \]</span></p>
<p>Isso diz que há uma probabilidade de 97% de a primeira nota ser seguida pela segunda, a segunda pela terceira e assim por diante. Se sabemos que a sequência sempre começa com a primeira nota, definimos a probabilidade anterior:</p>
<p><span class="math display">\[ D = \begin{bmatrix}
1  \\
0 \\
0 \\
0 \\
\end{bmatrix} \qquad\qquad\qquad (7.3) \]</span></p>
<p>Juntas, as equações 7.1–7.3 especificam completamente o modelo generativo HMM mostrado na figura 7.1. Em outras palavras, eles fornecem uma descrição de nossas crenças sobre como a música que ouvimos é gerada por nosso músico amador. Usando a equação 4.12 e substituindo em nosso modelo generativo, podemos simular a dinâmica da atualização da crença Bayesiana induzida por uma sequência de resultados. Isso é mostrado na figura 7.2. Observe o aumento na confiança mostrado no gráfico superior esquerdo à medida que mais dados são acumulados ao longo do tempo, exceto para o terceiro passo de tempo, onde ocorreu um resultado inesperado. Esse resultado pode ser explicado de duas maneiras. Primeiro, pode ser que a nota pretendida realmente fosse uma nota incomum sob nossas crenças anteriores na equação 7.2. Isso é menos provável pela raridade de tais transições sob a matriz B deste modelo. A explicação alternativa, mais plausível, é que o músico tocou a nota errada por engano. Conforme mostrado na terceira coluna do gráfico superior direito, esta é a explicação que nosso ouvinte simulado estabelece. No entanto, uma probabilidade diferente de zero é atribuída à possibilidade de que, afinal, fosse a nota certa. A capacidade de relatar esse tipo de incerteza é uma característica fundamental da perspectiva Bayesiana proporcionada pela Inferência Ativa.</p>
<p>O modelo mostrado aqui pode ser mais sofisticado de várias maneiras, mas talvez o mais simples dependa da fatoração do espaço de estados (Mirza et al. 2016). Um exemplo pode ser o tom e a dinâmica da nota (com uma distinção semelhante nos resultados). Em uma tarefa de inferência visual, a fatoração pode ser em quê e onde, o que tem muito valor na neurobiologia (Ungerleider e Haxby 1994). Nas seções subsequentes, apelaremos a esse tipo de fatoração para separar os estados que podem ser influenciados pela criatura em questão daqueles que não podem. Para ler mais sobre esse tipo de modelo (sem ações em jogo) e os tipos de esquema de transmissão de mensagens neuronais que podem ser usados para invertê-lo minimizando a energia livre, veja Parr, Markovic et al. (2019).</p>
<div class="figure">
<img src="images/Figura_7_2.png" alt="" />
<p class="caption">Figura 7.2 Esses gráficos de inferência perceptiva simulados ilustram o processo de atualização de crenças em um exemplo de tentativa baseado no modelo generativo descrito no texto principal. Superior esquerdo: Crenças (probabilidades posteriores) sobre cada nota na sequência em cada passo de tempo. Superior direito: Como os valores numéricos dessas crenças são difíceis de rastrear as crenças no final da sequência, tendo ouvido cada nota (ou seja, crenças retrospectivas) são mostradas. Cada coluna mostra crenças (retrospectivas) sobre os estados ocultos em um determinado intervalo de tempo. Cada linha representa uma hipótese alternativa para esse estado oculto. Quanto mais escuro o sombreamento, mais provável é que a nota tenha sido (com o preto indicando uma probabilidade de um e o branco uma probabilidade de zero). Inferior esquerdo: gradientes de energia livre (negativos) (ou seja, erros de previsão) ao longo do tempo. A taxa de mudança das crenças no gráfico superior esquerdo é determinada pelo valor desses erros em cada passo de tempo. Inferior direito: Sequência de notas musicais apresentadas ao nosso agente sintético (ou seja, as observações que ele recebe durante os passos de tempo 1 a 5). Observe que enquanto no terceiro passo de tempo (o3) o ouvinte ouviu a segunda nota (terceira coluna do gráfico inferior direito), ele infere a terceira nota com maior probabilidade (terceira coluna do gráfico superior direito).</p>
</div>
</div>
<div id="tomada-de-decisão-e-planejamento-como-inferência" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Tomada de decisão e planejamento como inferência<a href="inferência-ativa-em-tempo-discreto-1.html#tomada-de-decisão-e-planejamento-como-inferência" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>O HMM usado acima ilustra uma forma muito simples de inferência categórica baseada em uma sequência de resultados. No entanto, o tipo de criatura (séssil) que isso descreve é bastante desinteressante. Criaturas autônomas são claramente mais do que recipientes passivos de dados sensoriais. Em vez disso, eles mudam ativamente seu ambiente e se envolvem em uma troca bidirecional com seu sensório. Isso fala da importância de converter um HMM em um POMDP, pelo qual devemos inferir não apenas como nosso ambiente está mudando, mas também como nosso curso de ação escolhido o altera e qual curso de ação escolher.</p>
<p>A Figura 7.3 mostra um modelo generativo do POMDP. Isso é o mesmo que foi apresentado no capítulo 4, onde os detalhes da inferência nesse tipo de modelo são descompactados. Observe a semelhança dessa estrutura com o HMM na figura 7.1 e a adição de uma variável extra (π ), na qual estão condicionadas as probabilidades de transição (B). Isso significa que podemos considerar hipóteses alternativas sobre a dinâmica dos estados. Essas hipóteses podem ser interpretadas como planos entre os quais uma criatura pode selecionar. Essa perspectiva equipara avaliação de políticas com comparação de modelos e diz que uma política é simplesmente uma explicação
variável para uma sequência observada de sensações (autogeradas).</p>
<div class="figure">
<img src="images/Figura_7_3.png" alt="" />
<p class="caption">Figura 7.3 POMDP da figura 4.3, descompactando as distribuições de probabilidade em termos de fatores de estado ocultos e modalidades de resultado. (A Figura 7.1 é um caso especial dessa estrutura.) Três pontos a serem observados: Primeiro, a fatoração dos estados ocultos agora significa que a distribuição codificada por A tem (potencialmente) muitos fatores de estado em seu conjunto de condicionamento e não pode mais ser codificada por uma matriz. Em vez disso, isso se torna um objeto tensor, no qual cada índice corresponde a um fator de estado. Em segundo lugar, a separação dos resultados em diferentes modalidades significa que haverá um tensor A separado para cada modalidade. Terceiro, enquanto C e E aparecem no painel à direita, eles não aparecem no gráfico de fatores à esquerda porque só entram no modelo generativo por meio de crenças anteriores sobre políticas. Para uma perspectiva alternativa sobre isso, ver Parr e Friston (2018d) e van de Laar e de Vries (2019).</p>
</div>
<p>O modelo da figura 7.3 difere sutilmente daquele apresentado no capítulo 4: ele permite a fatoração de estados (sobrescrito n) e de resultados (sobrescrito m). A utilidade disso é óbvia quando consideramos a fatoração do mundo visual em onde um objeto está e o que é. Claramente, seria extremamente ineficiente (e incorreria em um alto custo de complexidade) para representar todas as combinações possíveis de localização e identidade, quando a identidade é (normalmente) invariável à localização e vice-versa. Um argumento semelhante pode ser usado para fatoração de tempo de identidade e localização (Friston e Buzsaki 2016). O benefício de introduzir essa fatoração neste estágio é que podemos separar os estados do mundo sobre os quais uma criatura tem controle daqueles que ela não tem. Embora as probabilidades de transição que governam a primeira sejam diferentes em cada política, a segunda será invariável a isso.</p>
<p>Com essas preliminares em vigor, agora esboçamos um exemplo simples de uma tarefa (Friston, FitzGerald et al. 2017) que requer planejamento e ilustra alguns dos principais aspectos da inferência ativa usando POMDPs. Isso envolve um rato em um labirinto em T contendo um estímulo aversivo em um braço, um estímulo atraente em outro e uma pista que indica a localização dos dois estímulos no braço final. Essa configuração significa que o rato pode se comportar de duas maneiras (amplamente). Ele poderia optar por ir direto para um dos dois braços que poderiam conter o estímulo atrativo, arriscando o estímulo aversivo. Alternativamente, ele pode optar por buscar a dica informativa e, em seguida, ir para o braço com maior probabilidade de conter o estímulo atraente.</p>
<p>Essa escolha remete ao clássico dilema prospecção-aproveitamento em psicologia: um dilema que é resolvido sob a Inferência Ativa. A resolução decorre da minimização da energia livre esperada exigida por crenças anteriores sobre políticas. Para revisar isso brevemente (veja o capítulo 4 para detalhes), as políticas mais prováveis (para uma criatura que minimiza sua energia livre variacional) são aquelas que levam à menor energia livre esperada. A energia livre esperada tem a seguinte forma:</p>
<p><span class="math display">\[G(\pi) =
\begin{matrix} \underbrace {\mathbb E_{Q(\tilde s | \pi)}[H[P(\tilde o| \tilde s)]]-H[Q(\tilde o|\pi)]]} \\ Valor\;epistêmico\;negativo\;(−\mathcal I(\pi)) \end{matrix} -
\begin{matrix}\underbrace {\mathbb E_{Q(\tilde s | \pi)}[\ln P(\tilde o | C)] } \\ Valor\;Pragmático  \end{matrix}\qquad (7.4)\]</span>
Essa decomposição da energia livre esperada em valor epistêmico e pragmático destaca o impulso (epistêmico) para a coleta de informações e o impulso (pragmático) para a realização de crenças anteriores (C na figura 7.3).</p>
<p>Tentaremos fornecer uma intuição mais profunda para o valor epistêmico na próxima seção, mas pode ser pensado simplesmente como a quantidade de informação que podemos obter sob uma política específica. A forma do valor pragmático trata efetivamente a probabilidade de resultados, calculada a média de todas as políticas, como se fosse um . Para colocar isso em termos mais intuitivos, se considerarmos um certo tipo. Ao fazê-lo, aquelas políticas com consequências consistentes com este prévio tornam-se mais prováveis, pois estão associadas a menor energia livre de observação esperada para serem muito prováveis, agiremos para cumprir nossa crença de que as encontraremos. Portanto, a probabilidade logarítmica dos resultados pode ser considerada equivalente a uma função de utilidade em outros formalismos, como teoria de controle ótimo e aprendizado por reforço. O fato de que a utilidade e o valor da informação emergem como dois componentes da energia livre esperada significa que não precisamos nos preocupar em equilibrar exploração e exploração. Ambos estão a serviço de otimizar a mesma função.</p>
<div class="figure">
<img src="images/Figura_7_4.png" alt="" />
<p class="caption">Figura 7.4 Probabilidade no contexto 1. Esquerda: configuração do labirinto em T de pistas e estímulos: o estímulo atrativo está à direita e o estímulo aversivo está à esquerda. Direita: Probabilidade ou modelo de observação especifica o mapeamento probabilístico da localização para pistas exteroceptivas (A1) e para pistas interoceptivas (A2). Cada elemento dessas matrizes é a probabilidade do resultado ilustrado no final da linha, condicionado ao contexto ser um e estar no local indicado pela linha. Os resultados exteroceptivos são entradas visuais ou proprioceptivas associadas a cada local, em que a localização do sinal pode dar origem a um sinal para a direita ou para a esquerda. Os resultados interoceptivos são ausentes (círculo com contorno pontilhado), atrativos (círculo preenchido) ou aversivos (círculo não preenchido).</p>
</div>
<p>Para ver como isso se desenrola no exemplo do labirinto em T, precisamos formalizar o modelo generativo da mesma forma que no HMM acima. As Figuras 7.4–7.6 ilustram as probabilidades de verossimilhança e de transição que compõem o modelo generativo para o labirinto em T. Examinaremos isso com alguns detalhes, pois este exemplo mínimo fornece os blocos de construção a partir dos quais os leitores podem construir seus próprios modelos generativos. A primeira coisa a fazer é decidir sobre o número de modalidades de resultados que representam os dados (sensoriais) que nosso modelo deve explicar. Isso nos diz o número de matrizes A que devemos especificar. Aqui, temos duas modalidades que representam dados exteroceptivos referentes a onde o rato está no labirinto (A1) e qual modalidade pode ser os dados interoceptivos que o rato experimenta quando encontra o estímulo atraente (comestível) (A2). Os níveis nessas modalidades (ou seja, as observações alternativas que podem ser feitas em cada uma) determinam as linhas de cada matriz A. A próxima decisão é o número de fatores de estado ocultos que podem ser usados ​​para explicar esses dados; este é o número de matrizes B que precisamos. Consideramos dois fatores aqui: a posição do rato no labirinto e o contexto (estímulo atrativo à esquerda ou à direita). Estes têm quatro e dois níveis, respectivamente. Agora devemos especificar, para cada combinação de estados ocultos, a probabilidade de cada resultado. O contexto 1 é mostrado na figura 7.4; o contexto 2 é mostrado na figura 7.5.</p>
<div class="figure">
<img src="images/Figura_7_5.png" alt="" />
<p class="caption">Figura 7.5 Probabilidade no contexto 2. Quase idêntica à figura 7.4 — neste contexto, os estímulos aversivos e atrativos foram trocados. Isso se reflete na probabilidade dos resultados exteroceptivos na localização da pista e nas probabilidades dos resultados interoceptivos nos braços direito e esquerdo do labirinto.</p>
</div>
<p>Para a primeira modalidade, nosso A1 associa cada local a um resultado com probabilidade um. A localização do “cue”(?) pode estar associada a um “cue”(?) esquerdo ou direito, dependendo do contexto. A modalidade interoceptiva (A2) associa um resultado neutro com os locais de início e “sugestão”(?) e uma chance de 98 por cento de encontrar o resultado atraente quando o contexto corresponde ao braço do labirinto em que o rato entrou. Tecnicamente, essas matrizes A são quantidades de tensores, porque seus elementos são especificados por três números (resultado, localização e contexto), enquanto uma matriz é especificada apenas por dois (linha e coluna).</p>
<p>Em seguida, precisamos especificar as probabilidades de transição. As matrizes B especificam a probabilidade de transição de um estado (coluna) para outro estado (linha), dependendo da escolha da política (π ). Estes especificam as transições referentes à posição do rato no labirinto (B1) e as transições no contexto (B2). A Figura 7.6 mostra as transições B1 controláveis. Cada matriz mostra as probabilidades sob uma escolha de ação diferente (subscrito). Estes permitem um movimento de qualquer local para qualquer outro local, exceto dos dois braços do labirinto, que são estados absorventes. Isso significa que, uma vez lá, o rato deve permanecer lá, independentemente das ações que escolher. Em contraste, o rato não tem controle sobre o contexto (ou seja, se está no contexto 1, mostrado na figura 7.4, ou no contexto 2, mostrado na figura 7.5). O contexto permanece constante ao longo do tempo e pode ser representado como uma matriz de identidade:</p>
<p><span class="math display">\[ B^2_\pi = \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix} \qquad (7.5)\]</span>
Aqui cada coluna (e linha) refere-se a um estado indexando a figura 7.4 ou a figura 7.5. Isso significa que qualquer contexto em que começamos permanece constante (transições para si mesmo ) ao longo do tempo. Isso é verdade independentemente da política selecionada. O vetor C1 mostra preferências anteriores para cada um dos resultados nesta modalidade, com preferências uniformes, exceto por uma leve aversão (−1) ao local de início.</p>
<div class="figure">
<img src="images/Figura_7_6.png" alt="" />
<p class="caption"><strong>Figura 7.6</strong> Probabilidades de transição controláveis para movimentação entre os diferentes locais. Cada uma das quatro matrizes corresponde a uma ação alternativa que o rato pode escolher. Estes permitem uma mudança de qualquer estado (exceto o braço direito e esquerdo) para qualquer outro estado. Os braços direito e esquerdo são estados absorventes, nos quais o rato deve permanecer uma vez inserido.</p>
</div>
<p>O vetor C2 especifica preferências (+6) para o estímulo atrativo e aversão (-6) para o estímulo aversivo. A ausência de qualquer um é considerada neutra (0).</p>
<p><span class="math display">\[ \begin{equation}
C^1 = \sigma([-1,0,0,0,0]^T) \qquad\qquad\qquad\\
C^2 = \sigma([0,6,-6]^T)
\end{equation} \qquad\qquad\qquad (7.6) \]</span>
A ordem dos elementos nesses vetores corresponde à ordem das linhas nas matrizes A correspondentes. A função softmax (σ ) permite especificar preferências em termos de valores positivos e negativos (correspondentes a probabilidades logarítmicas não normalizadas), que são então convertidas em probabilidades. Isso preserva a diferença nas probabilidades de log (ou a probabilidade relativa) enquanto garante a normalização. Praticamente, esta formulação significa que o estímulo atrativo é considerado e6 (≈ 400) vezes mais provável que o estímulo neutro no modelo generativo do rato. Esta é uma preferência muito forte que significa que o rato acredita que suas ações são muito mais propensas a levar ao resultado atraente. Essa restrição à inferência sobre a ação é crucial para o comportamento que se segue. Finalmente, os vetores D especificam as probabilidades anteriores para os estados iniciais:</p>
<p><span class="math display">\[ \begin{equation}
D^1 = [1,0,0,0,0]^T \qquad\qquad\qquad\\
D^2 =\frac{1}{2}[1,1]^T
\end{equation} \qquad\qquad\qquad (7.7) \]</span></p>
<p>A ordem dos elementos nestes vetores coincide com a das matrizes B. O vetor D1 indica uma crença confiante em começar no centro do labirinto. O vetor D2 indica que os dois contextos (figura 7.4 ou 7.5) são considerados igualmente prováveis no início.</p>
<p>A Figura 7.7 mostra o que acontece quando invertemos o modelo generativo das figuras 7.4–7.6. A linha superior ilustra o que veríamos se observássemos o comportamento do rato. Começa no centro e depois vai para a dica informativa. Isso se deve ao alto valor epistêmico associado a esse local (ou seja, as observações feitas nesse local têm o potencial de resolver a incerteza sobre o contexto). Ao ver a pista que indica um contexto à esquerda (contexto 1), o rato escolhe o braço esquerdo do labirinto e encontra o estímulo recompensador. Este movimento é impulsionado pelo alto valor pragmático atribuído a este local. Os gráficos inferiores ilustram a atualização de crenças que ocorre durante este teste simples. Como na figura 7.2, isso é mostrado na forma que poderíamos esperar observar em um rato idealizado se estivéssemos medindo a atividade neuronal (ou seja, taxas de disparo e potenciais de campo locais [LFPs]). Observe a rápida mudança nas crenças no segundo passo de tempo, quando o rato atinge o local da dica informativa e a LFP associada (linha tracejada).</p>
<div class="figure">
<img src="images/Figura_7_7.png" alt="" />
<p class="caption"><strong>Figura 7.7</strong> Comportamento epistêmico e pragmático simulado de um rato forrageando em um labirinto em T. O rato começa no local central, mas depois escolhe amostrar a sugestão informativa no braço inferior do labirinto. Esta localização está associada ao maior valor epistêmico, pois observar a deixa neste local revela o contexto (recompensa direita ou esquerda) em que o rato se encontra. LFP (ε ). Sem mais incertezas para resolver, o rato seleciona a opção pragmaticamente valiosa e vai para o braço esquerdo do labirinto. Os dois gráficos à direita mostram as crenças mantidas pelo rato no final da tentativa sobre todos os tempos anteriores (ou seja, são crenças retrospectivas e não as crenças do rato no momento da decisão). Ele acredita (corretamente) que começou no local central, foi para o braço do taco e depois foi para o braço esquerdo. Para o fator de estado oculto do contexto, o rato acredita que o contexto foi o contexto da esquerda por toda parte.</p>
</div>
</div>
<div id="busca-de-informações" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Busca de informações<a href="inferência-ativa-em-tempo-discreto-1.html#busca-de-informações" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A simulação na seção 7.2 ilustra um exemplo simples de um trade-off prospecção-aproveitamento, que é resolvido pela busca de informações até que a incerteza seja resolvida, então explorando o que foi inferido para atender às preferências anteriores. Nesta seção, descompactamos o conceito de valor epistêmico com mais detalhes. Como vimos na equação 7.4, isso compreende dois termos:</p>
<p>$$
<span class="math display">\[\begin{equation}
\begin{matrix} \underbrace{\mathcal I(\pi)} \\ valor\;epistêmico\end{matrix}
= \begin{matrix} \underbrace{H(Q(\tilde o|\pi))} \\ entropia\;preditiva\;posterior \end{matrix}
- \begin{matrix} \underbrace{E_{Q(\tilde s|\pi)}[H[P(\tilde o| \tilde s)]]} \\ ambiguidade\;esperada\end{matrix} \\
= \begin{matrix} \underbrace{D_{KL}[P(\tilde o | \tilde s)Q(\tilde o | \tilde \pi) || Q(\tilde o | \tilde \pi) Q(\tilde s | \tilde \pi)]} \\ informação\;mútua \end{matrix} \qquad\qquad\qquad (7.8) \\
= \begin{matrix} \underbrace{E_{Q(\tilde o | \tilde \pi)}[D_{KL}][Q(\tilde s |\pi, \tilde o) || Q(\tilde s | \pi)]} ; Q(\tilde s|\pi, \tilde o) \triangleq \frac{P(\tilde o| \tilde s)Q(\tilde s | \pi)}{Q(\tilde o | \pi)} \\ ganho\;de\;informação,\;saliência,\;surpresa\;Bayesiana \end{matrix}  \\

\end{equation}\]</span>
$$
Estas são a entropia preditiva posterior e a ambiguidade esperada, respectivamente. Abaixo destes, destacamos a correspondência entre estes e outros rearranjos. Para descompactá-los de forma intuitiva, vamos enquadrar isso em termos de um paradigma visual, onde sacadas alternativas (π ) levam a diferentes transições entre locais de fixação (s). Além dos locais de fixação, os estados ocultos incluem a identidade de um estímulo em cada local. Uma combinação de estímulo e fixação gera consequências visuais e proprioceptivas (o). Com isso em mente, podemos interpretar a entropia preditiva posterior como a dispersão (ou incerteza) associada ao “o que eu veria se realizasse esse movimento ocular”. Do ponto de vista de um cientista, isso quantifica o quão incertos podemos estar sobre os dados que obteríamos ao realizar um determinado experimento. Sob essa perspectiva, faz sentido selecionarmos as sacadas (ou experimentos) que estão associadas à maior entropia preditiva posterior, pois oferecem o maior potencial de resolução de incertezas. Não ganharíamos nada realizando um experimento se já soubéssemos quais seriam os resultados com um alto grau de confiança.</p>
<p>No entanto, a entropia preditiva apenas nos diz a quantidade total de incerteza. Não nos diz quanta incerteza é realmente solucionável. Sempre estaremos incertos sobre o próximo número em uma sequência de números gerados aleatoriamente, mas nunca resolveremos nossa incerteza sobre o processo que os gerou fixando neles. É aí que entra a ambiguidade esperada. Isso quantifica o grau em que as observações e os estados são independentes um do outro. Se os estados sempre gerarem a mesma observação, essa quantidade será zero. Será máximo se, como no gerador de números aleatórios, não houver associação entre estados e resultados. No domínio visual, isso implica que a melhor sacada será aquela em direção a um estímulo bem iluminado, onde há pouca ambiguidade sobre “o que eu veria se olhasse para esse estímulo”. Tomados em conjunto, isso diz que as melhores sacadas (ou seja, experimentos perceptivos) são aquelas para as quais há a maior incerteza para resolver (entropia preditiva posterior), mas somente se essa incerteza puder ser resolvida (ambiguidade negativa). Curiosamente, isso tem exatamente a mesma forma que as expressões desenvolvidas em estatística para pontuar o projeto experimental em termos de ganho de informação (Lindley 1956).</p>
<p>A Figura 7.9 ilustra o que acontece em um paradigma sacádico (Parr e Friston 2017b) quando simulamos manipulações para a ambiguidade e entropia preditiva posterior. Isso mostra quatro estímulos (quadrados), cada um dos quais pode mudar de cor a cada momento. Sobreposto a estes está um traço de rastreamento ocular simulado, como se estivéssemos medindo para onde um participante experimental estava olhando. Crucialmente, especificamos crenças anteriores sobre resultados como uniformes (ou seja, valor pragmático a ser ausente), impedindo quaisquer escolhas baseadas em preferências. Isso significa que cada sacada é selecionada para maximizar o valor epistêmico. Quando o modelo generativo trata todos os quatro estímulos como equivalentes (imagem da esquerda), todos são amostrados com aproximadamente a mesma frequência. No entanto, podemos modular a incerteza associada a cada estímulo (ver caixa 7.1). Se definirmos um estímulo para ter uma ambiguidade maior (aumentando o valor dos elementos fora da diagonal da matriz A correspondente), esse quadrado será ignorado (imagem do meio). Este é um exemplo do famoso efeito “streetlight” (Demirdjian et al. 2005), que leva o nome da metáfora de pessoas que perderam suas chaves tarde da noite. O primeiro lugar que eles podem procurar é sob a luz da rua - não porque as chaves provavelmente estejam lá, mas porque é o melhor lugar para encontrar informações de alta qualidade, inequívocas e que resolvem incertezas. A simulação mostra como a praça ambígua (por exemplo, mal iluminada) é ignorada, reproduzindo um efeito “streetlight” in silico.</p>
<p>Em contraste, a imagem da direita na Figura 7.8 mostra o que acontece quando tornamos as transições menos previsíveis para o quadrado inferior esquerdo. Acumulamos incerteza sobre esta localização muito rapidamente, garantindo uma alta entropia preditiva posterior sem alteração da ambiguidade. Como podemos ver, isso leva a uma fixação mais frequente nesse local, pois sempre há novas incertezas a serem resolvidas aqui. Intuitivamente, se eu sei que algo tem uma dinâmica muito previsível, não preciso olhar para ele com muita frequência para ter certeza de seu estado. Por outro lado, se algo pode ter mudado no tempo em que estive olhando para outra coisa, vale a pena olhar para trás para verificar. Essas simulações são projetadas para oferecer uma intuição para as duas partes do valor epistêmico, para ver como a minimização da energia livre esperada garante que selecionemos ativamente nossos dados sensoriais para descobrir o mundo.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Quadro 7.1 Incerteza e precisão</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>O exemplo da Figura 7.7 apela ao conceito de precisão – uma ideia importante neste livro. A precisão é o inverso da variância e pontua nossa confiança em uma determinada distribuição de probabilidade. Isso está intimamente relacionado à entropia negativa (negentropia) de uma distribuição:<span class="math display">\[ -H[P(s)]=\mathbb E_{P(x)}[\ln P(s)]\]</span>Uma maneira simples de parametrizar uma distribuição de forma que ela possa ser mais ou menos precisa é usar uma forma de Gibbs com um parâmetro de temperatura inverso (<span class="math inline">\(omega\)</span>) tem a seguinte forma: <span class="math display">\[ P(s |\omega )=Cat(\sigma(\omega\ln D))\]</span>Observe que a precisão multiplica o log anterior, para que possa ser interpretado como um dispositivo de controle de ganho (amplificador em vez de adicionar sinais neurais). Os gráficos na figura 7.8 mostram como a distribuição de probabilidade (cada coluna representando a probabilidade de um estado alternativo) muda para um dado D quando variamos ω. Observe o aumento da confiança com o aumento da precisão.<img src="images/Figura_7_8.png" alt="Figura 7.8" />Este tipo de parametrização pode ser aplicado a qualquer uma das distribuições utilizadas em um POMDP. Além disso, podemos definir a priori sobre a precisão e inferir isso da mesma forma que inferimos outras variáveis latentes (ou seja, através da minimização da energia livre). Supondo que o prior tenha uma distribuição Gamma (excluindo valores negativos da precisão), obtemos as seguintes atualizações (consulte o apêndice B para obter detalhes):<span class="math display">\[P(\omega)=\ \Gamma(1,\beta_\omega)\]</span><span class="math display">\[Q(\omega)=\Gamma(1,\beta_\omega)\]</span><span class="math display">\[\Longrightarrow\dot\beta_\omega=(D^{\beta_\omega^{-1}}-s)\cdot\ln D+\beta_w-{\beta_w}\]</span>Há um crescente reconhecimento de que o substrato biológico desses parâmetros de precisão podem ser os sistemas neuromoduladores que determinam o ganho das respostas neurais. O Capítulo 5 discute as evidências que relacionam esses parâmetros a neuroquímicos específicos.</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="images/Figura_7_9.png" alt="" />
<p class="caption">Figura 7.9 Paradigma de busca visual epistêmica simulada (Parr e Friston 2017b) com o traço sintético de rastreamento ocular sobreposto aos quatro locais de estímulo. Cada estímulo (quadrado sombreado) está associado a uma matriz de transição que pode ser mais ou menos previsível e uma matriz de probabilidade que pode ser mais ou menos ambígua. Esquerda: Quando as transições e probabilidades são igualmente previsíveis para todas as quatro localizações, todas as localizações são amostradas com aproximadamente a mesma frequência. Meio: O visualizador mostra aversão ao quadrado superior esquerdo quando é especificado com um mapeamento de probabilidade menos preciso (mais ambíguo). Direita: O quadrado inferior esquerdo é epistemicamente atraente quando as probabilidades de transição são especificadas como mais incertas.</p>
</div>
</div>
<div id="aprendizado-e-novidade" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Aprendizado e Novidade<a href="inferência-ativa-em-tempo-discreto-1.html#aprendizado-e-novidade" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As seções 7.2–7.4 estabelecem tudo o que é necessário para a maioria das aplicações práticas da Inferência Ativa. No entanto, assumimos que o modelo generativo já é conhecido e não muda como efeito da aprendizagem. Em algumas aplicações práticas, podemos querer considerar como uma ou mais partes do modelo generativo (por exemplo, a matriz A ou B) são aprendidas durante um experimento ou, mais amplamente, como otimizamos a estrutura do próprio modelo generativo , dados alguns dados (Friston, FitzGerald et al. 2016). Ao fazer isso, a Inferência Ativa se estende ao aprendizado ativo, e a saliência (equação 7.5) que descreve o ganho de informação sobre os estados é complementada pela novidade, que trata da resolução da incerteza sobre (por exemplo) os elementos da matriz A mostrada na equação 7.1, a matriz B mostrada na equação 7.2, ou quaisquer outros parâmetros do modelo generativo. Essas crenças agora podem variar com o tempo, em vez de serem fixas, como se supunha até agora (Schwartenbeck et al. 2019). Para chegar a isso, primeiro temos que estender o modelo generativo como na Figura 7.10 para incluir crenças sobre esses parâmetros do modelo.</p>
<div class="figure">
<img src="images/Figura_7_10.png" alt="" />
<p class="caption"><strong>Figura 7.10</strong> Esse modelo generativo para aprendizado usa a mesma estrutura POMDP da figura 7.3, mas as prioridades para cada um dos estados ocultos agora dependem de variáveis ​​(em círculos), que agora vêm equipadas com crenças anteriores. Estas têm a forma de distribuições de Dirichlet, que são conjugadas (ver quadro 7.2) às distribuições categóricas consideradas até agora. O modelo mostra como a probabilidade de resultados dados estados agora também depende de uma variável A (que é a mesma para todos os pontos de tempo), as probabilidades de transição agora estão condicionadas a uma variável B, as preferências dependem de C, os estados iniciais dependem em D, e a política de forma fixa a priori depende de E. Ao tornar explícitas as crenças prévias sobre os parâmetros do modelo generativo, essa figura enfatiza que tanto a inferência quanto o aprendizado são processos de minimização de energia livre, mas são distintos. Em suma, a inferência descreve a otimização de crenças sobre o estado do mundo como ele é (s), incluindo crenças sobre a maneira como estamos agindo (π ). Em contraste, a aprendizagem descreve a otimização de crenças sobre as relações entre essas variáveis ​​(A,  B,  C,  D ou E ). As últimas variam muito mais lentamente que as primeiras e só podem ser aprendidas quando os estados foram inferidos. Voltaremos a essa separação de escalas de tempo abaixo quando considerarmos os modelos generativos hierárquicos.</p>
</div>
<p>Conceitualmente, incluir crenças sobre parâmetros no modelo generativo permite tratar a aprendizagem como outra forma de inferência Bayesiana – ou seja, como a passagem de crenças anteriores para posteriores sobre parâmetros do modelo. Isso destaca a semelhança fundamental entre percepção e aprendizado: da mesma forma que a percepção pode ser descrita como a inversão de um modelo generativo para inferir estados ocultos a partir de observações, o aprendizado pode ser descrito como a inversão de um modelo generativo para incluir crenças sobre parâmetros ( embora normalmente esta inversão possa operar em uma escala de tempo mais lenta).</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Quadro 7.2 Antecedentes do Conjugado</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Ao configurar um modelo generativo da forma da figura 7.10, é importante selecionar cuidadosamente a distribuição apropriada para crenças anteriores. Normalmente, esta será a distribuição anterior conjugada associada à probabilidade. Uma crença prévia conjugada significa que, quando usada para realizar inferência Bayesiana, a crença posterior será do mesmo tipo de distribuição. Por exemplo, usando a regra de Bayes:<span class="math inline">\(P(D|s)\propto P(D) P(s|D)\)</span> Se <span class="math inline">\(P(s|D)\)</span> é uma distribuição categórica, quando escolhemos uma distribuição de Dirichlet (conjugada para categórica ) para <span class="math inline">\(P(D)\)</span>, podemos garantir que <span class="math inline">\(P(D|s)\)</span> também é uma distribuição de Dirichlet. Colocando formalmente:<span class="math inline">\(\begin{matrix}P(D)=Dir(d) \\ P(s|D)=Cat(D)\end{matrix}\bigg \}\Rightarrow P(D|s) = Dir(d)\)</span></td>
</tr>
</tbody>
</table>
<p>A maneira mais simples de escolher o tipo certo de a priori é procurar a priori conjugada para qualquer forma que a distribuição de verossimilhança assuma. Para as distribuições categóricas usadas aqui, uma distribuição de Dirichlet é a escolha apropriada para crenças sobre parâmetros (ver caixa 7.2). Tendo incluído essas crenças anteriores adicionais, podemos agora otimizar as crenças posteriores sobre a estrutura do modelo generativo. Isso significa incorporá-los à energia livre (como fizemos para os estados no capítulo 4) e encontrar os mínimos de energia livre.</p>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bases-matemáticas.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Inferencia Ativa.pdf", "Inferencia Ativa.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
