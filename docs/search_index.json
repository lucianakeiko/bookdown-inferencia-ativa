[["inferência-ativa-em-tempo-contínuo-1.html", "> 8 Inferência ativa em tempo contínuo 8.1 Introdução 8.2 Controles de movimento 8.3 Sistemas Dinâmicos 8.4 Sincronia Generalizada 8.5 Modelos Híbridos (Discretos e Contínuos) 6 Introdução 7 Álgebra Linear", " > 8 Inferência ativa em tempo contínuo Tudo flui, nada fica parado. —Heráclito, 501 aC 8.1 Introdução Este capítulo complementa o capítulo 7, continuando nossa discussão sobre como construir um modelo generativo. Nosso foco aqui é em modelos de espaço de estados contínuos, que são bem adequados para modelar as flutuações físicas que atingem os receptores sensoriais e para o movimento contínuo dos efetores (por exemplo, músculos) que usamos para mudar o mundo ao nosso redor. Existem muitas aplicações desses modelos. Neste capítulo, definimos os princípios por trás de seu uso. Destacamos os tipos de modelos usados no controle motor e os sistemas dinâmicos que desempenham um papel em tais modelos, e tocamos no conceito de sincronia generalizada. Finalmente, discutimos a reconciliação de modelos generativos discretos e contínuos. 8.2 Controles de movimento Como vimos no capítulo 4, o modelo generativo que subscreve a inferência ativa em tempo contínuo pode ser escrito como um par de equações estocásticas que determinam como os estados \\((x)\\) geram dados \\((y)\\) e como os estados evoluem ao longo do tempo dependendo de alguma variável estática \\((\\nu)\\): \\[\\begin{equation} y=g(x)+\\omega_y \\qquad\\qquad\\qquad\\qquad\\quad\\quad\\quad \\\\ \\dot x = f(x,\\nu) + \\omega_x \\qquad\\qquad\\qquad\\qquad (8.1) \\end{equation}\\] Essas equações e a precisão associada às flutuações \\((\\omega)\\) determinam o modelo utilizado para fazer inferências sobre as causas das sensações. Observe que a ação está ausente da equação 8.1. Isso ocorre porque (como descrito no capítulo 6), a ação é parte do processo generativo, não do modelo generativo. O modelo generativo lida apenas com aquelas variáveis que são diretamente influenciadas por estados externos a um envoltório de Markov. Se fôssemos escrever a dinâmica do mundo real (ou seja, o processo generativo), teríamos que incluir a ação \\((u)\\): \\[\\begin{equation} y=\\pmb g(x)+\\omega_y \\qquad\\qquad\\qquad\\qquad\\quad\\quad\\quad \\\\ \\dot x =\\pmb f(x,u) + \\omega_x \\qquad\\qquad\\qquad\\qquad (8.2) \\end{equation}\\] Observe que as funções \\(g\\) e \\(f\\) (e as precisões de $$) usadas para definir o modelo gerativo (equação 8.1) não são necessariamente as mesmas usadas para definir o processo gerativo (equação 8.2). Como vimos nos capítulos 2 a 4, as ações alteram os dados sensoriais de modo que a energia livre é minimizada. Isso significa que não precisamos escrever explicitamente a dinâmica da ação no modelo generativo – elas emergem das escolhas feitas para os termos da equação 8.1. Para obter alguma intuição para isso, começamos com um tipo muito simples de modelo generativo: \\[\\begin{equation} g(x) = x \\qquad\\qquad\\qquad\\qquad\\quad\\quad\\quad \\\\ f(x,\\nu) = \\nu - x \\qquad\\qquad\\qquad\\qquad (8.3) \\end{equation}\\] A Equação 8.3 diz que o estado oculto representa o valor esperado para os dados e que tem uma dinâmica consistente com um atrator simples (ou seja, ponto). Por atrator, queremos dizer que quando x é menor que v, a taxa de variação esperada de x é positiva e vice-versa. Isso significa que x sempre fluirá em direção a v (ou seja, v é um ponto de atração ou fixo). Para gerar dados, definimos um simples processo gerador: \\[\\begin{equation} \\pmb g(x) = x \\qquad\\qquad\\qquad\\qquad\\quad\\quad\\quad \\\\ \\pmb f(x,u) = u \\qquad\\qquad\\qquad\\qquad (8.4) \\end{equation}\\] Ao minimizar a energia livre, isso significa que a ação mudará para cumprir as previsões da equação 8.3. Se \\(\\mu\\) for o valor esperado de \\(x\\), isso significa que a ação que minimiza a diferença entre os dados previstos \\((g(\\mu))\\) e os dados observados \\((y)\\) é igualar \\(u\\) a \\(\\nu − \\mu\\). Esta é uma expressão da “hipótese do ponto de equilíbrio” (Feldman e Levin 2009), que trata o controle motor como encenado por arcos reflexos que simplesmente atraem os membros em direção a pontos de equilíbrio definidos por sinais motores descendentes. Na Inferência Ativa, esses sinais são previsões – especificamente, previsões proprioceptivas sobre, por exemplo, a posição esperada de membros ou olhos (Adams, Shipp e riston 2013). Portanto, o controle do movimento resulta do cumprimento de previsões (proprioceptivas) pela ação, conforme ilustrado esquematicamente na figura 8.1. Observe que este esquema não requer a especificação de “modelos inversos” (ou seja, mapeamentos de consequências desejadas para os comandos motores para alcançá-los) que são amplamente utilizados em outras formulações de controle motor (Wolpert e Kawato 1998). A expressão na equação 8.3 é o tipo mais simples de sistema atrator que podemos empregar em um modelo generativo. No entanto, é muito simples em muitos cenários, onde se aplicam dinâmicas newtonianas mais realistas. Um modelo mais sofisticado reconhece que as forças – geradas pelos músculos – alteram a velocidade (ou seja, induzem uma aceleração), não a posição. A Equação 8.5 estabelece isso explicitamente com \\(x_1\\) como a posição e \\(x_2\\) como a velocidade: \\[\\begin{equation} f(x, \\nu) = \\begin{bmatrix} x_2\\\\ \\frac{\\kappa}{m}(\\nu-x_1) \\end{bmatrix} \\qquad\\qquad\\qquad\\qquad (8.5) \\end{equation}\\] Esta expressão é equivalente à dinâmica de uma mola obedecendo à lei de Hooke. A taxa de mudança da posição (primeiro elemento) é simplesmente a velocidade. A taxa de variação da velocidade (segundo elemento) é proporcional à distância entre a posição atual e o ponto \\(\\nu\\), com a constante de proporcionalidade: uma razão entre a massa do objeto \\((m)\\) e uma constante (mola) \\((\\kappa)\\) ). Multiplicando ambos os lados pela massa, temos a força1 gerada por uma mola \\((κ (\\nu − x_1))\\) presa aos pontos \\(\\nu\\) e \\(x_1\\) igual à massa multiplicada pela taxa de variação da velocidade. Esta é apenas a segunda lei de Newton. Em outras palavras, podemos escrever um modelo generativo que prevê a dinâmica que se desenrolaria se houvesse uma mola puxando um membro para um local desejado. Ao prever os dados (proprioceptivos) decorrentes dessa mecânica newtoniana, podemos decretar o movimento que cumpre essas previsões. 8.3 Sistemas Dinâmicos Conforme descrito na seção 8.2, as formulações de tempo contínuo da Inferência Ativa são bem adequadas à caracterização de movimentos. Mais geralmente, eles são apropriados na especificação de modelos generativos de sistemas dinâmicos não lineares em que a discretização de tempo e espaço é ineficiente. A forma mais simples de sistema dinâmico é o atrator da equação 8.3, mas um comportamento muito mais rico pode ser desenvolvido a partir de sistemas mais complexos. No espaço limitado deste livro, não podemos fazer justiça ao grande corpo de trabalho desenvolvendo modelos com sistemas dinâmicos mais complexos (mas veja a tabela 8.1 para alguns dos principais avanços). Em vez disso, nos concentramos em alguns dos princípios necessários para entender esses sistemas. Nesta seção, apresentamos brevemente dois sistemas dinâmicos usados ​​na formulação de modelos generativos desse tipo: a dinâmica de Lotka-Volterra e os sistemas de Lorenz. Os primeiros podem ser utilizados na caracterização de sistemas com aspecto sequencial à sua dinâmica, enquanto os segundos representam sistemas caóticos. Figura 8.1 Reflexos espinhais, ilustrando a distinção entre um processo generativo (lá fora no mundo) e um modelo generativo no cenário de geração de ação. O modelo assume que a posição \\((x)\\) de um membro (ou mão ou outra parte do corpo) é traçada em direção a algum ponto \\((\\nu)\\). A seta tracejada no gráfico superior mostra essa crença. Crenças sobre \\(x(\\mu_x)\\) podem ser substituídas no lugar de \\(x\\) e usadas para atualizar crenças sobre sua taxa de mudança. O \\(\\mu_x\\) resultante é então usado para prever dados sensoriais \\((y)\\) por meio da função \\(g\\) no modelo generativo. Os dados sensoriais são realmente gerados pelo processo generativo por meio da função \\(g\\), que recebe o valor “real” de \\(x\\) como argumento. O erro \\((\\epsilon_y)\\) então conduz mudanças na ação \\((u)\\) de modo que o erro seja resolvido. Essa resolução acontece através do modelo generativo, pois a ação determina a taxa de variação de \\(x\\) via \\(\\pmb f\\). Isso faz com que \\(x\\) se mova para o local no espaço que gera dados \\(y\\) consistentes com a previsão \\((g(\\mu_x))\\), definindo \\(\\epsilon_y\\) e, portanto, a taxa de mudança de \\(a\\) para zero. Quadro 8.1 Precisão, atenção e atenuação sensorial Abordamos a importância da precisão no capítulo 7, mas vale a pena recapitular seu papel em sistemas de tempo contínuo. De muitas maneiras, esse conceito é abordado de forma mais natural nesse cenário, pois a variável \\(\\Pi\\) aparece como uma consequência direta da aproximação de Laplace. Isso atua diretamente como um ganho multiplicativo na dinâmica inferencial (ver figura 8.1), com diferentes precisões ponderando influências alternativas sobre a atualização de crenças.\\[ \\] A interpretação da precisão como ganho sináptico a conecta a vários aspectos importantes da neurobiologia. De um ponto de vista empírico, uma precisão mais alta implica uma atualização de crença mais vigorosa do tipo que pode ser medido em pesquisas eletrofisiológicas como uma resposta evocada de grande amplitude com um pico precoce ou em gravações de célula única como um efeito multiplicativo nas taxas de disparo neuronal em resposta a um estímulo colocado no campo receptivo dessa célula. Esses achados são frequentemente associados ao processamento atencional, onde um canal sensorial (ou subconjunto de canais) é favorecido em relação aos outros. Do ponto de vista da inferência ativa, precisão e atenção são sinônimos. O primeiro tem sido usado para reproduzir uma série de fenômenos atencionais in silico, incluindo o paradigma de Posner (Feldman e Friston 2010). Especificamente, usar uma sugestão para prever a precisão da entrada sensorial de um dos dois locais reproduz a descoberta empírica de que as respostas aos estímulos no local indicado são mais rápidas do que aquelas que aparecem no local alternativo.\\[ \\] Um segundo aspecto importante do controle de precisão é seu papel na geração de movimento. Para entender isso, vale pensar no que acontece na ausência desse controle. Imagine, primeiro, que os dados sensoriais sejam previstos com alta precisão. As mensagens desses dados, portanto, têm alto ganho sináptico e levam a inferências verídicas sobre a posição de alguma parte do corpo. O problema com isso é a equivalência entre comandos motores e previsões sob Inferência Ativa. Uma crença precisa de que “não estou me movendo” não pode ser usada para prever as consequências sensoriais do movimento, vitais para o início desse movimento. Com entrada sensorial de alta precisão, a crença de que “estou me movendo” é imediatamente corrigida diante de evidências em contrário; portanto, nenhum movimento é executado. Isso nos diz algo importante: para gerar movimento, devemos ser capazes de ignorar as consequências sensoriais desse movimento para formar a crença (inicialmente falsa) de que “estou me movendo”. Uma vez estabelecida essa crença, as consequências proprioceptivas (e outras sensoriais) desse movimento podem ser previstas e encenadas por meio dos mecanismos descritos na figura 8.1. Esse processo de ignorar evidências em contrário é conhecido como “atenuação sensorial” e representa a diminuição da precisão necessária para que um movimento ocorra (Brown, Adams et al. 2013; Pezzulo 2013; Set 2013; Pezzulo, Rigoli e Friston 2015; Seth e Friston 2016; Allen et ai. 2019).\\[ \\] Claramente, é útil entre os movimentos restaurar essa precisão, tirar as inferências apropriadas da entrada sensorial. Isso implica um processo cíclico de atenuação e movimento (por exemplo, a supressão cíclica da entrada visual durante as sacadas, depois uma supressão das sacadas). Predizer o movimento na suspensão da atenção tem estreitas relações com uma teoria ideomotora que se originou no século XIX para explicar os movimentos induzidos sob hipnose. A dinâmica de Lotka-Volterra é herdada das caracterizações da dinâmica predador-presa em ecologia. Embora desde então tenham encontrado aplicação em várias disciplinas, os sistemas predador-presa continuam sendo um exemplo útil para fornecer alguma intuição sobre seu funcionamento. Quando a população de predadores é pequena, a presa pode aumentar seu número para se tornar uma população relativamente grande. Isso fornece comida adicional para os predadores, cujo tamanho da população cresce. O aumento da predação causa uma diminuição no número de espécies de presas e, portanto, uma diminuição no número de predadores. A partir daqui, o ciclo continua. Isso fornece um padrão oscilatório em que o tamanho da população de presas atinge o pico, depois os predadores, depois as presas novamente e assim por diante. Ao generalizar isso para mais de duas populações (por exemplo, populações carnívoras, herbívoras e vegetais), podemos gerar uma sequência de picos. A Figura 8.2 ilustra a dinâmica generalizada de Lotka-Volterra com três populações, que obedecem a dinâmicas da seguinte forma: \\[ f(x,\\nu)= x \\circ (\\nu + \\pmb Ax) \\qquad \\qquad \\qquad \\qquad (8.6) \\] Aqui, \\(x\\) é um vetor como antes. O símbolo \\(\\circ\\) significa um produto elementar. As taxas intrínsecas de natalidade e mortalidade são dadas pelo vetor \\(\\nu\\), e \\(A\\) é uma matriz cujos elementos são positivos se as espécies indexadas pela coluna predam aquelas indexadas pela linha e negativas se a relação for invertida. Figura 8.2 Dinâmica sequencial generalizada que emerge dos sistemas Lotka-Volterra fornece um importante ponto de conexão com a dinâmica sequencial discreta assumida no capítulo 7. Essa dinâmica pode ser aplicada a uma variedade de sistemas, mas são enquadradas aqui em termos de relações predador-presa para facilitar de interpretação. Acima: A população muda ao longo do tempo. O tamanho da população é expresso em termos de unidades arbitrárias (a.u.). Os picos são rotulados com base em qual espécie tem a maior população naquele ponto. O padrão repetido de p, h, c pode ser visto como uma sequência de três passos de tempo discretos (não necessariamente uniformemente espaçados). Abaixo: Trajetórias enfatizando o padrão (aproximadamente) periódico que cada uma segue. A Figura 8.2 deixa claro que ter um modelo generativo que incorpore a dinâmica Lotka-Volterra permite o sequenciamento temporal (Huerta e Rabino vich 2004) – dependendo do pico mais alto atual. Cada linha pode ser pensada como representando um estado oculto, no lugar de uma espécie. A Figura 8.3 destaca dois exemplos importantes em que essas dinâmicas foram exploradas para gerar comportamento Um é um modelo hierárquico que usa a dinâmica sequencial oferecida por um sistema Lotka-Volterra para cronometrar a resposta de um piscar de olhos em relação a um estímulo condicionado (Friston e Herreros 2016). O paradigma é baseado naqueles usados na investigação da função cerebelar. Um estímulo incondicionado (um sopro de ar direcionado para o olho de um animal) provoca uma resposta (piscando). Figura 8.3 Duas aplicações da dinâmica sequencial generalizada de Lotka-Volterra na Inferência Ativa. Esquerda: Condicionamento de piscar de olhos usado para investigar empiricamente a função cerebelar (Friston e Herreros 2016). Começando no nível mais alto da coluna, os estados esperados mostram o mesmo tipo de padrão sequencial da figura 8.2. Isso passa para o próximo nível para prever causas ocultas sequenciais; os vários picos aqui predizem estados no próximo nível abaixo, onde o primeiro pico é o estímulo condicionado (CS) e o segundo é o estímulo incondicionado (US). Finalmente, os EUA previstos induzem à ação – um piscar de olhos. Direita: Picos sequenciais usando um ponto de atração como na equação 8.5, mas selecionando o atrator específico com base em qual população de um sistema Lotka-Volterra é atualmente mais alta; isso leva a uma visita sequencial de cada ponto, dando origem a uma forma de escrita à mão (Friston, Mattout e Kilner 2011). Um estímulo condicionado (um tom auditivo) pode ser reproduzido antes do estímulo incondicionado em várias ocasiões. Aprendendo (veja o quadro 8.2) o número de picos na dinâmica de Lotka-Volterra que separa o estímulo condicionado do estímulo incondicionado, o animal aprende a antecipar o sopro de ar e cronometrar o piscar apropriado. Esta é uma forma de aprendizado temporal, uma vez que o número de picos fornece uma estimativa implícita da duração do intervalo temporal entre os estímulos condicionados e incondicionados. No segundo exemplo da figura 8.3, cada pico sequencial está associado a um ponto de atração alternativo que direciona os movimentos para uma série de pontos de atração dispostos para sugerir escrita à mão (Friston, Mattout e Kilner 2011). Como os dois exemplos ilustram, os sistemas Lotka-Volterra generalizados fornecem modelos úteis de dinâmica sequencial usando um sistema dinâmico contínuo. Quadro 8.2 Aprendizagem em modelos contínuos Conforme discutido no capítulo 7, o aprendizado é o processo de otimizar crenças sobre os parâmetros \\((\\theta)\\) de um modelo generativo. No domínio de tempo contínuo, isso significa acumular evidências ao longo do tempo. Isso funciona como se tratássemos dados em uma série de intervalos de tempo infinitesimalmente pequenos como obedecendo a i.i.d. (independentes e identicamente distribuídos) e formular um modelo generativo que gera observações a partir de parâmetros (invariantes no tempo):\\[\\begin{equation} \\ln p(\\tilde y, \\theta) = \\ln p(\\theta) + \\int \\ln p(y(t)| \\theta)dt \\\\ \\approx \\ln p(\\theta) - \\int F[y(t)|\\theta]dt \\end{equation}\\]Isso pode ser usado para formular um funcional \\((S)\\) que desempenha o papel de uma energia livre para parâmetros usando a integral no tempo da energia livre condicionada aos parâmetros. Usando uma aproximação de Laplace, obtemos o seguinte, em que α atua para acumular gradientes de energia livre (ou seja, gradientes de evidência):\\[ \\begin{equation}S(\\theta)=\\mathbb E_{q(\\theta)}[\\ln q(\\theta)+ \\int F[y(t)|\\theta]dt - \\ln p(\\theta)] \\\\ \\approx \\int F[y(t)|\\mu_\\theta]dt - \\ln p(\\mu_\\theta)\\qquad\\qquad \\\\ \\dot \\mu_\\theta = \\partial_{\\mu_\\theta} S(\\mu_\\theta) \\qquad\\qquad\\qquad\\qquad\\qquad\\qquad \\\\ = \\partial_{\\mu_\\theta} \\ln p(\\mu_\\theta) - \\int \\partial_{\\mu_\\theta} F[y(t)|\\mu_\\theta]dt \\\\ = \\partial \\ln p(\\mu_{\\theta})-\\alpha \\qquad\\qquad\\qquad\\qquad \\\\ \\dot \\alpha = \\partial_{\\mu_\\theta}F[y(t)| \\mu_\\theta] \\end{equation}\\] A formulação POMDP do capítulo 7 substituiu amplamente o uso de sistemas Lotka-Volterra generalizados em aplicações de Inferência Ativa. No entanto, é útil ter esse tipo de dinâmica em mente como um sistema contínuo plausível que pode subscrever a dinâmica sequencial discreta do capítulo 7. Além disso, os sistemas Lotka-Volterra tornam explícita a distinção entre representações de sequências envolvidas no planejamento temporalmente profundo e representações de taxas de mudança em coordenadas generalizadas de movimento (ver capítulo 4). Cada um tem seu lugar, mas lida com diferentes tipos de problemas. O segundo tipo de sistema dinâmico que encontrou ampla aplicação na pesquisa de inferência ativa é o sistema de Lorenz: \\[\\dot x = \\begin{bmatrix} \\sigma (x_2 - x_1) \\\\ x_1(\\rho - x_3) - x_2 \\\\ x_1x_2 - \\beta x_3 \\end{bmatrix} \\qquad\\qquad\\qquad\\qquad (8.7)\\] Os parâmetros são conhecidos como o número de Prandtl \\((\\sigma)\\), o número de Rayleigh \\((\\rho)\\) e uma constante \\((\\beta)\\) que se relaciona com a física do sistema. Dependendo dos valores que eles assumem, o sistema pode se comportar de maneiras muito diferentes. Os atratores de Lorenz foram inicialmente formulados para explicar a dinâmica da convecção atmosférica. Seu comportamento itinerante (errante) estimulou seu uso em modelos generativos para simular problemas de inferência desafiadores. Um exemplo importante disso está na simulação do canto dos pássaros, que descompactamos na próxima seção. Esses sistemas também têm sido usados para simular sistemas físicos simples e investigar as condições sob as quais seu comportamento começa a parecer senciente. A Figura 8.4 mostra como o sistema Lorenz se comporta em configurações de parâmetros de exemplo. 8.4 Sincronia Generalizada Como mencionado acima, um exemplo-chave de aplicação de modelos de espaço de estados contínuos está em uma série de estudos baseados em pássaros sintéticos (Friston e Frith 2015b). Um aspecto importante desses estudos analisa a comunicação e os problemas de inferência multiagentes. A ideia aqui se baseia na capacidade de uma criatura de sincronizar seus estados internos com algo lá fora no mundo (ou seja, inferência). Quando o que está lá fora é outra criatura com um modelo semelhante, essa sincronização significa que os estados internos de uma criatura devem se assemelhar aos estados internos da outra: um tipo primitivo de teoria da mente. Figura 8.4 Comportamento de um atrator do sistema Lorenz (usando o mesmo formato da figura 8.2), mostrando como esse sistema tridimensional evolui. Caracteristicamente, parece caótico e imprevisível, passando algum tempo orbitando uma parte do espaço antes de mudar para outra órbita. Esta itinerância e aparente autonomia tornam este interessante sistema bem adequado para inclusão em modelos de fenômenos biológicos. A Figura 8.5 mostra o tipo de modelo generativo usado para simular pássaros canoros. Neste modelo hierárquico, os estados de alto nível (nível 2) evoluem de acordo com um sistema de Lorenz lento. Uma dimensão deste sistema é então usada para parametrizar o número Rayleigh de um sistema Lorenz mais rápido no nível inferior (nível 1). As variáveis de nível inferior são mapeadas para dados sensoriais (sonográficos). Analogamente à figura 8.1, o processo generativo inclui adicionalmente ação; aqui, em vez de mover um membro, as ações influenciam a laringe, de modo que os dados ultrassonográficos podem ser influenciados pela ave. Como antes, a ação é gerada para resolver o erro de previsão. Isso significa que, se um pássaro ouve o canto que está prevendo, não há necessidade de gerá-lo. No entanto, se ele prevê uma música que não é ouvida, ele deve começar a cantar para resolver qualquer erro. Figura 8.5 Sincronização e comunicação. Esquerda: Modelo generativo subscrevendo as simulações de canto de pássaros descritas no texto principal. Este é um modelo hierárquico, com atratores de Lorenz em cada nível. Direita: Sincronização multipla de expectativas no segundo nível para dois pássaros antes e depois de terem aprendido um sobre o outro. Depois de aprender os parâmetros dos modelos generativos um do outro, a trajetória conjunta dos dois pássaros é confinada a um subespaço (quase) unidimensional, indicando sincronização. Essa dinâmica se torna mais interessante quando há dois pássaros em jogo, com modelos generativos estruturados de forma semelhante. Enquanto um pássaro estiver cantando, o outro não precisa, pois não há erro a ser resolvido. No entanto, se um pássaro parar de cantar, o outro precisa continuar a mesma música. Isso leva a uma forma de troca de turnos, às vezes expressa como “cantar da mesma folha de hino”, com cada pássaro contribuindo com seções da mesma música. O que leva a essa virada? Por que um pássaro não continua cantando a música inteira para seu coespecífico? A resposta está relacionada à questão da atenuação sensorial (ver quadro 8.1), pois atuar para gerar o canto dos pássaros requer uma redução na precisão das previsões sobre as consequências da ação. Assim como nos movimentos oculares sacádicos, isso implica na alternância entre a atenção aos dados sensoriais (visuais ou auditivos) e a atenuação durante a ação (sacádica ou vocal) destinada a alterar esses dados. Quando há dois agentes envolvidos, isso leva a uma alternância entre ouvir o outro e cantar – uma forma simples de conversa. Para que essa conversa sintética funcione, é essencial que os dois pássaros se sincronizem e saibam onde estão no canto (ou trajetória conversacional). Isso implica que as inferências sobre estados ocultos no modelo generativo devem ser alinhadas entre as aves. No canto superior direito da figura 8.5, mostramos um coletor de sincronização de duas aves que ainda não otimizaram seus modelos generativos uma em relação à outra; isso traça uma trajetória das crenças que cada ave tem sobre os estados ocultos de nível superior. A sincronização implica que quando uma ave infere um valor de estado oculto específico, a outra ave deve inferir o mesmo; portanto, esperaríamos que a trajetória permanecesse fixa à linha x = y (tecnicamente chamada sincronização idêntica do caos). Flutuações em torno desta linha implicam sincronização imperfeita, como mostra este gráfico. Após a exposição um ao outro e o aprendizado dos parâmetros dos modelos generativos de cada um (veja o quadro 8.2), a sincronização é quase perfeita (gráfico inferior direito). A implicação é que cada pássaro aprendeu sobre o outro e é capaz de inferir o que está acontecendo na cabeça do outro. Em suma, eles aprenderam a compartilhar a mesma narrativa e “cantar da mesma folha de hinos”. Uma forma mais geral de sincronização não requer sincronização ao longo da linha x = y. Na sincronização generalizada, o comportamento da junta ocupa um espaço unidimensional inferior ao espaço bidimensional superior que poderia ser ocupado por esse comportamento. No entanto, esse espaço de baixa dimensão (o coletor de sincronização) pode ser curvo ou ter alguma outra forma; isso é análogo ao espaço bidimensional que ocupamos na superfície do planeta, apesar da superfície ser curvada em uma esfera tridimensional. Além de seu papel central no comportamento social, a sincronização generalizada – ocupação de uma região de baixa dimensão de um espaço de articulação de alta dimensão – é muito importante na caracterização de sistemas biológicos como envolvidos em inferência (sincronia generalizada entre estados internos e externos). Embora não tenhamos espaço para destrinchar este assunto extenso aqui, a perspectiva inferencial fala sobre o fracasso da sincronia generalizada associada a síndromes neuropsiquiátricas como o autismo. Esse tipo de sincronia é importante não apenas em modelos de tempo contínuo, mas também em modelos POMDP de comunicação linguística entre múltiplos agentes (Friston, Parr et al. 2020). 8.5 Modelos Híbridos (Discretos e Contínuos) Como vimos neste e no capítulo anterior, os modelos discretos e contínuos têm aplicações importantes na Inferência Ativa. Embora muitos cenários exijam um ou outro, uma perspectiva mais holística reconhece que ambos provavelmente estão em jogo. Isso significa que precisamos de uma maneira de combinar esses modelos generativos para que um único modelo inclua variáveis contínuas e discretas (Friston, Parr e de Vries 2017). Tais modelos híbridos ou mistos permitem inferências sobre planos de ação sequenciais e traduções dessas decisões em movimentos por meio de um modelo contínuo. A Figura 8.6 mostra a forma desses modelos, com um POMDP no nível superior, comportando-se conforme descrito no capítulo 7, que gera um modelo contínuo da ordenação abordada neste capítulo a cada passo de tempo discreto. Isso decompõe o tempo contínuo em uma sequência discreta de trajetórias contínuas curtas. Figura 8.6 Modelos generativos mistos na forma de um modelo hierárquico muito parecido com o da figura 7.12. No entanto, há uma diferença importante entre a forma do modelo no nível superior e no nível inferior. Enquanto o modelo de nível inferior (um exemplo é destacado pela caixa tracejada) é da mesma forma que os outros modelos considerados neste capítulo - ou seja, é enquadrado em termos de estados contínuos e tempo contínuo e usa coordenadas generalizadas de movimento - O modelo de nível superior é um modelo POMDP do tipo que vimos ao longo do capítulo 7 - ou seja, é enquadrado em termos de estados e tempos discretos. Efetivamente, isso significa que podemos selecionar (em intervalos de tempo regulares) entre segmentos alternativos de uma trajetória contínua. Para traduzir os resultados do nível discreto para o nível contínuo, precisamos associar cada resultado alternativo a um ponto em algum espaço contínuo. Para desenvolver a intuição para essa ideia, consideramos o exemplo de uma tarefa oculomotora com período de atraso – frequentemente usada em pesquisas com primatas; veja a figura 8.7. Essa tarefa envolve três etapas. Primeiro, um alvo aparece em um dos (por exemplo) quatro locais possíveis, enquanto um macaco mantém a fixação em uma cruz de fixação central. Em seguida, o alvo desaparece e deve ser lembrado durante um período de atraso. Por fim, é dado um sinal para que o macaco faça uma sacada, momento em que deve olhar para o local onde o alvo original apareceu. Para completar esta tarefa, o macaco deve ser capaz de fazer inferências sobre sequências (qual estágio da tarefa está em jogo) e inferir qual dos quatro locais visar. Estes são problemas de inferência categórica adequados a uma formulação POMDP. No entanto, uma vez que o local apropriado tenha sido selecionado, o macaco deve realizar o movimento do olho que traz sua fóvea para as coordenadas (contínuas) do local alvo. A Figura 8.7 ilustra o funcionamento de um modelo generativo misto que resolve esse problema. No painel superior, o nível superior do modelo toma decisões categóricas: ele calcula as crenças posteriores sobre quatro locais de destino discretos em quatro períodos de tempo. Nos gráficos do meio e do fundo, o nível inferior do modelo computa trajetórias comportamentais contínuas (movimentos oculares) resultantes de inferências discretas no nível superior. Transformar decisões sobre locais de alvos discretos em movimentos oculares contínuos requer que cada local de alvo discreto \\((o)\\) seja associado a uma distribuição sobre causas ocultas contínuas \\((\\nu)\\), que identifica as coordenadas do alvo. As coordenadas anteriores sobre o alvo podem ser calculadas tomando a média do modelo Bayesiano sobre esses locais, ponderada pelas inferências no nível POMDP: \\[P(\\tilde \\nu| o_\\tau)= \\mathcal N(\\tilde \\eta_{o_{\\tau}}, \\tilde \\Pi_\\nu) \\] \\[P(\\tilde \\nu) \\approx \\mathcal N( \\pmb {\\tilde \\eta}, \\tilde \\Pi_\\nu) \\] \\[ \\pmb {\\tilde \\eta} = \\mathbb E_{Q(o_\\tau)}[\\tilde \\eta]= \\pmb o_\\tau \\cdot \\tilde \\eta \\] 6 Introdução 7 Álgebra Linear 7.1 O básico 7.2 Derivadas Muitas vezes é necessário adicionar termos de amortecimento para levar em conta o atrito e/ou viscosidade para evitar soluções oscilatórias.↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
