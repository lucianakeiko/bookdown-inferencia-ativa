<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>> 4 Os Modelos Geradores de Inferência Ativa | Inferencia Ativa</title>
  <meta name="description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="> 4 Os Modelos Geradores de Inferência Ativa | Inferencia Ativa" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/Figura_1_1.png" />
  <meta property="og:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="> 4 Os Modelos Geradores de Inferência Ativa | Inferencia Ativa" />
  
  <meta name="twitter:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="twitter:image" content="/images/Figura_1_1.png" />

<meta name="author" content="Thomas Parr, Giovanni Pezzulo, and Karl J. Friston" />


<meta name="date" content="2022-07-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="o-caminho-para-a-inferência-ativa.html"/>
<link rel="next" href="passagem-de-mensagens-e-neurobiologia.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Inferencia Ativa</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Conteúdo</a></li>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html"><i class="fa fa-check"></i>Prefácio</a></li>
<li class="chapter" data-level="1" data-path="visão-geral.html"><a href="visão-geral.html"><i class="fa fa-check"></i><b>1</b> Visão Geral</a>
<ul>
<li class="chapter" data-level="1.1" data-path="visão-geral.html"><a href="visão-geral.html#introdução"><i class="fa fa-check"></i><b>1.1</b> Introdução</a></li>
<li class="chapter" data-level="1.2" data-path="visão-geral.html"><a href="visão-geral.html#como-os-organismos-vivos-persistem-e-agem-adaptativamente"><i class="fa fa-check"></i><b>1.2</b> Como os Organismos Vivos Persistem e Agem Adaptativamente?</a></li>
<li class="chapter" data-level="1.3" data-path="visão-geral.html"><a href="visão-geral.html#inferência-ativa-comportamento-a-partir-dos-primeiros-princípios"><i class="fa fa-check"></i><b>1.3</b> Inferência Ativa: Comportamento a partir dos Primeiros Princípios</a></li>
<li class="chapter" data-level="1.4" data-path="visão-geral.html"><a href="visão-geral.html#estrutura-do-livro"><i class="fa fa-check"></i><b>1.4</b> Estrutura do Livro</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="visão-geral.html"><a href="visão-geral.html#parte-1-inferência-ativa-na-teoria"><i class="fa fa-check"></i><b>1.4.1</b> Parte 1: Inferência Ativa na Teoria</a></li>
<li class="chapter" data-level="1.4.2" data-path="visão-geral.html"><a href="visão-geral.html#parte-2-inferência-ativa-na-prática"><i class="fa fa-check"></i><b>1.4.2</b> Parte 2: Inferência Ativa na Prática</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="visão-geral.html"><a href="visão-geral.html#resumo"><i class="fa fa-check"></i><b>1.5</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>2</b> O Caminho de baixo para a Inferência Ativa</a>
<ul>
<li class="chapter" data-level="2.1" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#introdução-1"><i class="fa fa-check"></i><b>2.1</b> Introdução</a></li>
<li class="chapter" data-level="2.2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#percepção-como-inferência"><i class="fa fa-check"></i><b>2.2</b> Percepção como Inferência</a></li>
<li class="chapter" data-level="2.3" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#inferência-biológica-e-otimização"><i class="fa fa-check"></i><b>2.3</b> Inferência Biológica e Otimização</a></li>
<li class="chapter" data-level="2.4" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#ação-como-inferência"><i class="fa fa-check"></i><b>2.4</b> Ação como Inferência</a></li>
<li class="chapter" data-level="2.5" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-discrepância-entre-o-modelo-e-o-mundo"><i class="fa fa-check"></i><b>2.5</b> Minimizando a discrepância entre o modelo e o mundo</a></li>
<li class="chapter" data-level="2.6" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-energia-livre-variacional"><i class="fa fa-check"></i><b>2.6</b> Minimizando a Energia Livre Variacional</a></li>
<li class="chapter" data-level="2.7" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#energia-livre-esperada-e-planejamento-como-inferência"><i class="fa fa-check"></i><b>2.7</b> Energia Livre Esperada e Planejamento como Inferência</a></li>
<li class="chapter" data-level="2.8" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#o-que-é-energia-livre-esperada"><i class="fa fa-check"></i><b>2.8</b> O que é energia livre esperada?</a></li>
<li class="chapter" data-level="2.9" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#no-final-da-estrada-baixa"><i class="fa fa-check"></i><b>2.9</b> No final da estrada baixa</a></li>
<li class="chapter" data-level="2.10" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#resumo-1"><i class="fa fa-check"></i><b>2.10</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>3</b> O caminho para a inferência ativa</a>
<ul>
<li class="chapter" data-level="3.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#introdução-2"><i class="fa fa-check"></i><b>3.1</b> Introdução</a></li>
<li class="chapter" data-level="3.2" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#envoltórios-de-markov"><i class="fa fa-check"></i><b>3.2</b> Envoltórios de Markov</a></li>
<li class="chapter" data-level="3.3" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-e-auto-evidência"><i class="fa fa-check"></i><b>3.3</b> Minimização de surpresa e auto-evidência</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-como-um-princípio-hamiltoniano-de-menor-ação"><i class="fa fa-check"></i><b>3.3.1</b> Minimização de surpresa como um princípio hamiltoniano de menor ação</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#relações-entre-inferência-cognição-e-dinâmica-estocástica"><i class="fa fa-check"></i><b>3.4</b> Relações entre Inferência, Cognição e Dinâmica Estocástica</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#energia-livre-variacional-evidência-modelo-e-surpresa"><i class="fa fa-check"></i><b>3.4.1</b> Energia Livre Variacional, Evidência Modelo e Surpresa</a></li>
<li class="chapter" data-level="3.4.2" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#energia-livre-esperada-e-inferência-da-trajetória-mais-provável"><i class="fa fa-check"></i><b>3.4.2</b> Energia Livre Esperada e Inferência da Trajetória Mais Provável</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#inferência-ativa-uma-nova-base-para-entender-o-comportamento-e-a-cognição"><i class="fa fa-check"></i><b>3.5</b> Inferência ativa: uma nova base para entender o comportamento e a cognição</a></li>
<li class="chapter" data-level="3.6" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#modelos-políticas-e-trajetórias"><i class="fa fa-check"></i><b>3.6</b> Modelos, Políticas e Trajetórias</a></li>
<li class="chapter" data-level="3.7" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#reconciliação-das-teorias-enativa-cibernética-e-preditiva-sob-inferência-ativa"><i class="fa fa-check"></i><b>3.7</b> Reconciliação das Teorias Enativa, Cibernética e Preditiva sob Inferência Ativa</a></li>
<li class="chapter" data-level="3.8" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#inferência-ativa-da-emergência-da-vida-para-a-atuação"><i class="fa fa-check"></i><b>3.8</b> Inferência Ativa, da Emergência da Vida para a atuação</a></li>
<li class="chapter" data-level="3.9" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#resumo-2"><i class="fa fa-check"></i><b>3.9</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html"><i class="fa fa-check"></i><b>4</b> Os Modelos Geradores de Inferência Ativa</a>
<ul>
<li class="chapter" data-level="4.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#introdução-3"><i class="fa fa-check"></i><b>4.1</b> Introdução</a></li>
<li class="chapter" data-level="4.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#da-inferência-bayesiana-à-energia-livre"><i class="fa fa-check"></i><b>4.2</b> Da Inferência Bayesiana à Energia Livre</a></li>
<li class="chapter" data-level="4.3" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#modelos-geradores"><i class="fa fa-check"></i><b>4.3</b> Modelos Geradores</a></li>
<li class="chapter" data-level="4.4" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-tempo-discreto"><i class="fa fa-check"></i><b>4.4</b> Inferência ativa em tempo discreto</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#processos-de-decisão-markov-parcialmente-observáveis"><i class="fa fa-check"></i><b>4.4.1</b> Processos de Decisão Markov Parcialmente Observáveis</a></li>
<li class="chapter" data-level="4.4.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-um-pomdp"><i class="fa fa-check"></i><b>4.4.2</b> Inferência ativa em um POMDP</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-tempo-contínuo"><i class="fa fa-check"></i><b>4.5</b> Inferência Ativa em Tempo Contínuo</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#um-modelo-generativo-para-codificação-preditiva"><i class="fa fa-check"></i><b>4.5.1</b> Um modelo generativo para codificação preditiva</a></li>
<li class="chapter" data-level="4.5.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-como-codificação-preditiva-com-reflexos-motores"><i class="fa fa-check"></i><b>4.5.2</b> Inferência Ativa como Codificação Preditiva com Reflexos Motores</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#resumo-3"><i class="fa fa-check"></i><b>4.6</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html"><i class="fa fa-check"></i><b>5</b> Passagem de Mensagens e Neurobiologia</a>
<ul>
<li class="chapter" data-level="5.1" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#introdução-4"><i class="fa fa-check"></i><b>5.1</b> Introdução</a></li>
<li class="chapter" data-level="5.2" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#microcircuitos-e-mensagens"><i class="fa fa-check"></i><b>5.2</b> Microcircuitos e Mensagens</a></li>
<li class="chapter" data-level="5.3" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#comandos-do-motor"><i class="fa fa-check"></i><b>5.3</b> Comandos do Motor</a></li>
<li class="chapter" data-level="5.4" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#estruturas-subcorticais"><i class="fa fa-check"></i><b>5.4</b> Estruturas Subcorticais</a></li>
<li class="chapter" data-level="5.5" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#neuromodulação-e-aprendizagem"><i class="fa fa-check"></i><b>5.5</b> Neuromodulação e Aprendizagem</a></li>
<li class="chapter" data-level="5.6" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#hierarquias-contínuas-e-discretas"><i class="fa fa-check"></i><b>5.6</b> Hierarquias Contínuas e Discretas</a></li>
<li class="chapter" data-level="5.7" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#resumo-4"><i class="fa fa-check"></i><b>5.7</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><i class="fa fa-check"></i><b>6</b> Uma receita para projetar modelos de inferência ativos</a>
<ul>
<li class="chapter" data-level="6.1" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#introdução-5"><i class="fa fa-check"></i><b>6.1</b> Introdução</a></li>
<li class="chapter" data-level="6.2" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#projetando-um-modelo-de-inferência-ativo-uma-receita-em-quatro-etapas"><i class="fa fa-check"></i><b>6.2</b> Projetando um modelo de inferência ativo: uma receita em quatro etapas</a></li>
<li class="chapter" data-level="6.3" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#que-sistema-estamos-modelando"><i class="fa fa-check"></i><b>6.3</b> Que sistema estamos modelando?</a></li>
<li class="chapter" data-level="6.4" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#qual-é-a-forma-mais-adequada-para-o-modelo-generativo"><i class="fa fa-check"></i><b>6.4</b> Qual é a forma mais adequada para o modelo generativo?</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#variáveis-discretas-ou-contínuas-ou-ambas"><i class="fa fa-check"></i><b>6.4.1</b> Variáveis Discretas ou Contínuas (ou Ambas)?</a></li>
<li class="chapter" data-level="6.4.2" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#escalas-de-tempo-de-inferência-modelos-rasos-versus-modelos-hierárquicos"><i class="fa fa-check"></i><b>6.4.2</b> Escalas de tempo de inferência: modelos rasos versus modelos hierárquicos</a></li>
<li class="chapter" data-level="6.4.3" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#profundidade-temporal-de-inferência-e-planejamento"><i class="fa fa-check"></i><b>6.4.3</b> Profundidade Temporal de Inferência e Planejamento</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#como-configurar-o-modelo-generativo"><i class="fa fa-check"></i><b>6.5</b> Como configurar o modelo generativo?</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#configurando-as-variáveis-do-modelo-gerador"><i class="fa fa-check"></i><b>6.5.1</b> Configurando as Variáveis do Modelo Gerador</a></li>
<li class="chapter" data-level="6.5.2" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#quais-partes-do-modelo-generativo-são-fixas-e-o-que-é-aprendido"><i class="fa fa-check"></i><b>6.5.2</b> Quais partes do modelo generativo são fixas e o que é aprendido?|</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#configurando-o-processo-gerador"><i class="fa fa-check"></i><b>6.6</b> Configurando o Processo Gerador</a></li>
<li class="chapter" data-level="6.7" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#simulando-visualizando-analisando-e-ajustando-dados-usando-inferência-ativa"><i class="fa fa-check"></i><b>6.7</b> Simulando, Visualizando, Analisando e Ajustando Dados Usando Inferência Ativa</a></li>
<li class="chapter" data-level="6.8" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#resumo-5"><i class="fa fa-check"></i><b>6.8</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html"><i class="fa fa-check"></i><b>7</b> Inferência ativa em tempo discreto</a>
<ul>
<li class="chapter" data-level="7.1" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#introdução-6"><i class="fa fa-check"></i><b>7.1</b> Introdução</a></li>
<li class="chapter" data-level="7.2" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#processamento-perceptivo"><i class="fa fa-check"></i><b>7.2</b> Processamento Perceptivo</a></li>
<li class="chapter" data-level="7.3" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#tomada-de-decisão-e-planejamento-como-inferência"><i class="fa fa-check"></i><b>7.3</b> Tomada de decisão e planejamento como inferência</a></li>
<li class="chapter" data-level="7.4" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#busca-de-informações"><i class="fa fa-check"></i><b>7.4</b> Busca de informações</a></li>
<li class="chapter" data-level="7.5" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#aprendizado-e-novidade"><i class="fa fa-check"></i><b>7.5</b> Aprendizado e Novidade</a></li>
<li class="chapter" data-level="7.6" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#inferência-hierárquica-ou-profunda"><i class="fa fa-check"></i><b>7.6</b> Inferência Hierárquica ou Profunda</a></li>
<li class="chapter" data-level="7.7" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#resumo-6"><i class="fa fa-check"></i><b>7.7</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html"><i class="fa fa-check"></i><b>8</b> Inferência ativa em tempo contínuo</a>
<ul>
<li class="chapter" data-level="8.1" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#introdução-7"><i class="fa fa-check"></i><b>8.1</b> Introdução</a></li>
<li class="chapter" data-level="8.2" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#controles-de-movimento"><i class="fa fa-check"></i><b>8.2</b> Controles de movimento</a></li>
<li class="chapter" data-level="8.3" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#sistemas-dinâmicos"><i class="fa fa-check"></i><b>8.3</b> Sistemas Dinâmicos</a></li>
<li class="chapter" data-level="8.4" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#sincronia-generalizada"><i class="fa fa-check"></i><b>8.4</b> Sincronia Generalizada</a></li>
<li class="chapter" data-level="8.5" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#modelos-híbridos-discretos-e-contínuos"><i class="fa fa-check"></i><b>8.5</b> Modelos Híbridos (Discretos e Contínuos)</a></li>
</ul></li>
<li class="appendix"><span><b>Apêndice</b></span></li>
<li class="chapter" data-level="A" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html"><i class="fa fa-check"></i><b>A</b> Bases Matemáticas</a>
<ul>
<li class="chapter" data-level="A.1" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#introdução-8"><i class="fa fa-check"></i><b>A.1</b> Introdução</a></li>
<li class="chapter" data-level="A.2" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#álgebra-linear"><i class="fa fa-check"></i><b>A.2</b> Álgebra Linear</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#o-básico"><i class="fa fa-check"></i><b>A.2.1</b> O básico</a></li>
<li class="chapter" data-level="A.2.2" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#derivadas"><i class="fa fa-check"></i><b>A.2.2</b> Derivadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="as-equações-da-inferência-ativa.html"><a href="as-equações-da-inferência-ativa.html"><i class="fa fa-check"></i><b>B</b> As equações da inferência ativa</a></li>
<li class="chapter" data-level="" data-path="dicionário.html"><a href="dicionário.html"><i class="fa fa-check"></i>Dicionário</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Inferencia Ativa</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="os-modelos-geradores-de-inferência-ativa" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">> 4</span> Os Modelos Geradores de Inferência Ativa<a href="os-modelos-geradores-de-inferência-ativa.html#os-modelos-geradores-de-inferência-ativa" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Every­thing should be made as ­simple as pos­si­ble, but not simpler.
—­Albert Einstein</p>
<div id="introdução-3" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Introdução<a href="os-modelos-geradores-de-inferência-ativa.html#introdução-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este capítulo complementa o tratamento conceitual da Inferência Ativa
dos capítulos anteriores com um tratamento mais formal. Especificamente,
estabelece a relação entre energia livre e inferência Bayesiana, a forma
dos modelos generativos tipicamente usados na Inferência Ativa, e a
dinâmica obtida da minimização da energia livre para esses modelos. Um
foco principal é como o tempo é representado em um modelo generativo.
Veremos a distinção entre modelos generativos formulados em tempo
contínuo e aqueles que tratam o tempo como uma sequência de eventos.
Finalmente, apresentamos a ideia de passagem de mensagens inferenciais,
que subscreve teorias proeminentes em neurobiologia — incluindo
codificação preditiva.</p>
</div>
<div id="da-inferência-bayesiana-à-energia-livre" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Da Inferência Bayesiana à Energia Livre<a href="os-modelos-geradores-de-inferência-ativa.html#da-inferência-bayesiana-à-energia-livre" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Nos dois capítulos anteriores, delineamos algumas das conexões
importantes entre a Inferência Ativa e outros paradigmas estabelecidos
nas neurociências. No capítulo 2, nos concentramos na noção de cérebro
bayesiano (Knill e Pouget 2004, Doya 2007) – um de seus parentes mais
próximos – que fornece uma maneira útil de pensar sobre algumas das
consequências da inferência ativa de uma perspectiva mais formal.</p>
<p>Especificamente, ele nos ajuda a enquadrar os problemas que um agente
envolvido na Inferência Ativa deve resolver. Em termos gerais, esses são
o problema de inferir estados do mundo (percepção) e inferir um curso de
ação (planejamento). Embora seja tentador igualar a otimalidade de Bayes
com a inferência Bayesiana exata, a inferência exata geralmente é
computacionalmente intratável ou mesmo inviável. Em aplicações de
psicologia cognitiva e inteligência artificial, é comum considerar
formas limitadas de inferência e racionalidade. Destacamos alguns
exemplos no capítulo 3. Sob uma estrutura bayesiana, isso se traduz no
uso de inferência aproximada. Esses métodos compreendem métodos de
amostragem e métodos variacionais – nos quais se baseia a inferência
ativa. Nesta seção, recapitulamos os elementos básicos da inferência
bayesiana e suas manifestações variacionais (Beal 2003, Wainwright e
Jordan 2008). Ao fazê-lo, esperamos fornecer alguma intuição para o
papel da energia livre e enfatizar a importância dos modelos generativos
na elaboração de inferências sobre o mundo.</p>
<p>Este capítulo é mais técnico do que os capítulos 1 a 3, apelando para um
pouco de álgebra linear, diferenciação e expansão em série de Taylor. Os
leitores interessados nos detalhes ou que precisem de uma atualização
podem recorrer aos apêndices para obter os antecedentes necessários.
Aqueles que não querem se aprofundar nos fundamentos teóricos podem
pular este capítulo. Ao longo, explicamos as principais implicações de
cada equação - para que seja possível desenvolver uma compreensão dos
pontos conceituais importantes aqui, mesmo sem seguir o argumento
formal.</p>
<p>Um bom ponto de partida é o teorema de Bayes. Lembre-se do capítulo 2
que esse teorema expressa uma igualdade entre o produto de uma
verossimilhança a priori e o produto de uma verossimilhança a
posteriori. Isso é reproduzido na equação 4.1:</p>
<p><span class="math display">\[P(x)P(y|x) = P(x|y)P(y)\]</span>
<span class="math display">\[ P(y) = \sum_x P(y|x) = \sum_x P(y|x)P(x) \qquad\qquad (4.1)\]</span></p>
<p>A primeira linha da equação 4.1 é o teorema de Bayes. A segunda linha
mostra que a verossimilhança marginal (ou evidência do modelo), <span class="math inline">\(P(y)\)</span>,
pode ser calculada diretamente a partir do anterior e da
verossimilhança.<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a> Isso mostra que a anterior e a verossimilhança -
que juntas compõem o modelo generativo - são suficientes para
calcularmos a evidência do modelo e a probabilidade posterior. Apesar
disso, nem sempre é fácil fazê-lo. A soma (ou integração, se lidar com
variáveis contínuas) na equação 4.1 pode ser computacionalmente ou
analiticamente intratável. Uma maneira de resolver isso – o ponto de
partida da inferência variacional – é converter esse problema de
integração potencialmente difícil em um problema de otimização. Para
entender como isso funciona, precisamos recorrer à desigualdade de
Jensen, que diz que “o log <a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> de uma média é sempre maior ou igual à
média de um log”. A Figura 4.1 fornece uma intuição gráfica de por que
esse é o caso.</p>
<div class="figure">
<img src="images/Figura_4_1.png" alt="" />
<p class="caption"><strong>Figura 4.1</strong> Função logarítmica fornecendo intuição para a
desigualdade de Jensen. Se tivéssemos apenas dois pontos de dados (<span class="math inline">\(x1\)</span>
e <span class="math inline">\(x2\)</span>), ou poderíamos pegar sua média (<span class="math inline">\(\mathbb E[x]\)</span>) e encontrar seu
log, ou poderíamos pegar o log de cada ponto de dados e então tirar a
média desses (<span class="math inline">\(\mathbb {E}[ln x]\)</span>). Este último (<span class="math inline">\(\mathbb{E}[ln x]\)</span>)
estará sempre abaixo do primeiro (<span class="math inline">\(ln \mathbb{E}[x]\)</span>), devido à
concavidade da função logarítmica, a menos que os pontos de dados sejam
os mesmos (onde o logaritmo da média e a média de o log são iguais).
Essa desigualdade vale para qualquer número de pontos de
dados.</p>
</div>
<p>Para tirar proveito dessa propriedade, podemos reescrever a equação 4.1
multiplicando o termo dentro da soma na segunda linha por uma função
arbitrária (<span class="math inline">\(Q\)</span>) dividida por ela mesma (isso é equivalente a
multiplicar por um, então a igualdade ainda é válida) e tomando o
logaritmo de cada lado. Matematicamente, isso não muda nada. No entanto,
agora podemos interpretar a expressão como uma expectativa
(<span class="math inline">\(\mathbb{E}\)</span>)<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a>: de uma razão entre duas probabilidades e assim
explorar a desigualdade de Jensen:</p>
<p><span class="math display">\[ \ln P(y) = \ln \sum_x P(y,x){Q(x)\over Q(x)}= \ln \mathbb{E_{Q(x)}[{P(y,x)\over Q(x)}]} \ge \mathbb{E}_{Q(x)} [\ln {P(y,x) \over Q(x)}] \triangleq -F[Q,y] \qquad(4.2)\]</span></p>
<p>A segunda linha desta equação usa o fato de que temos uma expectativa
logarítmica e que, pela desigualdade de Jensen, esta deve ser sempre
maior ou igual à expectativa logarítmica. Esse movimento às vezes é
chamado de amostragem de importância. O lado direito dessa desigualdade
é conhecido como energia livre variacional (negativa):<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> quanto menor
a energia livre, mais próxima está da evidência do modelo logarítmico
negativo. Com isso em mente, podemos reescrever o teorema de Bayes
(equação 4.1) na forma logarítmica, tomar sua média sob a distribuição
posterior e divulgar a relação entre isso e as quantidades da equação
4.2:</p>
<p><span class="math display">\[ \ln P(x,y) = \ln P(y) + \ln P(x|y) \Longrightarrow  \]</span>
<span class="math display">\[ \mathbb{E}_{P(x|y)} [\ln P(x,y)] = \ln P(y) + \mathbb{E}_{P(x|y)}[\ln P(x|y)] \qquad\qquad (4.3) \]</span></p>
<p><span class="math display">\[ \mathbb{E}_{Q(x)} [\ln P(x,y)] = \ln -F[Q,y] + \mathbb{E}_{Q(x)}[\ln Q(x)]\]</span>
A segunda linha decorre do fato de que a probabilidade logarítmica de y
não é uma função de x, portanto, tomar uma expectativa sob a
distribuição a posteriori não altera essa quantidade. A Equação 4.3
fornece alguma intuição para os papéis da energia livre e da
distribuição Q — as duas quantidades que eram difíceis de calcular sem
a aproximação variacional. A primeira desempenha o papel de evidência do
modelo logarítmico negativo, enquanto a segunda atua como se fosse a
probabilidade posterior. Mais formalmente, podemos reorganizar a energia
livre como fizemos no capítulo 2 para quantificar a relação entre a
energia livre e a evidência do modelo:</p>
<p><span class="math display">\[ F[Q,y] = \begin{matrix} \underbrace {D_{KL}[Q(x) ||P(x|y) ] } \\ divergência \end{matrix} - \begin{matrix} \underbrace {\ln P(y)} \\ Log\;da\;Evidência\;do\;modelo \end{matrix} \]</span></p>
<p><span class="math display">\[D_{KL}[Q(x) ||P(x|y) ] = \mathbb{E}_{Q(x)}[\ln Q(x)-\ln P(x|y)]\]</span> A
primeira linha da equação 4.4 mostra a energia livre expressa em termos
de KL-Divergence e uma evidência de log negativo. A KL-Divergence é
definida na segunda linha como a diferença esperada entre duas
probabilidades logarítmicas. Isso é frequentemente usado como uma medida
de quão diferentes duas distribuições de probabilidade são uma da outra.</p>
<p>Às vezes, o uso de energia livre é motivado diretamente em função dessa
divergência. O argumento é que, se nosso objetivo é realizar inferência
Bayesiana aproximada, precisamos encontrar um posterior aproximado que
melhor corresponda ao posterior exato. Como tal, podemos selecionar uma
medida da divergência entre os dois – da qual o KL-Divergence na
equação 4.4 é um exemplo – e minimizá-lo. Como não sabemos o posterior
exato, não podemos usar essa divergência diretamente. Uma solução é
adicionar o termo de evidência logarítmica, que pode ser combinado com o
logaritmo posterior para formar a probabilidade conjunta (que sabemos
porque este é o modelo generativo). O resultado é a energia livre.</p>
<p>Uma consequência interessante dessa perspectiva é que há alguma
ambiguidade sobre qual medida de divergência usar. Se quisermos fazer o
posterior aproximado e exato o mais próximo possível, poderíamos usar o
outro KL-Divergence, onde Q e P são trocados, ou escolher entre uma
grande família de divergências, cada uma das quais enfatizando
diferentes aspectos da diferença entre distribuições. No entanto, as
ideias expostas no capítulo 3 destacam a importância da autoevidência
para os sistemas envolvidos na Inferência Ativa. Portanto, estamos
procurando principalmente um esquema de maximização de evidências
tratável e apenas secundariamente procurando minimizar a divergência.
Nessa perspectiva, não há ambiguidade quanto à medida de divergência a
ser usada. Isso emerge do uso da desigualdade de Jensen.</p>
</div>
<div id="modelos-geradores" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Modelos Geradores<a href="os-modelos-geradores-de-inferência-ativa.html#modelos-geradores" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para calcular a energia livre, precisamos de três coisas: dados, uma
família de distribuições variacionais e um modelo generativo
(compreendendo uma a priori e uma probabilidade). Nesta seção,
descrevemos dois tipos muito gerais de modelos generativos usados para
Inferência Ativa e a forma que a energia livre assume em relação a cada
um. A primeira trata de inferências sobre variáveis categóricas (por
exemplo, identidade do objeto) e é formulada como uma sequência de
eventos. O segundo trata de inferências sobre variáveis contínuas (por
exemplo, contraste de luminância) e é formulado em tempo contínuo usando
equações diferenciais estocásticas. Antes de especificar os detalhes
desses modelos, revisamos um formalismo gráfico que expressa as
dependências implícitas em um modelo generativo.</p>
<p>A Figura 4.2 mostra vários exemplos de modelos generativos expressos
como gráficos de fatores, escolhidos para fornecer alguma intuição para
os tipos de coisas que podem ser articuladas dessa maneira. Estes
representam os fatores (por exemplo, anterior e probabilidade) de um
modelo generativo como quadrados e as variáveis nesse modelo (estados ou
dados ocultos) em círculos. As setas indicam a direção da causalidade
entre essas variáveis. O gráfico superior esquerdo mostra a forma mais
simples que esses modelos podem assumir, com um estado oculto <span class="math inline">\((x)\)</span>
causando dados <span class="math inline">\((y)\)</span>. A priori neste modelo é mostrada como fator 1, e a
probabilidade é fator 2. Os outros gráficos estendem essa ideia
introduzindo variáveis adicionais. No canto superior direito, z
desempenha o papel de um segundo estado oculto, de modo que y depende
dos estados de x e z.</p>
<p>Como exemplo, considere um teste de diagnóstico clínico. Nesse cenário,
o gráfico simples no canto superior esquerdo pode ser interpretado como
a presença ou ausência de uma doença <span class="math inline">\((x)\)</span> e o resultado do teste <span class="math inline">\((y)\)</span>.
O prior é então a prevalência da doença, enquanto a probabilidade
especifica as propriedades do teste. Estes incluem sua especificidade (a
probabilidade de um resultado negativo na ausência da doença) e a
sensibilidade (a probabilidade de um resultado positivo na presença da
doença). Podemos então pensar no modelo em termos do mecanismo pelo qual
um resultado de teste é obtido – indo de cima para baixo no gráfico de
fatores. Primeiro, amostramos uma pessoa de uma população com
prevalência conhecida de uma doença. Se eles tiverem a doença, eles
gerarão um resultado de teste positivo verdadeiro com probabilidade dada
pela sensibilidade do teste e um falso negativo caso contrário. Caso não
tenham a doença, gerarão um verdadeiro negativo com probabilidade dada
pela especificidade, e um falso positivo caso contrário.</p>
<div class="figure">
<img src="images/Figura_4_2.png" alt="" />
<p class="caption"><strong>Figura 4.2</strong> Dependências entre variáveis em um modelo
probabilístico (gráfico). Os círculos representam variáveis aleatórias
(ou seja, as coisas sobre as quais temos crenças); os quadrados
representam as distribuições de probabilidade que descrevem as relações
entre essas variáveis. Uma seta de um círculo para outro através de um
quadrado indica que a variável do segundo círculo depende daquela do
primeiro círculo e que essa dependência é capturada na distribuição de
probabilidade representada pelo quadrado.</p>
</div>
<p>Seguindo o mesmo exemplo, podemos interpretar os outros gráficos de
fatores. No painel superior direito, <span class="math inline">\(x\)</span> e <span class="math inline">\(z\)</span> poderia ser a presença ou
ausência de duas doenças diferentes, qualquer uma das quais poderia dar
um resultado de teste positivo. No canto inferior esquerdo, <span class="math inline">\(w\)</span>
desempenha o papel de dados. Ambos <span class="math inline">\(y\)</span> e <span class="math inline">\(w\)</span> são gerados por <span class="math inline">\(x\)</span> e podem
representar (por exemplo) dois testes diagnósticos diferentes que são
informativos sobre o mesmo processo de doença. Finalmente, o gráfico
inferior direito trata <span class="math inline">\(x\)</span> e <span class="math inline">\(v\)</span> como estados ocultos, mas introduz uma
estrutura hierárquica na qual <span class="math inline">\(v\)</span> causa <span class="math inline">\(x\)</span> causa <span class="math inline">\(y\)</span>. Aqui poderíamos
pensar em <span class="math inline">\(v\)</span> como fornecendo um contexto ou um fator predisponente (por
exemplo, polimorfismo genético) para a presença ou ausência da doença x,
que pode ser testada medindo y. Em princípio, podemos adicionar um
número arbitrário de variáveis a essa hierarquia.</p>
<p>Modelos generativos desse tipo são frequentemente usados para tarefas
perceptivas estáticas, como reconhecimento de objetos ou integração de
pistas. Os modelos generativos usados para inferência ativa diferem de
uma maneira importante: eles evoluem ao longo do tempo à medida que
novas observações são amostradas, e as observações que são adicionadas
dependem (via ação) de crenças sobre variáveis no modelo. Isso tem duas
implicações principais. Primeiro, as dependências condicionais incluem
as dependências de variáveis ocultas em um determinado momento daquelas
em momentos anteriores. Em segundo lugar, esses modelos às vezes incluem
hipóteses sobre “como estou agindo” como variáveis ocultas.</p>
<p>A Figura 4.3 ilustra as duas formas básicas do modelo generativo
dinâmico usado na inferência ativa (Friston, Parr e de Vries 2017) na
forma de gráfico fatorial (Loeliger 2004, Loeliger et al. 2007). O
gráfico superior mostra um Processo de Decisão Markov Parcialmente
Observável (POMDP), que expressa um modelo no qual uma sequência de
estados evolui ao longo do tempo. A cada passo de tempo, o estado atual
é condicionalmente dependente do estado no momento anterior e da
política (π ) que está sendo seguida. As políticas aqui podem ser
pensadas como indexadoras de trajetórias alternativas, ou sequências de
ações, que poderiam ser seguidas. Cada ponto no tempo está associado a
uma observação (o) que depende apenas do estado naquele momento. Esse
tipo de modelo é muito útil para lidar com tarefas de planejamento
sequencial – por exemplo, navegar em um labirinto (Kaplan e Friston
2018) – ou processos de tomada de decisão que envolvem a seleção entre
alternativas (por exemplo, categorização de uma cena [Mirza et al. 2016]).</p>
<div class="figure">
<img src="images/Figura_4_3.png" alt="" />
<p class="caption"><strong>Figura 4.3</strong> Dois modelos generativos dinâmicos (usando a mesma
notação gráfica da figura 4.2) aos quais recorreremos no restante deste
livro. Topo: Processo de Decisão Markov Parcialmente Observável (POMDP),
definido em termos de uma sequência de estados evoluindo ao longo do
tempo (indexados pelo subscrito). Abaixo: Modelo de tempo contínuo, do
tipo implícito por equações diferenciais estocásticas (com a notação
principal indicando derivadas temporais).</p>
</div>
<p>O gráfico inferior na figura 4.3 mostra um modelo gráfico muito
semelhante, mas expresso em tempo contínuo. Em vez de representar uma
trajetória como uma série de estados, este modelo representa a posição
atual, velocidade e aceleração (e sucessivas derivadas temporais) de um
estado (x). Esses valores (referidos como coordenadas generalizadas de
movimento) podem ser usados ​​para reconstruir uma trajetória usando uma
expansão em série de Taylor (consulte o apêndice A para uma introdução
às aproximações em série de Taylor neste contexto). A relação entre um
estado e sua derivada temporal aqui depende de (lentamente variando)
causas (v) que desempenham um papel semelhante às políticas acima. Como
antes, os estados geram observações ( y). A diferença de notação (s, π,
o vs. x, v, y) é usada para enfatizar a diferença entre variáveis
​​categóricas que evoluem em tempo discreto e variáveis ​​contínuas que
evoluem em tempo contínuo. Da mesma forma, daqui em diante, usaremos p e
q minúsculo para densidades de probabilidade sobre variáveis ​​contínuas
e P e Q maiúsculo para distribuições sobre variáveis ​​categóricas. As
Seções 4.4 e 4.5 descompactarão esses modelos com mais detalhes e
mostrarão como a minimização da energia livre em cada caso leva a um
conjunto de equações que descrevem a dinâmica dos processos
inferenciais.</p>
</div>
<div id="inferência-ativa-em-tempo-discreto" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Inferência ativa em tempo discreto<a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-tempo-discreto" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Nesta seção, focamos no modelo de tempo discreto descrito acima. Isso é
importante para entender uma série de processos cognitivos que lidam com
inferências categóricas e seleção entre hipóteses alternativas. Esse
formalismo também facilita o exame do problema clássico de
prospecção-aproveitamento e ilustra como a inferência ativa resolve
isso.</p>
<div id="processos-de-decisão-markov-parcialmente-observáveis" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Processos de Decisão Markov Parcialmente Observáveis<a href="os-modelos-geradores-de-inferência-ativa.html#processos-de-decisão-markov-parcialmente-observáveis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Conforme mostrado na figura 4.3, um POMDP expressa a evolução ao longo
do tempo de uma sequência de estados ocultos que dependem de uma
política. Para especificar formalmente esse processo, precisamos levar
em conta a forma de cada um dos nós de fator quadrado na figura.
Primeiro, descrevemos cada um desses fatores. Em seguida, nós os
combinamos para expressar a distribuição conjunta que constitui o modelo
generativo.</p>
<p>Assim como no exemplo simples da regra de Bayes dado no capítulo 2,
podemos separar os fatores entre aqueles que representam uma
probabilidade e aqueles que se combinam para formar uma a priori. A
probabilidade é semelhante à usada anteriormente e expressa a
probabilidade de um resultado (observável) dado um estado (oculto). Se
os resultados e os estados são variáveis categóricas, a probabilidade é
uma distribuição categórica, parametrizada por uma matriz, A:</p>
<p><span class="math display">\[P(o_\tau|s_\tau)=Cat(A)\]</span>
<span class="math display">\[A_{ij}=P(o_\tau=i | s_\tau = j) \qquad \qquad (4.5)\]</span> A segunda linha
aqui detalha o que significa a notação Cat (ou seja, especificação de
uma distribuição categórica). Isso representa os nós rotulados como “2”
na figura 4.3. A prioridade sobre a sequência (expressa usando o símbolo
~) de estados ocultos depende de duas coisas: a anterior sobre o estado
inicial (especificado por um vetor, D) e crenças sobre como o estado em
um momento transita para o estado seguinte ( especificado como uma
matriz, B):</p>
<p><span class="math display">\[P(\tilde S|\pi)=P(S_1)\prod P(S_{\tau+1 | S_{\tau}}, \pi)\]</span>
<span class="math display">\[P(S_1)=Cat(D) \qquad\qquad\qquad\qquad(4.6)\]</span>
<span class="math display">\[P(S_{\tau+1}|S_\tau,\pi)=Cat(B_{\pi\tau})\]</span></p>
<p>Juntos, eles representam os “3” nós na figura 4.3. Observe que as
transições são condicionalmente dependentes da política escolhida.
Assim, podemos interpretar as prioris da equação 4.6, combinadas com a
verossimilhança da equação 4.5, como expressando um modelo (π ) de uma
sequência comportamental. Para nos permitir selecionar entre esses
modelos (ou seja, para formar um plano), precisamos de uma crença prévia
sobre a sequência mais provável. Para uma criatura minimizadora de
energia livre, uma priorização autoconsistente é que as políticas mais
prováveis são aquelas que levarão à menor energia livre esperada (G) no
futuro:</p>
<p><span class="math display">\[P(\pi)=Cat(\pi_0)\]</span>
<span class="math display">\[\pi_0=\sigma(-G) \qquad\qquad\qquad\qquad\qquad (4.7)\]</span>
<span class="math display">\[G_\pi = G(\pi)=-\mathbb{E_\tilde Q[D_{KL}[Q(\tilde s|\tilde o, \pi) || Q(\tilde s| \pi)]]}-\mathbb{E_\tilde Q[\ln P(\tilde o|C)]}\]</span>
<span class="math display">\[\tilde Q(o_\tau, s_\tau | \pi) \triangleq P(o_\tau |s_\tau)Q(s_\tau | \pi)\]</span></p>
<p>Esta equação, sendo de fundamental importância para a Inferência Ativa,
vale a pena descompactar com mais profundidade. As duas primeiras linhas
expressam a probabilidade a priori para cada política, conforme
parametrizada por <span class="math inline">\(\pi_0\)</span>, como sendo relacionada à energia livre
esperada negativa associada àquela política . A função softmax
<span class="math inline">\((\sigma)\)</span> impõe normalização (ou seja, garante que a probabilidade
sobre as políticas soma um)</p>
<p>As duas linhas finais da equação 4.7 expressam a forma da energia livre
esperada.</p>
<p>Observe a semelhança entre isso e a forma funcional da energia livre
(equação 4.4) - com uma probabilidade logarítmica de resultados e uma
KL-Divergência. A principal diferença aqui é que a expectativa é tomada
em relação à densidade preditiva posterior conforme definida pela
igualdade final. Essa distribuição expressa uma probabilidade conjunta
sobre estados e observações futuras. Fundamentalmente, isso significa
que podemos calcular a energia livre esperada no futuro – algo que não
poderíamos fazer com a energia livre variacional, que depende de
observações (presentes e passadas). Além disso, observe que a
distribuição sobre os resultados depende dos parâmetros (C ) e da
reversão do sinal da KL-Divergência, que é consequência da expectativa
sob a probabilidade preditiva posterior. Este último ponto pode causar
alguma confusão, por isso vale a pena explicar explicitamente por que
isso acontece. No contexto da energia livre variacional, a
KL-Divergência foi a diferença esperada entre a probabilidade
logarítmica do posterior aproximado e a probabilidade logarítmica do
posterior exato (equação 4.4). O termo análogo na energia livre esperada
é a diferença esperada entre o posterior aproximado e o posterior exato
que obteríamos com base em toda a trajetória de resultados, usando
crenças posteriores atuais como se fossem anteriores. Descompactando
isso, temos o seguinte:</p>
<p><span class="math display">\[\mathbb E[\ln Q(\tilde s | \pi) - \ln Q(\tilde s | \tilde o, \pi) ]\]</span>
<span class="math display">\[= \mathbb E_{Q(\tilde o|\pi)}[ \mathbb E_{Q(\tilde s | \tilde o,\pi)}[\ln Q(\tilde s|\pi) - \ln Q(\tilde s|\tilde o, \pi) ] ]\]</span></p>
<p><span class="math display">\[= \mathbb E_{Q(\tilde o|\pi)}[ \mathbb E_{Q(\tilde s | \tilde o,\pi)}[\ln Q(\tilde s|\tilde o,\pi) - \ln Q(\tilde s| \pi) ] ] \qquad\qquad\qquad\qquad (4.8)\]</span></p>
<p><span class="math display">\[= - \mathbb E_{Q(\tilde o|\pi)}[D_{KL}[Q(\tilde s | \tilde o, \pi) || Q(\tilde s| \pi)]]\]</span></p>
<p>Aqui vemos que a ordem em que as expectativas devem ser tomadas é
importante.</p>
<p>Ele provoca uma inversão de sinal em relação ao termo análogo na energia
livre variacional. Isso subscreve uma diferença importante entre as duas
quantidades. A energia livre esperada é minimizada selecionando aquelas
observações que causam uma grande mudança nas crenças, em contraste com
a energia livre variacional que é minimizada quando as observações
obedecem às crenças atuais. Essa é a diferença entre otimizar as crenças
em relação aos dados que já foram coletados (minimização variacional de
energia livre) e selecionar os dados que melhor otimizarão as crenças
(minimização de energia livre esperada).</p>
<p>Isso reitera que a Inferência Ativa usa dois construtos, energia livre
variacional (F ) e energia livre esperada (G), que são matematicamente
relacionados, mas desempenham papéis distintos e complementares. A
energia livre variacional é a quantidade primária que é minimizada ao
longo do tempo. Ele é otimizado em relação a um modelo generativo, que
pode incluir políticas (ou sequências de ações). Assim como em todos os
outros estados ocultos, o agente precisa atribuir uma probabilidade
anterior às políticas - porque as políticas são apenas mais uma variável
aleatória no modelo generativo. A Inferência Ativa usa uma priori que é
(vagamente falando) equivalente à crença de que se minimizará a energia
livre no futuro: ou seja, a energia livre esperada. Em outras palavras,
a energia livre esperada fornece uma prioridade sobre as políticas e,
portanto, é um pré-requisito para minimizar a energia livre variacional.</p>
<p>No capítulo 2 vimos que, assim como a energia livre variacional, a
energia livre esperada pode ser rearranjada de várias maneiras para
revelar várias interpretações. Aqui, nos concentramos em uma
interpretação como a diferença entre o risco e a ambiguidade associada a
uma política. Isso é equivalente à expressão na equação 4.7:</p>
<p>$$$$</p>
<p><span class="math display">\[G(\pi)=\begin{matrix} \underbrace{-\mathbb{E_\tilde Q}[D_{KL}[Q(\tilde S | \tilde o, \pi)||Q(\tilde S | \pi)]]} \\ ganho\;de\;informação  \end{matrix} - \begin{matrix} \underbrace{-\mathbb{E_\tilde Q}[\ln P(\tilde o | C)]} \\ valor\;pragmático \end{matrix} \qquad \qquad \qquad (4.9)\]</span></p>
<p><span class="math display">\[\begin{matrix} \underbrace{\mathbb{E_\tilde Q}[H[P(\tilde o|\tilde s)]]} \\ ambiguidade\;esperada  \end{matrix} +  \begin{matrix} \underbrace{D_{KL}[Q(\tilde o | \pi) || P(\tilde o | C)]} \\ risco \end{matrix}\]</span></p>
<p>Lembre-se do capítulo 2 que o primeiro deles expressa o trade-off entre
buscar novas informações (ou seja, prospecção) e buscar observações
preferidas (ou seja, aproveitamento). Ao minimizar a energia livre
esperada, o equilíbrio relativo entre esses termos determina se o
comportamento é predominantemente exploratório ou explorador. Observe
que o valor pragmático surge como uma crença prévia sobre observações,
onde os parâmetros C dessa distribuição podem ser escolhidos para
refletir o tipo de sistema que estamos interessados em caracterizar (em
termos de suas características ou estados de resultado preferidos).
Seguindo a segunda linha da equação 4.9, podemos reescrever a equação
4.7 na forma algébrica linear da seguinte forma:</p>
<p><span class="math display">\[\pi_o = \sigma(-G)\]</span>
<span class="math display">\[G_\pi = H\cdot  s_{\pi\tau} + o_{\pi\tau} \cdot \varsigma_{\pi\tau}\]</span></p>
<p><span class="math display">\[\varsigma_{\pi\tau} = \ln o_{\pi\tau} - \ln C_\tau \]</span>
<span class="math display">\[H = -diag(A \cdot \ln A)\]</span></p>
<p><span class="math display">\[P(o_\tau | C) = Cat(C_\tau) \qquad \qquad (4.10)\]</span></p>
<p><span class="math display">\[Q(o_\tau | \pi) = Cat(o_{\pi\tau}) , o_{\pi\tau} = As_{\pi\tau} \]</span></p>
<p><span class="math display">\[Q(S_\tau|\pi)=Cat(s_{\pi\tau})\]</span>
<span class="math display">\[Q(S_\tau)=Cat(S_\tau) , s_\tau = \sum_\pi \pi_\pi s_{\pi\tau} \]</span> A
primeira linha da equação 4.10 usa um operador softmax (exponencial
normalizado) para construir uma distribuição de probabilidade
(parametrizada com estatísticas suficientes <span class="math inline">\(π_0\)</span> que soma um do vetor
de energia livre esperado. As linhas dois a quatro expressam os
componentes da energia livre esperada em notação algébrica linear. A
quinta linha mostra que a crença prévia sobre as observações é uma
distribuição categórica (cujas estatísticas suficientes são dadas no
vetor C). A sexta a oitava linhas especificam a relação entre as
quantidades algébricas lineares e as distribuições de probabilidade
associadas. Concluída a especificação do modelo generativo, podemos
agora expressar a energia livre em função das variáveis acima:</p>
<p><span class="math display">\[F = \pi \cdot F \]</span>
<span class="math display">\[F_\pi = \sum_\tau F_{\pi\tau} \qquad\qquad\qquad (4.11)\]</span>
<span class="math display">\[F_{\pi\tau}=s_{\pi\tau} \cdot (\ln s_{\pi \tau} - ln A \cdot o_\tau - \ln B_{\pi\tau}s_{\pi\tau-1})\]</span>
A decomposição disso em uma soma ao longo do tempo é devido à
aproximação implícita de campo médio que assume que podemos fatorar o
posterior aproximado em um produto de fatores:</p>
<p><span class="math display">\[Q(\tilde s | \pi) = \prod_\tau Q(s_\tau|\pi)\]</span> Na forma logarítmica,
isso se torna uma soma, assim como na equação 4.11. Essa fatoração é uma
das muitas possibilidades na inferência variacional – e representa a
opção mais simples. Na prática, isso é muitas vezes ligeiramente
matizado, conforme detalhado no apêndice B.</p>
</div>
<div id="inferência-ativa-em-um-pomdp" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Inferência ativa em um POMDP<a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-um-pomdp" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Até agora, definimos os quatro ingredientes principais para um modelo
generativo de tempo discreto. Estas são a probabilidade <span class="math inline">\((A)\)</span>,
probabilidades de transição <span class="math inline">\((B)\)</span>, crenças anteriores sobre observações
<span class="math inline">\((C)\)</span> e crenças anteriores sobre o estado inicial <span class="math inline">\((D)\)</span>. Uma vez que
essas distribuições de probabilidade são especificadas, um esquema
genérico de passagem de mensagens pode ser empregado para minimizar a
energia livre e resolver o POMDP. Para fazer inferências sobre estados
ocultos sob uma determinada política, definimos a taxa de variação de
uma variável auxiliar <span class="math inline">\((v)\)</span>, que representa o log posterior <span class="math inline">\((s)\)</span>, igual
ao gradiente de energia livre negativo. Uma função softmax (exponencial
normalizada) é então usada para calcular <span class="math inline">\(s\)</span> de <span class="math inline">\(v\)</span>.</p>
<p><span class="math display">\[s_{\pi\tau}=\sigma(v_{\pi\tau})\]</span></p>
<p><span class="math display">\[\dot v_{\pi\tau} =\epsilon_{\pi\tau} \triangleq - \nabla F_{\pi\tau} \qquad (4.13)\]</span></p>
<p><span class="math display">\[ =\ln A \cdot o_\tau + ln B_{\pi\tau}s_{\pi\tau-1} + \ln B_{\pi\tau+1} \cdot s_{\pi\tau-1} - \ln s_{\pi\tau}  \]</span></p>
<p>A Equação 4.13 pode ser considerada como um exemplo de passagem de
mensagens variacional (ver caixa 4.1). Para atualizar crenças sobre
políticas, encontramos a posterior que minimiza a energia livre:</p>
<p><span class="math display">\[ \nabla_\pi F = 0 \Longleftrightarrow  \qquad \qquad (4.14)\]</span></p>
<p><span class="math display">\[ \pi = \sigma(-G-F)\]</span></p>
<p>Para a forma mais simples de POMDP, as equações 4.13 e 4.14 podem ser
usadas para resolver um problema de Inferência Ativa para qualquer
conjunto de matrizes de probabilidade; estes podem ser pensados como
descrevendo percepção e planejamento, respectivamente. Vamos destrinchar
isso com mais detalhes na segunda parte do livro, onde forneceremos
exemplos trabalhados de Inferência Ativa para percepção e planejamento
(e outras funções cognitivas).</p>
<p>As representações gráficas da Figura 4.4 das equações 4.10, 4.13 e 4.14
sugerem possíveis implementações neuronais de minimização de energia
livre no cérebro – se interpretarmos nós como populações neuronais,
bordas como sinapses e mensagens como trocas sinápticas. Em capítulos
posteriores, consideraremos a extensão disso para espaços de estados
fatorados, modelos temporais profundos e a otimização dos parâmetros do
próprio modelo generativo (aprendizagem).</p>
</div>
</div>
<div id="inferência-ativa-em-tempo-contínuo" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Inferência Ativa em Tempo Contínuo<a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-tempo-contínuo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Na seção anterior, tratamos da forma que a Inferência Ativa assume sob
uma escolha particular de modelo generativo. Esses POMDPs são uma
maneira útil de articular uma série de problemas de inferência,
incluindo aqueles que subscrevem o planejamento e a tomada de decisões.
No entanto, quando se trata de interagir com um ambiente real, os
modelos descritos em tempo discreto com variáveis categóricas ficam
aquém. Isso ocorre porque as entradas sensoriais e as saídas motoras são
variáveis em constante evolução. Para explicar isso, agora nos voltamos
para um tipo diferente de modelo generativo. Aplicamos exatamente a
mesma ideia, um gradiente descendente na energia livre variacional, a
esses modelos para encontrar os esquemas de passagem de mensagens
análogos.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Quadro 4.1 Transmissão e inferência de mensagens</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Envoltórios de Markov</strong> <br> Encontramos o conceito de um envoltório de Markov no capítulo 3. No entanto, vale a pena revisar brevemente a ideia aqui. Refere-se a um sistema de múltiplas variáveis que interagem. Um envoltório de Markov para uma determinada variável compreende um subconjunto daquelas que interagem com ela. Se sabemos tudo sobre esse subconjunto, o conhecimento de qualquer coisa fora desse subconjunto não aumenta nosso conhecimento da variável de interesse. A relevância aqui é que podemos fazer inferências sobre uma variável em um modelo gráfico com base em informações locais sobre seu envoltório de Markov. O envoltório de uma variável <span class="math inline">\(x\)</span> são aquelas variáveis que causam <span class="math inline">\(x\)</span> ( pais, <span class="math inline">\(ρ(x)\)</span>), as variáveis que são causadas por <span class="math inline">\(x\)</span> (filhos, <span class="math inline">\(κ (x)\)</span>) e os pais dos filhos de <span class="math inline">\(x\)</span>. Usando esta notação, dois dos esquemas Bayesianos de passagem de mensagens mais comuns usados para inferência aproximada são definidos da seguinte forma:<br><strong>Passagem de mensagem variacional</strong><span class="math display">\[ \ln Q(x)=\mathbb{E}_{Q(\rho(x))}[\ln P(x|\rho(x))]+\mathbb{E}_{\frac {Q(\kappa (x))Q(\rho(\kappa (x)))}{Q(x)}}[\ln P( \kappa (x) | \rho(\kappa (x)))]\]</span>Isso envolve mensagens de todos os constituintes do envoltório de Markov de <span class="math inline">\(x\)</span>, incluindo os pais (através da probabilidade condicional de <span class="math inline">\(x\)</span> dado seus pais) e os filhos. O último depende da probabilidade condicional dos filhos de <span class="math inline">\(x\)</span> dados todos os seus pais – que incluem <span class="math inline">\(x\)</span>. Observe que a expectativa inclui os filhos e os pais das crianças. Como os pais das crianças incluem <span class="math inline">\(x\)</span>, dividimos por <span class="math inline">\(Q(x)\)</span> para garantir que a expectativa inclua apenas o envoltório.<br><strong>Propagação de crenças</strong><span class="math display">\[\ln Q(x) = \ln \mu_\kappa(x) + \ln \mu_\rho(x) \]</span> <span class="math display">\[\mu_\kappa(x)=\mathbb{E_{\frac{\mu_\kappa(\kappa(x))\mu_\rho(\kappa(x))}{\mu_x(\kappa(x))}}}[P( \kappa(x) | \rho(\kappa(x)) )]\]</span><span class="math display">\[\mu_\rho(x)=\mathbb{E_{\frac{\mu_\rho(\rho(x))\mu_\kappa(\rho(x))}{\mu_x(\rho(x))}}}[P( x | \rho(x) )]\]</span>Isso tem basicamente a mesma estrutura que a passagem de mensagens variacional, mas usa uma definição recursiva de mensagens tal que cada mensagem  <span class="math inline">\(μ_a(b)\)</span> sendo a mensagem de <span class="math inline">\(a\)</span> para <span class="math inline">\(b\)</span> ) depende de outras mensagens (as mensagens para <span class="math inline">\(a\)</span>). Há um aspecto direcional nisso, de modo que a mensagem de <span class="math inline">\(a\)</span> para <span class="math inline">\(b\)</span> depende de todas as mensagens para <span class="math inline">\(a\)</span>, exceto a de <span class="math inline">\(b\)</span> (daí a divisão nas expectativas). NB: O uso ligeiramente fora do padrão do operador de expectativa aqui nos permite (1) cobrir variáveis discretas e contínuas e (2) destacar as semelhança entre a passagem de mensagens variacional e a propagação de crenças.</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="images/Figura_4_4.png" alt="" />
<p class="caption"><strong>Figura 4.4</strong> Passagem de mensagens bayesianas. Direita: Dependências
entre diferentes variáveis ​​no esquema de atualização de crenças
descrito no texto principal. Intuitivamente, as crenças atuais sobre os
estados (sob cada política) em cada momento são comparadas com aquelas
que seriam previstas dadas as crenças sobre os estados em outros
momentos (1) e os resultados atuais para calcular os erros de previsão.
Esses erros então impulsionam a atualização dessas crenças (2); dadas
crenças sobre estados sob cada política, podemos então calcular os
gradientes da energia livre esperada (3). Estes são combinados com os
resultados previstos em cada política (omitidos da figura) para calcular
as crenças sobre as políticas (4). Usando uma média do modelo Bayesiano,
podemos então calcular as crenças posteriores sobre os estados
calculados sobre as políticas (5). Este resumo de alto nível da passagem
de mensagens omite algumas conexões intermediárias que podem ser
incluídas (por exemplo, a conexão (4) pode ser descompactada para
incluir explicitamente o cálculo da energia livre esperada). Esquerda:
Este esquema pode ser expandido hierarquicamente (reduzindo ao longo de
etapas de tempo e políticas para simplificar). A ideia-chave é que uma
rede de nível superior pode prever os estados e políticas no nível
inferior e usá-los para fazer inferências sobre o contexto em que
ocorrem. Descompactaremos essa ideia mais adiante no capítulo
7.</p>
</div>
<div id="um-modelo-generativo-para-codificação-preditiva" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Um modelo generativo para codificação preditiva<a href="os-modelos-geradores-de-inferência-ativa.html#um-modelo-generativo-para-codificação-preditiva" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para motivar a forma de modelo generativo usado para estados contínuos,
começamos com o seguinte par de equações:</p>
<p><span class="math display">\[ \begin{matrix} \dot x = f(x,v) + \omega_x \\
y = g (x,v) + \omega_y  \end{matrix}  \qquad\qquad\qquad\qquad (4.15) \]</span>
A primeira delas expressa a evolução de um estado oculto ao longo do
tempo, segundo uma função determinística <span class="math inline">\(( f (x, v))\)</span> e flutuações
estocásticas <span class="math inline">\((ω)\)</span>. A segunda equação expressa a maneira pela qual os
dados são gerados a partir do estado oculto. Em cada caso, as flutuações
são assumidas normalmente distribuídas, dando as seguintes densidades de
probabilidade para a dinâmica e a probabilidade:</p>
<p><span class="math display">\[ \begin{matrix}  
\rho(\dot x | x,v) = N(f(x,v, \prod_x)) \\
\rho(y | x,v) = N(g(x,v, \prod_y))
\end{matrix}  \qquad\qquad\qquad\qquad (4.16) \]</span></p>
<p>Os termos de precisão <span class="math inline">\((\prod)\)</span> são a covariância inversa das
flutuações. Essas duas equações formam o modelo generativo que escreve
os filtros de Kalman-Bucy na engenharia. No entanto, esquemas desse tipo
são limitados pela suposição de flutuações não correlacionadas ao longo
do tempo (ou seja, suposições de Wiener). Isso é inadequado para
inferência em sistemas biológicos, onde as próprias flutuações são
geradas por sistemas dinâmicos e têm um grau de suavidade. Podemos
explicar isso considerando não apenas a taxa de mudança do estado oculto
e o valor atual dos dados, mas também suas velocidades, acelerações e
derivadas temporais subsequentes – isto é, coordenadas generalizadas de
movimento (Friston, Stephan et al. 2010; ver quadro 4.2):</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Quadro 4.2 Coordenadas generalizadas de movimento</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Figura 4.5</strong> Para representar uma trajetória em tempo contínuo, as coordenadas generalizadas de movimento fornecem uma parametrização simples. Isso é baseado em uma expansão polinomial (série de Taylor) em torno do tempo presente para fornecer uma função que nos permite extrapolar para o passado recente e futuro próximo. Os gráficos na figura 4.5 mostram uma trajetória em algum espaço <span class="math inline">\((x)\)</span> ao longo do tempo <span class="math inline">\((\tau)\)</span> como uma linha contínua. Da esquerda para a direita, mostram a trajetória representada em coordenadas generalizadas de movimento com uma, duas e três coordenadas (derivadas temporais sucessivas de x). Esta é a linha tracejada. A expansão aqui é em torno do ponto de tempo inicial. Com cada coordenada generalizada sucessiva, obtemos uma aproximação mais precisa da trajetória para o futuro proximal. Para a maioria das aplicações, cerca de seis coordenadas generalizadas são suficientes.<img src="images/Figura_4_5.png" alt="Figura 4.5" /></td>
</tr>
</tbody>
</table>
<p><span class="math display">\[ \begin{matrix}  
\dot x = f(x,v) + \omega_x &amp; \qquad \qquad y = g(x,v) + \omega_y \\
\dot x&#39; = f&#39;(x&#39;,v&#39;) + \omega&#39;_x &amp; \qquad \qquad y&#39; = g&#39;(x&#39;,v&#39;) + \omega&#39;_y \\
\dot x&#39;&#39; = f&#39;&#39;(x&#39;&#39;,v&#39;&#39;) + \omega&#39;&#39;_x &amp; \qquad \qquad y&#39;&#39; = g&#39;&#39;(x&#39;&#39;,v&#39;&#39;) + \omega&#39;&#39;_y \\
\vdots &amp; \vdots \\
\dot x^{[i]} = f^{[i]}(x^{[i]},v^{[i]}) + \omega^{[i]}_x &amp; \qquad \qquad y^{[i]} = g^{[i]}(x^{[i]},v^{[i]}) + \omega^{[i]}_y \\
\vdots &amp; \vdots
\end{matrix}  \qquad\qquad\qquad\qquad (4.17) \]</span> Essas coordenadas
generalizadas podem ser resumidas de forma mais sucinta ao representar
uma trajetória (novamente usando o símbolo ~) como um vetor com
elementos correspondentes às derivadas sucessivas acima:</p>
<p><span class="math display">\[\left . \begin{matrix} D\tilde x = \tilde f(\tilde x,\tilde v) + \tilde \omega_x \\ \tilde y = \tilde g(\tilde x,\tilde v) + \tilde \omega_y \end{matrix} \right \} \Longrightarrow \begin{matrix} p(\tilde x |\tilde v) = N(D \cdot \tilde f, \tilde \prod_x) \\ p(\tilde y |\tilde x,\tilde v) = N( \tilde g, \tilde \prod_y) \end{matrix} \qquad (4.18) \]</span>
Na equação 4.18, <span class="math inline">\(D\)</span> é uma matriz com uns acima da diagonal principal e
zeros em outros lugares. Isso efetivamente desloca todos os elementos do
vetor para cima e pode ser considerado um operador derivativo. As
matrizes de precisão generalizadas podem ser construídas com base na
suavidade que assumimos para as flutuações, conforme detalhado no
apêndice B. Equipado com uma a priori sobre a causa oculta <span class="math inline">\((v)\)</span>, cuja
relevância ficará mais clara a seguir, isso nos permite escrever as
energia livre para este modelo generativo:</p>
<p><span class="math display">\[ \begin{matrix}
F[\mu,y] &amp; = &amp; -\ln p(\tilde y, \tilde \mu_x , \tilde \mu_\nu) \\
  &amp; = &amp; \frac{1}{2}\tilde \epsilon \cdot \tilde \prod \tilde \epsilon \\
  &amp; = &amp; \frac{1}{2}(\tilde \epsilon_y \cdot \tilde \prod_y \tilde \epsilon_y + \tilde \epsilon_x \cdot \tilde \prod_x \tilde \epsilon_x + \tilde \epsilon_v \cdot \tilde \prod_\nu \tilde \epsilon_\nu  \\
\tilde \epsilon &amp; = &amp; \begin{bmatrix} \tilde \epsilon_y \\ \tilde \epsilon_x \\ \tilde \epsilon_\nu \end{bmatrix} &amp; = \begin{bmatrix} \tilde y - \tilde g(\tilde \mu_x,\tilde \mu_v)\\ D\tilde \mu_x - \tilde f(\tilde \mu_x,\tilde \mu_\nu) \\ \tilde \mu_\nu - \tilde \eta \end{bmatrix} \\
\tilde \prod &amp; = &amp; \begin{bmatrix} \tilde \prod_y &amp; &amp; \\   &amp; \tilde \prod_y &amp; \\  &amp;   &amp; \tilde \prod_y \end{bmatrix}
\end{matrix}  \qquad \qquad \qquad (4.19)\]</span></p>
<p>Na equação 4.19, os termos <span class="math inline">\(\mu\)</span> indicam a moda da densidade posterior
aproximada para os termos <span class="math inline">\(x\)</span> e <span class="math inline">\(\nu\)</span>. A razão pela qual a energia livre
assume uma forma tão simples na primeira linha é que empregamos uma
aproximação de Laplace, conforme detalhado no quadro 4.3. Em resumo,
isso trata todas as densidades de probabilidade como gaussianas, o que
– por meio de uma expansão em série de Taylor – é equivalente a
assumir que estamos operando perto da moda da distribuição. A segunda
linha da equação expressa a probabilidade logarítmica em termos de erros
de predição ponderados de precisão quadrática. Isso omite todos os
termos que são constantes em relação ao modo posterior. A terceira linha
descompacta isso em termos de log de probabilidade, log de probabilidade
de <span class="math inline">\(x\)</span> dado <span class="math inline">\(\nu\)</span> e log antes de <span class="math inline">\(\nu\)</span>.</p>
</div>
<div id="inferência-ativa-como-codificação-preditiva-com-reflexos-motores" class="section level3 hasAnchor" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Inferência Ativa como Codificação Preditiva com Reflexos Motores<a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-como-codificação-preditiva-com-reflexos-motores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Como a variância do posterior aproximado é uma função analítica da moda,
sob a aproximação de Laplace, podemos otimizar a energia livre em
relação a moda. Uma maneira simples de pensar sobre isso é que
precisamos apenas encontrar as estimativas <strong>máximas a posteriori</strong>
(MAP) <a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> para cada estado. Estes são os meios da distribuição a
posteriori que podem ser equipados com sua precisão sem necessidade de
mais inferências através da aproximação de Laplace. (ver quadro 4.3).</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Quadro 4.3 A aproximação de Laplace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>As aproximações de Laplace baseiam-se num princípio semelhante às coordenadas generalizadas de movimento descritas no quadro 4.2. A ideia é que a energia livre pode ser aproximada por uma expansão quadrática em torno do modo posterior (<span class="math inline">\(\mu\)</span>). Em uma dimensão, é o seguinte: <span class="math display">\[ \begin{equation} F[y,q]= E_{q(x)}[\ln q(x) - \ln p(y,x) \end{equation}\]</span> <span class="math display">\[ \begin{aligned}  \approx E_{q(x)} [ \ln q(\mu) +
\begin{matrix}
(x-\mu)\underbrace {\partial_x \ln q(x)|_{x=\mu}}\\{=0}  
\end{matrix} +
\frac{1}{2}(x-\mu)²\partial²_x \ln q(x)|_{x-\mu}  \\
-\ln p(y,\mu)-(x-\mu)\partial_x \ln p(y,x)|_{x=\mu}
- \frac{1}{2}(x-\mu)^2\partial_x^2\ln p(y,x)|_{x=\mu}]
\end{aligned}\]</span> A suposição de que uma expansão quadrática é suficiente equivale a dizer que podemos tratar as probabilidades como gaussianas (como o logaritmo de uma densidade gaussiana é quadrática). Tornando isso explícito, podemos simplificar o acima para o seguinte: <span class="math display">\[q(x)=\mathcal{N}(\mu,\sum{}^{-1} )\]</span> <span class="math display">\[F[y,\mu]= -ln 2\pi\sum-\ln p(y,\mu)-1/2tr\bigg[\sum \partial_x^2 \ln p (y,\mu)\bigg|_{x=\mu} \bigg]\]</span> Sob suposições quadráticas, o único termo que depende da moda é o segundo termo. A omissão dos outros termos leva à expressão na equação 4.19. Podemos encontrar a precisão do posterior aproximado diretamente, uma vez que conhecemos a moda, através da seguinte expansão: <span class="math display">\[ \begin{equation}
\ln q(x) \approx \ln p(x|y)
\\ ln p(x,y) - \ln (y)
\\ \approx \ln p(\mu, y) + (x - \mu) \cdot \underbrace{\partial_x\ln p(x,y)|_{x=\mu}}_{=0}
\\ + \frac{1}{2} (x-\mu)\cdot \partial_x^2 \ln p(x,y)\bigg|_{x=\mu}(x-\mu)-\ln p(y)
\\ \Longrightarrow q(x) \varpropto e^{-\frac{1}{2}(x-\mu)\sum{}^{-1}(x-\mu)} , \quad \sum{}^{-1}=-\partial^2_x \ln p(x,y)\bigg|_{x=\mu}
\end{equation} \]</span> Isso nos diz que a precisão posterior é simplesmente a segunda derivada da probabilidade conjunta avaliada na moda posterior</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[ \begin{equation}
\dot{\tilde \mu} = D\tilde = \mu-\nabla_{\tilde\mu}F
\\ = \nabla_\tilde{\mu} \ln p(\tilde y,\tilde\mu)
\\ = -\nabla_{\tilde\mu}\tilde \epsilon \cdot \tilde \prod \tilde \epsilon
\end{equation} \qquad\qquad(4.20)
\]</span></p>
<p><span class="math display">\[ \begin{equation}
\begin{bmatrix}
\dot{\tilde \mu}_x - D\tilde \mu_x  \\ \dot{\tilde \mu}_\nu - D\tilde \mu_\nu
\end{bmatrix}
= \begin{bmatrix}
\nabla_{{\tilde \mu}_x}\tilde g\cdot \tilde \prod_y\tilde\epsilon_y - D\cdot\tilde\prod_x\tilde\epsilon_x + \nabla_{\tilde\mu_x}\tilde f \cdot \tilde \prod_x \tilde \epsilon_x  
\\  \nabla_{{\tilde \mu}_\nu}\tilde g\cdot \tilde \prod_y\tilde\epsilon_y + \nabla_{\tilde\mu_\nu}\tilde f \cdot \tilde \prod_x \tilde \epsilon_x - \tilde \prod_\nu \tilde \epsilon_\nu
\end{bmatrix}  
\end{equation} \]</span></p>
<p>.Em contraste com as descidas de gradiente que vimos para o esquema de tempo discreto, o lado esquerdo da equação 4.20 é a diferença entre a taxa de variação de <span class="math inline">\(\mu\)</span> e o operador derivativo aplicado a ela. Isso ocorre porque quando a energia livre é minimizada, não faz sentido que a taxa de variação da moda posterior seja zero se a moda posterior associado às taxas de variação for diferente de zero. Em outras palavras, “o movimento da moda deve ser a moda do movimento” no mínimo de energia livre. Isso garante <span class="math inline">\(\mu^{[i]}=\mu^{[i+1]}\)</span> quando a energia livre é minimizada.</p>
<p>Podemos ir um passo além da equação 4.20 e tratar a causa oculta (<span class="math inline">\(\nu\)</span>) como se fossem dados gerados por um nível hierárquico superior, com dinâmica mais lenta (de modo que <span class="math inline">\(\nu\)</span> parece não mudar no nível inferior). Ao fazer isso, podemos encadear uma hierarquia de equações:</p>
<p><span class="math display">\[ \begin{bmatrix}
\vdots \\ \dot{\tilde\mu_x}^{[i]}- D\tilde\mu_x^{[i]} \\ \dot{\tilde\mu_\nu}^{[i]}- D\tilde\mu_\nu^{[i]} \\ \vdots \end{bmatrix} = \begin{bmatrix} \vdots
\\ \nabla_{{\tilde \mu}_x^{(i)}}\tilde g^{(i)}\cdot \tilde \prod_\nu^{(i-1)}\tilde\epsilon_\nu^{(i-1)} - D\cdot\tilde\prod_x^{(i)}\tilde\epsilon_x^{(i)} + \nabla_{\tilde\mu_x}^{(i)}\tilde f^{(i)} \cdot \tilde \prod_x^{(i)} \tilde \epsilon_x^{(i)}
\\ \nabla_{{\tilde \mu}_\nu^{(i)}}\tilde g^{(i)}\cdot \tilde \prod_\nu^{(i-1)}\tilde\epsilon_\nu^{(i-1)} + \nabla_{\tilde\mu_x^{(i)}}\tilde f^{(i)} \cdot \tilde \prod_x^{(i)} \tilde \epsilon_x^{(i)}-\tilde\prod_\nu^{(i)}\tilde\epsilon_\nu^{(i)}
\\ \vdots \end{bmatrix} \qquad (4.21)\]</span></p>
<p><span class="math display">\[\begin{bmatrix} \tilde \epsilon_x^{(i)} \\ \tilde \epsilon_\nu^{(i)} \end{bmatrix} = \begin{bmatrix} D\tilde\mu_x^{(i)}-f^{(i)}(\tilde\mu_x^{(i)}, \tilde\mu_\nu^{(i)}) \\ \tilde\mu_\nu^{(i)} - g^{(i+1)}(\tilde\mu_x^{(i+1)}, \tilde\mu_\nu^{(i+1)}) \end{bmatrix} \]</span>
<span class="math display">\[ \tilde\epsilon_\nu^{(0)} \triangleq \tilde\epsilon_y \]</span>
A Figura 4.6 enfatiza graficamente o papel dos estados ocultos (x) na ligação entre as derivadas temporais dentro de um nível hierárquico e o papel das causas ocultas (v) na ligação entre os níveis hierárquicos. Nesse esquema de codificação preditiva (Rao e Ballard 1999, Friston e Kiebel 2009), níveis mais altos enviam previsões descendentes para níveis mais baixos, que computam erros nessas previsões e os repassam de volta para a hierarquia para atualizar as crenças.</p>
<p>Para completar nossa visão geral da codificação preditiva no contexto da Inferência Ativa, precisamos incorporar a ação. Dado que nosso objetivo é minimizar a energia livre e que as consequências da ação são que alteramos nossos dados sensoriais, temos o seguinte:</p>
<p><span class="math display">\[\begin{equation}\dot u = \nabla_uF = \\ -\nabla_u\tilde y(u) \cdot \tilde\prod_y \tilde\epsilon_y\end{equation} \qquad (4.22)\]</span>
Essa equação diz que minimizamos a energia livre através da ação e que a única parte da energia livre que depende diretamente da ação é o nível mais baixo de erro de previsão. Em outras palavras, a ação simplesmente cumpre as previsões descendentes sobre os dados, minimizando o erro entre as consequências sensoriais da ação previstas e observadas. Uma maneira de pensar sobre isso é como se tivéssemos equipado um esquema de codificação preditivo com arcos reflexos clássicos no nível mais baixo da hierarquia (Adams, Shipp e Friston 2013). Nesta configuração, a Inferência Ativa é apenas codificação preditiva mais arcos reflexos. De uma perspectiva neurobiológica, a ideia é que os aferentes sensoriais entrem no tronco cerebral ou na medula espinhal e façam sinapse nos neurônios motores. Previsões descendentes da entrada sensorial são propagadas do córtex para os neurônios motores, cuja saída depende da diferença entre suas entradas corticais e sensoriais.</p>
<div class="figure">
<img src="images/Figura_4_6.png" alt="" />
<p class="caption"><strong>Figura 4.6</strong> Passagem de mensagens de esquemas de codificação preditivos generalizados. Esquerda: Cálculo de erros de previsão a partir de dados sensoriais, mostrando como eles podem ser propagados para cima através de uma hierarquia. Níveis mais altos enviam previsões para os níveis mais baixos que podem ser comparados com dados sensoriais para calcular esses erros. Direita: Uma única camada da hierarquia ilustra como as populações neuronais que representam diferentes ordens de movimento generalizado interagem umas com as outras.</p>
</div>
<p>Do ponto de vista computacional, um arco reflexo é uma das formas mais simples de controlador; esses desvios corretos nos sinais proprioceptivos previstos e observados. Comportamentos motores mais complexos requerem a geração de sequências de previsões e seu cumprimento em ordem usando arcos reflexos. Esse mecanismo diferencia a inferência ativa de outros esquemas de controle motor biológico, como o controle ótimo, que não são baseados em codificação preditiva e utilizam modelos e controladores inversos mais complexos que os arcos reflexos (Friston 2011). Outra característica peculiar da Inferência Ativa é que ela dispensa noções de valor ou custo usadas no controle ótimo (e aprendizado por reforço); estes são totalmente absorvidos pela noção (geralmente mais expressiva) de priores (ver capítulo 10 para uma discussão mais aprofundada).</p>
</div>
</div>
<div id="resumo-3" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Resumo<a href="os-modelos-geradores-de-inferência-ativa.html#resumo-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este capítulo delineou as ideias formais básicas que sustentam a Inferência Ativa. A principal mensagem a ser retirada é que a inferência Bayesiana (aproximada) pode ser enquadrada como minimizando uma quantidade conhecida como energia livre variacional. Isso depende de um modelo generativo que expresse nossas crenças sobre como os dados são gerados. Examinamos duas formas de modelo generativo que podem ser empregadas dependendo do problema de inferência em questão: especificamente, se estamos interessados em variáveis categóricas ou contínuas. A solução de minimização de energia livre para ambos podem ser descompactados em termos de troca de mensagens entre populações de neurônios, incluindo os esquemas de codificação preditivos generalizados que seguem de modelos contínuos. Finalmente, notamos que a energia livre pode ser minimizada não apenas mudando as crenças – de modo que elas se tornem consistentes com os dados – mas também agindo no mundo para tornar os dados mais consistentes com as crenças. Nos capítulos subsequentes, apelaremos aos formalismos aqui introduzidos e os aplicaremos a configurações mais concretas, oferecendo uma oportunidade de explorar as extensões dos conceitos amplos aqui estabelecidos.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="16">
<li id="fn16"><p>Aqui e ao longo do capítulo, o condicionamento ao modelo é deixado
implícito; portanto, a evidência do modelo é escrita como <span class="math inline">\(P(y)\)</span> e
não <span class="math inline">\(P(y|m)\)</span>.<a href="os-modelos-geradores-de-inferência-ativa.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>Tecnicamente, isso é verdade para qualquer função côncava, mas
estamos preocupados apenas com logaritmos aqui.<a href="os-modelos-geradores-de-inferência-ativa.html#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>Uma expectativa é uma soma ponderada ou integral do termo dentro
dos colchetes; cada termo é ponderado pela probabilidade indicada
pelo índice (ver quadro 2.2).<a href="os-modelos-geradores-de-inferência-ativa.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>Neste livro, seguimos a convenção do físico em que a energia livre
é um limite superior na evidência de log negativo. No entanto,
outras disciplinas (incluindo estatística e aprendizado de máquina)
usam a energia livre negativa como um limite inferior de evidência
(ou ELBO). Estes são completamente equivalentes, mas podem causar
alguma confusão na pesquisa interdisciplinar.<a href="os-modelos-geradores-de-inferência-ativa.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>As estimativas MAP são os estados mais prováveis considerando as
crenças anteriores e os dados disponíveis; contraste isso com
abordagens de máxima verossimilhança que não levam crenças em conta.<a href="os-modelos-geradores-de-inferência-ativa.html#fnref20" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="o-caminho-para-a-inferência-ativa.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="passagem-de-mensagens-e-neurobiologia.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Inferencia Ativa.pdf", "Inferencia Ativa.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
