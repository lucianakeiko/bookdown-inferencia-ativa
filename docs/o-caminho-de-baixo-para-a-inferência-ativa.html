<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>> 2 O Caminho de baixo para a Inferência Ativa | Inferencia Ativa</title>
  <meta name="description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="> 2 O Caminho de baixo para a Inferência Ativa | Inferencia Ativa" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/Figura_1_1.png" />
  <meta property="og:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="> 2 O Caminho de baixo para a Inferência Ativa | Inferencia Ativa" />
  
  <meta name="twitter:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="twitter:image" content="/images/Figura_1_1.png" />

<meta name="author" content="Thomas Parr, Giovanni Pezzulo, and Karl J. Friston" />


<meta name="date" content="2022-06-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="visão-geral.html"/>
<link rel="next" href="o-caminho-para-a-inferência-ativa.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Inferencia Ativa</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Conteúdo</a></li>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html"><i class="fa fa-check"></i>Prefácio</a></li>
<li class="chapter" data-level="1" data-path="visão-geral.html"><a href="visão-geral.html"><i class="fa fa-check"></i><b>1</b> Visão Geral</a>
<ul>
<li class="chapter" data-level="1.1" data-path="visão-geral.html"><a href="visão-geral.html#introdução"><i class="fa fa-check"></i><b>1.1</b> Introdução</a></li>
<li class="chapter" data-level="1.2" data-path="visão-geral.html"><a href="visão-geral.html#como-os-organismos-vivos-persistem-e-agem-adaptativamente"><i class="fa fa-check"></i><b>1.2</b> Como os Organismos Vivos Persistem e Agem Adaptativamente?</a></li>
<li class="chapter" data-level="1.3" data-path="visão-geral.html"><a href="visão-geral.html#inferência-ativa-comportamento-a-partir-dos-primeiros-princípios"><i class="fa fa-check"></i><b>1.3</b> Inferência Ativa: Comportamento a partir dos Primeiros Princípios</a></li>
<li class="chapter" data-level="1.4" data-path="visão-geral.html"><a href="visão-geral.html#estrutura-do-livro"><i class="fa fa-check"></i><b>1.4</b> Estrutura do Livro</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="visão-geral.html"><a href="visão-geral.html#parte-1-inferência-ativa-na-teoria"><i class="fa fa-check"></i><b>1.4.1</b> Parte 1: Inferência Ativa na Teoria</a></li>
<li class="chapter" data-level="1.4.2" data-path="visão-geral.html"><a href="visão-geral.html#parte-2-inferência-ativa-na-prática"><i class="fa fa-check"></i><b>1.4.2</b> Parte 2: Inferência Ativa na Prática</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="visão-geral.html"><a href="visão-geral.html#resumo"><i class="fa fa-check"></i><b>1.5</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>2</b> O Caminho de baixo para a Inferência Ativa</a>
<ul>
<li class="chapter" data-level="2.1" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#introdução-1"><i class="fa fa-check"></i><b>2.1</b> Introdução</a></li>
<li class="chapter" data-level="2.2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#percepção-como-inferência"><i class="fa fa-check"></i><b>2.2</b> Percepção como Inferência</a></li>
<li class="chapter" data-level="2.3" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#inferência-biológica-e-otimização"><i class="fa fa-check"></i><b>2.3</b> Inferência Biológica e Otimização</a></li>
<li class="chapter" data-level="2.4" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#ação-como-inferência"><i class="fa fa-check"></i><b>2.4</b> Ação como Inferência</a></li>
<li class="chapter" data-level="2.5" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-discrepância-entre-o-modelo-e-o-mundo"><i class="fa fa-check"></i><b>2.5</b> Minimizando a discrepância entre o modelo e o mundo</a></li>
<li class="chapter" data-level="2.6" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-energia-livre-variacional"><i class="fa fa-check"></i><b>2.6</b> Minimizando a Energia Livre Variacional</a></li>
<li class="chapter" data-level="2.7" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#energia-livre-esperada-e-planejamento-como-inferência"><i class="fa fa-check"></i><b>2.7</b> Energia Livre Esperada e Planejamento como Inferência</a></li>
<li class="chapter" data-level="2.8" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#o-que-é-energia-livre-esperada"><i class="fa fa-check"></i><b>2.8</b> O que é energia livre esperada?</a></li>
<li class="chapter" data-level="2.9" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#no-final-da-estrada-baixa"><i class="fa fa-check"></i><b>2.9</b> No final da estrada baixa</a></li>
<li class="chapter" data-level="2.10" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#resumo-1"><i class="fa fa-check"></i><b>2.10</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>3</b> O caminho para a inferência ativa</a>
<ul>
<li class="chapter" data-level="3.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#introdução-2"><i class="fa fa-check"></i><b>3.1</b> Introdução</a></li>
<li class="chapter" data-level="3.2" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#envoltórios-de-markov"><i class="fa fa-check"></i><b>3.2</b> Envoltórios de Markov</a></li>
<li class="chapter" data-level="3.3" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-e-auto-evidência"><i class="fa fa-check"></i><b>3.3</b> Minimização de surpresa e auto-evidência</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-como-um-princípio-hamiltoniano-de-menor-ação"><i class="fa fa-check"></i><b>3.3.1</b> Minimização de surpresa como um princípio hamiltoniano de menor ação</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#relações-entre-inferência-cognição-e-dinâmica-estocástica"><i class="fa fa-check"></i><b>3.4</b> Relações entre Inferência, Cognição e Dinâmica Estocástica</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#energia-livre-variacional-evidência-modelo-e-surpresa"><i class="fa fa-check"></i><b>3.4.1</b> Energia Livre Variacional, Evidência Modelo e Surpresa</a></li>
<li class="chapter" data-level="3.4.2" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#energia-livre-esperada-e-inferência-da-trajetória-mais-provável"><i class="fa fa-check"></i><b>3.4.2</b> Energia Livre Esperada e Inferência da Trajetória Mais Provável</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#inferência-ativa-uma-nova-base-para-entender-o-comportamento-e-a-cognição"><i class="fa fa-check"></i><b>3.5</b> Inferência ativa: uma nova base para entender o comportamento e a cognição</a></li>
<li class="chapter" data-level="3.6" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#modelos-políticas-e-trajetórias"><i class="fa fa-check"></i><b>3.6</b> Modelos, Políticas e Trajetórias</a></li>
<li class="chapter" data-level="3.7" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#reconciliação-das-teorias-enativa-cibernética-e-preditiva-sob-inferência-ativa"><i class="fa fa-check"></i><b>3.7</b> Reconciliação das Teorias Enativa, Cibernética e Preditiva sob Inferência Ativa</a></li>
<li class="chapter" data-level="3.8" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#inferência-ativa-da-emergência-da-vida-para-a-atuação"><i class="fa fa-check"></i><b>3.8</b> Inferência Ativa, da Emergência da Vida para a atuação</a></li>
<li class="chapter" data-level="3.9" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#resumo-2"><i class="fa fa-check"></i><b>3.9</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html"><i class="fa fa-check"></i><b>4</b> Os Modelos Geradores de Inferência Ativa</a>
<ul>
<li class="chapter" data-level="4.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#introdução-3"><i class="fa fa-check"></i><b>4.1</b> Introdução</a></li>
<li class="chapter" data-level="4.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#da-inferência-bayesiana-à-energia-livre"><i class="fa fa-check"></i><b>4.2</b> Da Inferência Bayesiana à Energia Livre</a></li>
<li class="chapter" data-level="4.3" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#modelos-geradores"><i class="fa fa-check"></i><b>4.3</b> Modelos Geradores</a></li>
<li class="chapter" data-level="4.4" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-tempo-discreto"><i class="fa fa-check"></i><b>4.4</b> Inferência ativa em tempo discreto</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#processos-de-decisão-markov-parcialmente-observáveis"><i class="fa fa-check"></i><b>4.4.1</b> Processos de Decisão Markov Parcialmente Observáveis</a></li>
<li class="chapter" data-level="4.4.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-um-pomdp"><i class="fa fa-check"></i><b>4.4.2</b> Inferência ativa em um POMDP</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-tempo-contínuo"><i class="fa fa-check"></i><b>4.5</b> Inferência Ativa em Tempo Contínuo</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#um-modelo-generativo-para-codificação-preditiva"><i class="fa fa-check"></i><b>4.5.1</b> Um modelo generativo para codificação preditiva</a></li>
<li class="chapter" data-level="4.5.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-como-codificação-preditiva-com-reflexos-motores"><i class="fa fa-check"></i><b>4.5.2</b> Inferência Ativa como Codificação Preditiva com Reflexos Motores</a></li>
<li class="chapter" data-level="4.5.3" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#testes-odysseus"><i class="fa fa-check"></i><b>4.5.3</b> testes odysseus</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Apêndice</b></span></li>
<li class="chapter" data-level="A" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html"><i class="fa fa-check"></i><b>A</b> Bases Matemáticas</a>
<ul>
<li class="chapter" data-level="A.1" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#introdução-4"><i class="fa fa-check"></i><b>A.1</b> Introdução</a></li>
<li class="chapter" data-level="A.2" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#álgebra-linear"><i class="fa fa-check"></i><b>A.2</b> Álgebra Linear</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#o-básico"><i class="fa fa-check"></i><b>A.2.1</b> O básico</a></li>
<li class="chapter" data-level="A.2.2" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#derivadas"><i class="fa fa-check"></i><b>A.2.2</b> Derivadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="as-equações-da-inferência-ativa.html"><a href="as-equações-da-inferência-ativa.html"><i class="fa fa-check"></i><b>B</b> As equações da inferência ativa</a></li>
<li class="chapter" data-level="" data-path="dicionário.html"><a href="dicionário.html"><i class="fa fa-check"></i>Dicionário</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Inferencia Ativa</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="o-caminho-de-baixo-para-a-inferência-ativa" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">> 2</span> O Caminho de baixo para a Inferência Ativa<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#o-caminho-de-baixo-para-a-inferência-ativa" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>My thinking is first and last and always for the sake of my ­doing. —­William James</p>
<div id="introdução-1" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Introdução<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#introdução-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este capítulo introduz a Inferência Ativa partindo da visão helmholtziana — ou talvez kantiana — da “percepção como inferência inconsciente” (Helmholtz 1867) e ideias relacionadas que surgiram mais recentemente sob a hipótese do cérebro bayesiano. Ele explica como a Inferência Ativa engloba e estende essas ideias tratando não apenas a percepção, mas também a ação, o planejamento e o aprendizado como problemas de inferência (Bayesiana) e derivando uma aproximação baseada em princípios (variacional) para esses problemas de outra forma intratáveis.</p>
</div>
<div id="percepção-como-inferência" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Percepção como Inferência<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#percepção-como-inferência" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Há uma longa tradição de ver o cérebro como uma “máquina preditiva”, ou um órgão estatístico que infere e prevê estados externos do mundo. Essa ideia remonta à noção de “percepção como inferência inconsciente” (Helmholtz 1866). Mais recentemente, isso foi reformulado como a hipótese do “cérebro bayesiano” (Doya 2007). A partir dessa perspectiva, a percepção não é uma transdução puramente de baixo para cima de estados sensoriais (por exemplo, da retina) em representações internas do que está lá fora (por exemplo, como padrões de atividade neuronal). Em vez disso, é um processo inferencial que combina informações anteriores (de cima para baixo) sobre as causas mais prováveis ​​das sensações com estímulos sensoriais (de baixo para cima). Os processos inferenciais operam em representações probabilísticas de estados do mundo e seguem a regra de Bayes, que prescreve a atualização (ótima) à luz da evidência sensorial. A percepção não é um processo passivo de fora para dentro – no qual a informação é extraída de impressões em nosso epitélio sensorial de “lá fora”. É um processo construtivo de dentro para fora – no qual as sensações são usadas para confirmar ou refutar hipóteses sobre como elas foram geradas (MacKay 1956, Gregory 1980, Yuille e Kersten 2006, Neisser 2014, A. Clark 2015).</p>
<p>Por sua vez, realizar a inferência Bayesiana requer um modelo generativo – às vezes chamado de modelo direto. Um modelo generativo é uma construção da teoria estatística que gera previsões sobre as observações. Pode ser formulado como a probabilidade conjunta <span class="math inline">\(P({\color{Red}x,\color{Orange}y)}\)</span> das observações <span class="math inline">\(\color{Orange}y\)</span> e os estados ocultos do mundo <span class="math inline">\(\color{Red}x\)</span> que geram essas observações. Estes últimos são referidos como estados ocultos ou latentes, pois não podem ser observados diretamente. Esta probabilidade conjunta pode ser decomposta em duas partes. O primeiro é um <span class="math inline">\(P({\color{Red}x)}\)</span> prévio, que denota o conhecimento do organismo sobre os estados ocultos do mundo antes de ver os dados sensoriais.</p>
<p>A segunda é a probabilidade <span class="math inline">\(P( y | x)\)</span>, que denota o conhecimento do organismo de como as observações são geradas a partir de estados. A regra de Bayes nos diz como combinar esses dois elementos, essencialmente atualizando uma probabilidade anterior <span class="math inline">\(P(x)\)</span> em uma probabilidade posterior de estados ocultos após receber observações <span class="math inline">\(P(x | y)\)</span>. Para os leitores que precisam de uma breve atualização sobre a teoria básica da probabilidade, o <strong>quadro 2.1</strong> fornece um resumo.</p>
<p>A inferência bayesiana é um tópico amplo que surge em disciplinas como estatística, aprendizado de máquina e neurociência computacional. Um tratamento completo dos tópicos associados está além do escopo deste livro, mas há excelentes recursos disponíveis para aqueles que desejam entendê-lo em profundidade (Murphy 2012). No entanto, tudo isso é baseado em uma regra simples. Para ilustrar essa regra, consideramos um exemplo de inferência perceptiva Bayesiana (figura 2.1). Imagine uma pessoa que acredita fortemente que está diante de uma maçã. Essa crença corresponde a uma probabilidade anterior, ou abreviada. Essa priori compreende a probabilidade atribuída à hipótese da maçã e a probabilidade atribuída às hipóteses alternativas. Neste exemplo, nossa hipótese alternativa é que não é uma maçã, mas um sapo. Numericamente, a distribuição de probabilidade anterior atribui 0,9 à maçã e 0,1 à rã. Observe que, como assumimos que existem apenas duas hipóteses plausíveis (mutuamente exclusivas), elas devem somar um. A pessoa também está equipada com um modelo de probabilidade, que atribui uma alta probabilidade ao fato de que os sapos pulam, enquanto as maçãs não. Essa probabilidade especifica o mapeamento (probabilístico) dos dois estados ocultos (sapo ou maçã) para as duas observações (pula ou não pula). Juntos, o anterior e a probabilidade formam o modelo generativo da pessoa.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Quadro 2.1 As regras de soma e produto de probabilidade</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>O raciocínio probabilístico é sustentado por duas regras principais: as regras de soma e produto de probabilidade, que são as seguintes (respectivamente):<span class="math display">\[\sum_{x} P(x)=1\]</span> <span class="math display">\[P(x)P(y|x)=P(x,y)\]</span> A regra da soma diz que a probabilidade de todos os eventos possíveis <span class="math inline">\((x)\)</span> deve somar (ou integrar) a um. A regra do produto diz que a probabilidade conjunta de duas variáveis aleatórias (<span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>) pode ser decomposta no produto da probabilidade de uma variável (<span class="math inline">\(P(x)\)</span>) e a probabilidade condicional da segunda variável dada a primeira (<span class="math inline">\(P(y|x)\)</span>). Uma probabilidade condicional é a probabilidade de uma variável (aqui, <span class="math inline">\(y\)</span>) se soubermos o valor que a outra variável (aqui, <span class="math inline">\(x\)</span>) assume. Podemos desenvolver dois resultados importantes a partir dessas regras simples. A primeira é a operação de marginalização. A segunda é a regra de Bayes. A marginalização nos permite obter uma distribuição de apenas uma das duas variáveis de uma distribuição conjunta:<span class="math display">\[\begin{matrix} \underbrace{\sum_{x}{P(x,y)}=\sum_{x}{P(y)P(x|y)}} \\ Regra\; do\; Produto \end{matrix}=\begin{matrix} \underbrace{P(x)\sum_{x}{P(x|y)}=P(y)} \\ Regra\; da\; Soma \end{matrix}\]</span> A probabilidade de y é chamada de probabilidade marginal, e nos referimos a essa operação como marginalização de x. A regra de Bayes pode ser obtida diretamente da regra do produto: <span class="math display">\[\begin{matrix} \underbrace{P(x)P(y|x)}=P(x,y)=\underbrace{P(y)P(x|y)}\\regra\;do\;produto\qquad \qquad regra\;do\;produto\end{matrix}\]</span> Isso nos permite traduzir entre uma distribuição prévia e condicional (verossimilhança) e a marginal associada e a outra distribuição condicional (posterior). Simplificando, a regra de Bayes apenas diz que a probabilidade de duas coisas é a probabilidade da primeira, dada a segunda, vezes a probabilidade da segunda, que é o mesmo que a probabilidade da segunda, dada a primeira, vezes a probabilidade do primeiro.</td>
</tr>
</tbody>
</table>
<p>Agora imagine que a pessoa observa que seu sapo-maçã pula. A regra de Bayes nos diz como formar uma crença posterior a partir da anterior, levando em conta a probabilidade de pular. Essa regra é expressa da seguinte forma:</p>
<p><span class="math display">\[P(x|y)=\frac{P(x)P(y|x)}{P(y)}\]</span></p>
<div class="figure">
<img src="images/Figura2_1.png" alt="" />
<p class="caption"><strong>Figura 2.1</strong> Um exemplo simples de inferência Bayesiana. Superior esquerdo: A crença prévia P(x) do organismo sobre o objeto que ele verá, antes de ter feito qualquer observação, ou seja, uma distribuição categórica sobre duas possibilidades, maçã (com probabilidade 0,9) e sapo (com probabilidade 0,1). Superior direito: A crença posterior do organismo P(x | y ) após observar que o objeto salta. Crenças posteriores podem ser calculadas usando a regra de Bayes sob uma função de verossimilhança P( y | x). Isso é mostrado abaixo do anterior e do posterior e específica que, se o objeto for uma maçã, há uma probabilidade muito pequena (0,01) de que ele pule, enquanto se for um sapo, a probabilidade de pular é muito maior ( 0,81). (As barras de probabilidade nesta figura não estão exatamente em escala.) Neste caso específico, a atualização de anterior para posterior é grande.</p>
</div>
<p>Sob o modelo de verossimilhança da figura 2.1, a probabilidade posterior atribuída ao sapo é 0,9 e a probabilidade atribuída à maçã é 0,1. Conforme destacado no quadro 2.1, o denominador da equação 2.1 pode ser calculado marginalizando o numerador. Usando nosso exemplo do sapo-maçã, aproveitamos a oportunidade para descompactar duas noções diferentes de surpresa — ambas importantes na Inferência Ativa. A primeira, a que nos referimos simplesmente como surpresa, é a evidência logarítmica negativa, onde a evidência é a probabilidade marginal das observações. Em nosso exemplo, esta é a probabilidade logarítmica negativa de observar qualquer coisa saltando sob o modelo generativo. A surpresa é uma quantidade muito importante do ponto de vista bayesiano. É uma medida de quão mal um modelo se ajusta aos dados que tenta explicar. Para colocar isso intuitivamente, podemos calcular a probabilidade do comportamento observado (pulo) sob nosso modelo. Lembre-se de que isso atribui uma probabilidade a priori muito alta às maçãs e uma probabilidade a priori baixa às rãs. Assim, nossa probabilidade marginal de pular é a seguinte:</p>
<p><img src="images/Prob%20Sapos%20Ma%C3%A7as.png" /></p>
<p>Isso significa que, sob esse modelo, esperaríamos observar o comportamento de pulor cerca de 9 vezes em 100 observações. Como tal, deveríamos nos surpreender ao observar isso se subscrevermos o modelo da figura 2.1. Podemos quantificar isso em termos de surpresa <span class="math inline">\((ℑ)\)</span>. Isso é dado por <span class="math inline">\(ℑ(y=pular) = −lnP(y=pular) = −ln(0,09) = 2,4 nats\)</span> <a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> . Quanto maior esse número, pior o modelo como explicação adequada para as observações em questão. Isso nos permite comparar modelos em relação aos dados. Por exemplo, considere um modelo alternativo, onde temos uma crença prévia de que os sapos são vistos 100% do tempo. Seguindo os mesmos passos da equação 2.2, calculamos uma surpresa de cerca de 0,2 nats. Este é um modelo melhor desses dados, pois a observação é muito menos surpreendente. O procedimento de pontuação de modelos com base em suas evidências (ou surpresa) é frequentemente chamado de comparação de modelos bayesianos. Para modelos mais complicados, a forma da surpresa pode não ser tão simples.</p>
<p>A <strong>Tabela 2.1</strong> fornece a forma da surpresa (omitindo constantes) para uma série de distribuições de probabilidade – além da probabilidade categórica em nosso exemplo. Crucialmente, isso nos permite falar sobre surpresa para distribuições de probabilidade cujo suporte<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> difere do exemplo simples usado aqui. Isso é importante porque a maneira pela qual os dados sensoriais são gerados pelo mundo varia com o tipo de dados. Podemos nos surpreender ao encontrar o rosto de alguém que não esperávamos ver (distribuição categórica), ou podemos nos surpreender por estar mais frio do lado de fora do que prevíamos (distribuição contínua). A Tabela 2.1 pode ser vista como um portfólio das distribuições de probabilidade à nossa disposição quando passamos a construir modelos generativos em capítulos subsequentes. De maneira mais geral, ele afirma que a surpresa é um conceito que pode ser avaliado para qualquer família de distribuições de probabilidade.</p>
<p><strong>Tabela 2.1 Distribuições de probabilidade e surpresa<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></strong></p>
<table>
<colgroup>
<col width="27%" />
<col width="45%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Distribuição</th>
<th align="center">Suporte</th>
<th align="center">Surpresa<span class="math inline">\((ℑ)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Gaussiana<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></td>
<td align="center"><span class="math inline">\(x\in\mathbb{R}\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{2}(x-\mu)\prod(x-\mu)\)</span></td>
</tr>
<tr class="even">
<td align="center">Multinomial</td>
<td align="center"><span class="math display">\[x_{i}\in\left ( 0,\cdots, N \right )\]</span> <span class="math display">\[{i}\in\left \{ 1 , \cdots , K \right \}\]</span> <span class="math display">\[\sum_i{x_i}=N\]</span></td>
<td align="center"><span class="math display">\[-\sum_i{x_i}\ln d_i\]</span></td>
</tr>
<tr class="odd">
<td align="center">Dirichlet<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></td>
<td align="center"><span class="math display">\[x_{i}\in\left ( 0,1 \right )\]</span> <span class="math display">\[{i}\in\left \{ 1 , \cdots , K \right \}\]</span> <span class="math display">\[\sum_i{x_i}=1\]</span></td>
<td align="center"><span class="math inline">\(\sum(1 - \alpha_i)\ln(x_i)\)</span></td>
</tr>
<tr class="even">
<td align="center">Gamma</td>
<td align="center"><span class="math inline">\(x\in(0,\infty)\)</span></td>
<td align="center"><span class="math inline">\((bx+(1-a)\ln x)\)</span></td>
</tr>
</tbody>
</table>
<p>A segunda noção de surpresa é (um pouco confusa) referida como surpresa bayesiana. Esta é uma medida de quanto temos que atualizar nossas crenças após uma observação. Em outras palavras, a surpresa Bayesiana quantifica a diferença entre uma probabilidade anterior e uma posterior. Isso levanta a questão de como quantificamos a dissimilaridade de duas distribuições de probabilidade.</p>
<p>Uma resposta, da teoria da informação, é usar uma divergência de Kullback-Leibler (KL). Isso é definido como a diferença média entre duas probabilidades logarítmicas</p>
<p><span class="math inline">\(D_{KL}[Q(x)||P(x)] \overset{\Delta}{=} \mathbb{E_{Q(x)}}[\ln{Q(x)} - \ln{P(x)}] \quad\quad\quad\quad\quad\quad\quad\quad\quad\quad \text{(2.3)}\)</span></p>
<p>O símbolo <span class="math inline">\(\mathbb{E}\)</span> aqui indica uma média (ou expectativa) conforme descrito no <strong>quadro 2.2</strong>. Usando o KL-Divergence, podemos quantificar a surpresa Bayesiana do nosso exemplo:</p>
<p><img src="images/Surpresa%20Sapos%20Ma%C3%A7as.png" /></p>
<p>Isso pontua a quantidade de atualização de crenças, em oposição a simplesmente quão improvável era a observação. Para destacar a distinção entre surpresa e surpresa bayesiana, considere o que acontece se nos comprometermos com uma crença prévia de que sempre veremos maçãs. A surpresa bayesiana será zero, já que o prior está tão confiante que não o atualizamos seguindo nossas observações. No entanto, a surpresa é muito grande (4,6 nats), pois é altamente improvável que uma maçã salte.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Quadro 2.2 Expectativas</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">É útil referir-se à expectativa de uma variável aleatória <span class="math inline">\(x\)</span>, geralmente denotada por <span class="math inline">\(\mathbb{E[x]}\)</span>. Esta é a média ponderada de todos os valores que a variável pode assumir, ponderada pela sua probabilidade. Para variáveis aleatórias discretas (que só podem receber um número contável de valores possíveis), isso é dado por uma soma ponderada: <span class="math display">\[\mathbb{E(x)}=\sum_x{xP(x)}\]</span> Por exemplo, para uma variável discreta (numérica) que só pode assumir dois valores (1 e 2) com igual probabilidade de <span class="math inline">\(\frac{1}{2}\)</span>, isto é <span class="math inline">\(\mathbb{E(x)}=1*\frac{1}{2}+2*\frac{1}{2}=\frac{3}{2}\)</span>. Para variáveis aleatórias contínuas (que podem ter infinitos valores), as somas são substituídas por integrais. As expectativas também podem ser aplicadas a funções de variáveis aleatórias, em oposição às variáveis diretamente. Por exemplo, se tivermos uma função f (x), onde x tem alguma distribuição contínua, a expectativa é definida como segue: <span class="math display">\[\mathbb{E[f(x)]}=\int_{}^{} f(x)p(x)\, dx\]</span>Usaremos essa notação ao longo deste livro, onde a função <span class="math inline">\(f (x)\)</span> será frequentemente uma probabilidade logarítmica ou razão de probabilidade logarítmica.</td>
</tr>
<tr class="even">
<td align="left"></td>
</tr>
</tbody>
</table>
<p>Observe que, embora tenhamos ilustrado a inferência bayesiana com base em um modelo generativo muito simples, ela se aplica a modelos generativos de qualquer complexidade. No capítulo 4, destacaremos duas formas de modelo generativo que subscrevem a maioria das aplicações em Inferência Ativa.</p>
</div>
<div id="inferência-biológica-e-otimização" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Inferência Biológica e Otimização<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#inferência-biológica-e-otimização" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Há dois pontos importantes que conectam o esquema inferencial acima às teorias biológicas e psicológicas da percepção. Primeiro, o procedimento inferencial discutido requer a interação de processos de cima para baixo que codificam previsões (a partir do anterior) e processos de baixo para cima que codificam observações sensoriais (mediadas pela probabilidade). Essa interação de processos de cima para baixo e de baixo para cima distingue a visão inferencial de abordagens alternativas que consideram apenas processos de baixo para cima. Além disso, é central nos tratamentos biológicos modernos da percepção, como a codificação preditiva (discutida no capítulo 4), que é uma implementação algorítmica específica (ou em nível de processo) do esquema de inferência mais geral (bayesiano) discutido aqui.</p>
<p>Em segundo lugar, a inferência Bayesiana é ótima. A otimalidade é definida em relação a uma função de custo que é otimizada (ou seja, minimizada), que, por inferência Bayesiana, é conhecida como energia livre variacional – intimamente relacionada à surpresa. Voltamos a isso na seção 2.5. Ao considerar explicitamente a distribuição completa sobre os estados ocultos, ele lida naturalmente com a incerteza, evitando as limitações de abordagens alternativas que consideram apenas estimativas pontuais de estados ocultos (por exemplo, o valor médio de x). Uma dessas alternativas seria a estimativa de máxima verossimilhança, que simplesmente seleciona o estado oculto mais provável de ter gerado os dados disponíveis. O problema com isso é que tais estimativas ignoram tanto a plausibilidade prévia do estado oculto quanto a incerteza em torno da estimativa. A inferência bayesiana não sofre essas limitações. No entanto, apesar do uso da surpresa para avaliar objetivamente se o modelo é adequado ao propósito, é importante apreciar que a inferência em si é subjetiva. Os resultados da inferência não são necessariamente precisos em nenhum sentido objetivo (ou seja, a crença do organismo pode não corresponder à realidade) por pelo menos duas razões importantes. Primeiro, as criaturas biológicas operam com base em recursos computacionais e energéticos limitados, que tornam a inferência Bayesiana exata intratável<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> . Isso requer aproximações que excluem garantias de otimalidade Bayesiana exata. Essas aproximações incluem a noção de uma posterior variacional - baseada em algo chamado aproximação de campo médio - que é central para o capítulo 4.</p>
<p>A segunda razão pela qual a otimalidade pode ser pensada como subjetiva é que os organismos operam com base no modelo generativo de um sujeito de como suas observações são geradas, o que pode ou não corresponder ao processo generativo real que gera suas observações. Isso não quer dizer que o modelo generativo deva corresponder ao processo generativo. De fato, pode haver modelos que forneçam explicações melhores (por exemplo, mais simples) dos dados disponíveis do que os processos que realmente os geraram – conforme quantificado por sua relativa surpresa. Um bom exemplo disso são as ilusões, para as quais alguém encontra uma explicação mais simples para sua entrada visual em relação a como os estímulos visuais foram cuidadosamente projetados por um psicofísico malicioso.</p>
<p>O próprio modelo generativo pode ser otimizado à medida que novas experiências são adquiridas. Isso pode ou não convergir para o processo generativo.</p>
<p>A <strong>Figura 2.2</strong> ilustra esse ponto e a diferença entre as verdadeiras contingências ambientais, ou o processo generativo, que é inacessível ao organismo e o modelo generativo do organismo do mundo. Neste exemplo em particular, o processo generativo está em um verdadeiro estado <span class="math inline">\(x*\)</span> que é inacessível ao organismo. No entanto, o organismo e o mundo estão mutuamente acoplados, e <span class="math inline">\(x*\)</span> gera uma observação <span class="math inline">\(y\)</span>, que o organismo sente. O organismo pode usar esta observação <span class="math inline">\(y\)</span> e a regra de Bayes para inferir a (probabilidade posterior de) alguma variável explicativa ou estado oculto no modelo generativo. Na figura, nos referimos a <span class="math inline">\(x*\)</span> e <span class="math inline">\(x\)</span> como estados ocultos, enfatizando que nenhum deles é observável. No entanto, eles são sutilmente diferentes: o primeiro faz parte do modelo generativo do organismo, enquanto o último faz parte do processo generativo e inacessível ao organismo. Além disso, <span class="math inline">\(x*\)</span> e <span class="math inline">\(x\)</span> não vivem necessariamente no mesmo espaço. Pode ser que os estados ocultos no mundo externo assumam valores que estão fora do espaço de explicações disponíveis ao cérebro. Por outro lado, pode ser que as explicações do cérebro incluam variáveis que não existem no mundo exterior. Por exemplo, o primeiro pode ser de 5 dimensões e o último de 2 dimensões, ou um pode ser contínuo e o outro categórico.</p>
<p><img src="images/Figura2_2.png" alt="Figura 2.2 Processo generativo e modelo generativo. Ambos representam maneiras pelas quais os dados sensoriais (y) podem ser gerados dados estados ocultos (x) e são representados por setas de x a y para indicar causalidade. A diferença é que o processo é a verdadeira estrutura causal pela qual os dados são gerados, enquanto o modelo é uma construção usada para fazer inferências sobre as causas dos dados (ou seja, usar observações para derivar estados inferidos). Os estados ocultos do modelo generativo e do processo generativo não são os mesmos. O modelo do organismo inclui uma série de hipóteses (x) sobre o estado oculto, que não necessariamente incluem o verdadeiro valor do estado oculto x∗ do processo generativo. Em outras palavras, os modelos que usamos para explicar nosso sensório podem incluir estados ocultos que não existem no mundo exterior e vice-versa. A ação (u) é gerada com base nas inferências feitas sob um modelo generativo. A ação é mostrada aqui como parte do processo generativo, fazendo mudanças no mundo, apesar de ser selecionada a partir das inferências traçadas sob o modelo." />
A distinção entre o modelo generativo e o processo é importante para contextualizar as afirmações psicológicas sobre a otimalidade da inferência – na medida em que essas afirmações são válidas – que, em uma visão bayesiana, é sempre contingente aos recursos do organismo. Por recursos, queremos dizer seu modelo generativo específico e recursos computacionais e mnemônicos limitados.</p>
</div>
<div id="ação-como-inferência" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Ação como Inferência<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#ação-como-inferência" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A discussão até este ponto é comum a todas as teorias do cérebro Bayesianas. No entanto, agora apresentamos o avanço simples, mas fundamental, oferecido pela Inferência Ativa. Isso parte da mesma perspectiva inferencial discutida acima, mas a estende para considerar a ação como inferência. Essa ideia decorre do conceito de que a inferência bayesiana minimiza a surpresa (ou, equivalentemente, maximiza a evidência do modelo bayesiano). Até agora, consideramos o que acontece quando computamos a surpresa realizando inferências – e selecionamos entre os modelos com base em sua capacidade de minimizar a surpresa. No entanto, a surpresa não depende apenas do modelo. Também depende dos dados. Ao agir no mundo para mudar a maneira como os dados são gerados, podemos garantir que um modelo seja adequado ao propósito, escolhendo os dados que são menos surpreendentes em nosso modelo.</p>
<p>Equipado com um mecanismo para produzir ações, um organismo pode se engajar em trocas recíprocas com seu ambiente; veja a figura 2.2. Nos animais, esse mecanismo assume a forma de um loop reflexo motor. Essencialmente, para cada ciclo de ação-percepção, o ambiente envia uma observação ao organismo. O organismo usa (uma aproximação da) inferência Bayesiana para inferir seus estados ocultos mais prováveis. Em seguida, gera uma ação e a envia para o ambiente na tentativa de tornar o ambiente menos surpreendente. O ambiente executa a ação, gera uma nova observação e a envia ao organismo. Em seguida, inicia-se um novo ciclo. A descrição sequencial aqui é escrita para fins didáticos; é importante perceber que estes não são realmente passos discretos, mas são processos dinâmicos contínuos.</p>
<p>A Inferência Ativa vai além do reconhecimento de que percepção e ação têm a mesma natureza (inferencial). Também pressupõe que tanto a percepção quanto a ação cooperam para realizar um único objetivo – ou otimizar apenas uma função – em vez de ter dois objetivos distintos, como mais comumente se supõe. Na literatura de Inferência Ativa, esse objetivo comum foi descrito de várias maneiras (informais e formais), incluindo a minimização de surpresa, entropia, incerteza, erro de previsão ou energia livre (variacional). Esses termos estão relacionados entre si, mas às vezes suas relações não são imediatamente claras, causando alguma confusão. Além disso, esses termos são usados em diferentes contextos; por exemplo, a minimização de erros de previsão é usada em contextos biológicos onde o objetivo é explicar os sinais cerebrais, enquanto a minimização de energia livre variacional é usada em aprendizado de máquina.</p>
<p>Nas próximas duas seções, esclareceremos que a única quantidade que os agentes de Inferência Ativa minimizam por meio da percepção e da ação é a energia livre variacional. No entanto, sob algumas condições, pode-se reduzir a energia livre variacional a outras noções, como a discrepância entre o modelo generativo e o mundo, ou a diferença entre o que se espera e o que se observa (ou seja, um erro de previsão). Introduziremos formalmente a energia livre variacional na seção 2.5. Para simplificar, a seção 2.4 concentra-se nas maneiras pelas quais a percepção e a ação minimizam a discrepância entre o modelo generativo e o mundo.</p>
</div>
<div id="minimizando-a-discrepância-entre-o-modelo-e-o-mundo" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Minimizando a discrepância entre o modelo e o mundo<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-discrepância-entre-o-modelo-e-o-mundo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Tendo estabelecido percepção e ação em termos de inferência bayesiana, agora nos voltamos para a questão de qual é o objetivo da inferência. Em outras palavras, o que está sendo otimizado por inferência? Na ciência cognitiva, é comum supor que diferentes funções cognitivas, como percepção e ação, otimizam objetivos diferentes. Por exemplo, poderíamos supor que a percepção maximiza a precisão da reconstrução enquanto a seleção de ação maximiza a utilidade. Em vez disso, um insight fundamental da Inferência Ativa é que tanto a percepção quanto a ação servem ao mesmo objetivo. Como primeira aproximação, esse objetivo comum de percepção e ação pode ser formulado como uma minimização da discrepância entre o modelo e o mundo. Às vezes, isso é operacionalizado em termos de erro de previsão.</p>
<p>Para entender como a percepção e a ação reduzem a discrepância entre o modelo e o mundo, considere novamente o exemplo de uma pessoa que espera ver uma maçã (figura 2.3). Ela gera uma previsão visual de cima para baixo (por exemplo, sobre ver algo vermelho e não pular). Essa previsão visual é comparada com uma sensação (por exemplo, algo pulando) – e essa comparação resulta em uma discrepância.</p>
<div class="figure">
<img src="images/Figura2_3.png" alt="" />
<p class="caption"><strong>Figura 2.3</strong> Tanto a percepção quanto a ação minimizam a discrepância entre modelo e mundo.</p>
</div>
<p>A pessoa pode resolver essa discrepância de duas maneiras. Primeiro, ela pode mudar de ideia sobre o que está vendo (ou seja, um sapo) para se adequar ao mundo, resolvendo assim a discrepância. Isso corresponde à percepção. Segundo, ela poderia fovear a macieira mais próxima e ver algo que se parece muito com uma maçã. Isso também resolve a discrepância inicial, mas de uma maneira diferente. Isso implica mudar o mundo – incluindo a direção do olhar – e as sensações subsequentes para se adequar ao que está em sua mente, não mudar sua mente para se adequar ao mundo. Esta é a outra direção de ajuste. Isso é ação.</p>
<p>Embora mudar a direção do olhar pareça menos atraente do que mudar de ideia no mundo das maçãs e sapos, vamos considerar outro caso: uma pessoa que espera que sua temperatura corporal esteja em uma certa faixa que sente uma temperatura alta por meio de termorreceptores centrais. Isso é surpreendente e apresenta uma discrepância significativa para resolver. Como no exemplo anterior, ele tem duas formas de minimizar essa discrepância, correspondendo à percepção (mudança de mente) e ação (mudança do mundo), respectivamente. Nesse caso, simplesmente mudar de ideia não parece muito adaptativo, mas agir para diminuir a temperatura do corpo (por exemplo, abrindo a janela) é.</p>
<p>Isso fala do fato de que, na Inferência Ativa, a noção de probabilidades marginais ou surpresa (por exemplo, sobre a temperatura corporal) tem um significado que vai além dos tratamentos Bayesianos padrão para absorver noções como pontos de ajuste homeostáticos e alostáticos. Tecnicamente, os agentes de Inferência Ativa vêm equipados com modelos que atribuem altas probabilidades marginais aos estados que preferem visitar ou às observações que preferem obter. Para um peixe, isso significa uma alta probabilidade marginal de estar na água. Isso implica que os organismos esperam implicitamente que as observações que eles amostram estejam dentro de sua zona de conforto (por exemplo, limites fisiológicos).</p>
<p>Em suma, discutimos como, a qualquer momento, podemos minimizar a discrepância entre nosso modelo e nosso mundo por meio da percepção e da ação. Se ajustamos nossas crenças ou nossos dados depende da confiança com que mantemos essas crenças. Em nosso exemplo da maçã, a crença é mantida com incerteza suficiente de que isso será atualizado em vez de posto em prática. Em contraste, no exemplo da temperatura, estamos consideravelmente mais confiantes sobre nossa temperatura central porque ela garante nossa existência. Essa confiança significa que atualizamos nosso mundo para cumprir nossas crenças. Ainda, na Inferência Ativa, percepção e ação agem de forma mais cooperativa do que o sugerido por este tratamento. Para entender por que esse é o caso, a próxima seção passa da noção restrita de discrepância (ou erro de previsão) para a noção mais geral de energia livre variacional - que é a quantidade que a Inferência Ativa realmente minimiza e que inclui o erro de previsão como um caso especial.</p>
</div>
<div id="minimizando-a-energia-livre-variacional" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Minimizando a Energia Livre Variacional<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-energia-livre-variacional" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Até agora, discutimos percepção e ação dentro de um esquema bayesiano que visa minimizar a surpresa. No entanto, a inferência Bayesiana exata que suporta a percepção e a ação é computacionalmente intratável na maioria dos casos, porque duas quantidades – a evidência do modelo (<span class="math inline">\(P( y)\)</span>) e a probabilidade posterior (<span class="math inline">\(P(x | y)\)</span>) – não podem ser computadas por duas razões possíveis. A primeira é que, para modelos complexos, pode haver muitos tipos de estados ocultos que precisam ser marginalizados, tornando o problema computacionalmente intratável. A segunda é que a operação de marginalização pode exigir integrais analiticamente intratáveis. A Inferência Ativa apela a uma aproximação variacional da inferência Bayesiana que é tratável.</p>
<p>O formalismo da inferência variacional será desvendado no capítulo 4. Aqui, basta dizer que realizar inferência Bayesiana variacional implica substituir as duas quantidades intratáveis - probabilidade posterior e evidência do modelo (log) - por duas quantidades que as aproximam, mas podem ser calculadas eficientemente - a saber, um Q posterior aproximado e uma energia livre variacional F, respectivamente. A posterior aproximada às vezes é chamada de distribuição variacional ou de reconhecimento. A energia livre variacional negativa também é conhecida como um limite inferior de evidência (ELBO), especialmente em aprendizado de máquina.</p>
<p>Mais importante ainda, o problema da inferência bayesiana agora se torna um problema de otimização: a minimização da energia livre variacional F. A energia livre variacional é uma quantidade com raízes na física estatística que desempenha um papel fundamental na Inferência Ativa. Na equação 2.5, é denotado como F [Q, y], pois é um funcional (função de uma função) do Q posterior aproximado e uma função dos dados y:</p>
<p><span class="math display">\[F[Q,y]=
\begin{matrix}  \underbrace{  -\mathbb{E_{Q(x)}}[\ln P(x,y) }[\\ Energia \end{matrix}
\begin{matrix}  \underbrace{  -\mathbb{H_{Q(x)}}) } \\ Entropia \end{matrix}\]</span>
<span class="math display">\[=
\begin{matrix}  \underbrace{  D_{KL}{[Q(x)||P(x)]}}\\ Complexidade \end{matrix}
\begin{matrix}  \underbrace{  -\mathbb{E_{Q(x)}}[\ln P(y|x)]}\\ Acurácia \end{matrix}\]</span>
<span class="math display">\[=\begin{matrix} \underbrace{ D_{KL}{[Q(x) || P(x|y)]} } \\ Divergência \end{matrix}
\begin{matrix} \underbrace{-\ln P(x)} \\ Evidência \end{matrix} \qquad\qquad (2.5)
\]</span></p>
<p>A energia livre variacional pode parecer, a primeira vista, um conceito abstrato, mas sua natureza e o papel que desempenha na Inferência Ativa tornam-se aparentes quando decompostas em quantidades que são mais intuitivas e familiares na ciência cognitiva. Cada uma dessas perspectivas sobre energia livre variacional oferece intuições úteis sobre o que significa minimização de energia livre. Esboçamos brevemente essas intuições aqui, pois elas se tornarão importantes quando discutirmos exemplos na segunda parte do livro.</p>
<p>A primeira linha da equação 2.5 mostra que a minimização em relação a <span class="math inline">\(Q\)</span> requer consistência com o modelo generativo (energia), mantendo também uma alta entropia posterior.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> A última significa que, na ausência de dados ou crenças prévias precisas (que apenas influenciam o termo de energia), devemos adotar crenças maximamente incertas sobre os estados ocultos do mundo, de acordo com o princípio de entropia máxima de Jaynes ( Jaynes 1957). Simplificando, devemos ser incertos (adotar uma crença de alta entropia ) quando não temos informações. O termo energia herda da física estatística. Especificamente, sob uma distribuição de Boltzmann, a probabilidade logarítmica média de um sistema adotar alguma configuração é inversamente proporcional à energia associada a essa configuração - ou seja, a energia necessária para mover o sistema para essa configuração a partir de uma configuração de linha de base.</p>
<p>A segunda linha enfatiza a interpretação da minimização da energia livre como encontrar a melhor explicação para os dados sensoriais, que deve ser a explicação mais simples (minimamente complexa <a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>) capaz de explicar com precisão <a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> os dados (cf. navalha de Occam) . O trade-off complexidade-precisão ocorre em vários domínios, normalmente no contexto de comparação de modelos para análise de dados. Em estatística, às vezes são usadas outras aproximações para a evidência do modelo, como o critério de informação Bayesiano ou o critério de informação de Akaike. A compensação complexidade-precisão se tornará importante quando descrevermos como usar a energia livre para comparação de modelos durante a análise de dados baseada em modelo - e no contexto de aprendizado de estrutura e redução de modelo. Inferir explicações que tenham complexidade mínima também é importante do ponto de vista cognitivo. Isso porque pode-se supor que atualizar o que se sabe (o anterior) para acomodar os dados acarreta um custo cognitivo (Ortega e Braun 2013, Zénon et al. 2019); portanto, uma explicação que diverge minimamente da anterior é preferível.</p>
<p>Nesta visão, o custo da complexidade é apenas uma surpresa bayesiana. Em outras palavras, o grau em que “mudo de ideia” é quantificado pela divergência entre o anterior e o posterior. Isso significa que toda explicação precisa para minhas sensações incorre em um custo de complexidade, e esse custo pontua o grau de atualização da crença bayesiana. A energia livre variacional, então, marca a diferença entre precisão e complexidade.</p>
<p>A linha final expressa a energia livre como um limite na evidência logarítmica negativa (veja a figura 2.4). Como a parte esquerda da figura ilustra, a energia livre é um limite superior na evidência logarítmica negativa, onde o limite é a divergência entre <span class="math inline">\(Q\)</span> e a probabilidade posterior que teria sido obtida se fosse possível realizar exatamente (em oposição a variacional) inferência. A parte direita da figura mostra que, à medida que a divergência diminui, a energia livre se aproxima da evidência logarítmica negativa (surpresa) - e se torna igual a surpresa, se o Q posterior aproximado corresponder ao posterior exato <span class="math inline">\(P(x | y)\)</span>. Isso oferece uma motivação formal para a inferência perceptiva como uma maneira de diminuir a energia livre otimizando nosso Q posterior aproximado o máximo possível.</p>
<div class="figure">
<img src="images/Figura2_4.png" alt="" />
<p class="caption"><strong>Figura 2.4</strong> Energia livre variacional como um limite superior na evidência logarítmica negativa.</p>
</div>
<p>A linha final da equação 2.5 mostra que a inferência perceptual não é a única maneira de minimizar a energia livre. Também poderíamos alterar o termo de evidência de log agindo para alterar os dados sensoriais. Essa decomposição é interessante do ponto de vista cognitivo, pois minimizar a divergência e maximizar a evidência mapeiam os dois subobjetivos complementares de percepção e ação, respectivamente; veja a figura 2.5. Observe que todas as expressões acima se tornam formas de caracterizar a evidência logarítmica negativa se substituirmos <span class="math inline">\(Q\)</span> por <span class="math inline">\(P( x| y)\)</span>, generalizando para o caso de inferência exata.</p>
<p>Em suma, a Inferência Ativa equivale a minimizar a energia livre variacional por percepção e ação. Essa minimização permite que um organismo ajuste seu modelo generativo às observações que amostra. Esse ajuste é uma medida tanto da adequação perceptual (como expressa pelo termo de divergência) quanto do controle ativo sobre os estados externos – no sentido de que permite que o organismo se mantenha em um conjunto adequado de estados preferidos, conforme definido pelo modelo generativo. Outra maneira de expressar isso é apelar para a divergência versus decomposição de evidências da energia livre. Igualando a evidência logarítmica negativa com surpresa e notando que a menor divergência possível é zero, vemos que a energia livre é um limite superior da surpresa. Isso significa que só pode ser maior ou igual a surpresa. Quando o organismo minimiza sua divergência (através da percepção), então a energia livre torna-se uma aproximação da surpresa. Quando um organismo altera adicionalmente as observações que reúne (atuando) para torná-las mais semelhantes às previsões anteriores, minimiza a surpresa.</p>
<div class="figure">
<img src="images/Figura_2_5.png" alt="" />
<p class="caption"><strong>Figura 2.5</strong> Papéis complementares de percepção e ação na minimização da energia livre variacional.</p>
</div>
<p>A energia livre variacional tem um aspecto retrospectivo, pois é uma função de observações passadas e presentes, mas não futuras. Embora facilite inferências sobre o futuro com base em dados passados, não facilita diretamente formas prospectivas de inferência com base em dados futuros previstos. Isso é importante no planejamento e na tomada de decisões. Aqui, inferimos as melhores ações ou sequências de ações (políticas) com base nas observações futuras que se espera que elas tragam. Fazer isso requer que complementemos nossos modelos generativos com a noção de energia livre esperada.</p>
</div>
<div id="energia-livre-esperada-e-planejamento-como-inferência" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> Energia Livre Esperada e Planejamento como Inferência<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#energia-livre-esperada-e-planejamento-como-inferência" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A energia livre esperada estende a Inferência Ativa para incluir uma forma de cognição essencialmente prospectiva: planejamento. Planejar uma sequência de ações, como a série de movimentos necessários para escapar de um labirinto, requer considerar as observações futuras que se espera reunir. Por exemplo, as consequências de possíveis cursos de ação incluem ver um beco sem saída depois de virar à direita ou ver a saída após uma sequência de três curvas à esquerda. Cada sequência possível de ações é chamada de política. Isso destaca uma importante distinção feita na Inferência Ativa entre uma ação e uma política. O primeiro é algo que influencia diretamente o mundo exterior, enquanto o segundo é uma hipótese sobre um modo de se comportar. A implicação é que a Inferência Ativa trata o planejamento e a tomada de decisão como um processo de inferir o que fazer. Isso traz o planejamento firmemente para o domínio da inferência bayesiana e significa que devemos especificar prioritários e probabilidades como antes (seção 2.1). No entanto, no lugar de rãs e maçãs, as alternativas são políticas comportamentais (é mais provável que eu olhe para o lago ou para a árvore?). Nesta seção, primeiro lidamos brevemente com a probabilidade - isto é, as consequências de seguir uma política - e depois nos voltamos para o anterior. É aqui que entra a energia livre esperada.</p>
<p>Os resultados dependentes de políticas não estão imediatamente disponíveis (eles estão no futuro), mas podem ser previstos encadeando dois componentes do modelo generativo. A primeira são nossas crenças sobre como os estados ocultos mudam em função das políticas. Entraremos em detalhes disso no capítulo 4. Por enquanto, usamos a notação <span class="math inline">\(x\sim\)</span> para denotar uma sequência ou trajetória de estados ocultos ao longo do tempo, e condicionamos as trajetórias às políticas <span class="math inline">\((π)\)</span> que uma criatura segue. Isso significa que a parte dinâmica do nosso modelo é dada por <span class="math inline">\(P(x\sim{}|π)\)</span>. Com base em nosso exemplo anterior da maçã-rã, a política pode ser a decisão de ir a um lago ou a um pomar, o que altera a probabilidade de encontrar rãs versus maçãs.</p>
<p>O segundo componente do modelo é a distribuição de verossimilhança usual. Isso descreve quais observações esperar em todos os estados possíveis (por exemplo, pulando ou não, condicionado ao sapo ou à maçã). Ao combinar esses dois componentes, um organismo pode engajar seu modelo generativo indiretamente para executar “e se” ou simulações contrafactuais das consequências de suas possíveis ações ou políticas – por exemplo, “O que aconteceria se eu fosse ao lago?” Marginalizando sobre os estados, isso nos dá a probabilidade marginal ou evidência para uma política <span class="math inline">\((P(y\sim|π))\)</span>, ou uma aproximação de energia livre para essa quantidade. Em outras palavras, saber como as políticas influenciam as transições de estado nos permite calcular a probabilidade de uma sequência de observações sob essa política. Como vimos na equação 2.1, precisamos combinar essa probabilidade com uma probabilidade anterior para calcular a probabilidade posterior de seguir uma política.</p>
<p>A Inferência Ativa decompõe esse problema de planejamento em duas operações sucessivas. A primeira é calcular uma pontuação para cada política. A segunda é formar crenças posteriores sobre as quais perseguir. A primeira define a crença prévia sobre as políticas a serem seguidas, onde as melhores políticas têm alta probabilidade e as piores políticas têm baixa probabilidade. Sob a Inferência Ativa, a qualidade de uma política é pontuada pela energia livre esperada negativa associada – assim como a qualidade de um ajuste de modelo é pontuada pela energia livre negativa desse modelo. A energia livre esperada <span class="math inline">\((G)\)</span> da política é diferente da energia livre variacional <span class="math inline">\((F)\)</span>, uma vez que o cálculo da primeira requer a consideração de observações futuras dependentes da política. Em contraste, este último considera apenas observações presentes e passadas. O cálculo da energia livre esperada, portanto, envolve o modelo generativo para prever observações futuras que resultariam de cada política – se ela fosse executada – até algum horizonte de planejamento. Além disso, como uma política se desdobra em várias etapas de tempo, a medida final da energia livre esperada para cada política deve ser integrada em todas as etapas de tempo futuras dessa política.</p>
<p>A energia livre esperada de cada política pode ser convertida em um índice de qualidade (tomando seu negativo) e é disponibilizada diretamente como a priori pelos agentes envolvidos na Inferência Ativa. Isso ocorre porque - consistente com a noção de energia potencial na física - a energia livre esperada é expressa no espaço de probabilidades logarítmicas. Convertê-lo em uma crença (ou distribuição de probabilidade) sobre políticas é então uma questão de exponenciar (para desfazer o log) e normalizar (para garantir consistência com a regra da soma no quadro 2.1). As políticas que estão associadas a uma menor energia livre esperada recebem maior probabilidade e se tornam as políticas que o organismo espera seguir.</p>
<p>Em última análise, inferir que estamos seguindo uma política específica tem consequências para os dados sensoriais que prevemos. Por exemplo, uma política que inclui flexionar o cotovelo implica em previsões sobre a entrada proprioceptiva dos músculos bíceps e tríceps. Isso fornece a ligação entre planejamento e ação, pois as previsões associadas a um plano se traduzem em ação que resolve discrepâncias com dados proprioceptivos medidos (consulte a seção 2.3).</p>
</div>
<div id="o-que-é-energia-livre-esperada" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> O que é energia livre esperada?<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#o-que-é-energia-livre-esperada" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Até agora, assumimos que durante o planejamento, o organismo pontua suas políticas de acordo com sua energia livre esperada. No entanto, evitamos o que a energia livre esperada realmente é. Como a energia livre variacional, a energia livre esperada pode ser decomposta de várias maneiras matematicamente equivalentes. Cada um deles fornece uma perspectiva alternativa sobre essa quantidade.</p>
<p><span class="math display">\[G(x)=\begin{matrix} \underbrace{-\mathbb{E_{Q(\tilde x,\tilde y|\pi)}}[ D_{KL}[Q(\tilde x|\tilde y,\pi)||Q(\tilde x|\pi)] }\\ ganho\; de\; informação  \end{matrix} -  \begin{matrix} \underbrace{\mathbb{E_{Q(\tilde y|\pi)}} \ln P(\tilde y|C)])} \\ valor\;pragmático \end{matrix} \]</span>
<span class="math display">\[ =  \begin{matrix} \underbrace{\mathbb{E_{Q(\tilde x,\tilde y | \pi)}}[H[P(\tilde y, \tilde x)]]} \\ ambiguidade\; esperada \end{matrix} + \begin{matrix} \underbrace{D_{KL}[Q(\tilde y | \pi) \;||\; P(\tilde y | C)]} \\ risco(resultados) \end{matrix} \]</span>
<span class="math display">\[ \le  \begin{matrix} \underbrace{\mathbb{E_{Q(\tilde x,\tilde y | \pi)}}[ H[P(\tilde y, \tilde x)]]} \\ ambiguidade\; esperada \end{matrix} + \begin{matrix} \underbrace{D_{KL}[Q(\tilde x | \pi) \;||\; P(\tilde x | C)]} \\ risco(estados) \end{matrix} \]</span>
<span class="math display">\[ =  \begin{matrix} \underbrace{-\mathbb{E_{Q(\tilde x,\tilde y | \pi)}}[\ln P(\tilde y, \tilde x|C)]} \\ energia\; esperada \end{matrix} - \begin{matrix} \underbrace{H[Q(\tilde x | \pi)]} \\ entropia \end{matrix} \;\;\;\;\;\; (2.6)\]</span></p>
<p><span class="math display">\[ Q(\tilde x,\tilde y | \pi) \overset{\Delta}{=}  Q(\tilde x | \pi)P(\tilde y | \tilde x) \]</span></p>
<p>O primeiro deles é talvez o mais útil, intuitivamente, pois expressa o valor de buscar novas informações (ou seja, exploração(“/ prospecção”) exatamente nas mesmas unidades (nats) que o valor de buscar observações preferidas (ou seja, exploração(“/aproveitamento”), dissolvendo o clássico Dilema explorar-explorar em psicologia comportamental. Ao minimizar a energia livre esperada, o equilíbrio relativo entre esses termos determina se o comportamento é predominantemente exploratório ou explorador. Observe que o valor pragmático surge como uma crença prévia sobre observações, onde o parâmetro C inclui preferências.
A ligação (potencialmente não intuitiva) entre crenças anteriores e preferências é descompactada no capítulo 7; por enquanto, notamos que esse termo pode ser tratado como uma utilidade ou valor esperado, sob a suposição de que resultados valiosos são os tipos de resultados que caracterizam cada agente (por exemplo, uma temperatura corporal de 37°C).</p>
<p>O termo ganho de informação herda da divergência que consideramos na seção 2.5, que garante que a energia livre seja um limite superior da surpresa. No entanto, há uma reviravolta: em vez de minimizar a divergência, queremos selecionar políticas que maximizem a divergência esperada – portanto, ganho de informação. Essa mudança se deve ao fato de que agora estamos obtendo uma média das probabilidades logarítmicas sobre os resultados que ainda não foram observados. Este é um ponto sutil que pode ser entendido em termos de resultados mudando seus papéis. Ao avaliar a energia livre dos resultados, os resultados são as consequências. No entanto, ao avaliar a energia livre esperada, os resultados desempenham o papel de causas no sentido de que são variáveis que estão ocultas no futuro, mas explicam as decisões no presente.</p>
<p>O ganho de informação resultante penaliza as observações para as quais há um mapeamento de muitos para um de observações para estados - no sentido de que se pode obter as mesmas observações em diferentes estados - pois isso impede a atualização precisa da crença. Em inteligência artificial e robótica, os estados que trazem a mesma observação (por exemplo, duas junções em T de um labirinto que parecem idênticos) às vezes são chamados de alias e geralmente são difíceis de lidar usando métodos simples (ou seja, estímulo-resposta, sem inferência ou memória).
O problema é que não podemos saber qual estado ocupamos apenas a partir de observações atuais. A Inferência Ativa evita entrar em tais situações em primeiro lugar, dado seu baixo potencial de ganho de informação.</p>
<p>Um exemplo simples pode ajudar a desfazer a distinção entre ganho de informação (ou valor epistêmico) e valor pragmático e destacar por que, na maioria das situações realistas, os valores pragmáticos e epistêmicos precisam ser perseguidos em conjunto. Imagine uma pessoa que quer um expresso e sabe que existem dois bons cafés na cidade: um que abre apenas de segunda a sexta e outro que abre apenas durante o fim de semana. Se ele não sabe que dia da semana é, ele deve primeiro selecionar uma ação que tenha valor epistêmico e resolva sua incerteza (ou seja, uma ação epistêmica para olhar o calendário) – e somente depois disso selecione uma ação que carrega valor pragmático e traz a recompensa (ou seja, uma ação pragmática para ir ao café correto). Esse cenário ilustra o fato de que, na maioria das situações incertas, deve-se primeiro realizar ações epistêmicas para resolver a incerteza antes de selecionar com confiança uma ação pragmática. Os métodos de seleção de políticas que não consideram a possibilidade epistêmica das escolhas só podem selecionar políticas usando geradores de números aleatórios – e muitas vezes perderão seu café expresso. Portanto, esquemas que consideram apenas valor pragmático são geralmente restritos a situações sem incerteza epistêmica, como no caso de uma pessoa que já sabe o dia da semana e, portanto, pode dirigir-se diretamente ao café correto.</p>
<p>A segunda decomposição na equação 2.6 é em termos de risco e ambiguidade esperada. Esses termos são análogos de complexidade e imprecisão: risco é a complexidade esperada e ambiguidade é a imprecisão esperada. Risco, uma noção comum em economia, corresponde ao fato de que pode haver um mapeamento um-para-muitos entre políticas e suas consequências – no sentido de que se pode obter vários resultados diferentes (por acaso) sob a mesma política. Um exemplo é um cenário de jogo com recompensas estocásticas (por exemplo, um bandido de um braço só, também conhecido como caça-níqueis), em que se pode conhecer a distribuição de recompensas - digamos, que obteremos recompensa 10% das vezes. Isso é chamado de situação de risco em economia porque, após o mesmo movimento (puxar uma alavanca), pode-se obter duas observações diferentes (recompensa ou nenhuma recompensa). Isso significa que é preciso escolher políticas ou planos que acomodem a incerteza. Em esquemas sensíveis ao risco – como inferência ativa – o jogo é escolher políticas cujos resultados probabilísticos correspondam, no sentido de uma KL-Divergência, às preferências anteriores. Em suma, minimizar o custo da complexidade torna-se minimizar o risco quando ambos são medidas de afastamento de crenças anteriores.</p>
<p>Da mesma forma, a ambiguidade corresponde à imprecisão esperada devido a um mapeamento ambíguo entre estados e resultados. Um mapeamento é ambíguo se a distribuição dos resultados previstos for altamente dispersa (ou entrópica), mesmo que conheçamos os estados que os geram com total confiança. Por exemplo, a probabilidade de cara ou coroa no lançamento de uma moeda, condicionada pelo sol ou pela chuva, será extremamente ambígua, pois não há relação entre o clima e a chance de 50% de cara ou coroa. Como tal, não seria possível obter informações sobre o clima observando as caudas. Observe que a maioria das situações é dotada de risco e ambiguidade – o que implica um mapeamento de muitos para um entre estados e resultados e entre políticas e resultados. Lembre-se de que os resultados (observações) são o único tipo de variável que pode ser observada. A Inferência Ativa lida automaticamente com essas situações, porque a energia livre esperada compreende termos de risco e ambiguidade.</p>
<p>A terceira linha da equação 2.6 destaca uma formulação alternativa da energia livre esperada ao reexpressar o risco como uma divergência entre crenças sobre estados e preferências definidas em termos de estados. Uma característica atraente dessa forma é que ela pode ser rearranjada em uma energia e entropia esperadas em analogia com a energia livre variacional (equação 2.5). Embora essa relação seja atraente, uma desvantagem dessa formulação é que ela assume que o espaço de estados é conhecido a priori, de modo que as preferências anteriores podem ser associadas aos estados. Na maioria dos cenários, isso não é um problema, e a escolha entre definir preferências em termos de estados ou resultados tem pouca relevância prática. No entanto, a prática comum é especificar preferências em termos de resultados – permitindo que o próprio espaço de estados seja aprendido enquanto preserva a motivação extrínseca.</p>
<p>Em resumo, a energia livre esperada pode ser decomposta em termos de risco e ambiguidade e em termos de valores pragmáticos e epistêmicos. Essas decomposições são interessantes, pois permitem uma compreensão formal da ampla variedade de situações com as quais a Inferência Ativa lida. Além disso, eles facilitam uma apreciação de como a Inferência Ativa inclui vários esquemas de decisão – que podem ser obtidos ignorando um ou mais componentes da energia livre esperada (figura 2.6). Se removermos as preferências anteriores, o valor pragmático torna-se irrelevante e toda ação é motivada por affordances epistêmicas – portanto, tais esquemas só podem lidar com a resolução da incerteza. Uma vez que as preferências anteriores são removidas, a energia livre esperada (negativa) é conhecida como surpresa Bayesiana esperada (no contexto da exploração atencional) ou motivação intrínseca (no contexto da aprendizagem autônoma). Se a ambiguidade for removida, o esquema resultante corresponde ao controle sensível ao risco ou KL na teoria do controle. Finalmente, se removermos tanto a ambiguidade quanto às preferências anteriores, o único imperativo restante é maximizar a entropia das observações (ou estados, se estiver usando a formulação da terceira linha da equação 2.6). Isso pode ser interpretado como amostragem de incerteza (ou manter as opções em aberto). A Inferência Ativa evidencia as relações formais entre esses esquemas e as situações (limitadas) em que eles se aplicam.</p>
<div class="figure">
<img src="images/Figura_2_6.png" alt="" />
<p class="caption"><strong>Figura 2.6</strong> Vários esquemas que podem ser derivados removendo termos da equação da energia livre. O painel superior mostra os termos que contribuem para a energia livre esperada. Os painéis inferiores mostram os esquemas resultantes da remoção de preferências anteriores (1), ambiguidade (2) ou tudo, exceto as preferências anteriores. Cada uma dessas quantidades aparece em vários campos diferentes sob uma variedade de nomes, mas todas podem ser vistas como componentes de a mesma energia livre esperada.</p>
</div>
<p>Embora tenhamos decomposto cuidadosamente a energia livre esperada de forma que pessoas diferentes possam ler esse funcional, não há maneira certa ou errada de dividi-la. Veremos na segunda metade deste livro por que sistemas autônomos de um certo tipo devem, em virtude de existir, escolher ações que pareçam minimizar a energia livre esperada. Essa perspectiva significa que não há papel privilegiado para imperativos epistêmicos (explorativos) versus pragmáticos (exploradores) – ou para risco versus ambiguidade. Essas (possivelmente falsas) dicotomias são apenas dois lados da mesma moeda existencial.</p>
</div>
<div id="no-final-da-estrada-baixa" class="section level2 hasAnchor" number="2.9">
<h2><span class="header-section-number">2.9</span> No final da estrada baixa<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#no-final-da-estrada-baixa" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Tendo introduzido as duas noções distintas de energia livre variacional e energia livre esperada, estamos agora em condições de considerar o que elas alcançam juntas. Isso representa um ponto final para o caminho inferior da Inferência Ativa, a partir da noção de inferência inconsciente, via cérebro Bayesiano, a dualidade de percepção e ação e, finalmente, planejamento como inferência.</p>
<p>A energia livre variacional está no centro da Inferência Ativa. Ele mede o ajuste entre o modelo generativo interno e as observações (atuais e passadas). Ao minimizar a energia livre variacional, as criaturas maximizam sua evidência de modelo. Isso garante que o modelo generativo se torne um bom modelo do ambiente e que o ambiente esteja em conformidade com o modelo.</p>
<p>A energia livre esperada é uma forma de pontuar políticas alternativas para o planejamento. Isso é fundamentalmente prospectivo – considera possíveis observações futuras – e contrafactual – as possíveis observações futuras estão condicionadas às políticas que se podem adotar. A energia livre esperada mede a plausibilidade das políticas de ação em relação aos estados e observações preferidos (futuros). Ao pontuar as políticas em termos de sua energia livre negativa esperada, as criaturas envolvidas na Inferência Ativa efetivamente acreditam que seguem o curso de ação para o qual essa quantidade é mais baixa. Em termos psicológicos, isso implica que a crença de uma criatura sobre as políticas corresponde diretamente à sua intenção – que ela cumpre agindo.</p>
<p>Do ponto de vista conceitual, podemos associar a minimização da energia livre variacional e da energia livre esperada com dois laços inferenciais, um aninhado no outro. A minimização variacional de energia livre é o ciclo chave (externo) da Inferência Ativa, que é suficiente para otimizar a percepção e as crenças sobre as políticas. Um agente de Inferência Ativa também pode ser dotado de um modelo generativo das consequências de sua ação que envolve uma avaliação da energia livre esperada (o loop interno). Essa capacidade de planejar o futuro suporta formas prospectivas de seleção de ações, fornecendo valores de probabilidade para políticas (Friston, Samothrakis e Montague 2012; Pezzulo 2012).</p>
</div>
<div id="resumo-1" class="section level2 hasAnchor" number="2.10">
<h2><span class="header-section-number">2.10</span> Resumo<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#resumo-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A Inferência Ativa é uma teoria de como os artefatos vivos sustentam sua existência minimizando a surpresa – ou um proxy tratável para surpreender, energia livre variacional – via percepção e ação. Neste capítulo, buscamos motivar essa ideia partindo de um tratamento bayesiano da percepção como inferência e estendendo-o ao domínio da ação. A inferência bayesiana baseia-se em um modelo generativo de como as observações sensoriais são geradas, que codifica (probabilisticamente) o conhecimento implícito do organismo do mundo – formalizado como crenças anteriores e os resultados esperados sob estados e políticas alternativas.</p>
<p>A tomada específica da Inferência Ativa nos força a revisitar a semântica usual de um prior na inferência Bayesiana. Os estados esperados são preferidos e incluem as condições do organismo para a sobrevivência (por exemplo, estados objetivos específicos de nicho), enquanto seus opostos – estados surpreendentes – são despreferidos. Dessa forma, ao atender suas expectativas, os agentes de Inferência Ativa garantem sua própria sobrevivência. Dadas as importantes ligações entre a noção de a priori e as condições que sustentam a existência de um organismo, também podemos dizer que, na Inferência Ativa, a identidade de um agente é isomórfica com suas a priori. Essa terminologia se tornará mais familiar mais adiante no livro.</p>
<p>Observe que, nessa visão, surpresa (ou às vezes surpresa ) é uma construção formal da teoria da informação e não necessariamente equivalente a uma construção psicológica (popular). Grosso modo, quanto mais o estado do organismo difere do estado anterior (que codifica os estados preferidos), mais surpreendente é – portanto, a Inferência Ativa equivale à ideia de que um organismo (ou seu cérebro) tem que minimizar ativamente sua surpresa para permanecer vivo. Sob certas condições, a minimização da surpresa pode ser interpretada como a redução da discrepância entre o modelo e o mundo. Mais geralmente, a quantidade que é realmente minimizada na Inferência Ativa é a energia livre variacional. A energia livre variacional é uma aproximação (limite superior) da surpresa e pode ser minimizada de forma eficiente usando a passagem de mensagens químicas ou neuronais e informações que estão disponíveis para o modelo generativo do organismo.</p>
<p>É importante ressaltar que tanto a percepção quanto a ação minimizam a energia livre variacional de maneiras complementares: refinando sua estimativa (crença posterior ) e realizando ações que amostram seletivamente o que é esperado. Além disso, o Active Inference também minimiza a energia livre esperada seguindo políticas associadas a ambiguidade e risco mínimos. A energia livre esperada então estende a Inferência Ativa para formas de inferência prospectivas e contrafactuais. Isso completa nossa jornada ao longo da estrada secundária para a Inferência Ativa. No capítulo 3, percorreremos a estrada principal, que chega à mesma conclusão com base nos primeiros princípios e na auto-organização.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Como bits, nats são unidades de informação. A escolha da unidade depende se usamos um logaritmo de base 2 (bits) ou um logaritmo natural (nats).<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Suporte é um termo técnico que se refere aos argumentos possíveis para uma distribuição. Por exemplo, o suporte de uma distribuição de probabilidade categórica é uma série de estados alternativos (isto é, espaço de eventos) cuja probabilidade pode ser quantificada. O suporte de uma distribuição normal univariada é toda a reta numérica real.<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Os detalhes desta tabela não são importantes para entender conceitualmente a Inferência Ativa, mas para leitores interessados, descompactamos brevemente os pontos-chave. A coluna Suporte nos informa o conjunto de variáveis cuja surpresa pode ser quantificada usando cada distribuição. Este é o conjunto de números reais para a distribuição gaussiana. Para a distribuição multinomial, o suporte compreende um grupo de K variáveis, cada uma assumindo um valor inteiro até um máximo N, sob a restrição de que todos os elementos desse grupo somam N. Para a distribuição de Dirichlet, o suporte inclui qualquer grupo de K números reais entre 0 e 1, onde todos os elementos do grupo somam 1. A distribuição gama quantifica a surpresa de números reais não negativos. A coluna Surpresa mostra como a surpresa pode ser calculada. Isso depende de constantes (além da variável aleatória x) que controlam a forma da distribuição subjacente.<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Casos especiais incluem distribuições categóricas <span class="math inline">\((K  &gt; 2, N  =  1)\)</span>, binomial <span class="math inline">\((K  = 2, N  &gt;  1)\)</span> e Bernoulli <span class="math inline">\((K = 2, N  =  1)\)</span><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Um caso especial é a distribuição beta <span class="math inline">\((K=2)\)</span><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Curiosamente, as limitações de recursos não são a única barreira para a inferência Bayesiana exata. Na presença de modelos complexos, a inferência exata pode ser analiticamente intratável, de modo que nenhum recurso adicional poderia ajudar a resolver o problema exato.<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>Como o KL-Divergence, a entropia é uma quantidade da teoria da informação. É uma medida da dispersão (ou incerteza) de uma distribuição de probabilidade. Tecnicamente, é a média da probabilidade logarítmica negativa ou surpresa média.<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>A complexidade, conforme usada aqui, pontua o grau em que devemos nos afastar de nossas crenças anteriores sobre o mundo para explicar os dados.<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>Isso é chamado de precisão porque a precisão de uma explicação aumenta quando uma alta probabilidade logarítmica de resultados, esperada sob os estados ocultos inferidos, é atribuída a dados observados - ou seja, quando a distribuição prevista de resultados captura com precisão a distribuição medida.<a href="o-caminho-de-baixo-para-a-inferência-ativa.html#fnref11" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="visão-geral.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="o-caminho-para-a-inferência-ativa.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Inferencia Ativa.pdf", "Inferencia Ativa.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
