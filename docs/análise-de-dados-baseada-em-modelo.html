<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>> 9 Análise de dados baseada em modelo | Inferencia Ativa</title>
  <meta name="description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="> 9 Análise de dados baseada em modelo | Inferencia Ativa" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/Figura_1_1.png" />
  <meta property="og:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="> 9 Análise de dados baseada em modelo | Inferencia Ativa" />
  
  <meta name="twitter:description" content="O Princípio da Energia Livre na Mente, Cérebro e Comportamento." />
  <meta name="twitter:image" content="/images/Figura_1_1.png" />

<meta name="author" content="Thomas Parr, Giovanni Pezzulo, and Karl J. Friston" />


<meta name="date" content="2022-07-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inferência-ativa-em-tempo-contínuo-1.html"/>
<link rel="next" href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Inferencia Ativa</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Conteúdo</a></li>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html"><i class="fa fa-check"></i>Prefácio</a></li>
<li class="chapter" data-level="1" data-path="visão-geral.html"><a href="visão-geral.html"><i class="fa fa-check"></i><b>1</b> Visão Geral</a>
<ul>
<li class="chapter" data-level="1.1" data-path="visão-geral.html"><a href="visão-geral.html#introdução"><i class="fa fa-check"></i><b>1.1</b> Introdução</a></li>
<li class="chapter" data-level="1.2" data-path="visão-geral.html"><a href="visão-geral.html#como-os-organismos-vivos-persistem-e-agem-adaptativamente"><i class="fa fa-check"></i><b>1.2</b> Como os Organismos Vivos Persistem e Agem Adaptativamente?</a></li>
<li class="chapter" data-level="1.3" data-path="visão-geral.html"><a href="visão-geral.html#inferência-ativa-comportamento-a-partir-dos-primeiros-princípios"><i class="fa fa-check"></i><b>1.3</b> Inferência Ativa: Comportamento a partir dos Primeiros Princípios</a></li>
<li class="chapter" data-level="1.4" data-path="visão-geral.html"><a href="visão-geral.html#estrutura-do-livro"><i class="fa fa-check"></i><b>1.4</b> Estrutura do Livro</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="visão-geral.html"><a href="visão-geral.html#parte-1-inferência-ativa-na-teoria"><i class="fa fa-check"></i><b>1.4.1</b> Parte 1: Inferência Ativa na Teoria</a></li>
<li class="chapter" data-level="1.4.2" data-path="visão-geral.html"><a href="visão-geral.html#parte-2-inferência-ativa-na-prática"><i class="fa fa-check"></i><b>1.4.2</b> Parte 2: Inferência Ativa na Prática</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="visão-geral.html"><a href="visão-geral.html#resumo"><i class="fa fa-check"></i><b>1.5</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>2</b> O Caminho de baixo para a Inferência Ativa</a>
<ul>
<li class="chapter" data-level="2.1" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#introdução-1"><i class="fa fa-check"></i><b>2.1</b> Introdução</a></li>
<li class="chapter" data-level="2.2" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#percepção-como-inferência"><i class="fa fa-check"></i><b>2.2</b> Percepção como Inferência</a></li>
<li class="chapter" data-level="2.3" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#inferência-biológica-e-otimização"><i class="fa fa-check"></i><b>2.3</b> Inferência Biológica e Otimização</a></li>
<li class="chapter" data-level="2.4" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#ação-como-inferência"><i class="fa fa-check"></i><b>2.4</b> Ação como Inferência</a></li>
<li class="chapter" data-level="2.5" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-discrepância-entre-o-modelo-e-o-mundo"><i class="fa fa-check"></i><b>2.5</b> Minimizando a discrepância entre o modelo e o mundo</a></li>
<li class="chapter" data-level="2.6" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#minimizando-a-energia-livre-variacional"><i class="fa fa-check"></i><b>2.6</b> Minimizando a Energia Livre Variacional</a></li>
<li class="chapter" data-level="2.7" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#energia-livre-esperada-e-planejamento-como-inferência"><i class="fa fa-check"></i><b>2.7</b> Energia Livre Esperada e Planejamento como Inferência</a></li>
<li class="chapter" data-level="2.8" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#o-que-é-energia-livre-esperada"><i class="fa fa-check"></i><b>2.8</b> O que é energia livre esperada?</a></li>
<li class="chapter" data-level="2.9" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#no-final-da-estrada-baixa"><i class="fa fa-check"></i><b>2.9</b> No final da estrada baixa</a></li>
<li class="chapter" data-level="2.10" data-path="o-caminho-de-baixo-para-a-inferência-ativa.html"><a href="o-caminho-de-baixo-para-a-inferência-ativa.html#resumo-1"><i class="fa fa-check"></i><b>2.10</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html"><i class="fa fa-check"></i><b>3</b> O caminho para a inferência ativa</a>
<ul>
<li class="chapter" data-level="3.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#introdução-2"><i class="fa fa-check"></i><b>3.1</b> Introdução</a></li>
<li class="chapter" data-level="3.2" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#envoltórios-de-markov"><i class="fa fa-check"></i><b>3.2</b> Envoltórios de Markov</a></li>
<li class="chapter" data-level="3.3" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-e-auto-evidência"><i class="fa fa-check"></i><b>3.3</b> Minimização de surpresa e auto-evidência</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#minimização-de-surpresa-como-um-princípio-hamiltoniano-de-menor-ação"><i class="fa fa-check"></i><b>3.3.1</b> Minimização de surpresa como um princípio hamiltoniano de menor ação</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#relações-entre-inferência-cognição-e-dinâmica-estocástica"><i class="fa fa-check"></i><b>3.4</b> Relações entre Inferência, Cognição e Dinâmica Estocástica</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#energia-livre-variacional-evidência-modelo-e-surpresa"><i class="fa fa-check"></i><b>3.4.1</b> Energia Livre Variacional, Evidência Modelo e Surpresa</a></li>
<li class="chapter" data-level="3.4.2" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#energia-livre-esperada-e-inferência-da-trajetória-mais-provável"><i class="fa fa-check"></i><b>3.4.2</b> Energia Livre Esperada e Inferência da Trajetória Mais Provável</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#inferência-ativa-uma-nova-base-para-entender-o-comportamento-e-a-cognição"><i class="fa fa-check"></i><b>3.5</b> Inferência ativa: uma nova base para entender o comportamento e a cognição</a></li>
<li class="chapter" data-level="3.6" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#modelos-políticas-e-trajetórias"><i class="fa fa-check"></i><b>3.6</b> Modelos, Políticas e Trajetórias</a></li>
<li class="chapter" data-level="3.7" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#reconciliação-das-teorias-enativa-cibernética-e-preditiva-sob-inferência-ativa"><i class="fa fa-check"></i><b>3.7</b> Reconciliação das Teorias Enativa, Cibernética e Preditiva sob Inferência Ativa</a></li>
<li class="chapter" data-level="3.8" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#inferência-ativa-da-emergência-da-vida-para-a-atuação"><i class="fa fa-check"></i><b>3.8</b> Inferência Ativa, da Emergência da Vida para a atuação</a></li>
<li class="chapter" data-level="3.9" data-path="o-caminho-para-a-inferência-ativa.html"><a href="o-caminho-para-a-inferência-ativa.html#resumo-2"><i class="fa fa-check"></i><b>3.9</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html"><i class="fa fa-check"></i><b>4</b> Os Modelos Geradores de Inferência Ativa</a>
<ul>
<li class="chapter" data-level="4.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#introdução-3"><i class="fa fa-check"></i><b>4.1</b> Introdução</a></li>
<li class="chapter" data-level="4.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#da-inferência-bayesiana-à-energia-livre"><i class="fa fa-check"></i><b>4.2</b> Da Inferência Bayesiana à Energia Livre</a></li>
<li class="chapter" data-level="4.3" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#modelos-geradores"><i class="fa fa-check"></i><b>4.3</b> Modelos Geradores</a></li>
<li class="chapter" data-level="4.4" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-tempo-discreto"><i class="fa fa-check"></i><b>4.4</b> Inferência ativa em tempo discreto</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#processos-de-decisão-markov-parcialmente-observáveis"><i class="fa fa-check"></i><b>4.4.1</b> Processos de Decisão Markov Parcialmente Observáveis</a></li>
<li class="chapter" data-level="4.4.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-um-pomdp"><i class="fa fa-check"></i><b>4.4.2</b> Inferência ativa em um POMDP</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-em-tempo-contínuo"><i class="fa fa-check"></i><b>4.5</b> Inferência Ativa em Tempo Contínuo</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#um-modelo-generativo-para-codificação-preditiva"><i class="fa fa-check"></i><b>4.5.1</b> Um modelo generativo para codificação preditiva</a></li>
<li class="chapter" data-level="4.5.2" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#inferência-ativa-como-codificação-preditiva-com-reflexos-motores"><i class="fa fa-check"></i><b>4.5.2</b> Inferência Ativa como Codificação Preditiva com Reflexos Motores</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="os-modelos-geradores-de-inferência-ativa.html"><a href="os-modelos-geradores-de-inferência-ativa.html#resumo-3"><i class="fa fa-check"></i><b>4.6</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html"><i class="fa fa-check"></i><b>5</b> Passagem de Mensagens e Neurobiologia</a>
<ul>
<li class="chapter" data-level="5.1" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#introdução-4"><i class="fa fa-check"></i><b>5.1</b> Introdução</a></li>
<li class="chapter" data-level="5.2" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#microcircuitos-e-mensagens"><i class="fa fa-check"></i><b>5.2</b> Microcircuitos e Mensagens</a></li>
<li class="chapter" data-level="5.3" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#comandos-do-motor"><i class="fa fa-check"></i><b>5.3</b> Comandos do Motor</a></li>
<li class="chapter" data-level="5.4" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#estruturas-subcorticais"><i class="fa fa-check"></i><b>5.4</b> Estruturas Subcorticais</a></li>
<li class="chapter" data-level="5.5" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#neuromodulação-e-aprendizagem"><i class="fa fa-check"></i><b>5.5</b> Neuromodulação e Aprendizagem</a></li>
<li class="chapter" data-level="5.6" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#hierarquias-contínuas-e-discretas"><i class="fa fa-check"></i><b>5.6</b> Hierarquias Contínuas e Discretas</a></li>
<li class="chapter" data-level="5.7" data-path="passagem-de-mensagens-e-neurobiologia.html"><a href="passagem-de-mensagens-e-neurobiologia.html#resumo-4"><i class="fa fa-check"></i><b>5.7</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><i class="fa fa-check"></i><b>6</b> Uma receita para projetar modelos de inferência ativos</a>
<ul>
<li class="chapter" data-level="6.1" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#introdução-5"><i class="fa fa-check"></i><b>6.1</b> Introdução</a></li>
<li class="chapter" data-level="6.2" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#projetando-um-modelo-de-inferência-ativo-uma-receita-em-quatro-etapas"><i class="fa fa-check"></i><b>6.2</b> Projetando um modelo de inferência ativo: uma receita em quatro etapas</a></li>
<li class="chapter" data-level="6.3" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#que-sistema-estamos-modelando"><i class="fa fa-check"></i><b>6.3</b> Que sistema estamos modelando?</a></li>
<li class="chapter" data-level="6.4" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#qual-é-a-forma-mais-adequada-para-o-modelo-generativo"><i class="fa fa-check"></i><b>6.4</b> Qual é a forma mais adequada para o modelo generativo?</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#variáveis-discretas-ou-contínuas-ou-ambas"><i class="fa fa-check"></i><b>6.4.1</b> Variáveis Discretas ou Contínuas (ou Ambas)?</a></li>
<li class="chapter" data-level="6.4.2" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#escalas-de-tempo-de-inferência-modelos-rasos-versus-modelos-hierárquicos"><i class="fa fa-check"></i><b>6.4.2</b> Escalas de tempo de inferência: modelos rasos versus modelos hierárquicos</a></li>
<li class="chapter" data-level="6.4.3" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#profundidade-temporal-de-inferência-e-planejamento"><i class="fa fa-check"></i><b>6.4.3</b> Profundidade Temporal de Inferência e Planejamento</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#como-configurar-o-modelo-generativo"><i class="fa fa-check"></i><b>6.5</b> Como configurar o modelo generativo?</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#configurando-as-variáveis-do-modelo-gerador"><i class="fa fa-check"></i><b>6.5.1</b> Configurando as Variáveis do Modelo Gerador</a></li>
<li class="chapter" data-level="6.5.2" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#quais-partes-do-modelo-generativo-são-fixas-e-o-que-é-aprendido"><i class="fa fa-check"></i><b>6.5.2</b> Quais partes do modelo generativo são fixas e o que é aprendido?|</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#configurando-o-processo-gerador"><i class="fa fa-check"></i><b>6.6</b> Configurando o Processo Gerador</a></li>
<li class="chapter" data-level="6.7" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#simulando-visualizando-analisando-e-ajustando-dados-usando-inferência-ativa"><i class="fa fa-check"></i><b>6.7</b> Simulando, Visualizando, Analisando e Ajustando Dados Usando Inferência Ativa</a></li>
<li class="chapter" data-level="6.8" data-path="uma-receita-para-projetar-modelos-de-inferência-ativos.html"><a href="uma-receita-para-projetar-modelos-de-inferência-ativos.html#resumo-5"><i class="fa fa-check"></i><b>6.8</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html"><i class="fa fa-check"></i><b>7</b> Inferência ativa em tempo discreto</a>
<ul>
<li class="chapter" data-level="7.1" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#introdução-6"><i class="fa fa-check"></i><b>7.1</b> Introdução</a></li>
<li class="chapter" data-level="7.2" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#processamento-perceptivo"><i class="fa fa-check"></i><b>7.2</b> Processamento Perceptivo</a></li>
<li class="chapter" data-level="7.3" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#tomada-de-decisão-e-planejamento-como-inferência"><i class="fa fa-check"></i><b>7.3</b> Tomada de decisão e planejamento como inferência</a></li>
<li class="chapter" data-level="7.4" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#busca-de-informações"><i class="fa fa-check"></i><b>7.4</b> Busca de informações</a></li>
<li class="chapter" data-level="7.5" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#aprendizado-e-novidade"><i class="fa fa-check"></i><b>7.5</b> Aprendizado e Novidade</a></li>
<li class="chapter" data-level="7.6" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#inferência-hierárquica-ou-profunda"><i class="fa fa-check"></i><b>7.6</b> Inferência Hierárquica ou Profunda</a></li>
<li class="chapter" data-level="7.7" data-path="inferência-ativa-em-tempo-discreto-1.html"><a href="inferência-ativa-em-tempo-discreto-1.html#resumo-6"><i class="fa fa-check"></i><b>7.7</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html"><i class="fa fa-check"></i><b>8</b> Inferência ativa em tempo contínuo</a>
<ul>
<li class="chapter" data-level="8.1" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#introdução-7"><i class="fa fa-check"></i><b>8.1</b> Introdução</a></li>
<li class="chapter" data-level="8.2" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#controles-de-movimento"><i class="fa fa-check"></i><b>8.2</b> Controles de movimento</a></li>
<li class="chapter" data-level="8.3" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#sistemas-dinâmicos"><i class="fa fa-check"></i><b>8.3</b> Sistemas Dinâmicos</a></li>
<li class="chapter" data-level="8.4" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#sincronia-generalizada"><i class="fa fa-check"></i><b>8.4</b> Sincronia Generalizada</a></li>
<li class="chapter" data-level="8.5" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#modelos-híbridos-discretos-e-contínuos"><i class="fa fa-check"></i><b>8.5</b> Modelos Híbridos (Discretos e Contínuos)</a></li>
<li class="chapter" data-level="8.6" data-path="inferência-ativa-em-tempo-contínuo-1.html"><a href="inferência-ativa-em-tempo-contínuo-1.html#resumo-7"><i class="fa fa-check"></i><b>8.6</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="análise-de-dados-baseada-em-modelo.html"><a href="análise-de-dados-baseada-em-modelo.html"><i class="fa fa-check"></i><b>9</b> Análise de dados baseada em modelo</a>
<ul>
<li class="chapter" data-level="9.1" data-path="análise-de-dados-baseada-em-modelo.html"><a href="análise-de-dados-baseada-em-modelo.html#introdução-8"><i class="fa fa-check"></i><b>9.1</b> Introdução</a></li>
<li class="chapter" data-level="9.2" data-path="análise-de-dados-baseada-em-modelo.html"><a href="análise-de-dados-baseada-em-modelo.html#métodos-meta-bayesianos"><i class="fa fa-check"></i><b>9.2</b> Métodos Meta-Bayesianos</a></li>
<li class="chapter" data-level="9.3" data-path="análise-de-dados-baseada-em-modelo.html"><a href="análise-de-dados-baseada-em-modelo.html#laplace-variacional"><i class="fa fa-check"></i><b>9.3</b> Laplace Variacional</a></li>
<li class="chapter" data-level="9.4" data-path="análise-de-dados-baseada-em-modelo.html"><a href="análise-de-dados-baseada-em-modelo.html#bayes-empíricos-paramétricos-peb"><i class="fa fa-check"></i><b>9.4</b> Bayes Empíricos Paramétricos (PEB)</a></li>
<li class="chapter" data-level="9.5" data-path="análise-de-dados-baseada-em-modelo.html"><a href="análise-de-dados-baseada-em-modelo.html#instruções-para-análise-baseada-em-modelo"><i class="fa fa-check"></i><b>9.5</b> Instruções para Análise Baseada em Modelo</a></li>
<li class="chapter" data-level="9.6" data-path="análise-de-dados-baseada-em-modelo.html"><a href="análise-de-dados-baseada-em-modelo.html#modelos-de-falsa-inferência"><i class="fa fa-check"></i><b>9.6</b> Modelos de falsa inferência</a></li>
<li class="chapter" data-level="9.7" data-path="análise-de-dados-baseada-em-modelo.html"><a href="análise-de-dados-baseada-em-modelo.html#resumo-8"><i class="fa fa-check"></i><b>9.7</b> Resumo</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><i class="fa fa-check"></i><b>10</b> Inferência ativa como uma teoria unificada do comportamento sensível</a>
<ul>
<li class="chapter" data-level="10.1" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#introdução-9"><i class="fa fa-check"></i><b>10.1</b> Introdução</a></li>
<li class="chapter" data-level="10.2" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#empacotando"><i class="fa fa-check"></i><b>10.2</b> Empacotando</a></li>
<li class="chapter" data-level="10.3" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#conectando-os-pontos-a-perspectiva-integrativa-da-inferência-ativa"><i class="fa fa-check"></i><b>10.3</b> Conectando os Pontos: A Perspectiva Integrativa da Inferência Ativa</a></li>
<li class="chapter" data-level="10.4" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#cérebros-preditivos-mentes-preditivas-e-processamento-preditivo"><i class="fa fa-check"></i><b>10.4</b> Cérebros Preditivos, Mentes Preditivas e Processamento Preditivo</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#processamento-preditivo"><i class="fa fa-check"></i><b>10.4.1</b> Processamento Preditivo</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#percepção"><i class="fa fa-check"></i><b>10.5</b> Percepção</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#hipótese-do-cérebro-bayesiano"><i class="fa fa-check"></i><b>10.5.1</b> Hipótese do Cérebro Bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#controle-de-ação"><i class="fa fa-check"></i><b>10.6</b> Controle de Ação</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#teoria-ideomotora"><i class="fa fa-check"></i><b>10.6.1</b> Teoria Ideomotora</a></li>
<li class="chapter" data-level="10.6.2" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#cibernética"><i class="fa fa-check"></i><b>10.6.2</b> Cibernética</a></li>
<li class="chapter" data-level="10.6.3" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#teoria-do-controle-ótimo"><i class="fa fa-check"></i><b>10.6.3</b> Teoria do Controle Ótimo</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#utilidade-e-tomada-de-decisão"><i class="fa fa-check"></i><b>10.7</b> Utilidade e Tomada de Decisão</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#teoria-da-decisão-bayesiana"><i class="fa fa-check"></i><b>10.7.1</b> Teoria da Decisão Bayesiana</a></li>
<li class="chapter" data-level="10.7.2" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#aprendizado-por-reforço"><i class="fa fa-check"></i><b>10.7.2</b> Aprendizado por Reforço</a></li>
<li class="chapter" data-level="10.7.3" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#planejamento-como-inferência"><i class="fa fa-check"></i><b>10.7.3</b> Planejamento como Inferência</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#comportamento-e-racionalidade-limitada"><i class="fa fa-check"></i><b>10.8</b> Comportamento e Racionalidade Limitada</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#teoria-da-energia-livre-da-racionalidade-limitada"><i class="fa fa-check"></i><b>10.8.1</b> Teoria da Energia Livre da Racionalidade Limitada</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#valência-emoção-e-motivação"><i class="fa fa-check"></i><b>10.9</b> Valência, emoção e motivação</a></li>
<li class="chapter" data-level="10.10" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#homeostase-alostase-e-processamento-interoceptivo"><i class="fa fa-check"></i><b>10.10</b> Homeostase, Alostase e Processamento Interoceptivo</a></li>
<li class="chapter" data-level="10.11" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#atenção-saliência-e-dinâmica-epistêmica"><i class="fa fa-check"></i><b>10.11</b> Atenção, Saliência e Dinâmica Epistêmica</a></li>
<li class="chapter" data-level="10.12" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#aprendizado-de-regras-inferência-causal-e-generalização-rápida"><i class="fa fa-check"></i><b>10.12</b> Aprendizado de regras, inferência causal e generalização rápida</a></li>
<li class="chapter" data-level="10.13" data-path="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html"><a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html#inferência-ativa-e-outros-campos-direções-abertas"><i class="fa fa-check"></i><b>10.13</b> Inferência ativa e outros campos: direções abertas</a></li>
</ul></li>
<li class="appendix"><span><b>Apêndice</b></span></li>
<li class="chapter" data-level="A" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html"><i class="fa fa-check"></i><b>A</b> Bases Matemáticas</a>
<ul>
<li class="chapter" data-level="A.1" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#introdução-10"><i class="fa fa-check"></i><b>A.1</b> Introdução</a></li>
<li class="chapter" data-level="A.2" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#álgebra-linear"><i class="fa fa-check"></i><b>A.2</b> Álgebra Linear</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#o-básico"><i class="fa fa-check"></i><b>A.2.1</b> O básico</a></li>
<li class="chapter" data-level="A.2.2" data-path="bases-matemáticas.html"><a href="bases-matemáticas.html#derivadas"><i class="fa fa-check"></i><b>A.2.2</b> Derivadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="as-equações-da-inferência-ativa.html"><a href="as-equações-da-inferência-ativa.html"><i class="fa fa-check"></i><b>B</b> As equações da inferência ativa</a></li>
<li class="chapter" data-level="" data-path="dicionário.html"><a href="dicionário.html"><i class="fa fa-check"></i>Dicionário</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Inferencia Ativa</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="análise-de-dados-baseada-em-modelo" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">> 9</span> Análise de dados baseada em modelo<a href="análise-de-dados-baseada-em-modelo.html#análise-de-dados-baseada-em-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Só porque temos o melhor martelo não significa que todo problema é um prego. —Barack Obama</p>
<div id="introdução-8" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Introdução<a href="análise-de-dados-baseada-em-modelo.html#introdução-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Em última análise, os modelos descritos neste livro só são úteis se puderem responder a questões científicas. Neste capítulo, nos concentramos nas maneiras pelas quais a Inferência Ativa pode ser aplicada na compreensão de dados empíricos. A ideia central é que nós, como cientistas, podemos recorrer à mesma matemática que supusemos que o cérebro usa nos capítulos anteriores. Nosso objetivo geral é recuperar os parâmetros do modelo generativo que o cérebro de um sujeito usa para produzir comportamento – o modelo subjetivo. Para isso, podemos usar nosso próprio modelo generativo (de como o modelo subjetivo produz comportamento) – o modelo objetivo. Podemos inverter nosso modelo objetivo com base no comportamento que observamos para fazer inferências sobre os parâmetros do modelo generativo subjetivo. Essa inferência meta-Bayesiana oferece a oportunidade de testar hipóteses sobre o modelo que assumimos que o cérebro usa e fenotipar os indivíduos com base nas crenças anteriores que eles teriam que manter para que seu comportamento fosse o ideal de Bayes. A fenotipagem computacional baseada em crenças desse tipo é promissora nos campos emergentes da psiquiatria computacional, neuropsicologia e neurologia.</p>
</div>
<div id="métodos-meta-bayesianos" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Métodos Meta-Bayesianos<a href="análise-de-dados-baseada-em-modelo.html#métodos-meta-bayesianos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este capítulo trata da utilidade das formulações de Inferência Ativa na análise de dados de experimentos comportamentais. Isso vai além das simulações de prova de princípio que vimos nos capítulos anteriores e, em vez disso, explora a Inferência Ativa para responder a questões científicas. Já vimos que o modelo generativo de um sujeito é o principal determinante do comportamento sob Inferência Ativa. Isso implica que as hipóteses sobre as causas das medidas comportamentais empíricas devem ser enquadradas em termos dos modelos generativos alternativos usados para selecionar essas ações. Nosso desafio, então, é ajustar um esquema de Inferência Ativa aos dados observados, manipulando os parâmetros (ou seja, crenças anteriores) do modelo generativo.</p>
<p>De um modo geral, existem duas razões (relacionadas) para ajustar um modelo computacional ao comportamento observado. A primeira é estimar os parâmetros de interesse desse modelo que melhor explicam o comportamento de um determinado sujeito ou grupo de sujeitos. Isso é útil para caracterizar o comportamento subjetivo em termos dos cálculos que o geram, um processo conhecido como fenotipagem computacional (Montague et al. 2012, Schwartenbeck e Friston 2016, Friston 2017). Os fenótipos computacionais podem ser usados em combinação com outras medidas (por exemplo, para estabelecer ligações entre achados de neuroimagem e função) ou podem ser usados sozinhos na previsão de comportamentos em outros ambientes (por exemplo, após uma intervenção terapêutica).</p>
<p>A segunda razão é comparar hipóteses alternativas, expressas como modelos, que representam diferentes explicações para um fenômeno comportamental (Mirza et al. 2018). Essas duas agendas – estimativa de parâmetros e comparação de modelos – mapeiam para um lado do teorema de Bayes. A estimativa de parâmetros é o processo de encontrar a probabilidade posterior, sob um modelo, de um ajuste de parâmetros. A comparação de modelos baseia-se em encontrar as probabilidades marginais (ou seja, evidências) para cada modelo. Para recapitular, o teorema de Bayes é</p>
<p><span class="math display">\[ \begin{matrix}\underbrace {P(u|\theta,m)} \\ Verossimilhança \end{matrix}
\begin{matrix}\underbrace {P(\theta|m)} \\ Prior \end{matrix}
= \begin{matrix}\underbrace {P(\theta|u, m)} \\ Posterior \end{matrix}
\begin{matrix}\underbrace {P(u,m)} \\ Evidência \end{matrix}
(9.1)\]</span></p>
<p>O lado direito lida com a probabilidade posterior de parâmetros <span class="math inline">\((\theta)\)</span> dados dados comportamentais <span class="math inline">\((u)\)</span> sob um modelo <span class="math inline">\((m)\)</span> e a evidência do modelo, e o lado esquerdo nos diz o que precisamos especificar para nosso modelo: precisamos de crenças prévias sobre nossos parâmetros de interesse e uma função de verossimilhança.</p>
<p>É importante ressaltar que, embora apelamos para o mesmo esquema de inferência bayesiana usado nos capítulos anteriores, nosso objetivo é diferente aqui. Isso se baseia no fato de que existem dois processos de inferência acontecendo (figura 9.1). A primeira é que as criaturas usam seu modelo dos processos que geram seus dados sensoriais para fazer inferências sobre seu mundo (e sobre como agir). Este foi o foco dos capítulos anteriores. A segunda é que nós, como cientistas objetivos, observamos o comportamento da criatura e procuramos fazer inferências sobre o modelo generativo (subjetivo) que ela está usando invertendo nosso próprio modelo generativo (objetivo). A implicação aqui é que estamos fazendo inferências sobre um processo inferencial – às vezes chamado de inferência “metabayesiana” (Daunizeau et al. 2010).</p>
<div class="figure">
<img src="images/Figura_9_1.png" alt="" />
<p class="caption">Figura 9.1 Relação entre os modelos subjetivo e objetivo de inferência metabayesiana. Caixa tracejada interna: Modelo subjetivo assumido para ser usado por um sujeito experimental. Este poderia ser um modelo POMDP como ilustrado ou alguma outra forma de modelo. As características importantes são que depende de parâmetros <span class="math inline">\((\theta)\)</span> cujo valor não sabemos e que gera dados sensoriais <span class="math inline">\((o)\)</span>. Caixa tracejada externa: O modelo objetivo do experimentador <span class="math inline">\((m)\)</span> inclui crenças prévias sobre os parâmetros e prediz o comportamento <span class="math inline">\((u)\)</span> que esperaríamos ao apresentar estímulos experimentais (dados sensoriais da perspectiva do modelo subjetivo). Fundamentalmente, a distribuição de verossimilhança do modelo objetivo depende do modelo subjetivo. Isso significa que avaliamos a probabilidade de os parâmetros assumirem um valor específico da seguinte maneira. Primeiro, incorporamos os parâmetros no modelo subjetivo. Em seguida, usamos os esquemas de Inferência Ativa descritos nos capítulos anteriores para resolver esse modelo, apresentando nossos estímulos experimentais como dados sensoriais e inferindo uma distribuição sobre o curso de ação mais provável. Por fim, avaliamos a probabilidade das ações ou escolhas observadas, dada essa distribuição. Esta é a probabilidade do comportamento observado dados parâmetros e estímulos - ou seja, a distribuição de verossimilhança no modelo objetivo.</p>
</div>
<p>Mais formalmente, essa abordagem define a distribuição de verossimilhança em termos da solução de um problema de Inferência Ativa. Ao usar uma determinada configuração de parâmetro, podemos simular o comportamento sob Inferência Ativa e quantificar a probabilidade de que uma série de ações tenha sido executada. Equipados com crenças anteriores sobre o valor desses parâmetros, temos um modelo generativo de como uma criatura usa seu modelo generativo para produzir ações. Embora nosso foco seja a Inferência Ativa (e modelos de tempo discreto especificamente), os métodos genéricos usados aqui podem ser usados com qualquer função de verossimilhança arbitrária. Outros modelos normativos de comportamento (como os usados no aprendizado por reforço) podem ser substituídos pelos modelos de Inferência Ativa.</p>
<p>As seções a seguir descompactam um exemplo de um esquema de inferência genérico que pode ser usado para inferência meta-Bayesiana (ou seja, Laplace variacional) e o uso de modelos hierárquicos para comparação de modelos. Em seguida, fornecemos uma receita simples para análise de dados baseada em modelo e, finalmente, revisamos um exemplo-chave desse procedimento. É importante enfatizar que não é necessário entender os detalhes técnicos para usar esses métodos de forma eficaz; assim, os leitores desinteressados nesses detalhes são convidados a pular as seções 9.3 e 9.4.</p>
<p>Em resumo, a ideia básica é avaliar a probabilidade de qualquer conjunto observado de escolhas, dados os parâmetros desconhecidos de interesse – ou seja, os parâmetros das crenças anteriores de um sujeito. Em seguida, combinamos essa verossimilhança com nosso objetivo anterior sobre esses parâmetros para avaliar o posterior sobre os antecedentes do sujeito, da maneira usual. Se tivermos vários sujeitos, esses posteriores podem ser combinados para fazer inferências sobre efeitos de grupo ou entre sujeitos, usando Bayes empíricos paramétricos (PEB). A probabilidade necessária é simplesmente a probabilidade de amostragem da sequência observada de escolhas, sob as crenças posteriores do sujeito sobre a ação. Essas crenças posteriores dependem do que o sujeito vê (ou seja, pistas ou estímulos) e suas crenças anteriores – e são avaliadas de maneira direta, resolvendo o esquema de Inferência Ativa apropriado. Observe que estamos usando procedimentos bayesianos duas vezes: primeiro para avaliar as crenças posteriores do sujeito sobre a ação e, segundo, para avaliar nossas crenças posteriores sobre os antecedentes desconhecidos que caracterizam o sujeito. Agora ensaiamos as várias partes desse procedimento metabayesiano.</p>
</div>
<div id="laplace-variacional" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Laplace Variacional<a href="análise-de-dados-baseada-em-modelo.html#laplace-variacional" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Variational Laplace é um esquema de inferência baseado nos mesmos princípios da codificação preditiva (Friston, Mattout et al. 2007). No entanto, pode ser usado para funções de verossimilhança mais genéricas do que aquelas encontradas anteriormente – que foram definidas como gaussianas. Começaremos esta seção com uma visão geral da função de verossimilhança <span class="math inline">\(\mathcal L(\theta)\)</span> de interesse aqui. Isso deve fornecer a probabilidade de ações para um esquema de Inferência Ativa com um modelo generativo com parâmetros definidos no valor <span class="math inline">\(\theta\)</span>. As ações selecionadas dependem das observações feitas:</p>
<p><span class="math display">\[ \mathcal L(\theta)=\ln P(\tilde u |\theta,m,\tilde o )\]</span>
<span class="math display">\[ P(\tilde u |\theta,m,\tilde o ) = \tilde u \cdot \sigma (\theta_\alpha ln  \pmb {\tilde u}) \qquad\qquad (9.2)\]</span>
<span class="math display">\[ \pmb {\tilde u} = \pmb \pi \cdot U\]</span></p>
<p><span class="math display">\[ \pmb \pi =arg \;min\; F \]</span></p>
<p>Descompactando isso, o primeiro termo fornece a probabilidade logarítmica de uma sequência observada de ações <span class="math inline">\((\tilde u)\)</span> em função dos parâmetros <span class="math inline">\((\theta)\)</span>, do modelo <span class="math inline">\((m)\)</span> e de uma sequência de estímulos <span class="math inline">\((\tilde o)\)</span> apresentada durante um experimento real. A probabilidade dessas ações é encontrada usando os parâmetros para definir as crenças anteriores em um modelo POMDP do tipo descrito no capítulo 7. Podemos então resolver o POMDP conforme descrito nos capítulos 4 e 7, forçando a simulação a realizar a ação observada sequência e apresentando-a com os mesmos estímulos experimentais. Como descrevemos nos capítulos anteriores, isso envolve calcular as crenças <span class="math inline">\((\pi)\)</span> que um sujeito sintético mantém sobre a política ou curso de ação que ele escolhe seguir. Isso minimiza a energia livre <span class="math inline">\((F)\)</span> associada ao seu modelo generativo do mundo. Podemos então pegar essas crenças e calcular a probabilidade média de seguir uma sequência de ação. Isso exige que distribuamos a probabilidade de cada política pelas ações implícitas nessa política (indexadas por uma matriz <span class="math inline">\(U\)</span> ). Finalmente, um parâmetro de temperatura softmax <span class="math inline">\((θ_\alpha)\)</span> é aplicado para levar em conta a aleatoriedade (tremor) no comportamento não contabilizado pelo modelo. Se esse parâmetro softmax for um, estamos efetivamente assumindo que o sujeito amostra suas ações a partir de crenças posteriores sobre suas ações; às vezes, isso é chamado de comportamento de correspondência. Alternativamente, se o parâmetro softmax for muito grande, a ação emitida é a ação com maior posterior subjetiva, ou seja, o sujeito sempre escolhe a opção mais provável. Este parâmetro softmax pode ser estimado.</p>
<p>O resultado é a probabilidade das ações sob o modelo, dada uma sequência de estímulos e parâmetros – isto é, uma probabilidade de dados comportamentais dado um modelo. Equipando os parâmetros objetivos com priors gaussianas<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> $ (N (, ^{(1)}) $, podemos usar a suposição de Laplace para expressar a (energia livre) aproximação à evidência do modelo:</p>
<p><span class="math display">\[\begin{equation}
\ln P(\tilde u| m, \tilde o) \approx \mathcal L(\mu)- \frac{1}{2} \Big(\epsilon \cdot \Pi^{(1)}\epsilon + \ln \Big| \nabla_{\mu\mu} \mathcal L (\mu)-\Pi^{(1)} \Big| \Big) \\
e = \eta - \mu  \qquad \qquad (9.3)\\
\mu = arg \; max \Big\{ \mathcal L(\mu)- \frac{1}{2} \Big(\epsilon \cdot \Pi^{(1)}\epsilon + \ln \Big| \nabla_{\mu\mu} \mathcal L (\mu)-\Pi^{(1)} \Big| \Big)  \Big\}
\end{equation}\]</span></p>
<p>A Equação 9.3 é a mesma que foi descompactada na Quadro 4.3 (generalizada para um espaço de parâmetros multidimensional), mas aqui substituímos uma forma explícita para a covariância posterior e assumimos uma distribuição a priori normalmente. No capítulo 4 e nas aplicações do capítulo 8, ignoramos os termos da equação 9.3 que não dependiam da moda. No entanto, é importante incluí-los aqui quando consideramos problemas de comparação de modelos.</p>
<p>Para encontrar o valor de μ que maximiza a última linha da equação 9.3, realizamos uma subida de gradiente. Sob suposições quadráticas, isso se reduz ao seguinte:</p>
<p><span class="math display">\[ \mu = \nabla_\mu \mathcal L(\mu) + \Pi^{(1)}\epsilon \qquad\qquad\qquad (9.4) \]</span></p>
<p>Embora uma forma explícita para o gradiente da probabilidade logarítmica usada aqui possa não estar disponível, métodos de diferenças finitas <a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> podem ser usados para calcular uma aproximação numérica razoável. Eles também podem ser usados para encontrar a precisão posterior, que é a segunda derivada (ou Hessiana) da probabilidade logarítmica negativa mais a precisão anterior. A Equação 9.4 é a forma mais simples de atualização, mas geralmente são usados métodos mais sofisticados baseados na curvatura local.</p>
</div>
<div id="bayes-empíricos-paramétricos-peb" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Bayes Empíricos Paramétricos (PEB)<a href="análise-de-dados-baseada-em-modelo.html#bayes-empíricos-paramétricos-peb" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>O procedimento variacional de Laplace na seção anterior nos permite fazer inferências e quantificar a evidência de um modelo de comportamento de escolha. Isso nos permite fenotipar computacionalmente um indivíduo e comparar hipóteses alternativas sobre esse indivíduo. No entanto, as questões interessantes geralmente estão em nível de grupo. Por exemplo, podemos estar interessados em como um parâmetro – como a precisão de preferências anteriores – varia com a idade. Para responder a essa pergunta, podemos usar a abordagem da seção 9.3 para ajustar modelos ao comportamento de participantes individuais com uma faixa de idades. Formulamos então um modelo linear geral que gera o parâmetro de interesse, levando em consideração a idade:</p>
<p><span class="math display">\[ P(\theta| \beta, X) = \mathcal N(X\beta, \Pi^{(2)}) \qquad\qquad\qquad (9.5) \]</span>
Aqui, <span class="math inline">\(X\)</span> é uma matriz cujas colunas são variáveis explicativas alternativas e cujas linhas indicam cada participante. A primeira coluna de <span class="math inline">\(X\)</span> normalmente compreende uma matriz de uns (para indicar o efeito do parâmetro médio sobre os sujeitos). A segunda coluna, em nosso exemplo, pode ser a idade de cada participante. O vetor <span class="math inline">\(\beta\)</span> indica o tamanho do efeito de cada uma das variáveis explicativas em <span class="math inline">\(X\)</span>. O primeiro elemento de <span class="math inline">\(\beta\)</span> é então o valor médio da precisão (ou qualquer outro parâmetro), enquanto o segundo é o efeito da idade na precisão. Esse valor é a inclinação da linha em um gráfico de idade (eixo <span class="math inline">\(x\)</span>) em relação à precisão prevista (eixo <span class="math inline">\(y\)</span>). Pode haver um número arbitrário de colunas de <span class="math inline">\(X\)</span>, com um número arbitrário de elementos em <span class="math inline">\(\beta\)</span>.</p>
<p>Uma vez ajustado o modelo expresso na equação 9.5, suplementado com a priori para os valores de <span class="math inline">\(\beta\)</span>, podemos fazer perguntas sobre o papel das variáveis explicativas. Por exemplo, podemos perguntar se a idade tem efeito sobre a precisão das preferências anteriores comparando a evidência de um modelo no qual o segundo elemento de <span class="math inline">\(\beta\)</span> pode desviar-se de zero com a evidência de um modelo com uma crença precisa de que é zero. Praticamente falando, isso pode ser feito sem múltiplas inversões de modelo por meio do uso da redução do modelo Bayesiano (Friston, Parr e Zeidman 2018).</p>
</div>
<div id="instruções-para-análise-baseada-em-modelo" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Instruções para Análise Baseada em Modelo<a href="análise-de-dados-baseada-em-modelo.html#instruções-para-análise-baseada-em-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Na prática, seguimos os passos descritos abaixo para analisar o comportamento de escolha empírica usando inferência ativa (Schwartenbeck e Friston 2016). Estas se referem às rotinas relevantes disponíveis no pacote SPM12 Matlab.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Colete dados comportamentais</strong>, incluindo as escolhas feitas e a entrada sensorial disponível para a pessoa que faz essa escolha. Além disso, colete dados de interesse para análise de segundo nível entre sujeitos (por exemplo, se o sujeito é um paciente ou um sujeito de controle, informações demográficas relevantes e assim por diante).</p></li>
<li><p><strong>Formule um modelo POMDP</strong> como no capítulo 7. Esta deve ser uma função que recebe parâmetros como entradas e saídas de um POMDP totalmente especificado (mas ainda não resolvido).</p></li>
<li><p><strong>Especifique uma função de verossimilhança</strong> (ou seja, equação 9.2). Isso nos diz como o modelo deve ser usado para calcular uma probabilidade. Isso normalmente chama um solucionador POMDP (como a rotina spm_MDP_VB_X.m) para simular o comportamento e quantificar a probabilidade de ações observadas.</p></li>
<li><p><strong>Especifique crenças prévias</strong> sobre os parâmetros em termos de expectativas e precisões. Muitas vezes, eles serão centrados em zero, com precisões refletindo intervalos plausíveis.</p></li>
<li><p><strong>Resolva a probabilidade posterior e a evidência do modelo</strong>. Isso usa um esquema de inferência padrão, como o procedimento variacional de Laplace descrito acima (equação 9.4). A rotina spm_nlsi_Newton.m fará isso automaticamente.</p></li>
<li><p><strong>Realizar análise em nível de grupo</strong>. Isso normalmente faz uso do PEB, que trata os parâmetros estimados para cada indivíduo como se fossem gerados por um modelo de segundo nível. Isso nos permite testar hipóteses sobre as causas desses parâmetros. Praticamente, isso pode ser feito usando a rotina spm_dcm_peb.m. As análises alternativas incluem testes estatísticos padrão de associação entre os parâmetros inferidos para cada sujeito e outras medidas específicas do sujeito. Por exemplo, uma análise de variáveis canônicas pode ser usada para avaliar a relação entre as pontuações do questionário e os parâmetros inferidos.</p></li>
</ol>
<p>O resumo dessas instruções da Figura 9.2 é baseado no comportamento do rato na tarefa do labirinto em T descrita no capítulo 7. Primeiro, colocamos um rato em um labirinto em T com um estímulo recompensador no braço esquerdo ou direito e uma dica informativa no braço central. Em seguida, registramos a sequência de ações realizadas pelo rato. Este procedimento pode ser repetido em vários ensaios para registrar o comportamento aprendido e pode ser repetido para vários ratos diferentes sob diferentes intervenções (por exemplo, farmacológicas ou optogenéticas).</p>
<p>Uma vez que esses dados comportamentais tenham sido obtidos, precisamos de uma função de verossimilhança que nos permita quantificar a probabilidade do comportamento (para um determinado rato em uma determinada condição) sob configurações de parâmetros específicos. Podemos fazer isso formulando o modelo POMDP que consideramos no capítulo 7. Isso deve ser parametrizado em termos dos parâmetros cuja probabilidade procuramos encontrar. Por exemplo, se quisermos avaliar a precisão associada às preferências, podemos incluir um parâmetro de escala logarítmica que torne a distribuição de preferências mais ou menos intensa.</p>
<p>Tendo estabelecido o modelo generativo (da perspectiva do rato), podemos resolver automaticamente o POMDP usando as equações de atualização de crença no capítulo 4. Isso nos permite calcular a probabilidade dos dados (ou seja, a sequência de braços visitados) condicionados no modelo com o parâmetro de escala (preferências) em um valor específico. A combinação dessa probabilidade com nossa anterior completa a especificação de um modelo generativo para o comportamento (da perspectiva do cientista). Isso pode ser resolvido usando Laplace variacional para encontrar uma distribuição de probabilidade posterior sobre o parâmetro de escala para cada rato</p>
<div class="figure">
<img src="images/Figura_9_2.png" alt="" />
<p class="caption">Figura 9.2 Roteiro do procedimento de inversão de seis etapas para análise de dados baseada em modelo, conforme descrito no texto principal (com referência aos capítulos onde mais detalhes podem ser encontrados). As setas indicam as dependências entre cada parte do processo. O modelo POMDP deve ser definido para que a probabilidade seja avaliada. A inversão do modelo requer dados coletados e a probabilidade e os antecedentes; a análise do PEB não pode ocorrer antes da inversão do modelo para cada sujeito. As etapas 4 e 5 esquematizam a atualização de uma distribuição anterior sobre parâmetros sob um modelo para uma distribuição posterior. A evidência e a posterior de cada modelo podem então ser combinadas usando PEB para encontrar densidades a posteriori (mostradas como expectativas com intervalos confiáveis) para os coeficientes β de um modelo linear que prevê esses parâmetros.</p>
</div>
<p>Na prática, antes de analisar dados reais, podemos querer verificar a validade aparente do modelo POMDP usando-o para gerar dados fictícios – e considerando se eles são qualitativamente plausíveis, dado o problema em questão. Um segundo teste sensato para o modelo é a recuperação de parâmetros. Isso implica gerar dados fictícios sob alguma parametrização (conhecida) para ver se esses parâmetros podem ser recuperados ao inverter o modelo. Isso é útil para verificar se alguns parâmetros (ou suas combinações) são possíveis de serem recuperados (ou seja, identificáveis).</p>
<p>Finalmente, podemos construir uma matriz de projeto para um modelo linear, cada linha representando um fenótipo computacional (por exemplo, uma densidade posterior sobre as preferências de cada sujeito), com colunas representando diferentes atributos desses sujeitos. Esses atributos são variáveis que podem explicar diferenças nas preferências de um rato. Além de uma coluna indicando as preferências médias em relação a todos os ratos, isso incluirá coisas como idade, se uma droga foi administrada e assim por diante. Com este modelo de efeitos entre sujeitos, agora realizamos uma análise PEB para avaliar a contribuição dessas variáveis explicativas para as preferências anteriores.</p>
<p>9.6  Exemplos de modelos generativos</p>
<p>Nesta seção, aproveitamos dois exemplos na literatura que ilustram o uso de modelos generativos contínuos e discretos. Em primeiro lugar, apresentamos brevemente os métodos utilizados por Adams, Aponte et al. (2015) e Adams, Bauer et al. (2016) (doravante nesta seção, Adams et al.) para modelar movimentos oculares de perseguição suave como forma de quantificar os parâmetros de precisão dos modelos generativos de cada sujeito. Um aspecto importante desse projeto foi a coleta simultânea de dados eletrofisiológicos (via magnetoencefalografia) que permitiram aos autores fazer perguntas sobre os substratos neurobiológicos de codificação de precisão ou confiança. Passamos então a uma análise dos movimentos oculares sacádicos de Mirza et al. (2018; doravante nesta seção, Mirza et al.) formulado como um modelo POMDP. Cada um dos experimentos associados está desenhado na figura 9.3. Nossa esperança é que esses exemplos ajudem os leitores a entender como os métodos genéricos descritos acima podem ser usados ​​empiricamente para responder a questões científicas.</p>
<p>Em termos da sequência de etapas descritas na figura 9.2, Adams et al. dados coletados (passo 1) de uma tarefa em que os sujeitos tinham que manter a fixação em um alvo visual em movimento. Os detalhes não são importantes, mas essa tarefa compreendia duas condições.</p>
<div class="figure">
<img src="images/Figura_9_3.png" alt="" />
<p class="caption">Figura 9.3 Dois experimentos descritos na seção 9.5. Os detalhes não são importantes, mas destacam onde a inferência meta-Bayesiana foi explorada com sucesso e os tipos de dados comportamentais aos quais ela pode ser aplicada. Esquerda: Experimento de Adams et al., que mediram movimentos oculares de perseguição suave enquanto os sujeitos seguiam um alvo em movimento. Direita: Experimento de Mirza et al., que mediu movimentos oculares sacádicos durante uma tarefa de exploração. A exibição visual foi dividida em quatro quadrantes, dois dos quais incluíam estímulos (gato e pássaro). Diferentes categorias de cena envolveram diferentes configurações de estímulos, o que significa que os participantes tiveram que selecionar quais quadrantes fovear para obter informações suficientes para categorizar a cena. A tarefa de Adams (esquerda ) gera dados contínuos de rastreamento ocular, enquanto a tarefa de Mirza (direita ) leva a uma sequência de fixações e pode ser discretizada. Estes são os dados comportamentais (u) da etapa 1 na figura 9.2.</p>
</div>
<p>No primeiro, o alvo se movia de acordo com uma senóide previsível. Na segunda, seguiu a mesma trajetória com ruído gaussiano aditivo. Os dados coletados incluíram as trajetórias dos movimentos dos olhos. Os autores formularam um modelo subjetivo (passo 2). Ao contrário do modelo POMDP mostrado na figura 9.2, eles optaram por um modelo contínuo do tipo descrito no capítulo 8. Em resumo, o modelo previu a entrada proprioceptiva e visual dos olhos, onde o ponto de fixação foi considerado atraído para o local alvo . A probabilidade (etapa 3) é construída usando os esquemas de codificação preditiva (ativos) descritos no capítulo 4. Isso quantifica a probabilidade das ações (movimentos oculares) sob um conjunto de parâmetros de precisão de log e o modelo estabelecido na etapa 2. Continuando para a etapa 4, os autores especificaram crenças anteriores como distribuições normais sobre as precisões logarítmicas. Eles inverteram o modelo (passo 5) para encontrar distribuições posteriores sobre esses parâmetros de precisão. A etapa 6 não usou uma análise de PEB, mas usou os dados de neuroimagem coletados simultaneamente com a tarefa comportamental. Os autores usaram modelagem causal dinâmica para estimar o ganho de células piramidais superficiais no córtex visual primário. Isso significa que eles tinham estimativas de precisão e ganho sináptico para cada sujeito. Isso permitiu que os autores realizassem uma análise em nível de grupo, avaliando a correlação entre os parâmetros do modelo subjetivo e seus substratos biológicos. A demonstração dessa correlação fornece um exemplo importante de como as formulações de comportamento da Inferência Ativa nos permitem fazer (e responder) perguntas sobre a relação entre atualização de crenças e neurobiologia.</p>
<p>Em nosso segundo exemplo, Mirza et al. usaram a formulação POMDP de Inferência Ativa para abordar o papel do ganho de informação na condução do comportamento humano. Novamente, descompactamos isso em termos das etapas da Figura 9.2. Mirza et ai. coletaram dados comportamentais (etapa 1) enquanto os sujeitos realizavam uma tarefa de forrageamento visual. Aqui, o objetivo era classificar uma cena visual em um dos vários grupos. Cada elemento da cena só foi revelado quando os sujeitos fixaram esses locais; isso significava que várias fixações eram necessárias para adquirir evidências suficientes para uma determinada categoria de cena. Os dados coletados pelos autores incluíram a sequência de movimentos sacádicos (movimentos rápidos dos olhos) realizada. O modelo (passo 2) utilizado foi um modelo POMDP descrito em Mirza et al. (2016) que previam resultados proprioceptivos, visuais e de feedback discretizados, condicionados ao local de fixação atual e à categoria da cena. As preferências (veja o capítulo 7) foram colocadas sobre o resultado do feedback de modo que o modelo antecipa (e, portanto, prefere) estar correto na categorização. A função de verossimilhança (passo 3) foi obtida resolvendo o modelo usando o esquema descrito no capítulo 4 sob diferentes configurações de parâmetros. Os parâmetros em questão incluíam (entre outros) um parâmetro de escala de log para a precisão da distribuição de preferências. Os autores especificaram distribuições prévias (etapa 4) sobre a escala de log (e outros parâmetros) e inverteram o modelo para cada sujeito (etapa 5). Eles usaram a evidência logarítmica estimada para cada sujeito para avaliar a evidência de modelos que motivaram ou não o comportamento usando o componente epistêmico da energia livre esperada, encontrando maior evidência para aqueles modelos que incluíam affordance epistêmica em todos os sujeitos. Eles então empregaram uma análise PEB (etapa 6) para avaliar as mudanças nas crenças anteriores para os sujeitos ao longo de vários ensaios, encontrando evidências a favor de mudanças nos parâmetros de crença (ou seja, aprendizado ativo). Finalmente, eles usaram uma análise de covariáveis ​​canônicas para avaliar a relação entre combinações lineares das variáveis ​​fenotípicas estimadas para cada sujeito (por exemplo, precisão de preferências) e combinações lineares de medidas de desempenho (por exemplo, porcentagem correta e tempo de reação).</p>
</div>
<div id="modelos-de-falsa-inferência" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> Modelos de falsa inferência<a href="análise-de-dados-baseada-em-modelo.html#modelos-de-falsa-inferência" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Os homens em geral são rápidos em acreditar naquilo que desejam que seja verdade. —Júlio César</p>
<p>Dada a relevância desses métodos para campos como a psiquiatria computacional (Friston, Stephan et al. 2014), terminamos com uma visão geral da falsa inferência, que é central para a noção de psicopatologia como falha na atualização de crenças. Um benefício de usar uma estrutura inferencial como a Inferência Ativa é que ela aborda simultaneamente múltiplas dimensões de transtornos psiquiátricos, ligando comportamento desadaptativo (por exemplo, compulsões ou vícios) e nível psicológico (por exemplo, falsas crenças) e fenômenos de nível biológico (por exemplo, anormalidades de neuromoduladores).</p>
<p>Como não podemos fazer justiça aqui à extensa literatura que usa a Inferência Ativa na modelagem de processos de doença, esta seção fornece a mais breve das visões gerais para sugerir uma estrutura para pensar sobre patologias computacionais. Veja a tabela 9.1 para uma amostragem não exaustiva de exemplos ilustrativos, que incluem modelos especificados em tempo discreto e contínuo (com base nos capítulos 7 e 8, respectivamente). Em nossa discussão, apelaremos para a estrutura de modelos do tipo POMDP; os princípios que sustentam a falsa inferência nessas configurações são basicamente os mesmos.</p>
<p>A hipótese subjacente às abordagens inferenciais (como a Inferência Ativa) é que as condições psicopatológicas podem ser conceituadas como distúrbios de inferência. O termo transtorno não implica necessariamente que o mecanismo inferencial seja falho (por exemplo, gera probabilidades posteriores incorretas). Na maioria dos estudos revisados na tabela 9.1, o mecanismo inferencial opera normalmente, mas com base em um modelo generativo falho (ou seja, um modelo generativo dotado de crenças anteriores aberrantes). Isso significa que, em última análise, a patologia é uma consequência de crenças anteriores aberrantes - e pode-se recuperar essas anteriores usando a análise de dados baseada em modelo descrita neste capítulo.</p>
<p>Tabela 9.1 Patologia computacional</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Patologia</th>
<th>Fontes</th>
<th>Notas</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Dependência, impulsividade e compulsividade</td>
<td>FitzGerald, Schwartenbeck et al. 2015 Schwartenbeck, FitzGerald, Mathys, Dolan, Wurst et al. 2015 Mirza et al. 2019 Fradkin et al. 2020</td>
<td>O vício é um exemplo importante de comportamento que parece aberrante, mas pode ser enquadrado como uma inferência ótima sob o tipo certo de modelo generativo. Trabalho de Schwartenbeck et al. ilustrou isso usando uma tarefa de oferta limitada em que os participantes estão mais ou menos confiantes sobre se receberão uma recompensa por esperar. A baixa confiança leva a um comportamento compulsivo do tipo associado ao vício. Trabalhos subsequentes sobre este tema examinam as crenças anteriores associadas a comportamentos mais ou menos impulsivos, usando o paradigma de deixar manchas, e examinam o papel da precisão anterior atenuada no transtorno obsessivo-compulsivo.</td>
</tr>
<tr class="even">
<td>Delírios</td>
<td>Brown et al. 2013 Friston, Parr et al. 2020</td>
<td>Os delírios, caracterizados por crenças falsas e fixas, são simplesmente articulados na Inferência Ativa como distribuições de probabilidade posteriores precisas na ausência de evidências de suporte. Se suficientemente precisos, eles serão fixados mesmo diante de evidências contraditórias (posteriores). Os mecanismos subjacentes a cada delírio podem ser diferentes. Por exemplo, falhas de atenuação sensorial podem ser centrais para delírios de ação. Trabalhos recentes fornecem um exemplo de um delírio compartilhado (folie à deux), que depende de dois agentes – sem nenhuma informação – chegarem a um consenso confiante sobre o estado do mundo</td>
</tr>
<tr class="odd">
<td>Alucinações</td>
<td>Adams, Stephan et ai. 2013 Benrimoh et al. 2018 Parr, Benrimoh et al. 2018 Corlett et al. 2019</td>
<td>Essas simulações se baseiam em desequilíbrios entre precisões anteriores e de probabilidade. Superinterpretação de dados sensoriais espúrios devido a uma falha na atenuação da precisão da verossimilhança, ou uma falha na correção de crenças anteriores devido à atenuação excessiva, cada uma oferece mecanismos para falsa inferência perceptiva.</td>
</tr>
<tr class="even">
<td>Interpessoal e distúrbios de personalidade</td>
<td>Moutoussis et ai. 2014 Prosser et al. 2018</td>
<td>A inferência interpessoal depende de ter modelos sobre outras pessoas e como elas podem reagir às nossas decisões. Isso levou ao desenvolvimento de modelos de jogos de confiança, que dependem de interações entre duas (ou mais) partes, e jogos de caridade. Estes últimos têm sido usados para reproduzir o auto-engrandecimento e a falta de remorso associados à psicopatia. Esses traços são simulados modulando o grau em que as crenças sobre a autoestima dependem de decisões de ser caridoso versus egoísta e sensibilidade à aprovação dos outros.</td>
</tr>
<tr class="odd">
<td>Síndromes oculomotoras</td>
<td>Adams, Perrinet, and Friston 2012 Parr and Friston 2018a</td>
<td>Nestes artigos, modelos generativos de tempo contínuo são empregados para prever a evolução dinâmica de sistemas newtonianos. Ao tornar vários aspectos do modelo generativo condicionalmente independentes de outros, podem ser induzidas síndromes oculomotoras, como oftalmoplegias internucleares.</td>
</tr>
<tr class="even">
<td>Farmacoterapia</td>
<td>Parr e Friston 2019b</td>
<td>Dadas as associações que propusemos entre parâmetros de precisão e neuroquímicos no capítulo 5, deve ser possível simular as consequências da manipulação farmacológica desses sistemas. Este trabalho ilustra as consequências de várias intervenções farmacológicas sintéticas no desempenho de uma tarefa oculomotora do período de atraso, fornecendo uma prova de princípio de que esses métodos podem ser usados para simular não apenas a patologia, mas também a influência da terapêutica.</td>
</tr>
<tr class="odd">
<td>Síndromes pré-frontais</td>
<td>Parr, Rikhye et al. 2019</td>
<td>Essas simulações estabelecem uma diferença entre as síndromes pré-frontais medial e lateral, atenuando a precisão das transições para prejudicar o desempenho de uma tarefa guiada pela memória (lateral) versus a precisão de uma probabilidade interoceptiva que determina a motivação para se envolver na tarefa (medial).</td>
</tr>
<tr class="even">
<td>Negligência visual</td>
<td>Parr and Friston 2017a</td>
<td>A desatenção ao lado esquerdo do espaço pode ser induzida por várias lesões prévias alternativas. Entre estes, um aumento nos parâmetros de Dirichlet para este lado do espaço reduz a novidade associada às sacadas à esquerda, aumentando a amostragem visual da direita. Alternativamente, definir preferências consistentes com resultados proprioceptivos ou visuais do lado direito ou aumentar o envolvimento habitual em sacadas do lado direito reproduz um comportamento qualitativamente semelhante.</td>
</tr>
<tr class="odd">
<td>Distúrbios de inferência interoceptiva</td>
<td>Barrett et al. 2016 Allen et al. 2019 Maisto, Barca et al. 2019 Pezzulo, Maisto et al. 2019 Barca and Pezzulo 2020 Tschantz et al. 2021</td>
<td>Simulações de inferência interoceptiva (ou inferência ativa no domínio interoceptivo) sugerem que desequilíbrios entre precisões anteriores e de probabilidade sobre (por exemplo) sinais cardíacos ou gástricos podem causar falsas crenças sobre o estado interno do corpo, percepções errôneas de sintomas corporais e alucinações psicossomáticas . Além disso, eles podem ter efeitos em cascata na regulação autonômica e na seleção de ações, causando vários tipos de comportamento desadaptativo, como hipervigilância, uso excessivo de medicamentos e restrições alimentares excessivas.</td>
</tr>
</tbody>
</table>
<p>Prioridades aberrantes podem ser sobre estados ou precisões, ou podem ser a priori estruturais sobre a forma do modelo generativo. Uma maneira útil de pensar sobre as causas do comportamento patológico é pensar sobre a crença anterior usada para políticas e sobre como cada parte disso pode ser interrompida para dar origem a uma seleção anormal de políticas. As políticas anteriores dependem da energia livre esperada, que por sua vez depende das crenças posteriores, do potencial de ganho de informação e das preferências anteriores (C). Prioridades sobre as apólices também podem ser equipadas com um termo de forma fixa (E ), representando vieses habituais.</p>
<p>Tomando cada um destes por sua vez: Crenças posteriores dependem de anteriores e probabilidades. Para formar uma crença posterior aberrante, uma ou ambas devem ser rompidas. Normalmente, essa ruptura assume a forma de sub ou superestimação do equilíbrio de precisões. A probabilidade excessivamente alta, em comparação com a precisão anterior, leva a uma interpretação exagerada da entrada sensorial (potencialmente barulhenta). Isso leva ao overfitting no sentido de que conclusões injustificadas podem ser tiradas de dados espúrios. Se o equilíbrio é interrompido na direção oposta, favorecendo a confiança no anterior, as percepções geradas internamente tornam-se resistentes a entradas sensoriais conflitantes. Ambos os mecanismos têm sido associados ao desenvolvimento de alucinações, e os dois podem coexistir quando são empregados modelos hierárquicos. Dada a associação de várias precisões com substâncias químicas neuromoduladoras (ver capítulo 5), parece sensato que condições como a demência por corpos de Lewy, na qual a sinalização colinérgica é prejudicada, e a esquizofrenia, com anormalidades do sistema dopaminérgico, apresentem fenômenos alucinatórios – isto é, falsa inferência perceptual.</p>
<p>Em seguida, consideramos o papel do ganho de informação. Aqui, a precisão da probabilidade e a precisão das crenças anteriores nos dizem o grau em que a incerteza pode ser resolvida e a quantidade de incerteza que há para resolver, respectivamente. A precisão das crenças anteriores se aplica tanto aos parâmetros do modelo generativo (ou seja, influencia a novidade) quanto aos estados (ou seja, influencia a saliência). Interpretar os parâmetros de probabilidades condicionais como eficácias sinápticas ou as precisões como ganhos sinápticos sugere que as síndromes de desconexão sináptica podem ser consideradas como ruptura de um ou ambos. Sinapses ausentes não podem ser moduladas, então isso é como ter crenças anteriores extremamente confiantes sobre uma probabilidade condicional, pois novos dados não podem atualizar a eficácia associada. Isso tem implicações importantes para o potencial ganho de informação de diferentes políticas, como tem sido explorado na modelagem de síndromes de negligência sensorial.</p>
<p>Finalmente, as preferências e as políticas anteriores fornecem uma clara influência sobre o comportamento. Estes podem sustentar o desenvolvimento de hábitos viciantes ou a apatia associada a várias síndromes psiquiátricas e neurológicas (Hezemans, Wolpe e Rowe 2020). Em resumo, crenças anteriores defeituosas em vários lugares nos modelos generativos descritos acima fornecem uma explicação funcional ou teleológica para o comportamento patológico.</p>
</div>
<div id="resumo-8" class="section level2 hasAnchor" number="9.7">
<h2><span class="header-section-number">9.7</span> Resumo<a href="análise-de-dados-baseada-em-modelo.html#resumo-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Neste capítulo, delineamos uma abordagem que utiliza os modelos teóricos descritos nos capítulos anteriores para colocar questões aos dados empíricos. Isso nos permite usar a Inferência Ativa como uma ferramenta não invasiva para investigar os processos computacionais que os indivíduos usam para tomar decisões. Nós nos concentramos em alguns exemplos simples. No entanto, modelos baseados em Inferência Ativa foram desenvolvidos para tarefas mais realistas e complicadas (Cullen et al. 2018) projetadas para evocar um comportamento mais rico para fenotipagem computacional. Além de estabelecer um processo de seis etapas para análise baseada em modelos, destacamos dois exemplos do uso desses métodos. Isso traz variações importantes em como isso pode ocorrer, incluindo os tipos de comportamento medidos (trajetórias suaves ou escolhas discretas), a escolha do modelo (contínuo ou discreto) e as diferentes questões científicas que estão sendo feitas. A última delas é a mais importante, pois determina as escolhas anteriores. Vimos o uso de fenotipagem computacional em combinação com neuroimagem (Adams, Bauer et al. 2016) para fazer perguntas sobre a relação entre ganho sináptico e precisão. Além disso, vimos como a inversão de modelo pode ser usada para avaliar as contribuições de impulsos comportamentais alternativos e preditores de desempenho (Mirza et al. 2018). Em última análise, as seis etapas na Figura 9.1 fornecem um método genérico para projetar experimentos para interrogar de forma não invasiva os modelos generativos implícitos que as pessoas (ou outros animais) usam para direcionar o comportamento. Isso oferece uma oportunidade para responder a perguntas sobre a função do sistema nervoso na saúde e na doença.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="25">
<li id="fn25"><p>Praticamente, muitas vezes é útil definir parâmetros como parâmetros de escala de log: o parâmetro atua como um fator de escala não negativo e não pode ser caracterizado por uma distribuição normal, que aloca números negativos em uma densidade de probabilidade finita. Assumir que o log do parâmetro de escala é normalmente distribuído garante positividade quando exponenciado para obter o próprio parâmetro de escala. O mesmo objetivo pode ser alcançado modelando a raiz quadrada de um parâmetro como sendo normalmente distribuído.<a href="análise-de-dados-baseada-em-modelo.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>Por exemplo, <span class="math inline">\(∂x f(x) ≈ 2Δx f(x + Δx) − f(x − Δx)).\)</span><a href="análise-de-dados-baseada-em-modelo.html#fnref26" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inferência-ativa-em-tempo-contínuo-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="inferência-ativa-como-uma-teoria-unificada-do-comportamento-sensível.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Inferencia Ativa.pdf", "Inferencia Ativa.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
