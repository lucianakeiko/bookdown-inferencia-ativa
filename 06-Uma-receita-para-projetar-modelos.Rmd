# Uma receita para projetar modelos de inferência ativos

Dê-me seis horas para derrubar uma árvore e passarei as primeiras quatro afiando o machado. ---Abraham Lincoln

## Introdução

Este capítulo fornece uma receita de quatro etapas para construir um modelo de Inferência Ativa, discutindo as escolhas de projeto mais importantes que se deve fazer para realizar um modelo e fornecendo algumas diretrizes para essas escolhas. Ele serve como uma introdução à segunda parte do livro, que ilustrará vários modelos computacionais específicos usando a Inferência Ativa e suas aplicações em vários domínios cognitivos.

omo a Inferência Ativa é uma abordagem normativa, ela tenta explicar o máximo possível sobre o comportamento, os processos cognitivos e neurais a partir dos primeiros princípios. Consistentemente, a filosofia de design da Inferência Ativa é de cima para baixo. Ao contrário de muitas outras abordagens da neurociência computacional, o desafio não é emular um cérebro, peça por peça, mas encontrar o modelo generativo que descreve o problema que o cérebro está tentando resolver. Uma vez que o problema é formalizado apropriadamente em termos de um modelo generativo, a solução para o problema surge sob a Inferência Ativa -- com as respectivas previsões sobre cérebros e mentes. Em outras palavras, o modelo generativo fornece uma descrição completa de um sistema de interesse. O comportamento resultante, a inferência e a dinâmica neural podem ser derivados de um modelo minimizando a energia livre.

A abordagem de modelagem generativa é usada em várias disciplinas para a realização de modelos cognitivos, modelagem estatística, análise de dados experimentais e aprendizado de máquina (Hinton 2007b; Lee e Wagenmakers 2014; Pezzulo, Rigoli e Friston 2015; Allen et al. 2019; Foster 2019). Aqui, estamos principalmente interessados ​​em projetar modelos generativos que engendram processos cognitivos de interesse. Vimos essa metodologia de projeto nos capítulos anteriores. Por exemplo, usando um modelo generativo para codificação preditiva, a percepção foi lançada como uma inferência sobre a causa mais provável das sensações; usando um modelo generativo que evolui em tempo discreto, o planejamento foi lançado como uma inferência sobre o curso de ação mais provável. Dependendo do problema de interesse (por exemplo, planejamento durante a navegação espacial ou planejamento de sacadas durante a busca visual), pode-se adaptar a forma desses modelos generativos para equipá-los com diferentes estruturas (por exemplo, rasas ou hierárquicas) e variáveis ​​(por exemplo, crenças sobre localizações espaciais alocêntricas ou egocêntricas). É importante ressaltar que a Inferência Ativa pode assumir muitas formas diferentes sob diferentes suposições sobre a forma do modelo generativo que está sendo otimizado. Por exemplo, suposições sobre modelos que evoluem em tempo discreto ou contínuo influenciam a forma de transmissão de mensagens (veja o capítulo 4). Isso implica que a escolha de um modelo generativo corresponde a previsões específicas sobre comportamento e neurobiologia.

Essa flexibilidade é útil, pois nos permite usar a mesma linguagem para descrever processos em vários domínios. No entanto, também pode ser confuso do ponto de vista prático, pois há uma série de escolhas que devem ser feitas para encontrar o nível apropriado de descrição para o sistema de interesse. Na segunda parte deste livro, tentaremos resolver essa confusão por meio de uma série de exemplos ilustrativos de Inferência Ativa in silico. Este capítulo apresenta uma receita geral para o projeto de modelos de Inferência Ativa, destacando algumas das principais escolhas de projeto, distinções e dicotomias que aparecerão na análise numérica de modelos computacionais descritos nos capítulos subsequentes.

## Projetando um modelo de inferência ativo: uma receita em quatro etapas

Projetar um modelo de Inferência Ativa requer quatro etapas fundamentais, cada uma resolvendo uma questão de projeto específica:

1.  Qual sistema estamos modelando? A primeira escolha a fazer é sempre o sistema de interesse. Isso pode não ser tão simples quanto parece; baseia-se na identificação dos limites (ou seja, envoltório de Markov) desse sistema. O que conta como agente de Inferência Ativa (modelo generativo), o que conta como ambiente externo (processo generativo) e qual é a interface (dados sensoriais e ações) entre eles?

2.  Qual a forma mais adequada para o modelo generativo? O primeiro dos próximos três desafios práticos é decidir se é apropriado pensar em um processo mais em termos de inferências categóricas (discretas) ou inferências contínuas, motivando a escolha entre implementações discretas ou de tempo contínuo (ou uma híbrida) de Inferência Ativa. . Em seguida, precisamos selecionar a profundidade hierárquica mais adequada, motivando a escolha entre modelos rasos versus modelos profundos. Finalmente, precisamos considerar se é necessário dotar os modelos generativos de profundidade temporal e a capacidade de prever observações contingentes à ação para apoiar o planejamento.

3.  Como configurar o modelo generativo? Quais são as variáveis e a priori mais apropriadas do modelo generativo? Quais partes são fixas e o que deve ser aprendido? Enfatizamos a importância de escolher o tipo certo de variáveis e crenças anteriores; além disso, enfatizamos uma separação em escalas de tempo entre a atualização (mais rápida) das variáveis de estado que ocorre durante a inferência e a atualização (mais lenta) dos parâmetros do modelo que ocorre durante o aprendizado.

4.  Como configurar o processo generativo? Quais são os elementos do processo generativo (e como eles diferem do modelo generativo)?

Essas quatro etapas (na maioria dos casos) são suficientes para projetar um modelo de Inferência Ativa. Uma vez concluído, o comportamento do sistema é determinado pelos esquemas padrão de Inferência Ativa: a descida dos estados ativo e interno sobre o funcional de energia livre associado ao modelo. De uma perspectiva mais prática, uma vez especificado o modelo generativo e o processo generativo, pode-se usar rotinas padrão do software Active Inference para obter resultados numéricos, bem como para realizar visualização de dados, análise e ajuste (por exemplo, análise de dados baseada em modelo ). A seguir, revisaremos as quatro opções de design em ordem.

## Que sistema estamos modelando?

Um primeiro passo útil na aplicação do formalismo da Inferência Ativa é identificar os limites do sistema de interesse porque estamos interessados em caracterizar a interação entre o que é interno a um sistema e o mundo externo por meio de receptores sensoriais e efetores (por exemplo, músculos ou glândulas). Conforme discutido no capítulo 3, uma maneira formal de caracterizar a distinção entre estados internos de um sistema e variáveis externas (e variáveis intermediárias que medeiam suas interações) é em termos de um envoltório de Markov (Pearl 1988). Para reiterar o argumento, um envoltório de Markov pode ser subdividida em dois tipos de variáveis (Friston 2013): aquelas que mediam a influência do mundo externo nos estados internos do sistema de interesse (isto é, estados sensoriais) e aquelas que mediam a influência de estados internos do sistema de interesse no mundo externo (ou seja, estados ativos). Veja a figura 6.1.

É importante ressaltar que há muitas maneiras pelas quais um limite entre interno e externo pode ser definido. Na maioria das simulações que discutiremos na segunda parte deste livro, haverá uma separação (envoltório de Markov) entre um agente (aproximadamente, um organismo vivo) e seu ambiente. Isso corresponde à configuração usual de modelos cognitivos, onde um agente implementa processos cognitivos como percepção e seleção de ação com base em seus estados internos (por exemplo, cérebro) e é fornecido com sensores e efetores.

![**Figura 6.1** Loop de ação-percepção entre um sistema adaptativo (aqui, o cérebro) e o ambiente, juntamente com o envoltório de Markov (composta de estados ativos e estados sensoriais) que medeia sua interação. A figura implica que o sistema adaptativo afeta apenas o ambiente realizando ações (via estados ativos) e que o ambiente afeta apenas o sistema adaptativo produzindo observações (via estados sensoriais). A figura exemplifica a distinção entre o modelo generativo do sistema adaptativo e o processo generativo (externo) que produz suas observações.](images/Figura_6_1.png)

No entanto, esta não é a única possibilidade. Do ponto de vista da neurobiologia, poderíamos desenhar um envoltório de Markov em torno de um único neurônio, em torno do cérebro ou de todo o corpo. No primeiro caso, os estados sensoriais incluem ocupações de receptores pós-sinápticos e os estados ativos incluem a taxa na qual as vesículas contendo neurotransmissores se fundem com a membrana pré-sináptica. Os estados internos do neurônio (por exemplo, potenciais de membrana, concentrações de cálcio) podem ser considerados como inferindo as causas de seus estados sensoriais de acordo com algum modelo generativo (implícito) (Palacios, Isomura et al. 2019). Essa configuração trata os estados externos (que estão sendo modelados) como incluindo a rede neuronal da qual nosso neurônio participa. Isso é muito diferente da inferência que ocorre quando assumimos que toda a nossa rede é interna ao envoltório de Markov. Por exemplo, se tomarmos um sistema cujos estados sensoriais são os fotorreceptores na retina e cujos estados ativos são os músculos oculomotores, as inferências realizadas pelos estados internos são sobre coisas fora do cérebro. Isso fala da importância da escala, pois os estados internos desse envoltório de Markov incluem os estados internos da perspectiva de um único neurônio. Os últimos estados internos parecem fazer inferências sobre coisas dentro do cérebro quando o envoltório de Markov é colocado em torno de um único neurônio, mas não quando o envoltório é colocado em torno do sistema nervoso.

O acima é particularmente relevante quando se trata de perspectivas incorporadas ou estendidas sobre cognição (Clark e Chalmers 1998; Barsalou 2008; Pezzulo, Lw et al. 2011). Por exemplo, se puxarmos o envoltório ao redor do sistema nervoso, o resto do corpo se torna um estado externo, sobre o qual devemos fazer inferências a partir de estados sensoriais interoceptivos (Allen et al. 2019). Alternativamente, poderíamos colocar nosso envoltório em torno de todo o organismo. Isso faria parecer que outros órgãos além do cérebro estavam fazendo inferências sobre seu ambiente. Por exemplo, a depressão da pele em resposta a uma pressão externa pode ser enquadrada como uma inferência sobre a fonte da pressão externa. A perspectiva de cognição estendida leva isso adiante e diz que objetos externos ao corpo podem ser incorporados ao envoltório de Markov (por exemplo, o uso de uma calculadora para auxiliar na inferência implica que a calculadora é parte do espaço de estados interno do sistema de inferência ). Finalmente, poderíamos ter vários envoltórios de Markov, aninhados um no outro (por exemplo, cérebros, organismos, comunidades).

Em suma, definir o envoltório de Markov garante que saibamos o que está sendo inferido (estados externos) e o que está fazendo a inferência. De fato, a minimização da energia livre em relação a um modelo generativo envolve apenas os estados internos e ativos de um sistema: estes apenas veem os estados sensoriais, de modo que só podem inferir o estado externo do mundo vicariamente.

## Qual é a forma mais adequada para o modelo generativo?

Uma vez que tenhamos decidido sobre os estados internos de um sistema e os estados que medeiam sua interação com o mundo exterior, precisamos especificar o modelo generativo que explica como os estados externos influenciam os estados sensoriais. Conforme discutido nos capítulos anteriores, a Inferência Ativa pode operar em diferentes tipos de modelos generativos. Portanto, precisamos especificar a forma mais apropriada do modelo generativo para o problema em questão. Isso implica fazer três escolhas principais de design. A primeira é uma escolha entre modelos que incluem variáveis ​​contínuas ou discretas (ou ambas). O segundo é uma escolha entre modelos superficiais, nos quais a inferência opera em uma única escala de tempo (ou seja, todas as variáveis ​​evoluem na mesma escala de tempo), e modelos hierárquicos ou profundos, nos quais a inferência opera em várias escalas de tempo (ou seja, diferentes variáveis ​​evoluem em diferentes escalas de tempo). prazos). A terceira é uma escolha entre modelos que consideram apenas as observações presentes versus modelos com alguma profundidade temporal, que consideram as consequências de ações ou planos.

### Variáveis Discretas ou Contínuas (ou Ambas)?

A primeira escolha de projeto é considerar se modelos generativos que usam variáveis discretas ou contínuas são mais apropriados. Os primeiros incluem identidades de objetos, planos de ação alternativos e representações discretizadas de variáveis contínuas. Estes são modelados através da expressão da probabilidade -- em cada passo de tempo -- de uma variável em transição para outro tipo. Os últimos incluem coisas como posição, velocidade, comprimento do músculo e luminância e requerem um modelo generativo expresso em termos de taxas de mudança.

Computacionalmente, a distinção entre os dois pode não ser clara porque uma variável contínua pode ser discretizada e uma variável discreta pode ser expressa por meio de variáveis contínuas. No entanto, essa distinção é importante conceitualmente, pois fundamenta hipóteses específicas sobre o curso de tempo (discreto ou contínuo) dos processos cognitivos de interesse.[^uma-receita-para-projetar-modelos-1] Na maioria das implementações atuais de Inferência Ativa, processos de decisão de alto nível, como a escolha entre cursos de ações, são modelados usando variáveis discretas, enquanto percepção mais refinada e dinâmicas de ação são implementadas usando variáveis contínuas; forneceremos exemplos de ambos nos capítulos 7 e 8, respectivamente.

[^uma-receita-para-projetar-modelos-1]: Isso não implica em dinâmica temporal discreta de uma perspectiva neural. Em vez disso, a dinâmica neural contínua é vista como representando mudanças (contínuas) nas crenças sobre sequências (discretas) de eventos.

Além disso, a escolha entre variáveis discretas e contínuas é relevante para a neurobiologia. Enquanto cada estilo de modelagem apela para a minimização de energia livre, a mensagem que passa por eles implica assumir formas diferentes. Na medida em que se considera a passagem de mensagens relevante para uma teoria de processo (veja o capítulo 5), isso implica que as dinâmicas neurais que realizam essa minimização são diferentes em cada tipo de modelo. Esquemas contínuos subscrevem a codificação preditiva -- uma teoria de processamento neural que se baseia em previsões de cima para baixo corrigidas por erros de previsão de baixo para cima. No entanto, as teorias de processo análogas para inferências discretas envolvem mensagens de uma forma diferente. Finalmente, os dois tipos de modelo podem ser combinados de forma que estados discretos sejam associados a variáveis contínuas. Isso significa que podemos especificar um modelo generativo em que um estado discreto (por exemplo, identidade de objeto) gera algum padrão de variáveis contínuas (por exemplo, luminância). Discutiremos um exemplo de modelo generativo híbrido ou misto que inclui variáveis discretas e contínuas no capítulo 8.

### Escalas de tempo de inferência: modelos rasos versus modelos hierárquicos

A segunda opção de design diz respeito às escalas de tempo da Inferência Ativa. Pode-se selecionar modelos generativos (rasos), em que todas as variáveis evoluem na mesma escala de tempo, ou modelos (hierárquicos ou profundos), que incluem variáveis que evoluem em diferentes escalas de tempo: mais lento para níveis mais altos e mais rápido para níveis mais baixos.

Enquanto muitos modelos cognitivos simples requerem apenas modelos superficiais, estes não são suficientes quando há uma clara separação de escalas de tempo entre diferentes aspectos de um processo cognitivo de interesse. Um exemplo disso é no processamento de linguagem, em que sequências curtas de fonemas são contextualizadas pela palavra que é falada e sequências curtas de palavras são contextualizadas pela frase atual. Crucialmente, a duração da palavra transcende a de qualquer fonema na sequência e a duração da frase transcende a de qualquer palavra na sequência. Assim, para modelar o processamento da linguagem, pode-se considerar um modelo hierárquico no qual sentenças, palavras e fonemas aparecem em níveis hierárquicos diferentes (mais altos para mais baixos) e evoluem em escalas de tempo (mais lentas para mais rápidas) que são aproximadamente independentes umas das outras. Esta é apenas uma separação aproximada, pois os níveis devem influenciar uns aos outros (por exemplo, a frase influencia as próximas palavras na sequência; a palavra influencia os próximos fonemas na sequência).

No entanto, isso não significa que precisamos tentar modelar todo o cérebro para desenvolver simulações significativas de um único nível. Por exemplo, se quiséssemos focar no processamento de texto, poderíamos abordar alguns aspectos sem ter que lidar com o processamento de fonemas. Isso significa que podemos tratar a entrada de partes do cérebro fazendo inferências sobre fonemas como fornecendo observações da perspectiva de áreas de processamento de texto. Expressando isso em termos de um envoltório de Markov, isso normalmente significa que tratamos as inferências realizadas por níveis inferiores de um modelo como parte dos estados sensoriais do envoltório. Isso significa que podemos resumir as inferências realizadas na escala de tempo de interesse sem precisar especificar os detalhes dos processos inferenciais de nível inferior (mais rápidos) -- e essa fatoração hierárquica acarreta grandes benefícios computacionais.

Outro exemplo está no domínio da seleção de ações intencionais, onde o mesmo objetivo (entrar no seu apartamento) pode estar ativo por um longo período de tempo e contextualiza uma série de sub objetivos e ações (encontrar chaves, abrir porta, entrar) que são resolvidas em uma escala de tempo muito mais rápida. Essa separação de escalas de tempo, seja no domínio contínuo ou discreto, exige um modelo generativo hierárquico (profundo). Na neurociência, pode-se supor que as hierarquias corticais incorporam esse tipo de separação temporal de escalas de tempo, com estados de evolução lenta em níveis mais altos e estados de evolução rápida em níveis mais baixos, e que isso recapitula a dinâmica ambiental, que também evolui em várias escalas de tempo (por exemplo, durante tarefas perceptivas como reconhecimento de fala ou leitura). Na psicologia, esse tipo de modelo é útil na reprodução de processamento de metas hierárquicas (Pezzulo, Rigoli e Friston 2018) e tarefas de memória de trabalho (Parr e Friston 2017c) do tipo que depende da atividade do período de atraso (Funahashi et al. 1989) .

### Profundidade Temporal de Inferência e Planejamento

A terceira escolha de design diz respeito à profundidade temporal da inferência. É importante fazer uma distinção entre dois tipos de modelo generativo: o primeiro tem profundidade temporal e representa explicitamente as consequências de ações ou sequências de ação (políticas ou planos), enquanto o segundo não tem profundidade temporal e considera apenas observações presentes, mas não futuras . Esses dois tipos de modelo são exemplificados na figura 4.3: o POMDP dinâmico na parte superior e o modelo de tempo contínuo na parte inferior.[^uma-receita-para-projetar-modelos-2] A principal diferença entre esses dois modelos não é que eles usam variáveis discretas ou contínuas, respectivamente, mas apenas o modelo anterior (temporariamente profundo) dota as criaturas da capacidade de planejar com antecedência e selecionar entre possíveis futuros.

[^uma-receita-para-projetar-modelos-2]: ​Dito isso, o uso de coordenadas generalizadas de movimento (quadro 4.2) em modelos de tempo contínuo significa que eles são temporalmente profundos em virtude de sua representação implícita de uma trajetória curta. No entanto, esses modelos não incluem (necessariamente) variáveis que representam trajetórias alternativas que se poderia seguir (ou seja, as consequências de sequências de ações).

Imagine um roedor que planeja uma rota para um local de comida conhecido em um labirinto. Fazer isso se beneficia de um modelo temporalmente profundo, vagamente equivalente a um mapa espacial ou cognitivo (Tolman 1948), que codifica contingências entre localizações presentes e futuras condicionadas a ações (por exemplo, a localização futura após virar à direita ou à esquerda). O animal pode usar o modelo temporalmente profundo para considerar contrafactualmente vários cursos de ação (por exemplo, uma série de voltas à direita e à esquerda) e selecionar o que espera alcançar o local do alimento. Por que um modelo temporalmente profundo é necessário para o planejamento? Na Inferência Ativa, o planejamento é realizado calculando a energia livre esperada associada a diferentes ações ou políticas e, em seguida, selecionando a política associada à energia livre esperada mais baixa. A energia livre esperada não é apenas uma função das observações presentes (como a energia livre variacional), mas também um funcional das observações futuras. Este último não pode ser observado (por definição), mas apenas previsto usando um modelo temporalmente profundo, que descreve as maneiras pelas quais as ações produzem observações futuras.

Ao projetar um agente de Inferência Ativa, é útil considerar se ele deve ter capacidades de planejamento e orientadas para o futuro -- e, neste caso, selecionar um modelo temporalmente profundo. Além disso, é útil considerar a profundidade do planejamento -- isto é, até onde o processo de planejamento pode parecer no futuro. Finalmente, pode-se projetar modelos generativos que sejam hierárquicos e temporalmente profundos, em que o planejamento procede em várias escalas de tempo -- mais rápido em níveis mais baixos e mais lento em níveis mais altos. com a escolha entre modelos discretos e contínuos porque a ideia de selecionar entre futuros alternativos, definidos por sequências de ações, é articulada de forma mais simples usando modelos de tempo discreto.

## Como configurar o modelo generativo?

Quando especificamos nosso sistema de interesse e identificamos as formas relevantes do modelo generativo (por exemplo, representação contínua ou discreta, estrutura superficial versus estrutura hierárquica), nossos próximos desafios são especificar as variáveis específicas a serem incluídas no modelo generativo e decidir quais dessas variáveis permanecem fixas ou mudam como efeito da aprendizagem.

### Configurando as Variáveis do Modelo Gerador

As variáveis dos modelos generativos podem ser predefinidas ou aprendidas a partir de dados. Para fins ilustrativos, a maioria dos modelos que discutimos neste livro usa variáveis predefinidas. Ao projetar esses modelos, na prática, o principal desafio é decidir quais estados ocultos, observações e ações são mais apropriados para o problema em questão. Por exemplo, o modelo perceptivo capaz de distinguir rãs de maçãs no capítulo 2 incluía apenas dois estados ocultos (rãs, maçãs) e duas observações (salta, não pula). Um modelo mais sofisticado poderia incluir observações adicionais (por exemplo, vermelho, verde), bem como ações como tocar, que produzem efeitos sensoriais diferenciais (salto ou não salto) na presença de um sapo ou uma maçã.

A Figura 6.2 ilustra esquematicamente um modelo generativo para o conceito de um sapo saltador. O conceito é moldado como um modelo hierárquico, onde um único estado oculto (multimodal ou supramodal) no centro da figura se desdobra em uma cascata de estados ocultos (unimodais) correspondentes a perceptos em diferentes modalidades (exteroceptivo, proprioceptivo e interoceptivo; ver Quadro 6.1) e, em última análise, causando sensações nas mesmas modalidades. Esse arranjo corresponde a lançar o conceito de sapo saltitante como a causa comum de múltiplas consequências sensoriais (por exemplo, algo verde e pulando no domínio visual; um som de coaxar no domínio auditivo), algumas das quais podem ser contingentes à ação (por exemplo, o visão de algo saltando pode aumentar ao tocá-lo). A inversão do modelo generativo corresponde a uma inferência perceptiva (por exemplo, a presença de um sapo pulando) a partir de suas consequências sensoriais observadas (por exemplo, a visão de algo verde e nervoso) e integra informações em várias modalidades.

Uma vez estabelecidas essas variáveis de interesse, o próximo exercício é escrever o modelo generativo completo. Um exemplo é o modelo generativo simples para rãs e maçãs na figura 2.1, que é totalmente especificado por crenças anteriores sobre estados ocultos e um mapeamento (de probabilidade) entre estados ocultos e observações e cujos valores numéricos podem ser especificados à mão ou aprendidos a partir de dados. (ver 6.5.2).

![A **Figura 6.2** (hierárquica) modelo generativo para o conceito de um sapo saltitante usa uma notação simplificada em comparação com o capítulo 4: nós dentro do círculo pontilhado correspondem a estados ocultos, enquanto nós na periferia correspondem a observações sensoriais. As crenças sobre estados ocultos, após a inversão do modelo, correspondem a percepções que podem estar vinculadas a uma modalidade sensorial (por exemplo, percepção visual) ou podem ser amodais (por exemplo, o sapo saltitante). As contingências de ação são representadas como linhas tracejadas. Dependências horizontais entre estados ocultos em diferentes modalidades, bem como dependências temporais entre estados ocultos (como vimos nos modelos generativos dinâmicos do capítulo 4), são ignoradas por questão de simplicidade.](images/Figura_6_2.png)

| **Quadro 6.1** Variedades de modalidades sensoriais: Exteroceptivo, proprioceptivo e interoceptivo | 
| --- | 
| Na Inferência Ativa, muitas vezes é feita uma distinção conceitual entre três tipos de modalidades sensoriais: exteroceptivas (por exemplo, visão e audição), proprioceptivas (por exemplo, o sentido das posições das articulações e dos membros) e interoceptivas (por exemplo, o sentido dos órgãos internos). do corpo, como coração e estômago). Em modelos generativos multimodais, muitas vezes pode-se fatorar partes do modelo que se relacionam a diferentes modalidades; isso permite representar que (por exemplo) movimentos sacádicos têm consequências visuais, mas não auditivas. É importante ressaltar que os mesmos princípios da Inferência Ativa operam em todas as modalidades. Por exemplo, da mesma forma que o processamento visual pode ser descrito como a inferência sobre (variáveis ​​ocultas sobre) uma cena perceptiva, o processamento interoceptivo pode ser descrito como a inferência sobre (variáveis ​​ocultas que relatam) o estado interno do corpo. Além disso, ações motoras que alteram a cena perceptiva e ações direcionadas internamente que alteram o estado interoceptivo podem ser descritas de maneira semelhante. O primeiro aciona os reflexos espinhais que atendem às previsões proprioceptivas, enquanto o último aciona os reflexos autônomos que atendem às previsões interoceptivas. Tal processamento interoceptivo suporta alostase e regulação adaptativa, e suas disfunções podem ter consequências psicopatológicas (Pezzulo 2013, Seth 2013, Pezzulo e Levin 2015, Seth e Friston 2016, Allen et al 2019) | 

Além deste exemplo simples, os elementos que precisam ser especificados são totalmente determinados pela forma do modelo generativo selecionado. Por exemplo, o modelo para POMDP de tempo discreto mostrado na figura 4.3 (topo) requer a especificação das matrizes A, B, C, D e E; esquemas contínuos usam elementos análogos (embora menos alfabéticos), que serão tratados no capítulo 8. Mas mesmo nesses casos mais complexos, o exercício não é tão diferente do anterior: ou seja, especificar crenças anteriores sobre as variáveis ​​de interesse (por exemplo, em implementações de tempo discreto, sobre estados ocultos na primeira etapa de tempo no vetor D e sobre observações na matriz C) e seus mapeamentos probabilísticos (por exemplo, mapeamento de probabilidade entre estados ocultos e observações na matriz A). No entanto, em alguns casos, é útil pensar em fatorações do espaço de estados do modelo generativo, o que evita considerar todas as combinações possíveis de variáveis ​​caso algumas sejam desnecessárias. No capítulo 7, discutiremos um exemplo biologicamente plausível de fatoração que ocorre no processamento perceptual entre fluxos “o quê” e “onde” (Ungerleider e Haxby 1994) – ou seja, entre variáveis ​​que representam identidades e localizações de objetos, respectivamente, que podem ser tratados independentemente no modelo (portanto, simplificando-o), pois muitas vezes são invariantes entre si.

Decidir quais variáveis ​​são de interesse e como elas são relacionadas ou fatoradas no modelo é geralmente a parte mais desafiadora – mas também a mais criativa – do projeto do modelo. É um exercício de tradução de nossas hipóteses cognitivas em uma forma matemática que suporta a Inferência Ativa. Como devemos selecionar as variáveis ​​“certas”? Em última análise, trata-se de especificar alternativas plausíveis e escolher aquelas que têm a menor energia livre (cf. comparação do modelo bayesiano). No entanto, uma perspectiva praticamente útil para a maioria dos estudos é que o modelo generativo deve ser o mais semelhante possível à forma como acreditamos que os dados são gerados. Ao apelar para a Inferência Ativa no cenário da psicologia cognitiva, isso geralmente significa pensar em como os psicólogos experimentais gerariam os estímulos que apresentam aos participantes experimentais. Ao formalizar esses processos em termos das distribuições de probabilidade necessárias, chegamos a um modelo generativo cuja dinâmica de minimização de energia livre leva naturalmente ao desempenho da tarefa em questão.

Aqui, podemos fazer uma analogia com a maioria dos modelos Bayesianos (ou observadores ideais) de percepção, nos quais os modelos são projetados para imitar (em grande medida) a estrutura da tarefa em mãos, como no exemplo do reconhecimento de um sapo. ou uma maçã (capítulo 2). Essa ideia às vezes é equiparada ao teorema do bom regulador (Conant e Ashby 1970), que diz que para regular um ambiente de forma eficaz, uma criatura (seja biológica ou sintética) deve ser um bom modelo desse sistema. Da perspectiva da construção de nicho ecológico, isso às vezes é expresso em termos da adequação (estatística) (Bruineberg et al. 2018) do modelo de uma criatura ao seu ambiente (e vice-versa). No entanto, isso não significa que o modelo generativo de um agente deva ser idêntico ao processo generativo que realmente gera os dados. Para a maioria das aplicações práticas, pode ser simplificado ou diferente. Voltaremos a este ponto mais adiante neste capítulo (6.6). 

| Quadro 6.2 Prioridades e comportamento empírico |
| -- | 
| Outra perspectiva sobre a questão da seleção de prioridades baseia-se em um conjunto de resultados conhecidos como teoremas de classe completa (Wald 1947, Daunizeau et al. 2010), que afirmam que qualquer procedimento de decisão estatística (ou seja, comportamento) pode ser enquadrado como ótimo de Bayes sob o conjunto certo de crenças anteriores. Isso significa que, se estivermos interessados ​​em explicar o comportamento empírico, nosso desafio é identificar o modelo generativo (compreendendo crenças anteriores) que reproduziria esse comportamento da maneira mais simples possível. Em suma, as prioridades são uma declaração de uma hipótese sobre o sistema em questão. Se outras crenças anteriores forem plausíveis, isso oferece uma oportunidade de colocar isso em dados empíricos por meio de comparação de modelos bayesianos. Isso também tem implicações para a fenotipagem computacional em populações clínicas. Que sempre haverá um conjunto de crenças anteriores que tornam o comportamento de Bayes ótimo implica que a questão-chave – na compreensão dos déficits computacionais que dão origem a síndromes psiquiátricas ou neurológicas – é quais são essas prioridades. Essa ideia é um pouco contra-intuitiva no início. No entanto, o teorema da classe completa significa que perguntar se um comportamento é (Bayes) ótimo não tem sentido. A questão importante é: Quais são as crenças anteriores que tornariam isso ideal? No capítulo 9, veremos como um apelo à minimização da energia livre com base em nossas próprias crenças como cientistas oferece uma maneira de responder a essa pergunta.

###  Quais partes do modelo generativo são fixas e o que é aprendido?| 

Outra escolha de design é decidir quais partes do modelo generativo são fixas e quais são atualizadas ao longo do tempo como efeito do aprendizado. Em princípio, a Inferência Ativa permite que cada parte do modelo – e até mesmo sua estrutura – seja atualizada (ou aprendida) ao longo do tempo. Isso torna o aprendizado uma escolha de design em vez de algo obrigatório. De acordo com isso, abordaremos exemplos de modelos de Inferência Ativa que são completamente projetados à mão e exemplos em que algumas partes do modelo (por exemplo, probabilidades de transição) permanecem fixas enquanto outras (por exemplo, probabilidades) são atualizadas ao longo do tempo.

Na Inferência Ativa, a aprendizagem é lançada como um aspecto da inferência, como um processo de minimização de energia livre. Até agora, descrevemos a inferência em termos de uma atualização de crenças sobre estados do modelo generativo. Da mesma forma, podemos descrever a aprendizagem como uma atualização de crenças sobre os parâmetros do modelo generativo. Para isso, o modelo generativo deve ser dotado de crenças prévias sobre os parâmetros das distribuições a serem aprendidas, onde os parâmetros específicos dependem da distribuição de probabilidade associada a cada variável (por exemplo, média e variância para uma distribuição gaussiana). Esses valores anteriores são atualizados para formar crenças posteriores sempre que novos dados são encontrados. Como discutiremos no capítulo 7, a forma algorítmica dessa atualização é a mesma da atualização das variáveis de estado.

O fato de que tanto a inferência quanto o aprendizado usam o mesmo tipo de atualização de crenças bayesianas pode parecer confuso durante o projeto do modelo – em parte porque decidir o que deve ser modelado como um estado ou parâmetro nem sempre é simples. No entanto, quando se trata de modelos cognitivos, há uma clara diferença entre inferência e aprendizagem. A inferência descreve mudanças (rápidas) de nossas crenças sobre estados de modelo – por exemplo, como atualizamos nossa crença de que há uma maçã à nossa frente depois de observar algo vermelho. O aprendizado descreve mudanças (lentas) de nossas crenças sobre os parâmetros do modelo – por exemplo, como atualizamos nossa distribuição de probabilidade para aumentar o valor do mapeamento maçãs-vermelho após observar várias ocorrências de maçãs vermelhas. As crenças sobre parâmetros geralmente variam muito mais lentamente do que aquelas sobre estados, e só podem ser atualizadas após os estados terem sido inferidos. De uma perspectiva neurobiológica, é atraente mapear a inferência para a dinâmica neuronal e o aprendizado para a plasticidade sináptica. Além disso, como discutiremos no capítulo 7, manter crenças probabilísticas sobre os parâmetros do modelo induz comportamentos de busca de novidades para que as criaturas possam selecionar os melhores dados para aprender a estrutura causal de seus mundos. Isso sugere que dotar os modelos de Inferência Ativa com a capacidade de aprender seus parâmetros (ou mesmo sua estrutura; veja o capítulo 7) é uma maneira eficaz de estudar a dinâmica comportamental da aprendizagem ativa e da exploração baseada na curiosidade.

Antes de concluir esta seção, vale a pena notar que neste livro exemplificamos modelos generativos bastante simples que são definidos usando métodos tabulares (por exemplo, com matrizes explícitas para priores e verossimilhanças) e que operam em pequenos espaços de estados. Em comparação, tipos muito mais sofisticados de modelos generativos – e esquemas de aprendizado associados – estão sendo desenvolvidos em campos como aprendizado de máquina, aprendizado profundo e robótica, como, por exemplo, autoencoders variacionais (Kingma e Welling 2014), redes adversárias generativas ( Goodfellow et al. 2014), redes corticais recursivas (George et al. 2017) e modelos mundiais (Ha e Schmidhuber 2018). Em princípio, pode-se emprestar qualquer um desses métodos (e muitos outros) para implementar uma ou mais partes dos modelos de Inferência Ativa (por exemplo, modelos de probabilidade ou transição). Aproveitando os métodos de aprendizado de máquina mais atualizados, seria possível escalar a Inferência Ativa para domínios e aplicativos cada vez mais desafiadores; ver, por exemplo, Ueltzhöffer (2018) e Millidge (2019).

No entanto, existem alguns pontos importantes a serem considerados ao projetar modelos de Inferência Ativa que usam modelos sofisticados de aprendizado de máquina, especialmente se estiver interessado em implicações cognitivas e neurobiológicas. Um apelo da Inferência Ativa é que ela oferece uma perspectiva integradora das funções cognitivas, assumindo que (por exemplo) a inferência perceptiva, o planejamento de ações e o aprendizado derivam do mesmo processo de minimização de energia livre. Esse poder integrador seria perdido se (por exemplo) modelos generativos justapostos que operam ou aprendem independentemente uns dos outros. Além disso, os métodos de aprendizado de máquina mencionados correspondem a modelos de processo distintos da Inferência Ativa e possuem diferentes interpretações cognitivas e neurobiológicas. Finalmente, ao usar métodos de aprendizado de máquina, algumas das escolhas de design discutidas aqui (por exemplo, sobre a escolha de variáveis ​​de modelo) podem ser ignoradas, pois são propriedades emergentes de aprendizado; no entanto, eles podem ser substituídos por diferentes opções de design, sobre (por exemplo) número de camadas, parâmetros e taxas de aprendizado de uma rede neural profunda. Essas escolhas de design potencialmente têm implicações cognitivas e neurobiológicas relevantes, que estão além do escopo do que abordamos aqui.

## Configurando o Processo Gerador

Na Inferência Ativa, o processo generativo descreve a dinâmica do mundo externo ao agente da Inferência Ativa, que corresponde ao processo que determina as observações do agente (ver figura 6.1). Pode parecer bizarro ter adiado a definição do processo generativo para depois de descrever o modelo generativo do agente. Afinal, um modelador teria alguma tarefa (e processo generativo) em mente desde o início, então faria todo o sentido reverter essa ordem e projetar o processo generativo antes do modelo generativo, especialmente em aplicações onde o modelo generativo tem que ser aprendidas durante interações situadas, como em configurações de jogo ou robóticas (Ueltzhöffer 2018, Millidge 2019, Sancaktar et al. 2020).

A razão pela qual adiamos o projeto do processo generativo é que, em muitas aplicações práticas discutidas neste livro, simplesmente assumimos que a dinâmica do processo generativo é a mesma ou muito semelhante ao modelo generativo. Em outras palavras, geralmente assumimos que o modelo generativo do agente imita de perto o processo que gera suas observações. Isso não é o mesmo que dizer que o agente tem perfeito conhecimento do ambiente. De fato, mesmo que o agente conheça o processo que gera suas observações, ele pode estar incerto sobre (por exemplo) seu estado inicial no processo, como foi o caso do exemplo da maçã versus rã. Na linguagem da Inferência Ativa em tempo discreto, pode-se projetar um modelo no qual tanto o modelo generativo quanto o processo generativo são caracterizados pela mesma matriz A, mas no qual a crença do agente sobre seu estado inicial (vetor D), que faz parte de seu modelo generativo, é diferente – ou mesmo inconsistente – com o verdadeiro estado inicial do processo generativo. Uma coisa sutil a notar é que mesmo que tanto o modelo generativo quanto o processo generativo sejam caracterizados pelas mesmas matrizes A e B, suas semânticas são diferentes. A matriz A do processo generativo é uma propriedade objetiva do ambiente (às vezes chamada de distribuição de medição nos modelos Bayesianos), enquanto a matriz A do modelo generativo codifica a crença subjetiva de um agente (chamada de função de verossimilhança nos modelos Bayesianos).

Claro, exceto nos casos mais simples, não é obrigatório que o modelo generativo e o processo generativo sejam os mesmos. Em implementações práticas de Inferência Ativa, pode-se sempre especificar o processo generativo separadamente do modelo generativo, seja usando equações que diferem daquelas do modelo generativo ou usando outros métodos, como simuladores de jogos, que tomam ações como entradas e fornecem observações como saídas (Cullen et al. 2018), seguindo assim o ciclo usual de ação-percepção implícito no envoltório de Markov da figura 6.1.

Existem algumas implicações filosóficas de projetar modelos generativos que são semelhantes ou diferentes do processo generativo (Hohwy 2013; Clark 2015; Pezzulo, Donnarumma et al. 2017; Nave et al. 2020, Tschantz et al. 2020). Como discutido acima, o teorema do bom regulador (Conant e Ashby 1970) diz que uma criatura adaptativa eficaz deve ter ou ser um bom modelo do sistema que regula. No entanto, isso pode ser alcançado de várias maneiras. Primeiro, como discutido até agora, o modelo generativo da criatura pode imitar (pelo menos em grande medida) o processo generativo. Os modelos desenvolvidos dessa forma podem ser chamados de modelos explícitos ou ambientais, dada a semelhança entre seus estados internos e os estados externos do ambiente. Em segundo lugar, o modelo generativo da criatura pode ser muito mais parcimonioso do que (e até significativamente diferente) do processo generativo, na medida em que administra corretamente os aspectos do ambiente que são úteis para agir de forma adaptativa nele e atingir os objetivos da criatura. Os modelos desenvolvidos dessa maneira podem ser chamados de sensório-motores ou orientados para a ação, pois codificam principalmente contingências de observação de ação (ou sensório-motoras) e seu papel principal é apoiar ações direcionadas a objetivos, em vez de fornecer uma descrição precisa do ambiente.




