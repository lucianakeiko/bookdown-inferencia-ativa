#  Análise de dados baseada em modelo
Só porque temos o melhor martelo não significa que todo problema é um prego. —Barack Obama

## Introdução 

Em última análise, os modelos descritos neste livro só são úteis se puderem responder a questões científicas. Neste capítulo, nos concentramos nas maneiras pelas quais a Inferência Ativa pode ser aplicada na compreensão de dados empíricos. A ideia central é que nós, como cientistas, podemos recorrer à mesma matemática que supusemos que o cérebro usa nos capítulos anteriores. Nosso objetivo geral é recuperar os parâmetros do modelo generativo que o cérebro de um sujeito usa para produzir comportamento – o modelo subjetivo. Para isso, podemos usar nosso próprio modelo generativo (de como o modelo subjetivo produz comportamento) – o modelo objetivo. Podemos inverter nosso modelo objetivo com base no comportamento que observamos para fazer inferências sobre os parâmetros do modelo generativo subjetivo. Essa inferência meta-Bayesiana oferece a oportunidade de testar hipóteses sobre o modelo que assumimos que o cérebro usa e fenotipar os indivíduos com base nas crenças anteriores que eles teriam que manter para que seu comportamento fosse o ideal de Bayes. A fenotipagem computacional baseada em crenças desse tipo é promissora nos campos emergentes da psiquiatria computacional, neuropsicologia e neurologia.

## Métodos Meta-Bayesianos

Este capítulo trata da utilidade das formulações de Inferência Ativa na análise de dados de experimentos comportamentais. Isso vai além das simulações de prova de princípio que vimos nos capítulos anteriores e, em vez disso, explora a Inferência Ativa para responder a questões científicas. Já vimos que o modelo generativo de um sujeito é o principal determinante do comportamento sob Inferência Ativa. Isso implica que as hipóteses sobre as causas das medidas comportamentais empíricas devem ser enquadradas em termos dos modelos generativos alternativos usados para selecionar essas ações. Nosso desafio, então, é ajustar um esquema de Inferência Ativa aos dados observados, manipulando os parâmetros (ou seja, crenças anteriores) do modelo generativo.

De um modo geral, existem duas razões (relacionadas) para ajustar um modelo computacional ao comportamento observado. A primeira é estimar os parâmetros de interesse desse modelo que melhor explicam o comportamento de um determinado sujeito ou grupo de sujeitos. Isso é útil para caracterizar o comportamento subjetivo em termos dos cálculos que o geram, um processo conhecido como fenotipagem computacional (Montague et al. 2012, Schwartenbeck e Friston 2016, Friston 2017). Os fenótipos computacionais podem ser usados em combinação com outras medidas (por exemplo, para estabelecer ligações entre achados de neuroimagem e função) ou podem ser usados sozinhos na previsão de comportamentos em outros ambientes (por exemplo, após uma intervenção terapêutica).

A segunda razão é comparar hipóteses alternativas, expressas como modelos, que representam diferentes explicações para um fenômeno comportamental (Mirza et al. 2018). Essas duas agendas – estimativa de parâmetros e comparação de modelos – mapeiam para um lado do teorema de Bayes. A estimativa de parâmetros é o processo de encontrar a probabilidade posterior, sob um modelo, de um ajuste de parâmetros. A comparação de modelos baseia-se em encontrar as probabilidades marginais (ou seja, evidências) para cada modelo. Para recapitular, o teorema de Bayes é

$$ \begin{matrix}\underbrace {P(u|\theta,m)} \\ Verossimilhança \end{matrix}
\begin{matrix}\underbrace {P(\theta|m)} \\ Prior \end{matrix}
= \begin{matrix}\underbrace {P(\theta|u, m)} \\ Posterior \end{matrix}
\begin{matrix}\underbrace {P(u,m)} \\ Evidência \end{matrix}
(9.1)$$

O lado direito lida com a probabilidade posterior de parâmetros $(\theta)$ dados dados comportamentais $(u)$ sob um modelo $(m)$ e a evidência do modelo, e o lado esquerdo nos diz o que precisamos especificar para nosso modelo: precisamos de crenças prévias sobre nossos parâmetros de interesse e uma função de verossimilhança.

É importante ressaltar que, embora apelamos para o mesmo esquema de inferência bayesiana usado nos capítulos anteriores, nosso objetivo é diferente aqui. Isso se baseia no fato de que existem dois processos de inferência acontecendo (figura 9.1). A primeira é que as criaturas usam seu modelo dos processos que geram seus dados sensoriais para fazer inferências sobre seu mundo (e sobre como agir). Este foi o foco dos capítulos anteriores. A segunda é que nós, como cientistas objetivos, observamos o comportamento da criatura e procuramos fazer inferências sobre o modelo generativo (subjetivo) que ela está usando invertendo nosso próprio modelo generativo (objetivo). A implicação aqui é que estamos fazendo inferências sobre um processo inferencial – às vezes chamado de inferência “metabayesiana” (Daunizeau et al. 2010).

![Figura 9.1 Relação entre os modelos subjetivo e objetivo de inferência metabayesiana. Caixa tracejada interna: Modelo subjetivo assumido para ser usado por um sujeito experimental. Este poderia ser um modelo POMDP como ilustrado ou alguma outra forma de modelo. As características importantes são que depende de parâmetros $(\theta)$ cujo valor não sabemos e que gera dados sensoriais $(o)$. Caixa tracejada externa: O modelo objetivo do experimentador $(m)$ inclui crenças prévias sobre os parâmetros e prediz o comportamento $(u)$ que esperaríamos ao apresentar estímulos experimentais (dados sensoriais da perspectiva do modelo subjetivo). Fundamentalmente, a distribuição de verossimilhança do modelo objetivo depende do modelo subjetivo. Isso significa que avaliamos a probabilidade de os parâmetros assumirem um valor específico da seguinte maneira. Primeiro, incorporamos os parâmetros no modelo subjetivo. Em seguida, usamos os esquemas de Inferência Ativa descritos nos capítulos anteriores para resolver esse modelo, apresentando nossos estímulos experimentais como dados sensoriais e inferindo uma distribuição sobre o curso de ação mais provável. Por fim, avaliamos a probabilidade das ações ou escolhas observadas, dada essa distribuição. Esta é a probabilidade do comportamento observado dados parâmetros e estímulos - ou seja, a distribuição de verossimilhança no modelo objetivo.](images/Figura_9_1.png)

Mais formalmente, essa abordagem define a distribuição de verossimilhança em termos da solução de um problema de Inferência Ativa. Ao usar uma determinada configuração de parâmetro, podemos simular o comportamento sob Inferência Ativa e quantificar a probabilidade de que uma série de ações tenha sido executada. Equipados com crenças anteriores sobre o valor desses parâmetros, temos um modelo generativo de como uma criatura usa seu modelo generativo para produzir ações. Embora nosso foco seja a Inferência Ativa (e modelos de tempo discreto especificamente), os métodos genéricos usados aqui podem ser usados com qualquer função de verossimilhança arbitrária. Outros modelos normativos de comportamento (como os usados no aprendizado por reforço) podem ser substituídos pelos modelos de Inferência Ativa.

As seções a seguir descompactam um exemplo de um esquema de inferência genérico que pode ser usado para inferência meta-Bayesiana (ou seja, Laplace variacional) e o uso de modelos hierárquicos para comparação de modelos. Em seguida, fornecemos uma receita simples para análise de dados baseada em modelo e, finalmente, revisamos um exemplo-chave desse procedimento. É importante enfatizar que não é necessário entender os detalhes técnicos para usar esses métodos de forma eficaz; assim, os leitores desinteressados nesses detalhes são convidados a pular as seções 9.3 e 9.4.

Em resumo, a ideia básica é avaliar a probabilidade de qualquer conjunto observado de escolhas, dados os parâmetros desconhecidos de interesse – ou seja, os parâmetros das crenças anteriores de um sujeito. Em seguida, combinamos essa verossimilhança com nosso objetivo anterior sobre esses parâmetros para avaliar o posterior sobre os antecedentes do sujeito, da maneira usual. Se tivermos vários sujeitos, esses posteriores podem ser combinados para fazer inferências sobre efeitos de grupo ou entre sujeitos, usando Bayes empíricos paramétricos (PEB). A probabilidade necessária é simplesmente a probabilidade de amostragem da sequência observada de escolhas, sob as crenças posteriores do sujeito sobre a ação. Essas crenças posteriores dependem do que o sujeito vê (ou seja, pistas ou estímulos) e suas crenças anteriores – e são avaliadas de maneira direta, resolvendo o esquema de Inferência Ativa apropriado. Observe que estamos usando procedimentos bayesianos duas vezes: primeiro para avaliar as crenças posteriores do sujeito sobre a ação e, segundo, para avaliar nossas crenças posteriores sobre os antecedentes desconhecidos que caracterizam o sujeito. Agora ensaiamos as várias partes desse procedimento metabayesiano.

## Laplace Variacional

Variational Laplace é um esquema de inferência baseado nos mesmos princípios da codificação preditiva (Friston, Mattout et al. 2007). No entanto, pode ser usado para funções de verossimilhança mais genéricas do que aquelas encontradas anteriormente – que foram definidas como gaussianas. Começaremos esta seção com uma visão geral da função de verossimilhança $\mathcal L(\theta)$ de interesse aqui. Isso deve fornecer a probabilidade de ações para um esquema de Inferência Ativa com um modelo generativo com parâmetros definidos no valor $\theta$. As ações selecionadas dependem das observações feitas:

$$ \mathcal L(\theta)=\ln P(\tilde u |\theta,m,\tilde o )$$
$$ P(\tilde u |\theta,m,\tilde o ) = \tilde u \cdot \sigma (\theta_\alpha ln  \pmb {\tilde u}) \qquad\qquad (9.2)$$
$$ \pmb {\tilde u} = \pmb \pi \cdot U$$

$$ \pmb \pi =arg \;min\; F $$

Descompactando isso, o primeiro termo fornece a probabilidade logarítmica de uma sequência observada de ações $(\tilde u)$ em função dos parâmetros $(\theta)$, do modelo $(m)$ e de uma sequência de estímulos $(\tilde o)$ apresentada durante um experimento real. A probabilidade dessas ações é encontrada usando os parâmetros para definir as crenças anteriores em um modelo POMDP do tipo descrito no capítulo 7. Podemos então resolver o POMDP conforme descrito nos capítulos 4 e 7, forçando a simulação a realizar a ação observada sequência e apresentando-a com os mesmos estímulos experimentais. Como descrevemos nos capítulos anteriores, isso envolve calcular as crenças $(\pi)$ que um sujeito sintético mantém sobre a política ou curso de ação que ele escolhe seguir. Isso minimiza a energia livre $(F)$ associada ao seu modelo generativo do mundo. Podemos então pegar essas crenças e calcular a probabilidade média de seguir uma sequência de ação. Isso exige que distribuamos a probabilidade de cada política pelas ações implícitas nessa política (indexadas por uma matriz $U$ ). Finalmente, um parâmetro de temperatura softmax $(θ_\alpha)$ é aplicado para levar em conta a aleatoriedade (tremor) no comportamento não contabilizado pelo modelo. Se esse parâmetro softmax for um, estamos efetivamente assumindo que o sujeito amostra suas ações a partir de crenças posteriores sobre suas ações; às vezes, isso é chamado de comportamento de correspondência. Alternativamente, se o parâmetro softmax for muito grande, a ação emitida é a ação com maior posterior subjetiva, ou seja, o sujeito sempre escolhe a opção mais provável. Este parâmetro softmax pode ser estimado.
