#  Análise de dados baseada em modelo
Só porque temos o melhor martelo não significa que todo problema é um prego. —Barack Obama

## Introdução 

Em última análise, os modelos descritos neste livro só são úteis se puderem responder a questões científicas. Neste capítulo, nos concentramos nas maneiras pelas quais a Inferência Ativa pode ser aplicada na compreensão de dados empíricos. A ideia central é que nós, como cientistas, podemos recorrer à mesma matemática que supusemos que o cérebro usa nos capítulos anteriores. Nosso objetivo geral é recuperar os parâmetros do modelo generativo que o cérebro de um sujeito usa para produzir comportamento – o modelo subjetivo. Para isso, podemos usar nosso próprio modelo generativo (de como o modelo subjetivo produz comportamento) – o modelo objetivo. Podemos inverter nosso modelo objetivo com base no comportamento que observamos para fazer inferências sobre os parâmetros do modelo generativo subjetivo. Essa inferência meta-Bayesiana oferece a oportunidade de testar hipóteses sobre o modelo que assumimos que o cérebro usa e fenotipar os indivíduos com base nas crenças anteriores que eles teriam que manter para que seu comportamento fosse o ideal de Bayes. A fenotipagem computacional baseada em crenças desse tipo é promissora nos campos emergentes da psiquiatria computacional, neuropsicologia e neurologia.

## Métodos Meta-Bayesianos

Este capítulo trata da utilidade das formulações de Inferência Ativa na análise de dados de experimentos comportamentais. Isso vai além das simulações de prova de princípio que vimos nos capítulos anteriores e, em vez disso, explora a Inferência Ativa para responder a questões científicas. Já vimos que o modelo generativo de um sujeito é o principal determinante do comportamento sob Inferência Ativa. Isso implica que as hipóteses sobre as causas das medidas comportamentais empíricas devem ser enquadradas em termos dos modelos generativos alternativos usados para selecionar essas ações. Nosso desafio, então, é ajustar um esquema de Inferência Ativa aos dados observados, manipulando os parâmetros (ou seja, crenças anteriores) do modelo generativo.

De um modo geral, existem duas razões (relacionadas) para ajustar um modelo computacional ao comportamento observado. A primeira é estimar os parâmetros de interesse desse modelo que melhor explicam o comportamento de um determinado sujeito ou grupo de sujeitos. Isso é útil para caracterizar o comportamento subjetivo em termos dos cálculos que o geram, um processo conhecido como fenotipagem computacional (Montague et al. 2012, Schwartenbeck e Friston 2016, Friston 2017). Os fenótipos computacionais podem ser usados em combinação com outras medidas (por exemplo, para estabelecer ligações entre achados de neuroimagem e função) ou podem ser usados sozinhos na previsão de comportamentos em outros ambientes (por exemplo, após uma intervenção terapêutica).

A segunda razão é comparar hipóteses alternativas, expressas como modelos, que representam diferentes explicações para um fenômeno comportamental (Mirza et al. 2018). Essas duas agendas – estimativa de parâmetros e comparação de modelos – mapeiam para um lado do teorema de Bayes. A estimativa de parâmetros é o processo de encontrar a probabilidade posterior, sob um modelo, de um ajuste de parâmetros. A comparação de modelos baseia-se em encontrar as probabilidades marginais (ou seja, evidências) para cada modelo. Para recapitular, o teorema de Bayes é

$$ \begin{matrix}\underbrace {P(u|\theta,m)} \\ Verossimilhança \end{matrix}
\begin{matrix}\underbrace {P(\theta|m)} \\ Prior \end{matrix}
= \begin{matrix}\underbrace {P(\theta|u, m)} \\ Posterior \end{matrix}
\begin{matrix}\underbrace {P(u,m)} \\ Evidência \end{matrix}
(9.1)$$

O lado direito lida com a probabilidade posterior de parâmetros $(\theta)$ dados dados comportamentais $(u)$ sob um modelo $(m)$ e a evidência do modelo, e o lado esquerdo nos diz o que precisamos especificar para nosso modelo: precisamos de crenças prévias sobre nossos parâmetros de interesse e uma função de verossimilhança.

É importante ressaltar que, embora apelamos para o mesmo esquema de inferência bayesiana usado nos capítulos anteriores, nosso objetivo é diferente aqui. Isso se baseia no fato de que existem dois processos de inferência acontecendo (figura 9.1). A primeira é que as criaturas usam seu modelo dos processos que geram seus dados sensoriais para fazer inferências sobre seu mundo (e sobre como agir). Este foi o foco dos capítulos anteriores. A segunda é que nós, como cientistas objetivos, observamos o comportamento da criatura e procuramos fazer inferências sobre o modelo generativo (subjetivo) que ela está usando invertendo nosso próprio modelo generativo (objetivo). A implicação aqui é que estamos fazendo inferências sobre um processo inferencial – às vezes chamado de inferência “metabayesiana” (Daunizeau et al. 2010).

![Figura 9.1 Relação entre os modelos subjetivo e objetivo de inferência metabayesiana. Caixa tracejada interna: Modelo subjetivo assumido para ser usado por um sujeito experimental. Este poderia ser um modelo POMDP como ilustrado ou alguma outra forma de modelo. As características importantes são que depende de parâmetros $(\theta)$ cujo valor não sabemos e que gera dados sensoriais $(o)$. Caixa tracejada externa: O modelo objetivo do experimentador $(m)$ inclui crenças prévias sobre os parâmetros e prediz o comportamento $(u)$ que esperaríamos ao apresentar estímulos experimentais (dados sensoriais da perspectiva do modelo subjetivo). Fundamentalmente, a distribuição de verossimilhança do modelo objetivo depende do modelo subjetivo. Isso significa que avaliamos a probabilidade de os parâmetros assumirem um valor específico da seguinte maneira. Primeiro, incorporamos os parâmetros no modelo subjetivo. Em seguida, usamos os esquemas de Inferência Ativa descritos nos capítulos anteriores para resolver esse modelo, apresentando nossos estímulos experimentais como dados sensoriais e inferindo uma distribuição sobre o curso de ação mais provável. Por fim, avaliamos a probabilidade das ações ou escolhas observadas, dada essa distribuição. Esta é a probabilidade do comportamento observado dados parâmetros e estímulos - ou seja, a distribuição de verossimilhança no modelo objetivo.](images/Figura_9_1.png)

Mais formalmente, essa abordagem define a distribuição de verossimilhança em termos da solução de um problema de Inferência Ativa. Ao usar uma determinada configuração de parâmetro, podemos simular o comportamento sob Inferência Ativa e quantificar a probabilidade de que uma série de ações tenha sido executada. Equipados com crenças anteriores sobre o valor desses parâmetros, temos um modelo generativo de como uma criatura usa seu modelo generativo para produzir ações. Embora nosso foco seja a Inferência Ativa (e modelos de tempo discreto especificamente), os métodos genéricos usados aqui podem ser usados com qualquer função de verossimilhança arbitrária. Outros modelos normativos de comportamento (como os usados no aprendizado por reforço) podem ser substituídos pelos modelos de Inferência Ativa.

As seções a seguir descompactam um exemplo de um esquema de inferência genérico que pode ser usado para inferência meta-Bayesiana (ou seja, Laplace variacional) e o uso de modelos hierárquicos para comparação de modelos. Em seguida, fornecemos uma receita simples para análise de dados baseada em modelo e, finalmente, revisamos um exemplo-chave desse procedimento. É importante enfatizar que não é necessário entender os detalhes técnicos para usar esses métodos de forma eficaz; assim, os leitores desinteressados nesses detalhes são convidados a pular as seções 9.3 e 9.4.

Em resumo, a ideia básica é avaliar a probabilidade de qualquer conjunto observado de escolhas, dados os parâmetros desconhecidos de interesse – ou seja, os parâmetros das crenças anteriores de um sujeito. Em seguida, combinamos essa verossimilhança com nosso objetivo anterior sobre esses parâmetros para avaliar o posterior sobre os antecedentes do sujeito, da maneira usual. Se tivermos vários sujeitos, esses posteriores podem ser combinados para fazer inferências sobre efeitos de grupo ou entre sujeitos, usando Bayes empíricos paramétricos (PEB). A probabilidade necessária é simplesmente a probabilidade de amostragem da sequência observada de escolhas, sob as crenças posteriores do sujeito sobre a ação. Essas crenças posteriores dependem do que o sujeito vê (ou seja, pistas ou estímulos) e suas crenças anteriores – e são avaliadas de maneira direta, resolvendo o esquema de Inferência Ativa apropriado. Observe que estamos usando procedimentos bayesianos duas vezes: primeiro para avaliar as crenças posteriores do sujeito sobre a ação e, segundo, para avaliar nossas crenças posteriores sobre os antecedentes desconhecidos que caracterizam o sujeito. Agora ensaiamos as várias partes desse procedimento metabayesiano.

## Laplace Variacional

Variational Laplace é um esquema de inferência baseado nos mesmos princípios da codificação preditiva (Friston, Mattout et al. 2007). No entanto, pode ser usado para funções de verossimilhança mais genéricas do que aquelas encontradas anteriormente – que foram definidas como gaussianas. Começaremos esta seção com uma visão geral da função de verossimilhança $\mathcal L(\theta)$ de interesse aqui. Isso deve fornecer a probabilidade de ações para um esquema de Inferência Ativa com um modelo generativo com parâmetros definidos no valor $\theta$. As ações selecionadas dependem das observações feitas:

$$ \mathcal L(\theta)=\ln P(\tilde u |\theta,m,\tilde o )$$
$$ P(\tilde u |\theta,m,\tilde o ) = \tilde u \cdot \sigma (\theta_\alpha ln  \pmb {\tilde u}) \qquad\qquad (9.2)$$
$$ \pmb {\tilde u} = \pmb \pi \cdot U$$

$$ \pmb \pi =arg \;min\; F $$

Descompactando isso, o primeiro termo fornece a probabilidade logarítmica de uma sequência observada de ações $(\tilde u)$ em função dos parâmetros $(\theta)$, do modelo $(m)$ e de uma sequência de estímulos $(\tilde o)$ apresentada durante um experimento real. A probabilidade dessas ações é encontrada usando os parâmetros para definir as crenças anteriores em um modelo POMDP do tipo descrito no capítulo 7. Podemos então resolver o POMDP conforme descrito nos capítulos 4 e 7, forçando a simulação a realizar a ação observada sequência e apresentando-a com os mesmos estímulos experimentais. Como descrevemos nos capítulos anteriores, isso envolve calcular as crenças $(\pi)$ que um sujeito sintético mantém sobre a política ou curso de ação que ele escolhe seguir. Isso minimiza a energia livre $(F)$ associada ao seu modelo generativo do mundo. Podemos então pegar essas crenças e calcular a probabilidade média de seguir uma sequência de ação. Isso exige que distribuamos a probabilidade de cada política pelas ações implícitas nessa política (indexadas por uma matriz $U$ ). Finalmente, um parâmetro de temperatura softmax $(θ_\alpha)$ é aplicado para levar em conta a aleatoriedade (tremor) no comportamento não contabilizado pelo modelo. Se esse parâmetro softmax for um, estamos efetivamente assumindo que o sujeito amostra suas ações a partir de crenças posteriores sobre suas ações; às vezes, isso é chamado de comportamento de correspondência. Alternativamente, se o parâmetro softmax for muito grande, a ação emitida é a ação com maior posterior subjetiva, ou seja, o sujeito sempre escolhe a opção mais provável. Este parâmetro softmax pode ser estimado.

O resultado é a probabilidade das ações sob o modelo, dada uma sequência de estímulos e parâmetros – isto é, uma probabilidade de dados comportamentais dado um modelo. Equipando os parâmetros objetivos com priors gaussianas[^901] $ (\theta \sim \mathcal N (\eta, \Pi^{(1)}) $, podemos usar a suposição de Laplace para expressar a (energia livre) aproximação à evidência do modelo:

[^901]: Praticamente, muitas vezes é útil definir parâmetros como parâmetros de escala de log: o parâmetro atua como um fator de escala não negativo e não pode ser caracterizado por uma distribuição normal, que aloca números negativos em uma densidade de probabilidade finita. Assumir que o log do parâmetro de escala é normalmente distribuído garante positividade quando exponenciado para obter o próprio parâmetro de escala. O mesmo objetivo pode ser alcançado modelando a raiz quadrada de um parâmetro como sendo normalmente distribuído.


$$\begin{equation}
\ln P(\tilde u| m, \tilde o) \approx \mathcal L(\mu)- \frac{1}{2} \Big(\epsilon \cdot \Pi^{(1)}\epsilon + \ln \Big| \nabla_{\mu\mu} \mathcal L (\mu)-\Pi^{(1)} \Big| \Big) \\ 
e = \eta - \mu  \qquad \qquad (9.3)\\
\mu = arg \; max \Big\{ \mathcal L(\mu)- \frac{1}{2} \Big(\epsilon \cdot \Pi^{(1)}\epsilon + \ln \Big| \nabla_{\mu\mu} \mathcal L (\mu)-\Pi^{(1)} \Big| \Big)  \Big\}
\end{equation}$$

A Equação 9.3 é a mesma que foi descompactada na Quadro 4.3 (generalizada para um espaço de parâmetros multidimensional), mas aqui substituímos uma forma explícita para a covariância posterior e assumimos uma distribuição a priori normalmente. No capítulo 4 e nas aplicações do capítulo 8, ignoramos os termos da equação 9.3 que não dependiam da moda. No entanto, é importante incluí-los aqui quando consideramos problemas de comparação de modelos.

Para encontrar o valor de μ que maximiza a última linha da equação 9.3, realizamos uma subida de gradiente. Sob suposições quadráticas, isso se reduz ao seguinte:

$$ \mu = \nabla_\mu \mathcal L(\mu) + \Pi^{(1)}\epsilon \qquad\qquad\qquad (9.4) $$

Embora uma forma explícita para o gradiente da probabilidade logarítmica usada aqui possa não estar disponível, métodos de diferenças finitas [^902] podem ser usados para calcular uma aproximação numérica razoável. Eles também podem ser usados para encontrar a precisão posterior, que é a segunda derivada (ou Hessiana) da probabilidade logarítmica negativa mais a precisão anterior. A Equação 9.4 é a forma mais simples de atualização, mas geralmente são usados métodos mais sofisticados baseados na curvatura local.

[^902]: Por exemplo, $∂x f(x) ≈ 2Δx f(x + Δx) − f(x − Δx)).$ 

## Bayes Empíricos Paramétricos (PEB)

O procedimento variacional de Laplace na seção anterior nos permite fazer inferências e quantificar a evidência de um modelo de comportamento de escolha. Isso nos permite fenotipar computacionalmente um indivíduo e comparar hipóteses alternativas sobre esse indivíduo. No entanto, as questões interessantes geralmente estão em nível de grupo. Por exemplo, podemos estar interessados em como um parâmetro – como a precisão de preferências anteriores – varia com a idade. Para responder a essa pergunta, podemos usar a abordagem da seção 9.3 para ajustar modelos ao comportamento de participantes individuais com uma faixa de idades. Formulamos então um modelo linear geral que gera o parâmetro de interesse, levando em consideração a idade:

$$ P(\theta| \beta, X) = \mathcal N(X\beta, \Pi^{(2)}) \qquad\qquad\qquad (9.5) $$
Aqui, $X$ é uma matriz cujas colunas são variáveis explicativas alternativas e cujas linhas indicam cada participante. A primeira coluna de $X$ normalmente compreende uma matriz de uns (para indicar o efeito do parâmetro médio sobre os sujeitos). A segunda coluna, em nosso exemplo, pode ser a idade de cada participante. O vetor $\beta$ indica o tamanho do efeito de cada uma das variáveis explicativas em $X$. O primeiro elemento de $\beta$ é então o valor médio da precisão (ou qualquer outro parâmetro), enquanto o segundo é o efeito da idade na precisão. Esse valor é a inclinação da linha em um gráfico de idade (eixo $x$) em relação à precisão prevista (eixo $y$). Pode haver um número arbitrário de colunas de $X$, com um número arbitrário de elementos em $\beta$.

Uma vez ajustado o modelo expresso na equação 9.5, suplementado com a priori para os valores de $\beta$, podemos fazer perguntas sobre o papel das variáveis explicativas. Por exemplo, podemos perguntar se a idade tem efeito sobre a precisão das preferências anteriores comparando a evidência de um modelo no qual o segundo elemento de $\beta$ pode desviar-se de zero com a evidência de um modelo com uma crença precisa de que é zero. Praticamente falando, isso pode ser feito sem múltiplas inversões de modelo por meio do uso da redução do modelo Bayesiano (Friston, Parr e Zeidman 2018).

## Instruções para Análise Baseada em Modelo

Na prática, seguimos os passos descritos abaixo para analisar o comportamento de escolha empírica usando inferência ativa (Schwartenbeck e Friston 2016). Estas se referem às rotinas relevantes disponíveis no pacote SPM12 Matlab.

1. **Colete dados comportamentais**, incluindo as escolhas feitas e a entrada sensorial disponível para a pessoa que faz essa escolha. Além disso, colete dados de interesse para análise de segundo nível entre sujeitos (por exemplo, se o sujeito é um paciente ou um sujeito de controle, informações demográficas relevantes e assim por diante).

2. **Formule um modelo POMDP** como no capítulo 7. Esta deve ser uma função que recebe parâmetros como entradas e saídas de um POMDP totalmente especificado (mas ainda não resolvido).

3. **Especifique uma função de verossimilhança** (ou seja, equação 9.2). Isso nos diz como o modelo deve ser usado para calcular uma probabilidade. Isso normalmente chama um solucionador POMDP (como a rotina spm_MDP_VB_X.m) para simular o comportamento e quantificar a probabilidade de ações observadas.

4. **Especifique crenças prévias** sobre os parâmetros em termos de expectativas e precisões. Muitas vezes, eles serão centrados em zero, com precisões refletindo intervalos plausíveis.

5. **Resolva a probabilidade posterior e a evidência do modelo**. Isso usa um esquema de inferência padrão, como o procedimento variacional de Laplace descrito acima (equação 9.4). A rotina spm_nlsi_Newton.m fará isso automaticamente.

6. **Realizar análise em nível de grupo**. Isso normalmente faz uso do PEB, que trata os parâmetros estimados para cada indivíduo como se fossem gerados por um modelo de segundo nível. Isso nos permite testar hipóteses sobre as causas desses parâmetros. Praticamente, isso pode ser feito usando a rotina spm_dcm_peb.m. As análises alternativas incluem testes estatísticos padrão de associação entre os parâmetros inferidos para cada sujeito e outras medidas específicas do sujeito. Por exemplo, uma análise de variáveis canônicas pode ser usada para avaliar a relação entre as pontuações do questionário e os parâmetros inferidos.

O resumo dessas instruções da Figura 9.2 é baseado no comportamento do rato na tarefa do labirinto em T descrita no capítulo 7. Primeiro, colocamos um rato em um labirinto em T com um estímulo recompensador no braço esquerdo ou direito e uma dica informativa no braço central. Em seguida, registramos a sequência de ações realizadas pelo rato. Este procedimento pode ser repetido em vários ensaios para registrar o comportamento aprendido e pode ser repetido para vários ratos diferentes sob diferentes intervenções (por exemplo, farmacológicas ou optogenéticas).

Uma vez que esses dados comportamentais tenham sido obtidos, precisamos de uma função de verossimilhança que nos permita quantificar a probabilidade do comportamento (para um determinado rato em uma determinada condição) sob configurações de parâmetros específicos. Podemos fazer isso formulando o modelo POMDP que consideramos no capítulo 7. Isso deve ser parametrizado em termos dos parâmetros cuja probabilidade procuramos encontrar. Por exemplo, se quisermos avaliar a precisão associada às preferências, podemos incluir um parâmetro de escala logarítmica que torne a distribuição de preferências mais ou menos intensa.

Tendo estabelecido o modelo generativo (da perspectiva do rato), podemos resolver automaticamente o POMDP usando as equações de atualização de crença no capítulo 4. Isso nos permite calcular a probabilidade dos dados (ou seja, a sequência de braços visitados) condicionados no modelo com o parâmetro de escala (preferências) em um valor específico. A combinação dessa probabilidade com nossa anterior completa a especificação de um modelo generativo para o comportamento (da perspectiva do cientista). Isso pode ser resolvido usando Laplace variacional para encontrar uma distribuição de probabilidade posterior sobre o parâmetro de escala para cada rato

![Figura 9.2 Roteiro do procedimento de inversão de seis etapas para análise de dados baseada em modelo, conforme descrito no texto principal (com referência aos capítulos onde mais detalhes podem ser encontrados). As setas indicam as dependências entre cada parte do processo. O modelo POMDP deve ser definido para que a probabilidade seja avaliada. A inversão do modelo requer dados coletados e a probabilidade e os antecedentes; a análise do PEB não pode ocorrer antes da inversão do modelo para cada sujeito. As etapas 4 e 5 esquematizam a atualização de uma distribuição anterior sobre parâmetros sob um modelo para uma distribuição posterior. A evidência e a posterior de cada modelo podem então ser combinadas usando PEB para encontrar densidades a posteriori (mostradas como expectativas com intervalos confiáveis) para os coeficientes β de um modelo linear que prevê esses parâmetros.](images/Figura_9_2.png)

Na prática, antes de analisar dados reais, podemos querer verificar a validade aparente do modelo POMDP usando-o para gerar dados fictícios – e considerando se eles são qualitativamente plausíveis, dado o problema em questão. Um segundo teste sensato para o modelo é a recuperação de parâmetros. Isso implica gerar dados fictícios sob alguma parametrização (conhecida) para ver se esses parâmetros podem ser recuperados ao inverter o modelo. Isso é útil para verificar se alguns parâmetros (ou suas combinações) são possíveis de serem recuperados (ou seja, identificáveis).

Finalmente, podemos construir uma matriz de projeto para um modelo linear, cada linha representando um fenótipo computacional (por exemplo, uma densidade posterior sobre as preferências de cada sujeito), com colunas representando diferentes atributos desses sujeitos. Esses atributos são variáveis que podem explicar diferenças nas preferências de um rato. Além de uma coluna indicando as preferências médias em relação a todos os ratos, isso incluirá coisas como idade, se uma droga foi administrada e assim por diante. Com este modelo de efeitos entre sujeitos, agora realizamos uma análise PEB para avaliar a contribuição dessas variáveis explicativas para as preferências anteriores.

9.6  Exemplos de modelos generativos

Nesta seção, aproveitamos dois exemplos na literatura que ilustram o uso de modelos generativos contínuos e discretos. Em primeiro lugar, apresentamos brevemente os métodos utilizados por Adams, Aponte et al. (2015) e Adams, Bauer et al. (2016) (doravante nesta seção, Adams et al.) para modelar movimentos oculares de perseguição suave como forma de quantificar os parâmetros de precisão dos modelos generativos de cada sujeito. Um aspecto importante desse projeto foi a coleta simultânea de dados eletrofisiológicos (via magnetoencefalografia) que permitiram aos autores fazer perguntas sobre os substratos neurobiológicos de codificação de precisão ou confiança. Passamos então a uma análise dos movimentos oculares sacádicos de Mirza et al. (2018; doravante nesta seção, Mirza et al.) formulado como um modelo POMDP. Cada um dos experimentos associados está desenhado na figura 9.3. Nossa esperança é que esses exemplos ajudem os leitores a entender como os métodos genéricos descritos acima podem ser usados ​​empiricamente para responder a questões científicas.

Em termos da sequência de etapas descritas na figura 9.2, Adams et al. dados coletados (passo 1) de uma tarefa em que os sujeitos tinham que manter a fixação em um alvo visual em movimento. Os detalhes não são importantes, mas essa tarefa compreendia duas condições.

![Figura 9.3 Dois experimentos descritos na seção 9.5. Os detalhes não são importantes, mas destacam onde a inferência meta-Bayesiana foi explorada com sucesso e os tipos de dados comportamentais aos quais ela pode ser aplicada. Esquerda: Experimento de Adams et al., que mediram movimentos oculares de perseguição suave enquanto os sujeitos seguiam um alvo em movimento. Direita: Experimento de Mirza et al., que mediu movimentos oculares sacádicos durante uma tarefa de exploração. A exibição visual foi dividida em quatro quadrantes, dois dos quais incluíam estímulos (gato e pássaro). Diferentes categorias de cena envolveram diferentes configurações de estímulos, o que significa que os participantes tiveram que selecionar quais quadrantes fovear para obter informações suficientes para categorizar a cena. A tarefa de Adams (esquerda ) gera dados contínuos de rastreamento ocular, enquanto a tarefa de Mirza (direita ) leva a uma sequência de fixações e pode ser discretizada. Estes são os dados comportamentais (u) da etapa 1 na figura 9.2.](images/Figura_9_3.png)

No primeiro, o alvo se movia de acordo com uma senóide previsível. Na segunda, seguiu a mesma trajetória com ruído gaussiano aditivo. Os dados coletados incluíram as trajetórias dos movimentos dos olhos. Os autores formularam um modelo subjetivo (passo 2). Ao contrário do modelo POMDP mostrado na figura 9.2, eles optaram por um modelo contínuo do tipo descrito no capítulo 8. Em resumo, o modelo previu a entrada proprioceptiva e visual dos olhos, onde o ponto de fixação foi considerado atraído para o local alvo . A probabilidade (etapa 3) é construída usando os esquemas de codificação preditiva (ativos) descritos no capítulo 4. Isso quantifica a probabilidade das ações (movimentos oculares) sob um conjunto de parâmetros de precisão de log e o modelo estabelecido na etapa 2. Continuando para a etapa 4, os autores especificaram crenças anteriores como distribuições normais sobre as precisões logarítmicas. Eles inverteram o modelo (passo 5) para encontrar distribuições posteriores sobre esses parâmetros de precisão. A etapa 6 não usou uma análise de PEB, mas usou os dados de neuroimagem coletados simultaneamente com a tarefa comportamental. Os autores usaram modelagem causal dinâmica para estimar o ganho de células piramidais superficiais no córtex visual primário. Isso significa que eles tinham estimativas de precisão e ganho sináptico para cada sujeito. Isso permitiu que os autores realizassem uma análise em nível de grupo, avaliando a correlação entre os parâmetros do modelo subjetivo e seus substratos biológicos. A demonstração dessa correlação fornece um exemplo importante de como as formulações de comportamento da Inferência Ativa nos permitem fazer (e responder) perguntas sobre a relação entre atualização de crenças e neurobiologia.

Em nosso segundo exemplo, Mirza et al. usaram a formulação POMDP de Inferência Ativa para abordar o papel do ganho de informação na condução do comportamento humano. Novamente, descompactamos isso em termos das etapas da Figura 9.2. Mirza et ai. coletaram dados comportamentais (etapa 1) enquanto os sujeitos realizavam uma tarefa de forrageamento visual. Aqui, o objetivo era classificar uma cena visual em um dos vários grupos. Cada elemento da cena só foi revelado quando os sujeitos fixaram esses locais; isso significava que várias fixações eram necessárias para adquirir evidências suficientes para uma determinada categoria de cena. Os dados coletados pelos autores incluíram a sequência de movimentos sacádicos (movimentos rápidos dos olhos) realizada. O modelo (passo 2) utilizado foi um modelo POMDP descrito em Mirza et al. (2016) que previam resultados proprioceptivos, visuais e de feedback discretizados, condicionados ao local de fixação atual e à categoria da cena. As preferências (veja o capítulo 7) foram colocadas sobre o resultado do feedback de modo que o modelo antecipa (e, portanto, prefere) estar correto na categorização. A função de verossimilhança (passo 3) foi obtida resolvendo o modelo usando o esquema descrito no capítulo 4 sob diferentes configurações de parâmetros. Os parâmetros em questão incluíam (entre outros) um parâmetro de escala de log para a precisão da distribuição de preferências. Os autores especificaram distribuições prévias (etapa 4) sobre a escala de log (e outros parâmetros) e inverteram o modelo para cada sujeito (etapa 5). Eles usaram a evidência logarítmica estimada para cada sujeito para avaliar a evidência de modelos que motivaram ou não o comportamento usando o componente epistêmico da energia livre esperada, encontrando maior evidência para aqueles modelos que incluíam affordance epistêmica em todos os sujeitos. Eles então empregaram uma análise PEB (etapa 6) para avaliar as mudanças nas crenças anteriores para os sujeitos ao longo de vários ensaios, encontrando evidências a favor de mudanças nos parâmetros de crença (ou seja, aprendizado ativo). Finalmente, eles usaram uma análise de covariáveis ​​canônicas para avaliar a relação entre combinações lineares das variáveis ​​fenotípicas estimadas para cada sujeito (por exemplo, precisão de preferências) e combinações lineares de medidas de desempenho (por exemplo, porcentagem correta e tempo de reação).

## Modelos de falsa inferência

Os homens em geral são rápidos em acreditar naquilo que desejam que seja verdade. —Júlio César

Dada a relevância desses métodos para campos como a psiquiatria computacional (Friston, Stephan et al. 2014), terminamos com uma visão geral da falsa inferência, que é central para a noção de psicopatologia como falha na atualização de crenças. Um benefício de usar uma estrutura inferencial como a Inferência Ativa é que ela aborda simultaneamente múltiplas dimensões de transtornos psiquiátricos, ligando comportamento desadaptativo (por exemplo, compulsões ou vícios) e nível psicológico (por exemplo, falsas crenças) e fenômenos de nível biológico (por exemplo, anormalidades de neuromoduladores).

Como não podemos fazer justiça aqui à extensa literatura que usa a Inferência Ativa na modelagem de processos de doença, esta seção fornece a mais breve das visões gerais para sugerir uma estrutura para pensar sobre patologias computacionais. Veja a tabela 9.1 para uma amostragem não exaustiva de exemplos ilustrativos, que incluem modelos especificados em tempo discreto e contínuo (com base nos capítulos 7 e 8, respectivamente). Em nossa discussão, apelaremos para a estrutura de modelos do tipo POMDP; os princípios que sustentam a falsa inferência nessas configurações são basicamente os mesmos.

A hipótese subjacente às abordagens inferenciais (como a Inferência Ativa) é que as condições psicopatológicas podem ser conceituadas como distúrbios de inferência. O termo transtorno não implica necessariamente que o mecanismo inferencial seja falho (por exemplo, gera probabilidades posteriores incorretas). Na maioria dos estudos revisados na tabela 9.1, o mecanismo inferencial opera normalmente, mas com base em um modelo generativo falho (ou seja, um modelo generativo dotado de crenças anteriores aberrantes). Isso significa que, em última análise, a patologia é uma consequência de crenças anteriores aberrantes - e pode-se recuperar essas anteriores usando a análise de dados baseada em modelo descrita neste capítulo.

Tabela 9.1 Patologia computacional


| Patologia | Fontes | Notas |
| - | - | - |
|Dependência, impulsividade e compulsividade | FitzGerald, Schwartenbeck et al. 2015 Schwartenbeck, FitzGerald, Mathys, Dolan, Wurst et al. 2015 Mirza et al. 2019 Fradkin et al. 2020 | O vício é um exemplo importante de comportamento que parece aberrante, mas pode ser enquadrado como uma inferência ótima sob o tipo certo de modelo generativo. Trabalho de Schwartenbeck et al. ilustrou isso usando uma tarefa de oferta limitada em que os participantes estão mais ou menos confiantes sobre se receberão uma recompensa por esperar. A baixa confiança leva a um comportamento compulsivo do tipo associado ao vício. Trabalhos subsequentes sobre este tema examinam as crenças anteriores associadas a comportamentos mais ou menos impulsivos, usando o paradigma de deixar manchas, e examinam o papel da precisão anterior atenuada no transtorno obsessivo-compulsivo.|
|Delírios|Brown et al. 2013 Friston, Parr et al. 2020|Os delírios, caracterizados por crenças falsas e fixas, são simplesmente articulados na Inferência Ativa como distribuições de probabilidade posteriores precisas na ausência de evidências de suporte. Se suficientemente precisos, eles serão fixados mesmo diante de evidências contraditórias (posteriores). Os mecanismos subjacentes a cada delírio podem ser diferentes. Por exemplo, falhas de atenuação sensorial podem ser centrais para delírios de ação. Trabalhos recentes fornecem um exemplo de um delírio compartilhado (folie à deux), que depende de dois agentes – sem nenhuma informação – chegarem a um consenso confiante sobre o estado do mundo|
|Alucinações|Adams, Stephan et ai. 2013 Benrimoh et al. 2018 Parr, Benrimoh et al. 2018 Corlett et al. 2019|Essas simulações se baseiam em desequilíbrios entre precisões anteriores e de probabilidade. Superinterpretação de dados sensoriais espúrios devido a uma falha na atenuação da precisão da verossimilhança, ou uma falha na correção de crenças anteriores devido à atenuação excessiva, cada uma oferece mecanismos para falsa inferência perceptiva.|

